We present a study into the use of smell for searching digital photo collections.
Many people now have large photo libraries on their computers and effective search tools are needed.
Smell has a strong link to memory and emotion so may be a good way to cue recall when searching.
Our study compared text and smell based tagging.
For the first stage we generated a set of smell and tag names from user descriptions of photos.
Participants then used these to tag photos, returning two weeks later to answer questions on their photos.
Results showed that participants could tag effectively with text labels, as this is a common and familiar task.
Performance with smells was lower but participants performed significantly above chance, with some participants using smells well.
This suggests that smell has potential.
Results also showed that some smells were consistently identified and useful, but some were not and highlighted issues with smell delivery devices.
We also discuss some practical issues of using smell for interaction.
Our aim in this work is to explore how smell might be used in a real application, if it is effective, and to discover the issues and practical problems that must be dealt with when designing smell-based interactions.
Our application focus is on searching digital photographs.
Many people now have very large digital photograph collections with thousands of images.
These do not always provide the easiest ways to find photographs and users may not always use the tagging and searching features as they are too complex .
Our aim is to examine the use of smell and its link to memory and recall to aid photo searching by allowing users to tag photos with particular smells and then use those smells to help recall the photos later.
The whole area of smell is much less well understood than vision or audition.
We have no detailed understanding of how we perceive smell.
We cannot easily build up complex smells from simpler components.
This makes designing interfaces that use them more difficult, requiring rigorous evaluation to ensure usability.
As Kaye suggests in his thorough review of the whole topic , there are no good classification or description schemes for smells.
There are specific ones for the perfume, wine and beer industries, for example, but these do not apply to the wide range of smells that we might want to use in a user interface.
This makes it difficult to describe what is being used or to know what a smell you might want to use actually smells like.
Anosmia  also has a big impact.
Large groups of the population are unable to smell particular smells with reasons for this only now being understood.
Care must be taken to avoid these and evaluation is needed to ensure people can smell all of the smells you choose to use.
One of the key features of smell is its close link with memory.
You may smell something and it takes you right back to the time and place that you smelled it before.
Neuroscience research has shown strong links between smell and working memory, attention, reaction times, mood and emo-
Smell output is an under-explored presentation technique in human-computer interaction.
Our sense of smell is very rich, but not often used.
It is a powerful alerting mechanism and has strong links to both emotion and memory.
These make it an interesting area of study for future user interfaces.
One reason for the lack of research is that there are few effective computer controlled smell devices which can emit a range of odours.
Commercial devices are beginning to appear, but are not common.
Many companies have proposed systems, but few have come to market.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
If we can tap into these links then there is potential to use smell as an aid to searching or other interactions.
Cann and Ross  report that there is a strong link between smell and memory "One experience related to the influence of odors that seems nearly universal, at least within the folklore surrounding odors, is the occurrence of vivid memories, often involving events from the distant past, precipitated by exposure to an odor associated with the original experience".
They report a study by Laird in which 80% of men and 90% of women reported multiple odourrevived memories.
The memories were often emotionally charged, rather than neutral.
Cann and Ross say "... it is clear that people can respond to olfactory cues as memory devices, describing events associated with odors, and that they believe odors often lead to the recall of past events".
The kinds of memories evoked are often complex images or experiences rather than objects.
This suggests that there is a strong response to smells that we could make use of for photo recall.
It would seem essential to have a range of smells, both good and bad, to suit a wide emotional range.
Aggleton and Waskett  found a similar powerful effect with smells used in the Jorvik Viking Museum in York, UK with visitors recalling information about the museum significantly better in the presence of the Jorvik smells over six years later .
Cann and Ross  studied the use of odour to cue recognition of images.
Participants were exposed to one of two odours when learning images and then asked to recognise them with and without the same odours present.
They used a pleasant  or unpleasant  smell during the learning phase.
Results showed that recognition of the images 48 hours later was significantly better when the same smell was present as the learning phase.
The idea of such state-dependent recall is a useful one for our application as it gives us two choices of smells  and two opportunities for associating a smell with a photo.
Using representational smells that embody the original photo means that we can help people recall that original event.
However, learning will also occur at the tagging stage where people associate smells with photos.
Smells in this case could be either representational or more abstract .
Both types, when smelled again, would help recall of photos.
This gives a real application the possibility of using a larger range of smells as we are just not tied to ones representing the actual contents of the photos, although the representational ones may be the most effective as they would be reinforced at the tagging stage, giving users more chance to associate them with the photo.
Cain  showed that certain smells appear to be more identifiable than others: coffee, peanut butter, Vicks, and chocolate were shown to be the most easy to identify, with cough syrup, cleaning fluid, and lighter fluid being the hardest.
There is little practical work to help the interface designer choose smells.
For our purposes we wanted more `natural' smells to represent the real-world things that people might have in their photographs.
There are few studies into the perception of intensity of odours.
Engen and Pfaffman  showed that people could recognise three levels of the smells they used.
This was less important for our study as the technology we used to deliver our smells had no control over intensity.
With more sophisticated output devices one could perhaps use intensity to give some indication of the importance of the thing tagged, but this would be hard to control.
One important issue is smell delivery.
As discussed, there is no simple way to mix complex smells from atomic ones, therefore most systems just use pre-packaged smells.
The quality of the smells is often very variable; some smell very little like the thing they are supposed to, are quite synthetic smelling and hard to give a name to.
This is a problem for interface designers as smells are required that people can identify.
Kaye offers some help as he reports that "of personal memories evoked by an odor, 32% were evoked without an odor name".
This may mean that lower quality smells may still elicit the memories we need, even if they are not good enough for people to be able to name.
One key issue is that smells may diffuse across a room and thus be smelled by many people.
This may be beneficial for an ambient display, but problematic for more specific ones.
This fires a focused vortex of air so that others nearby do not smell anything.
Their initial prototype shows promise but is not commercially available.
There are several examples of other devices that have been proposed but have never made it to market .
For situations where there is just one user in an office or the smell can be displayed to a larger group of people things are easier.
Simple fans can blow across the surface of scented material to spread it across a room, or the smell may just diffuse naturally.
For our study we used smell cubes from Dale Air, UK .
These are 50mm3 green plastic cubes that contain an oil-based aroma on cotton wool.
When the plastic tape covering the holes on top is removed, the smell diffuses out into the surrounding air.
These are very cheap and are available in a wide range of different odours.
There is little work in the area of smell and HCI.
It has been used for ambient displays , but most uses have focused on notifications.
Kaye has done some of the first work .
He has proposed and built several systems that have investigated the use of olfaction for providing ambient notification information.
A spice rack with sensors attached to each spice jar was linked to a set of spray guns at a remote location.
These were filled with essential oils which smelled like the spices in the spice rack.
When a spice jar was removed from the rack, the corresponding essential oil was released at the remote location, allowing users there to be aware of activity at the location of the spice rack.
Although Kaye did not perform a detailed evaluation, he noted that when the essential oils combined they produced an unpleasant smell.
This further highlights that care must be taken when using multiple scents.
Kaye's second system, Dollars & Scents, presented information about the current value of the NASDAQ stock exchange using two scents.
In this system a device was constructed using solenoids and perfume bottles that would emit a mint smell if the market was rising, or lemon if it was falling.
Kaye reports no particular reason for the choice of these two scents other than they "leverage linguistic idioms as mnemonics".
He also noted that the original system was to have used rose as the scent for a rising market, but was changed since one of the residents at MIT Media Lab  was allergic to roses.
Although Kaye reports no specific evaluation of Dollars & Scents, there was a generally positive response and the smells quickly were incorporated into the culture of the environment.
For example people passing and saying "Smelling of mint today".
Scent Reminder used the same technology as Dollars & Scents but was integrated with Microsoft Outlook.
Appointments could be set and scents released as reminders.
Unfortunately, as with Kaye's other systems.
However, his applications do show the potential that smell has to be a useful addition to computer interfaces.
For their smells they chose glue and soy sauce.
No justification is given for the smells used.
Their results were inconclusive; individual differences masked the effects of particular modalities.
People's backgrounds made them respond very differently to the different modalities.
In a similar study Bodnar et al.
They used extract of cloves and artificial eucalyptus smells.
These were chosen from an initial set of 10 in a pilot study.
They could be easily differentiated at intervals of 30 seconds.
Their results showed that olfactory cues were less effective than audio or visual ones, causing participants to reduce the number of questions completed during the study.
Some interesting issues arose from participants' comments.
Many felt that the smells used were too similar and thus easy to confuse.
Smells lingering in the air and confusing participants was also a problem.
An aromatherapist had no problem with the smell cues, whereas other participants said lack of experience with smell cues made the task difficult.
These are serious issues for a photo searching application as users will have a wide range of backgrounds.
One potential solution is to provide a wide range of different smells so that users can choose ones that suit them best.
Smell has been proposed in several VR systems to improve fidelity .
For example Tominaga et al.
They suggest two types of smells: scent of the environment and scent of the object.
The environmental odours provide the smell of a place, to help the users feel like they are in a particular environment.
The objects' odours give information about a particular object in the environment.
Results showed very positive results with 5 aromas.
People responded more positively about being in particular locations  when smells were present.
Tillotson from the Royal College of Art in the UK has investigated the use of smell for fashion, health and wellbeing, using smell emitted from clothing to create a `scent bubble' around the wearer that "enhances the visual message of fashion with medical, sensory & psychological wellbeing for the wearer" .
Over recent years there has been a rapid growth in the use of digital cameras and many people have large numbers of photos on home computers which they need to search.
There have been few published studies that have investigated the management of personal photos and people's cataloguing, searching and browsing habits.
Rodden and Wood  undertook one of the most detailed studies to date using their ShoeBox digital photo cataloguing system with 13 users.
They found a range of organizing strategies, from users putting images into different folders, to all images being in one large folder.
Some users spent more time organising their photos, others spent very little time.
Those who spent more time often changed the name of the folder to help them remember what was in it.
Eight of their participants added extra text or spoken audio annotations to help searching.
The spoken annotations were generally of people and places.
One issue with the spoken annotations was the problem with speech recognition errors that could then make searching a problem.
The methods for adding annotations or meta tags to facilitate searching need to be simple and effective otherwise people may not use them.
Rodden and Wood found users made three main types of queries: * * * The set of photos from a particular event, e.g.
As Rodden and Wood say "...queries might start to seem more important as a collection grows, and the photos get older and less familiar".
Participants in our study brought their existing photos with them to avoid this problem.
We also wanted to make our tagging process as simple as possible, to avoid complexity that might put people off from using smell.
Shneiderman's PhotoFinder  looked at simpler and more effective ways to tag photos, particularly people in photos.
These were very low effort, simply requiring a user to drag a label onto a photo.
These techniques are now common in commercial tools.
We aimed to build on the simplicity of this approach in our photo tagging tool to make adding tags as simple as possible.
Bedersen's PhotoMesa  provides sophisticated layout and visualisation mechanisms to help users find images from large sets of thumbnails.
But with a large number of photos this can still be a problem.
Alternative mechanisms to help cut down the number of thumbnails that needed to be presented would ease the problem.
We attempted to build on these previous systems, but use smell as a tool to tag and then retrieve photos.
We also wanted to conduct an initial user study as many systems in this area have had little user evaluation.
We developed a simple olfactory photo browsing and searching tool, Olfoto, based on the freeware Ekspos photo viewer .
This provides basic thumbnail/photo viewing capabilities and, as it is written in Java, we could easily add our own code to allow smell and text tagging and searching .
It has a standard scrolling thumbnail pane occupying most of the screen, with a larger version of the chosen thumbnail shown top left in the photo viewing pane.
Below this is the tagging pane and below that the search pane.
To present the odours we used smell cubes from Dale Air.
An RFID disc tag was attached to the base of each of the cubes .
We used Phidgets for this  as they provide a very simple way of using RFID in Java.
In tagging mode, users add one or more tags to a photo by moving the appropriate smell cube over the RFID reader.
Multiple selections could be made in the thumbnail window so that the same smell could be added to multiple photos.
Multiple smell tags could by added to a photo by moving more cubes over the reader.
To remove a tag the cube was moved over the reader again.
We tried to create a simple, tangible interaction that was easy to do, to avoid the problems highlighted by Rodden and Wood.
In search mode, the user moved a cube over the reader and all of the photos with that smell were displayed in the thumbnail pane.
Multiple tags could be used for searching by passing the cubes of interest over the reader.
Text tagging and searching were done in a similar way; a user could choose one or more of the text tags from a drop down list and apply them to the selected photo.
For searching the user chose the text tags from a drop down list to display the thumbnails with that tag attached.
Our evaluation was done in three stages: * * * Categorisation Study: Participants generate a list of smell and text tags to be used in the main studies; Tagging Study: Users tag photos with the smell and text tags from the first study; Recall Study: Users return after two weeks to search for photos with text and smell tags that they used in the second study.
The aim of the studies was to find out if smell could play a role in photo searching, how it compared to text tagging, if users would consider using it, and for us to understand how to use smell in a practical setting.
This was our first study in this area and we needed to understand how to manage the practicalities of smell-based interaction.
Our participants were all undergraduates, PhD students or members of staff in our Department.
This was intentionally not a wide range.
We needed to keep the likely range of tags small enough that we could cover them with a small selection of different smells to make the study feasible.
In this phase we wanted to generate a list of smell and text labels that could be used to tag photos for the main two studies.
We used three participants, plus the three authors of the paper.
Each was asked to bring along 300-500 photos from their collection.
The experimenter then went through the photos asking each participant what smells labels he/she would use to describe the images; the process was then repeated for text labels.
They were free to use whatever words came to mind and these could be different for the smell and text labels.
We then grouped these words to come up with an overall set of smell and text categories.
Table 1 shows the category names we chose based on the words generated by the participants for six of the smell categories.
We came up with 16 smell categories .
We wanted to keep the number of categories small enough to make the rest of the study feasible.
There were 12 text categories , again avoiding single word categories.
These are by no means a complete classification of general photo searching keywords .
We used a focused group of users to make a set of tags that would likely be useful for a similar group of main test participants.
A major problem was taking the smell categories and matching them to a smell produced by Dale Air.
The company produces around 200 different odours, and without smelling them, it was hard to know which were the ones most useful to us.
This is an example of the problem that Kaye identified above - there is no standard classification scheme for smell.
A floral smell from one company may be completely different to that of another .
In addition, some of the names are not very informative ; it is difficult to know what the smell is like and if it matched the category we had, but we did our best.
The smells chosen from the Dale Air website to match our categories were: Brewery, Alpine, Bread, Ozone, Sea Shore, Smoke, Farmyard, Dusty, Grass, Floral, Sea Breeze, Sweaty Feet, Riverbank, Unisex Perfume, Machine Oil, Dark Chocolate.
The next stage of the work involved participants tagging photographs with the smell and text labels generated in the previous stage.
We used 12 new participants who were paid 10 if they completed both this and the following Recall Study.
There were four women and eight men, ages ranging from 20-45, six were from the UK, two were Indian, one each were from China, Mexico, Greece and South Africa.
All were asked to bring along around 500 digital photos from their collections.
This gave us a wide enough range of material for them to be able to tag and also to create a large enough set for the Recall Study.
We asked what software they used to manage their photo collections.
Six did nothing, just putting them into a folder on their PC, two used the online photo service Fickr , two used iPhoto and one used the Canon software that came with his camera.
Five did nothing, four renamed files with suitable labels, one Flickr user and one iPhoto user used text annotations and one iPhoto user created albums, used text annotations, created titles and keywords for his photos.
This is generally in line with the results of Rodden and Wood .
Participants either did the text tagging first or worked through the smell cubes and assigned a name to each one and then did the smell tagging .
Each tagging phase took around 20 minutes.
Finally, we interviewed the participants about the process of tagging and general issues raised.
The whole process took one hour.
When tagging with the smells participants were free to pick up any cube they desired and smell it by lifting the tape.
The cubes were not labelled in any way.
The cubes were on the table next to the PC running our software and they could smell  as many different cubes as they wanted.
If they were happy with a chosen smell they could move it over the RFID tag reader to tag the photo.
It means that a set of easily differentiable smells could be provided with the system.
However, a more important issue is how consistently people can name the smells over time, which was investigated in the Recall Study below.
Further work is needed to build up a set of good smells.
The only way this can be done is empirically because, as Kaye reports, there is very little research to help choose a wide range of uniquely identifiable smells.
Participants completed NASA TLX subjective workload scales after both conditions.
These give subjective data on how demanding people feel a task to be and are a good complement to quantitative measures of error rates, giving a more complete picture of usability.
We added a question on fatigue  and on which method was preferred .
Figure 3 shows the results.
We then performed a detailed analysis of each of the individual factors.
Temporal demand, Effort expended, Frustration and Preference showed no effect.
These results show that it was easier for people to tag photos with text labels than with the smells.
Participants found the task mentally demanding as they were not used to using smells in this way and it required some concentration.
This was reflected in the physical demand, fatigue and the low level of perceived performance.
It was interesting to note that there was no effect for frustration or preference given the above results.
Table 2 shows the names participants gave to 10 of the 16 smells.
The first five were less well identified; the last five were much more consistently named.
One problem was that some of the smells were very synthetic smelling.
Floral, for example, had a very soapy, bathroom cleaning product smell and many participants identified it as that rather than flowers.
As suggested by Cain  chocolate was well recognised.
His list also included Vicks .
It is interesting to note that four of the participants identified Riverbank as having that smell.
Again this was due to its very synthetic nature.
These results show that some smells could work really well, some do not smell like their name but are consistently identified by participants, and some are not consistently identified at all.
Smell/text  photo: Participants were shown 4 photos and given one smell or text tag.
They had to identify which photo had that tag.
Only one photo in the set of four had the tag and the three distracters were chosen randomly from the rest of their photo collection.
They had to do this 15 times with different photos.
We measured the number of correctly identified photos.
Photo  smell/text: Participants were given four smell/ text tags and one photo.
They had to identify which tag was attached to the photo.
This was done 15 times.
We measured the number of correctly identified tags.
Search: Participants then performed a more general search task.
They were given three key features of a photo and then asked to find it in their photo catalogue using smell or text tags.
We chose the photos at random and picked the key features ourselves.
For example, we might ask for photo with a building, people and palm trees, or an arch, angels and a roof.
They did this five times.
In the Smell Condition, the cubes were on the table next to the PC and participants were free to smell them as they liked.
If they were happy with a chosen smell they could move it over the RFID tag reader to search with it.
We measured the number of tags that they tried before finding the right photo.
The fewer tags used would suggest that that type of tag helped them find the particular photo better.
It was possible for a number of photos to match the three criteria we gave the participants.
If the photo identified matched the criteria, they were given a mark.
One of the most raised issues in the informal comments from participants was that the smells did not always match their photos.
Many wanted to choose their own smells, which was not practical for this study.
Some also said that certain of the smells were hard to tell apart .
This was a problem as we could not smell the cubes before we bought them.
Participants also wanted to be able to create their own text tags .
Two weeks after the Tagging Study participants returned to perform the second part of the task to see if smell helped them recall photos, and how this compared to the use of text labels.
Only six of the original twelve were able to return for this second phase due to other commitments.
Participants performed the two conditions in the same order as the previous study.
The first step got them to go through the smell cubes again and re-label them.
This allowed us to get an idea of the consistency of their naming.
They then answered three types of questions in both conditions.
The range of questions tried to gauge their ability to use smell and text labels in a range of different ways and were motivated by the queries identified by Rodden and Wood .
These results show that there is some similarity in the judgements made by the participants, but there is less consensus in this second phase .
It is not clear why they would be less good in this second phase, except if the smells were beginning to fade.
By the time the second study took place, the cubes had been open for a month and a half.
Some of the strong initial smells had definitely mellowed and changed.
This makes it hard to assess our participants' abilities to reidentify the smells as they may not have been the same.
For future work it would be worth using a set of new cubes for the second study to see if the effect disappeared.
This also had an impact on their answers to the questions we set in this phase.
If the smells were different then people were likely to do worse as the correct memories would not be evoked.
There was no variation in the text tags, so performance should be better.
The results for question type 3  showed no significant difference between smell and text tagging.
Participants again showed marked individual differences, with some participants using many more tags in the Smell Condition, and others using the same number as for Text.
We need a study with a larger number of participants to understand these effects fully.
Number of correct answers for question type 1 in the Recall Study.
Formal statistical analysis is limited due to the small number of participants.
Looking at the data in Figure 4 a trend towards text tagging can be seen, with participant 4 behaving somewhat differently to the rest.
This suggests we too were seeing the marked individual differences that Arroyo et al.
However, participants were right using the smells 52% of the time, chance would be 25%.
This shows that they were able to use the smell tags.
With new cubes and better smells we might improve upon this performance.
The results for question type 2 showed the text tags being significantly better than the smell ones .
Participants were very good at matching a text label to a photo.
Performance in the Smell Condition was at the same level as for question type 1, with participants right 53% of the time.
Results are shown in Figure 5.
The results of the subjective measures are shown in Figure 7.
Participant 4 failed to complete one part of the subjective scales, so was removed from the analysis.
However, looking at the figure there seems to be a clear trend in favour of the Text Condition  and the pattern of the data is very similar to that of the Tagging Study, with perhaps a larger difference between the perceived performance with smell and text tagging.
With a larger number of participants it is likely the differences would be significant.
We tried to allow users to make a natural mapping between photo and tag.
This is difficult as a large number of different smells would be required.
An alternative would be to use an abstract or semi-abstract mapping.
One might tag photos of the beach with chocolate, which has no relevance to the scene, but is easily identified.
This would remove the emotional link but might still help recall, as Cann and Ross showed .
We found this behaviour as one participant informally reported that he was using `nice' smells to tag `nice' photos and `bad' smells for `bad' photos when no suitable representational one was available.
For a further study it would be useful to try and get participants to describe the types of photos a smell brings to mind in the Recall Study, rather than just doing searching with the tags.
This would give some more general, subjective information about the effect of the smells.
Much work needs to go into the choice of smells.
As Kaye suggests , there is little practical research of use to interaction designers that can help in the choice.
Some of the smells we ordered smelled quite similar , others smelled little like we imagined when we ordered them.
There are some  that really worked well; we need further research to identify more of this type.
From informal comments many participants felt that the whole interaction with the smells was good and easy to use.
However, two people said that they felt they were trying to remember the smells, rather than being `taken back' to the photos they were looking for.
This may have been because the smells changed slightly between the two stages of the Study.
Differentiability of the smells was also mentioned again - people again found it difficult to tell some apart, so this affected their searching.
In general, participants were able to use the smells to identify pictures.
Participants were performing at greater than chance levels with the smells.
They were less effective than text tags, but this is perhaps not surprising.
Using smells in this way is an unusual thing for people to do, whereas text labels are much more familiar.
With greater usage performance is likely to improve.
An added difficulty was that some of the smells may have changed since the participants learned them, reducing their power for recall.
Even with these problems, participants were able to use the smells.
Is smell tagging really practical?
One key issue would be getting hold of the smells you wanted to tag with.
We provided a small set to our group of users and these did not cover all the things they wanted to tag.
There would need to be some simple way to buy appropriate smells, perhaps in cartridges like printer ink, dispensed by machines located by digital photo kiosks .
Lower odour intensity output devices are also needed, suitable for a single user type environment.
Dale Air recently released their Vortex USB device  that uses much less powerful smell discs.
They do not saturate the environment in the same way as the cubes do, so are much more suitable for single user environments.
We are using these for our next set of studies.
There turned out to be many practical issues to deal with when running our study.
Some have been mentioned before and some occurred because of our design.
We took care to make sure the room was well ventilated so that smells did not linger.
Some participants did complain that the smells got mixed with each other.
Due to our task users needed to switch between smells frequently.
Even if the top was only off a cube for a short while it did get out into the room.
The use of a fan might alleviate this problem, as would the use of less powerful smell discs.
When we first received the sixteen cubes the smells were very powerful and created a nasty mixture .
We put the cubes in zip-loc bags and then in a sealed plastic box to stop the smells escaping.
In the future we may leave new cubes open outside for a few days to let them `cool off' before using them so that we can get an even level of intensity for our studies.
After a week or so, the smells had evened out so that we could store them with no problems.
Some of the smells were of very different intensity levels.
Sweaty Feet was initially very strong, masking the other smells in early prototypes.
Smells rapidly diffuse across wide areas and can reach people for whom they were not intended.
Keeping them under control is difficult.
This affects the uses to which they can be put.
The cubes we were using were not designed for single users, they were meant for larger rooms, shops or museum exhibits so had to be quite intense.
For a real photo searching application much less powerful smells would be more useful.
After some pilot studies we took care to wipe the sides of the cubes.
Pilot users had complained of getting smells on their fingers so that one smell then interfered with the next.
At the start of each day we wiped the cubes so that there was no residue on them.
Related to the above is the important issue of consistency of the smell delivery device.
Our smell cubes were perhaps starting to run out by the second study which meant that the smells had changed .
A computer-controlled device that kept the smells sealed and only opened them when needed might solve this problem.
Two participants said their sense of smell was impaired .
One had hay fever and one a cold.
This is a particular issue for our olfactory sense as it is more susceptible to day-to-day variation than our sight or hearing.
A good screening program for experimental participants might avoid this problem, but it would not deal with the issues of using a smell-based interface as part of a normal interaction with a computer.
As with all such issues, a good multimodal system that used several different senses would be best.
Users could then pick the interaction techniques most suitable; if they had a cold they could use text or audio searches instead that day.
We will investigate the use of smell in a multimodal context in our next study.
The studies presented here have shown that smell can be used to aid photo recall.
Participants performed significantly better than chance when using the smells, and several participants used the same number of smell and text tags to find the photos for which they were searching.
Text tagging did work better overall, but the results were very positive for the first smell-based study of this type.
Many issues remain about the use of smell in HCI.
Choosing an appropriate set of smells is difficult and more research needs to be done into creating an easily differentiable set.
Individual differences also seem to play a large role; some people are better at using smells than others.
A bigger study is needed to investigate this further.
If some of these issues can be addressed, the research presented here shows that smell has a valuable role alongside the other senses in future user interfaces.
