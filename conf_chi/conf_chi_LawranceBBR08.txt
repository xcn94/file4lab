In recent years, the software engineering community has begun to study program navigation and tools to support it.
Some of these navigation tools are very useful, but they lack a theoretical basis that could reduce the need for ad hoc tool building approaches by explaining what is fundamentally necessary in such tools.
In this paper, we present PFIS , a model and algorithm of programmer navigation during software maintenance.
We also describe an experimental study of expert programmers debugging real bugs described in real bug reports for a real Java application.
We found that PFIS' performance was close to aggregated human decisions as to where to navigate, and was significantly better than individual programmers' decisions.
The research falls mainly into two categories: development of new tools without a theoretical basis, and derivation of new descriptive theories ground-up from data.
However, we believe that an existing theory, namely information foraging theory , can improve upon both of these approaches.
In particular, we propose that information foraging theory can provide the foundations needed for tool development.
This theory is more attractive than building new theories particular to navigation, because it has been empirically shown to be a good predictive theory in its own domain .
Thus, it has mature roots, and in that domain it has become widely accepted and established as a useful basis for tool development.
We therefore decided to investigate how information foraging theory might model programmers' navigation behavior in debugging and maintenance.
In this paper, we present PFIS , a model and accompanying algorithm to predict programmers' dynamic navigation behavior during program maintenance tasks.
Information foraging theory uses the concept of scent to determine where someone will go when searching for information related to their goal.
We believe that programmers may be information foragers when debugging, because research has shown that when debugging, programmers create hypotheses and then search for information to verify  these hypotheses.
Furthermore, we conjecture that such hypotheses are linguistically related to the words in the bug reports.
According to these assumptions, the bug report defines the programmer's goal and the scent they are seeking.
As with information foraging models that have been used to model web behavior, the PFIS model takes into account both the source code's topology  and its "scent."
Using these concepts, PFIS predicts that programmers will visit the source code with the highest scent in relation to the bug report.
The PFIS algorithm builds on the WUFIS  algorithm , adapting and extending the approach used in WUFIS to model programmer navigation during software maintenance.
Is navigating code like navigating the web?
Do programmers navigate source code in search of a bug in the same way that people navigate the web in search of particular information?
Can the behavior of programmers navigating source code be described using the same theories and models that have been used to describe web navigation?
In software maintenance, code navigation is a central task.
The importance of navigation to programming tasks such as maintenance and debugging is beginning to become recognized .
One study showed that programmers spend 35% of their on-line time navigating code .
Several research efforts, mostly in the software engineering com-
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
PFIS can model the places to which programmers navigate to during two software maintenance tasks.
We compare the PFIS results to competing possible predictors of where these programmers would navigate: a model based on word "scent" without making use of topology, a model based on topology without scent, and other programmers' navigation patterns both pairwise and aggregated.
We finally consider elements of program navigation not modeled by our information foraging model, and their relationships with information foraging.
The usability of a site for a particular query is determined by running WUFIS to obtain the probable number of users that would reach each page by following cues that best match the query.
This work in this paper also builds upon the work of .
Programmers debugging code may be information foragers in that they form hypotheses and then hunt for information to verify these hypotheses.
A study of programmers attempting to fix bugs found an interword' correlation between the bug report and the set of classes visited by the programmers .
That work presented evidence based on a static view of these interword' correlations, but did not present a model per se.
This paper, in contrast, contributes a model of information foraging, together with an algorithm, that takes into account programmers' dynamic program navigation behavior.
Information foraging theory emerged from the PARC labs in the mid-90's, led by Pirolli and Card .
Inspired by appeals in the psychological literature for ecological accounts of contextually dependent human behaviors, information foraging theory offered a new perspective for those attempting to develop theoretical accounts of HCI that could be applied to tool design.
Ecological theories contrast with information processing theories such as GOMS, that at the time did not account for effects of context.
Information foraging theory is based on optimal foraging theory, a theory of how predators and prey behave in the wild.
In the domain of information technology, the predator is the person in need of information and the prey is the information itself.
Using concepts such as "patch," "diet" and "scent," information foraging theory describes the most likely pages  a web-site user will visit in pursuit of their information need , by clicking links containing words that are a close match to  their information need.
The scent of information comes from the linguistic relationships between words expressing an information need and words contained in links to web pages.
The predator/prey model, when translated to the information technology domain, has been shown to mathematically model which web pages human information foragers select on the web , and therefore has become useful as a practical tool for web site design and evaluation .
The work described in this paper builds on the WUFIS algorithm  , an empirically validated algorithm approximating information foraging theory as defined by Pirolli et al's SNIF-ACT model .
The advantage of WUFIS over SNIF-ACT is that WUFIS can be readily applied in new contexts, whereas SNIF-ACT is a fully functioning cognitive model, and must be customized for each information foraging context being studied.
The WUFIS algorithm encodes link quality as a function of its match to the users' information need.
Someone is more likely to select the link on a page that appears to have the highest probability of eventually leading them to the page best matching their information need.
Flow refers to users surfing through the web site moving from page to page by clicking on the highest scent links on the page, and is modeled using spreading activation over the link topology.
Scent is computed as a function of the term frequency of words in a query and the term fre-
In recent years, the software engineering community has begun to study program navigation and tools to support it.
For example, Robillard et al.
Their theory focuses on the importance of methodical investigation; it does not suggest information foraging principles, but it is consistent with them.
However, as they point out, elements of their experimental design may have encouraged methodical investigation.
Fundamental differences from our work are that our use of theory focuses on the potential cause of methodical investigation  rather than on its presence and effect, our study does not create new theories but rather investigates the applicability of existing theory, and our theory is intended to be predictive rather than simply descriptive.
Their surprising result made clear the importance of trying to understand how programmers go about navigating, and how to help them save time while doing so.
This finding led to the development of a descriptive model of program understanding , which proposes that the cues  in an environment are central to searching, relating, and navigating code in software maintenance and debugging.
Although they did not investigate scent per se, their model is philosophically similar to information foraging theory.
Their work turned up two major problems: developers needed to scan a lot of the source code to find the important pieces , and they tended to get lost while exploring.
These results inspired the idea to combine collaborative filtering and computational "wear"  from users' interaction histories into a concept they call "wear-based filtering".
A number of software engineering tools have begun to be developed that are also based on concepts of "togetherness" as defined by developer navigation/editing actions.
A system that is particularly pertinent is Hipikat  which remembers paths traversed by earlier members of a team, and uses hand-crafted textual similarity to support search for code-related artifacts.
Evaluations showed that newcomers using Hipikat achieve results comparable in quality and correctness to those of more experienced team members.
These tools and analyses have not been grounded in theory, but their empirical success shows that they are useful.
Our premise is that the information foraging model may explain why they are useful, and may usefully guide the development of future program maintenance and debugging tools.
Therefore, packages link to member classes, classes link to their fields and methods, methods link to the methods they invoke, and variables link to their type.
Due to the many one-click links, program navigation has two fundamental differences from web page navigation.
First, what counts as a link is well-defined in a web site, whereas every identifier in a program may be  associated with a link to some definition or use.
Second, source code has a much denser "link" topology than web pages, so there are many more ways to navigate to the same place.
Such differences meant that, to extend the ideas of WUFIS to program navigation required defining the notion of links in source code, finding ways to process them, and defining the terms in and near a link that should be used and how to compute the scent of a link.
Another difference between PFIS and WUFIS is that PFIS is necessarily more "real world" than WUFIS.
Some assumptions/controls that simplify the problem domain were made when developing WUFIS into the Bloodhound usability service , but they are not viable for the domain of program navigation.
This implementation is an important point of comparison for the work presented here, because it was used in a study validating the predictions made by the WUFIS algorithm.
These simplifying assumptions/controls were  to disallow the use of search, which is not a reasonable limitation to place on a programmer attempting to maintain software ;  to have only one web page open at a time ;  to give pages that did not have any links in them a link back to the starting page, which we could not do since we wanted to use PFIS on real-world software without modifying it; and  to remove the scent for links on the desired target document.
This latter simplification was based on the assumption that people stopped searching when they reached the target and hence would not select any of the links on a target page.
We cannot assume a target destination, because there is often no one "correct" target for a code maintenance task.
PFIS is summarized in Figure 1.
We explain how each step is accomplished next.
Central to WUFIS is a description of the link topology of the web site, describing each link in terms of which page it is on, and which page it points to.
For example, Figure 2 shows on the left four nodes, and the links between them.
In WUFIS, the nodes are web pages; in PFIS the nodes are anything that is the destination of a link, e.g., method definitions, method invocations, variable definitions, etc.
The link topology is described by the matrix on the right.
To examine whether information foraging theory can predict the classes and methods programmers will visit, and the paths they will take as they navigate through code in search of relevant places to fix bugs, we created PFIS.
PFIS is based upon the web user flow by information scent  algorithm , which combines information retrieval techniques with spreading activation.
As WUFIS does for web path following, PFIS calculates the probability that a programmer will follow a particular "link" from one class or method in the source code to another, given a specific information need.
Consider the notion of links in the domain of program navigation.
According to information foraging theory, the path an information forager will take is determined by the scent of proximal cues of a particular link in relation to their information need.
In WUFIS, hyperlinks serve as the way information foragers navigate between pages, and thus the words in or near hyperlinks serve as proximal cues an information forager can use to choose among which links to follow in pursuit of a goal.
In PFIS, we define a link to be any means a programmer can use to navigate directly in one click to a specific place in source code, excluding scrolling between methods within a class or browsing among classes within a package.
Thus, the definition of links takes into account the features of the programming environment.
As in hyperlinks, links in programs have proximal cues associated with them: for example, a link from a method definition to a method invocation includes the name of the object of the invoked method, the name of the invoked method, and the names of the variables passed in as parameters to the invoked method.
For example, the Eclipse Package Explorer and Outline views allow programmers to navigate from packages to classes to fields and methods .
Eclipse also allows programmers to open definitions and search for ref-
Algorithm PFIS  Given: Bug report, body of source code Returns: A vector containing for each package, class, method, and variable, the probability that a programmer will visit that area of source code given the bug report.
Determine link topology of source code and store them in matrix T. Step 2.
Determine set of proximal cues around each link.
Determine proximal scent of each link to the bug report, and store the resulting similarity scores in matrix PS.
Normalize matrix PS so that each column sums to 1.00 .
Define the starting place  for the spreading activation, and create an entry vector E with the starting location given a 1.
Calculate the probability of programmers going from the starting location to other documents by multiplying the entry vector E=A by PS, to create an activation vector A.
Repeat step 6 to simulate programmers traversing through the link topology.
The final activation vector A, when normalized, contains for each location the expected probability that a programmer will visit that location given the bug report.
Steps 2 and 3 determine the proximal scent of each link relative to the bug report .
Proximal scent is the information foraging term referring to "scent" near the link.
For step 2 of PFIS, we developed a special tokenizer for words in cues, so that CamelCase identifiers " would be split into their constituent words , and also employed a standard stemming algorithm on the constituent words.
For step 3 of PFIS, the scent is determined by the similarity of words in the bug report to the text that labels the link and in close proximity to the link.
We used Lucene , an open-source search engine API to index the proximal cues  associated with each link.
Lucene uses TF-IDF , a technique commonly used in information retrieval to weight the importance of words in documents.
For our purposes, we treated the bug report as the query, and the proximal cues of each link as a document.
Lucene determined the cosine similarity of each link in relation to the bug report to determine the scent of each link.
We used these results as weights for the edges in T, producing a proximal scent matrix PS.
In step 4, PFIS normalizes PS so that each column sums to 1, thus producing a column-stochastic matrix.
Thus, at the end of step 4, the proximal scent relative to the bug report has been calculated, reflecting the information foraging premise that links in the source with proximal cues close to the important words in the bug report will smell more strongly of the bug, and are thus more likely to be followed.
Steps 5, 6 and 7 simulate programmers navigating through the source code, following links based on scent.
It calculates how widely the spreading emanates.
For PFIS, spreading activation calculates the likely spread of programmers to locations in source code, which can be interpreted as the expectation that a programmer trying to resolve a particular bug report will navigate to those locations in the program.
The parameter  scales PS by the portion of users who do not follow a link.
In the initial iteration, the activation vector equals the entry vector.
Activation is updated  in each iteration t as follows : A : =  PS * A + E In each iteration, activation from the entry vector is spread out to adjacent nodes, and activation present in any node is spread to neighboring nodes according to the scent, i.e., the edge weights in PS.
In the final iteration, activation vector A represents the activation of each node  in our topology T. Normalizing A, we interpret A as the probability of a hypothetical user visiting that node in T. See Figure 4.
We will refer to the first as issue B  and the second as issue MF .
Each participant worked on both issues, and we counterbalanced the ordering of issues among subjects to control for learning effects.
The former involves finding and fixing a bug, and the latter involves inserting missing functionality, requiring the search for a hook.
The issues we assigned to developers were open issues in RSSOwl.
We considered looking at closed issues whose solution we could examine, but this would have meant locating an older version of RSSOwl for participants to work on, and would have required us to ensure that participants would not find the solution accidentally by browsing the web.
Therefore, we decided that our participants would work on open issues, cognizant of the risk that RSSOwl's own developers could close the issues during the study, updating the web-available solution with the correct code in the process.
We recruited 12 professional programmers from IBM.
We required that each had at least two years experience programming Java, used Java for the majority of their software development, were familiar with Eclipse and bug tracking tools, and felt comfortable with searching, browsing, and finding bugs in code for a 3-hour period of time.
We searched for a program that met several criteria: we needed access to the source code, it needed to be written in Java, and it needed to be editable and executable through Eclipse, a standard Java IDE.
We selected RSSOwl, an open source news reader that is one of the most actively maintained and downloaded projects hosted at Sourceforge.net.
The popularity of newsreaders and the similarity of its UI to email clients meant that our participants would understand the functionality and interface after a brief introduction, ensuring that our participants could begin using and testing the program immediately.
RSSOwl  consists of three main panels: to the left, users may select news feeds from their favorites, to the upper right, users can review headlines.
On selecting a headline, the story appears in the lower right panel of the application window.
Having decided upon the program, we also needed bug reports for our participants to work on.
Since we were interested in source code navigation and not the actual bug fixes, we wanted to ensure that the issue could not be solved within the duration of the session.
We also decided that one issue should be about fixing erroneous code and the other about providing a missing feature.
Upon their arrival, after participants filled out initial paper work, we briefly described what RSSOwl is, and explained to our participants that we wanted them to try to find and possibly fix issues that we assigned to them.
We then set up the instant messenger so that participants could contact us remotely.
Then we excused ourselves from the room.
We observed each participant remotely for three hours.
We recorded electronic transcripts and video of each session using Morae screen and event log capture software.
For each of the participants in each task, we analyzed the video and tallied the frequency and duration of visits for each of the class files.
We will refer to these two metrics as visits and time span, respectively.
We then ran the PFIS algorithm for each task, applying the spreading activation algorithm over 100 iterations , with an  of 1 to simulate users navigating within source code.
Spreading activation requires us to specify the starting point of navigation .
In our study, we did not specify where programmers should start, so to construct our entry vector, we simply recorded in which classes or methods participants actually started.
This generated a series of activation vectors describing the probable number of programmers to have visited each location.
Although PFIS reasons at a finer granularity than classes, we combined the methods' results by class for uniformity of comparison with other methods.
We first compare PFIS' ability to model any one programmer's navigation to human wisdom, namely the actual navigation patterns of all the other programmers in our study.
First, we computed the Spearman correlation between the "hold one out" aggregate program navigation among all but one of the programmers to predict the remaining programmer's navigation for each metric in each task.
This collection of combined human judgments can be seen in Figures 6 and 7 as "Collective visits" and "Collective time span."
In Figures 6 and 7, "Classes" represents the correlation between each programmer's navigation and the "hold one out" count of programmers who visited each class.
Because programmers may visit classes multiple times, "Classes" differs from "Collective visits."
Second, we computed the Spearman correlation between each pair of programmers for each task  and each metric .
This comparison shows how well any one programmer could predict another programmer's navigation, representing situations with a low level of available human history, such as for new projects or very small teams.
These results are summarized in Figures 6 and 7 as "Pairwise visits" and "Pairwise time span."
Comparing the PFIS boxes in these figures to the "Collective" boxes shows that PFIS came reasonably close to aggregated human judgments.
We determined this using bootstrap resampling, which shows that the 95% confidence interval of the difference between PFIS and the pairwise correlation of programmers does not span zero for each task and metric.
Previous tools  have empirically shown the effectiveness of historical program navigation data as the basis for recommending which classes are relevant to an issue.
Our results suggest that  information foraging theory may account for these tools' success,  when there is no historical data available, PFIS is a reasonable substitute, and  when there is only a little historical data available, PFIS may outperform these tools.
The PFIS model, like other information foraging work, includes the notions of both scent and topology.
Therefore, to consider whether scent or topology might work better alone than in combination, we devised two additional models that model scent only and topology only.
The scent-only model was the interword correlation model of , which works at the granularity of classes.
We chose to include this model because of its basis in Pirolli's information foraging calculations of interword correlation  and its early indications of success in predicting programmer navigation.
3,612 class-class pairings based on the topology of links, leaving 33,444 not in the topology.
Thus, according to PFIS, for the maintenance tasks in our study, only 3% of all possible class-class traversals were potentially relevant.
Did PFIS pick the right 3%?
It was pretty close for Issue B, predicting 42 of the 61 pairs of classes  that were traversed more than once.
Only 7 visited pairs were not explained by either scent or topological relationships.
For issue MF, PFIS was not as stellar, but of the 103 pairs traversed more than once, it still predicted 33 .
However, 47 pairs were not explained by scent or topological relationships.
These relationships are shown in Figure 9.
These results were borne out statistically .
For Issue B, PFIS predicted edge traversals remarkably well-- almost as well as it predicted the allocation of time and visits to classes .
However, it only weakly predicted edge traversals for Issue MF, also shown in Table 2.
We further investigated the pairings visited more than once for each issue that were not in the topology, to determine why the topology did not contain these edges.
As shown in Table 3, some of the edges for issue MF could not be explained by the topology because two participants each added a class to the source code to implement the missing feature.
Some class-class pairings had words in common even if they did not share any links between them .
For Issue MF, we noticed some traversals that could be explained by indirect links.
In such cases, one class would contain a variable of an interface type, and the other class would implement the interface.
In some cases, membership to a common package explained the relationship between two classes .
This model is equivalent to the results returned by a standard  search engine.
The PFIS-Topology model uses spreading activation on the topology aspect of PFIS only .
Topology, as we have explained, is the collection of links.
Since most links are method calls, the topology is similar to a call graph plus links to each method's definition.
We used this model because many software tools are based on topological information, and we wanted to see how such tools potentially compare with new tools based on information foraging.
Table 1 shows the average correlations between each programmer's navigation choices and these three models' predictions , with the aggregated human judgments repeated for ease of comparison .
Particularly for Issue MF, the performance of the models were quite similar.
We also determined that the difference between PFIS on Issue B versus Issue MF  was significant, which raises a new question: are there fundamental differences in the ways programmers navigate when working on solving a bug versus working on adding new features?
We will return to this issue in a later section.
In the previous sections, we examined whether information foraging theory could model the set of users' visits to classes, by taking into account the relationships between classes, methods and variables.
We now consider the sequence of these visits by examining the "edges" from one class to another traversed by our participants.
Classes that are visited one directly after another could indicate a relationship between these classes, and when present, we would like to see if it is predicted by information foraging theory, and if not to understand what might account for it.
The two coders reached agreement on over 90% of their codes.
These sessions revealed interesting differences in the timing, generality, and process of hypothesis formation for Issue B versus Issue MF.
For example, when working on Issue B, participant 96s was able to formulate a specific and concrete hypothesis about exactly what needs to change within 5 minutes into the task.
Participant 82 likewise formed a very concrete hypothesis for Issue B, and even more quickly.
Somehow we want to have escaped XML because this is in CDATA.
In contrast, for Issue MF, the hypotheses were more openended, possibly because there were multiple correct solutions to the problem.
For example, Participant 85s's first hypothesis, given in the first minute, was simply a broad hypothesis about what he had to accomplish.
It was 23 minutes into Issue MF, after the subject had investigated the code and referred back to the bug report, until he provided a hypothesis about how to actually address part of Issue MF: Participant 85s : We want to remove the items based on the unread age and based on the read age.
Participant 84s decided that it would be hard to develop a useful hypothesis about Issue MF without a better understanding of RSSOwl, so after forming a general hypothesis about "adding" at six minutes in, he changed his strategy, deciding to experiment with the system before attempting to refine the hypothesis.
His experiments continued, without further hypothesis verbalizations for 22 more minutes.
At that time he finally began to become form a concrete hypothesis about a suitable "hook" for adding the feature.
Participant 84s : So what we are looking to do is to add -- I think what I'll start doing is trying to archive RSS feed entries after say some amount of time and then I'll make it increasingly more complex.
Participant 84s : When am I going to run this archive feature?
The answer would seem to be is this something that is going to be run automatically?
Thus, hypothesis formation appears to be different in nature between these two issues.
One possible cause may be the wording of the bug reports, which are shown in Figure 10.
Note that Issue B's bug report is fairly specific about symptoms and circumstances, which could have enabled the early formation of concrete hypotheses demonstrated by our participants.
This could be simply a matter of better wording and content in these particular reports, but we propose that it could be in part inher-
Back-links may be an important factor.
Some edges in the rows of Table 3 were traversed when programmers went back to a class they had just come from, or cycled between two classes; namely in 6 out of Issue B's 32 edges that were traversed more than 3 times, and 27 out of 54 such edges for issue MF.
Such back-links were not in the PFIS model , but these results show that they should be considered for inclusion in such models.
A final point is that not all scent is textual.
Information foraging theory as applied to the web has pointed this out, but PFIS does not yet model it.
For example, programmers often derive hypotheses from observing run-time behavior.
A possible corroboration of this notion of hypotheses' interactions with information foraging may be that many of the edge traversals throughout the rows of Table 3 involved GUI classes.
Thus, we next consider hypotheses and scent.
Prior research into debugging suggests that programmers form hypotheses about the reasons and places relevant to bugs, and that much of debugging revolves around attempts to confirm, refine, or refute those hypotheses .
Recall that PFIS performed better on issue B than on issue MF.
A key assumption behind the PFIS model is that, when the issue being pursued starts with a bug report, the programmer forms hypotheses that linguistically relate to the bug report.
Implicit in this assumption is the premise that a model can omit hypotheses and still be able to predict the necessary places to navigate well enough to be useful.
We decided to probe this premise by investigating whether programmers' hypothesis formation played fundamentally differing roles in the two issues.
We investigated this question via content analysis of four transcribed participant sessions, two sessions for each issue.
Two of the authors independently coded each transcript, replaying the videos at the same time to maintain context, coding the formation of an entirely new hypothesis, and coding for expanding or revis-
HTML entities in titles of atom items not decoded In an atom feed such as crookedtimber.org/feed/atom/ you can find both the post titles and the post contents expressed as escaped-HTML.
The post contents  are rendered correctly by RSSOwl, but the post titles that contain HTML entities are not.
The entities, like &#8217; are not expanded by RSSOwl in post titles.
I have attached a snapshot of that feed at this point in time.
Remove Feed Items Based on Age This is based on the assumption that the ability to archive feeds is available.
Create an option to delete feed items after a certain amount of time has passed.
Kind of like a rule saying `Delete all feed items that are 3 months old'.
Figure 10: Snapshot of the bug reports' contents.
The ultimate goal of this work is to provide theoretical grounding for tools to support software maintenance.
The results from our predictive model are consistent with a number of descriptive theories of debugging , but also add to the theoretical understanding of debugging by providing a dynamic model.
The model can be used in descriptive, explanatory, and predictive manners.
The PFIS model's performance shows that it already allows us to provide independent evidence about the premises behind current systems, such as Hipikat.
It also allows us to reason about new design possibilities.
In the domain of web navigation, information foraging and WUFIS have been used as the basis for both automated usability evaluation , and in browsing and navigation tools .
Similar applications of the theory could be developed for program navigation.
For example, just as ScentTrails  has been used to successfully speed up web navigation by highlighting hyperlinks to indicate paths to search results, our results suggest that source code navigation could be enhanced by highlighting links in class files with high scent for the bug report under consideration.
Scent-based indicators could also be added to existing software tools based on other ways of discovering relationships between source code, such as developer navigation and action histories , or structural or lexical relationships .
Scent indicators may also enhance the use of call graphs and program slices during maintenance, by indicating an additional relationship between parts of source code.
Fault localization tools, which use multiple information sources to make a best guess about the location of a bug, may also benefit by using scent as an additional factor.
Information foraging theories have also been used as the basis for web site usability evaluation tools.
In an analogous fashion, the PFIS model could be used for usability analysis of bug reports.
More helpful bug reports may get written if scent-based feedback is provided to bug report authors regarding how well their report is narrowing the possible set of places the bug might be located.
PFIS could also be used to evaluate proximal scent strength within source code itself, which could ultimately be used by programmers to improve their naming and commenting practices.
The above design suggestions are speculative, but they demonstrate how PFIS, as a predictive model, has the potential to both inform and evaluate tool development, as has been the case for information foraging in web navigation.
Reporting bugs often entails enumerating specific circumstances gone wrong with the assumption that the specifications are fairly well understood.
In contrast, reporting the need for missing features emphasizes providing reasonably complete specifications for the desired feature.
These differences are reflected in the bug reports in the figure.
They are also reflected in comments that were posted to these bug reports.
For Issue B, three of the four comments related to the possible location of the bug.
For Issue MF, the three comments elaborated upon the specifications.
We have previously suggested that it may be possible to use participants' words typed into "search" tools as surrogates for their hypotheses .
Eleven of our twelve participants used search, and searching was at least somewhat involved in the process of their work on their hypotheses.
Early concrete hypothesis formation for Issue B was apparent in our participants' search behaviors.
They used search more for Issue B , and what they searched for were low-level "how to" items on the web , and locations in the code base .
An example of a "how to" web search was participant 82s's search for "converting strings to HTML java", and an example of a location search was his search for "addListener" in the code base.
In Issue MF, our participants searched much less than in Issue B--specifically, only 54% as much.
The tasks were varied in order, so learning effects did not account for this difference.
More to the point, the Issue MF searches were almost all in the code base , looking for a hook.
For example, Participant 85s's only two searches were in the code base, looking for "items.put" and "Date".
These results suggest that there are  two relationships between hypotheses and search strings: searches in attempting to form a concrete hypothesis, and searches to pursue that concrete hypothesis after it is formed.
However, for Issue MF, it missed more of them.
Many of the edges PFIS missed were topological relationships not usually considered by information foraging algorithms, such as back-links, and scent relationships not in the topology.
These provide opportunities for future improvements.
We conjecture that this is due to inherent differences between the reporting of bugs versus feature requests, with the former tending to describe scentcarrying aspects such as circumstances and locations, but the latter describing specifications, which may have less scent.
Most important, our results suggest that information foraging's ability to predict programmer navigation during maintenance is indistinguishable from aggregated historical program navigation data.
This in turn suggests that information foraging can provide a theoretical account of program navigation in software maintenance.
