Figure 1: Implanted user interfaces allow users to interact with small devices through human skin.
Note: Throughout this paper, illustrations have been used in place of actual photographs of the specimen, to ensure ethical and professional standards are maintained.
ABSTRACT tinguishable from it" .
We investigate implanted user interfaces that small devices provide when implanted underneath human skin.
Such devices always stay with the user, making their implanted user interfaces available at all times.
We discuss four core challenges of implanted user interfaces: how to sense input through the skin, how to produce output, how to communicate amongst one another and with external infrastructure, and how to remain powered.
We investigate these four challenges in a technical evaluation where we surgically implant study devices into a specimen arm.
We find that traditional interfaces do work through skin.
We then demonstrate how to deploy a prototype device on participants, using artificial skin to simulate implantation.
We close with a discussion of medical considerations of implanted user interfaces, risks and limitations, and project into the future.
In 1991, Mark Weiser wrote that "the most profound technologies are those that disappear.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
We now use mobile devices to place calls and send emails on the go, maintain our calendars and setup reminders, and quickly access information.
While these devices have not yet disappeared, they have become an integral part of our lives, to the point where we have arguably become dependent on them .
For example, in a recent survey of 200 Stanford students that owned iPhones, nearly a quarter of those surveyed reported that the iPhone felt like an extension of their brain or body .
In this paper, we propose manifesting these dependencies on external devices by implanting them underneath human skin, allowing users to interact with them through implanted user interfaces.
While implanted devices have existed for a long time in the medical domain, such as hearing aids or pacemakers, they support only limited interaction, and cannot support personal tasks.
Unlike other types of mobile devices, such as wearables  or interactive clothing , implanted devices are with the user at all times.
Implanting thus truly allows always-available interaction .
Before implanted user interfaces can become a reality, numerous questions must be considered.
In this paper, we explore four core challenges: How can users produce input?
How can the devices provide output?
How can the devices communicate and transfer information?
How can the devices remain powered?
After discussing these challenges, we perform a technical evaluation, where we surgically implant seven devices into a specimen arm.
We evaluate and quantify the extent to which traditional interface components, such as LEDs, speakers, and input controls work through skin .
Our main finding is that traditional interface components do work when implanted underneath human skin, which provides an initial validation of the feasibility of implanted user interfaces.
Motivated by these results, we conduct a small qualitative evaluation using a prototype device , for the purpose of collecting user feedback.
As a substitute for actually implanting this device, we place it under a layer of artificial skin made from silicon, which affixes on the user's skin .
We conclude our exploration of implanted user interfaces with a comprehensive discussion of medical assessment, limitations, and potential for future work.
Recent on-body systems have allowed users to provide touch input on their bodies using a depth camera  or by capturing acoustic sensations .
To produce output, systems often feature wearable projectors , which, however, may complicate outdoor use and impede mobility.
Implanted user interfaces, in contrast, are fully contained and mobile.
Sensing body activity directly presents an alternative to using the body as a spatial input canvas, such as sensing muscle tension , tongue motions using prototypes worn inside the mouth  and micro-devices integrated into worn contact lenses .
Direct output through the body has been shown with electrodes that stimulate the user's muscles  or the user's ear to influence the sense of balance .
Uses of such output systems include learning gestures or receiving real-time feedback in gaming environments.
Results in these research areas are impressive and encouraging.
However, our focus is on implanted devices as standalone units with no coupling to the user's biological system.
Active medical implants typically maintain life-crucial functionality , improve body functionality to restore normal living , or monitor the user's health .
Passive implants are also commonly used for medical purposes, such as for artificial joints.
While swallowed and not implanted, physicians have also used small pill-sized autonomous microcomputers to record data from inside the body and transmit it to a receiver for external visualization .
For interactive purposes, electrodes have been implanted in the context of brain-computer interfaces  and speech production .
Moore and Kennedy powered such an implanted electrode using induction through the scalp .
Humans have experimented with adding new abilities to their bodies, such as implanting a small magnet to their finger  or an RFID chip into their body.
Masters and Michael discuss issues surrounding human-centric applications of RFID implants, such as automatically opening doors and turning on lights .
Warwick's Project Cyborg investigates user interaction through an implanted RFID chip with devices in the proximity, as well as the interaction of implants with user's nervous system .
Relevant work can also be found in the art community.
For example, Stelarc attached an ear-replica to his arm, which used a miniature microphone to transmit recorded sounds wirelessly .
These medical and non-medical examples demonstrate the feasibility of implanting devices.
However, such devices are typically passive, and do not provide any mechanisms for direct interaction with the actual implant.
In the next section, we introduce implanted user interfaces, which could support such interaction.
While users typically carry mobile devices inside pockets, retrieving them to start interacting imposes a significant overhead on usage time .
As mobile devices shrink to very small sizes, users can instead attach them directly to their bodies .
Disappearing mobile devices prototype smallest-possible visual sensors and researchers have speculated on the possibility of implanting them .
Instead of attaching devices to the body, clothing has been made interactive by using conductive thread to sense pinches  and touch on clothing, such as on keypads made of fabric  or entire touchpads .
Wearable devices typically need to be explicitly put on or removed, either on a daily basis, or for specific activities.
We consider implanted devices as devices that are surgically and permanently inserted under the human's skin.
Implanting devices that possess user interfaces would allow users to directly interact with them, allowing them to support a wide range of applications and tasks, beyond the medical usages prevalent today.
Implanted devices have several advantages over mobile and wearable devices.
First, implanted devices do not need to be manually attached to the user's body.
Second, implanted devices have the potential to be completely invisible.
This would avoid any social stigmas of having such devices.
Third, implanted devices, along with the information they store and provide, always travel with the user; the user can never lose or forget to take them.
The devices and applications become part of the user.
Since implanted devices sit under the skin, they are not directly accessible through their interfaces.
This makes providing input to them an interesting challenge.
One option is to use contact-based input through the skin, such as a button, which would additionally offer tactile and audible feedback to the user.
Tap and pressure sensors allow devices to sense how strongly touches protrude the skin, while brightness and capacitive sensors detect a limited range of hover.
Strategic placement of touch-based sensors could form an input surface on the skin that allows for tapping and dragging.
Audio is an alternative implanted user interface.
A microphone could capture speech input for voice activation.
Fully implanted and thus fully concealed controls require users to learn their locations, either by feeling them through skin or by indicating their location through small marks.
Natural features such as moles could serve as such marks.
Partial exposure, in contrast, would restore visual discoverability and allow for direct input.
Exposing a small camera, for example, would allow for spatial swiping input above the sensor .
All such input components, whether implanted or exposed, are subject to accidental activation, much like all wearable input components.
Systems have addressed this, for example, by using a global on/off switch or requiring a certain device posture .
To access and exchange data amongst each other or with external devices, implanted devices need to communicate.
If devices are fully implanted under the skin, communication will need to be wireless.
Bluetooth is already being used to replace wired short-range point-to-point communication, such as for health applications .
Wi-Fi, as an alternative, transmits across longer distances at higher speeds, but comes at the cost of increased power usage and processing efforts.
Equipping implanted devices with an exposed port would enable tethered communication.
Medical ports are already used to permit frequent injections to the circulatory system .
Ports and tethered connections are suitable for communication with external devices, but not amongst two devices implanted at different locations in a user's body.
Such devices would still require wireless communication.
A substantial challenge for implanted devices is how they source energy.
As power is at a premium, implanted devices should employ sleep states and become fully active only after triggering them.
A simple way to power an active implanted device is to use a replaceable battery.
This is common with pacemakers, which typically need surgical battery replacement every 610 years.
Rechargeable batteries would avoid the need for surgery and recharging could be wireless, through technology known as inductive charging .
If the implanted device is close to the skin surface, inductive charging may work through the skin .
Alternatively, an exposed port could provide tethered recharging to an implanted device.
Finally, an implanted device could harvest energy from using the device  or from body functions .
We direct the reader to Starner's overview for more information .
Device output typically depends on the senses of sight , hearing  and touch .
Stimulation of other senses, such as taste and smell, is still only experimental .
The size constraints of small devices require sacrificing spatial resolution and leave room for only individual visual signals, such as LEDs.
Furthermore, visual output may go unnoticed if the user is not looking directly at the source.
While audio output is not subject to such size constraints, its bandwidth is similar to the visual output of a single signal: varying intensities, pitches, and sound patterns .
Tactile output of single elements is limited to the bandwidth of pressure to the body and intensity patterns .
The purpose of this evaluation was to examine to what extent input, output, communication, and charging components remain useful when implanted underneath human skin.
In addition, we provide a proof of concept that these devices can in fact be implanted, both fully under the skin and with exposed parts.
We performed this evaluation in collaboration with the Department of Surgery in the Division of Anatomy at the University of Toronto, Canada.
The procedure of the study underwent full ethics review prior to the evaluation and received approval from the Research Ethics Board.
We evaluated seven devices featuring twelve controls in total, which were traditional input and output components as well as components for synchronization and powering common in conventional mobile devices.
As shown in Figure 3, we tested four basic sensors for direct touch input: button, pressure sensor, tap sensor.
In addition, we tested two devices that could potentially detect hover above the skin: capacitive and brightness sensor.
We also tested a microphone for auditory input.
For output, we tested an LED , vibration motor , and speaker .
For charging, we evaluated an inductive charging mat, and for communication, we tested Bluetooth data transfer.
These devices do not exhaust all possible implanted interface components, but we chose them as some of the more likely components that could be used.
We conducted the evaluation in two sessions.
In the baseline session, the devices lay on the table shown in Figure 4.
In the implant session, each of the seven devices was implanted into a cadaveric specimen, one at a time.
An external video camera documented the entire implant session, and parts of the baseline session.
The experimenter configured and initialized the devices through the laptop and monitored the incoming data, while the assistant performed the necessary interactions with the devices.
Cables connected each of the devices to a laptop computer to ensure reliable connectivity and communication with the devices throughout the study .
The laptop logged all signals sent from the input components on the devices, including device ID, sensor ID, sensed intensity and timestamp.
The laptop also logged time-stamped output triggers, including output component ID, intensity and frequency.
All active devices used an ATmega328 microcontroller with a 10-bit precision AD converter.
The chip forwarded all measurements to the laptop and also computed length of impact as well as average and maximum intensities.
We also recorded all background intensities separately.
One lightly embalmed cadaveric upper limb specimen  was used for this study.
With light embalming, the tissues remained pliable and soft, similar to fresh and unembalmed tissue .
The skin and subcutaneous tissues remained mobile.
Each of the seven devices was enclosed by two thin transparent plastic bags to prevent malfunction due to penetration by tissue fluid .
To insert devices, the skin was incised and separated along the tissue plane between the skin and underlying subcutaneous tissue at the cut end of the limb, about 7.5cm proximal to the elbow joint, which was 20cm from the insertion point.
Once the plane was established, a long metal probe was used to open the plane as far distally as the proximal forearm, creating a pocket for the devices.
Each of the devices was inserted, one at a time, into the tissue plane and the wires attached to the devices were used to guide the device into the pocket between the skin and subcutaneous tissue of the proximal forearm .
Distal to the insertion site of the device, the skin remained intact.
All devices were fully encompassed by skin, with no space between device and skin or tissue, or any opening.
The study was administered by an experimenter and an experimenter assistant, both with HCI backgrounds, and an anatomy professor, who carried out all of the surgical procedures .
Because the focus of this study was on the technical capabilities of the devices themselves, external participants were not necessary.
To produce input at controlled intensities, we built a stress test device as shown in Figure 4.
The assistant dropped a piston from controlled heights onto each input sensor to produce predictable input events.
For the pressure and tap sensors, the piston was dropped from six controlled heights , repeated five times each, and the intensities from the sensors were measured.
For the button, the piston was dropped from seven heights , also repeated five times each, and we recorded if the button was activated.
The pressure sensor used a voltage divider with a circular 0.2" Interlink Electronics force sense resistor  and a 10K resistor.
The touch sensor was a Murata 20mm piezoelectric disc.
The microcontroller captured events at 30kHz.
The piston was a 60g metal rod.
Without the finger present, skin diffused incoming light, resulted in reduced brightness .
The environmental light explains the differences in slopes between baseline and implant condition; as the finger approaches the sensor, light reflected from surfaces can still fall in at extreme angles in the baseline condition.
Skin in contrast diffuses light and thus objects approaching the sensor result in a less pronounced response.
Skin softened the peak pressure of the dropping piston, whereas the softening effect shrunk with increasing impact force .
We analyzed the measured voltages and, by relating them back to the forceresistance mapping in the datasheet, obtained an average of 3N in differences of sensing impact between conditions.
Button: Figure 7 illustrates the effect of skin dampening on the impact of the dropping piston.
In the baseline condition, the piston always activated the button, whereas only dropping from a height of 1cm and higher achieved enough force to activate the button through the skin at all times.
To evaluate the LED and motor, we used a descending staircase design to determine minimum perceivable intensities .
For each trial, the experimenter triggered components to emit output at a controlled intensity level for a duration of five seconds.
The assistant, a 32 year old male, served as the participant for the staircase study to determine absolute perception thresholds.
The method started with full output intensity, which the participant could clearly perceive.
The experimenter then decreased the intensity in discrete steps, and the participant reported if he could perceive it.
If he did not, the experimenter increased output intensities in smaller steps until the participant could perceive it.
We continued this procedure until direction had reversed eight times .
The last four reversal values then determined the absolute perception threshold .
The capacitive sensor was a 24-bit, 2-channel capacitance to digital converter .
The brightness sensor used a voltage divider with a 12mm cadmium sulfide 10M photoresistor and a 10K resistor.
Both sensors captured hover intensities at 250Hz.
Three rows of fluorescent overhead lighting illuminated the study room.
The staircase method dology yielde ed the absolu ute th hreshold for perceiving LE ED output at 8.1% intensi ity r required in th he baseline co ondition and 48.9% intensi ity r required throug gh the skin.
Fig gure 10  shows the actua ally y produced int tensities determ mined by the ex xternal camera.
T The assistant co ould perceive the stimuli sound at a level of 5 5.2dB at only 0.3% output i intensity in aseline session n, and at 7% in the impla ant session the ba .
The pe erceivable dec cibel levels compare to other r results .
Fi igure 11 illustr rates the additio onal output ity needed to ac chieve compar rable sound pre essures.
The baselin ne c condition with h the accelero ometer resting g on the mot tor d directly shows an expected li inear decay.
Th he shown valu ues r represent the mean m standard deviation of the three valu ues r read by the acc celerometer.
The T difference in personal pe erc ception of the vibration v was small s .
The skin n accounted for r a difference i in recorded sound intensities of f 6.5dB  for the clo ose-speaker ion and 6.24dB B  in t the far-speaker r condition.
T To evaluate th he speaker, we w again used d a descendin ng s staircase design n to determine e minimum pe erceivable aud dio levels.
We con nducted the ev valuation from m two distance es: 2 25cm  and a 60cm .
These dist tances simulated h holding the arm m to one's ear to t listen to a si ignal  an nd h hearing the sign nal from a rest ting state with the arms beside o one's body .
The stimulus was a 1kHz sine wav ve s signal .
Du uring each step p, an external desktop micr rop phone measured actual output t signals from 5cm away in th he c close condition n, and 60 cm aw way in the far condition.
Three of the soun nd p playbacks were e voice , on ne w was a chime so ound.
To eva aluate the powe ering device, w we docked the receiver to the pow wering mat .
In the baseline s session, the two de evices docked d directly.
In t the implant se ession, the receive er was implant ted, and the p powering mat w was placed on the surface of the skin directly a above the impla ant.
T The implanted microphone was w a regular el lectret condens ser m microphone.
The T external microphone was an audi iotechnica AT20 020 USB.
The speaker was a Murata Piez zo 2 25mm piezoele ectric buzzer.
The T laptop recorded from bo oth m microphones at t 44.1kHz with h the microphon ne gain set to 1.
Once docked, we s separately mea asured the vo oltages and ts the receive er supplied w with a voltmet ter and an current ampere e-meter.
We to ook five probe es for each measurement, each ti ime capturing values for five seconds for the meters to stab bilize.
We me easured the pro es and the ovided voltage drawn current with fo our resistors: 2 2K, 1K, 100 0, 56.
The Powermat receiver output a nominal voltage of 5.12V in the baseline condition.
Through skin, the provided voltage was unsubstantially smaller .
As shown in Figure 14, skin did not impact the current drawn by the device for low resistances.
For the 56 resistor, the difference was 7mA, still providing 80mA, which should easily power an Arduino microcontroller.
To test the performance of the wireless connection between two chips, one was external and one implanted with no space between chip and encompassing skin in the implant session.
The baseline session tested both devices placed outside.
We evaluated the connection at two speed levels , sending arrays of data in bursts between the devices  and calculating checksums for the sent packages.
The receiving device output time-stamped logs of number of received packages and its calculated checksum.
The test was fully bidirectional, repeated five times and then averaged.
Regarding input, skin expectedly required user input to increase in intensity to activate sensor controls.
Despite this required intensity overhead, all tested input sensors did perceive input through the skin, even at the lower levels of intensity we tested.
This leaves enough dynamic range for the sensors' additional degrees of freedom, such as detecting varying pressure.
As for hover detection, skin incurs an offset of brightness and diminishes capacitive signals, but both sensors responded to the approaching finger.
While output appears diminished through the skin, detection is possible at low-enough intensity levels, such that output components, too, can leverage a range of intensities for producing output.
Powering the device through the skin yielded enough voltage to have powered any of the implanted devices.
It is also enough to power our 3in3out prototype device, which we will describe in the next section.
More measurements with lower resistances remain necessary to determine the maximum throughput of the tested inductive power supply beyond the 100mA levels.
While skin affected the throughput of the fast wireless communication and accounted for a 3% higher loss of packages and a 0.2KB/s drop in speed, it did not affect the slow condition.
The flawless wireless communication in 9600bps enables reliable data exchange.
Results found in the related area of body-area networks differ, as transmission goes through the body or arm, not just skin .
In addition to quantitatively evaluating input components, we wanted to prototype an exposed implanted interface component.
To do so, we mounted a Blackberry trackball control on the back of an Arduino Pro Mini 8MHz board and soldered batteries to it.
The trackball was a fully autonomous standalone device.
We programmed the trackball to emit a different light color when the user swiped the ball horizontally or vertically.
To expose the roller ball, the skin and plastic cover over the roller ball were carefully incised using a scalpel.
The incision was about 3mm in length, so only the roller ball was exposed.
Once implanted into the specimen, the experimenters took turns interacting with the device, which worked as expected.
Figure 1f illustrates the exposed trackball.
Note that this exploration took place after the quantitative evaluation had fully finished.
The incision made for this exploration had no effect on our earlier evaluation.
To explore initial user feedback on implanted user interfaces, we built and deployed a prototype device covered with a layer of artificial skin on users.
Our goal was to gain initial insights on how users may feel about walking around with an interactive implanted device and to demonstrate how such devices can be prototyped and tested outside controlled lab conditions.
We W built the 3in3out 3 device e specifically for f th he qualitative evaluation .
It fea atures three inp put c controls  and thr ree o output components .
A L Li-Po battery powers the stan ndalone 3in3out device.
T The device im mplemented a game g as an ab bstract task th hat in nvolved receiv ving output and d responding with w input.
At 309 90 second intervals, a random mly chosen ou utput compone ent tr riggered the user, u who had to respond using u the corre ect in nput: pressure sensor for the LED, tap sensor for the moto or, a and button for the speaker.
While W the LED D kept blinkin ng, th he speaker and a vibration motor repeated their outp put tr rigger every 10 0s.
Without a response, r the trigger t timed out o a after one minute.
Participants s received poin nts based on th he s speed and accu uracy of their re esponses.
W We created arti ificial skin to cover our prot totype and sim mula ate actual im mplantation wit th the aid of f a profession nal p prosthetics sho op, which had years of expe erience modelin ng b body parts.
The artificial skin n is diffuse an nd diffused ligh ht, d dampened soun nd and vibratio on in roughly the t same mann ner to o the real skin n in our evalua ation.
Participa ants in the stud dy c confirmed that the artificial skin s qualitatively felt like re eal s skin.
As the foc cus of this stud dy was on obta aining qualitativ ve f feedback, we did not calibr rate the characteristics of th he a artificial skin to t match the absolute a quanti itative properti ies o of skin we mea asured in our ev valuation.
We did not need th he a artificial skin to match the Bluetooth pro operties of sk kin e either, because e our qualitativ ve study did not n include com mm munication dev vices.
Pa articipants' second dary task was s to respond to the trigger rs that the 3in3ou ut device emitte ed, and try to a achieve a high score.
The device recorded resp ponse times, err rors and point totals.
The took place in d downtown Tor ronto, Canada on a sumstudy t mer da ay, which represented a reali istic worst-case scenario; both, d direct sunlight a and noise levels were very in ntense.
Particip pants first rece eived a demons stration of the device and practic ced its use.
Th he participant then left the b building to perform m all primary t tasks, and retu urned after app proximately 60 min nutes.
Participa ants filled out a questionnair re after the study, sharing their impression w when using the e device in public environments and any the re eactions they re eceived.
T To create the artificial skin n, we mixed Polytek PlatsilG Gel 10 with Po olytek Smith's Theatrical Pro osthetic Deade ene er, which is kn nown to produ uce silicone wi ith skin-like fe eel a and consistency y.
We added sk kin-color liquid d foundation an nd e enhanced the skin s look with red, blue and d beige flockin ng.
W We then poure ed the silicone mixture into a mold custom miz zed to fit a hum man arm, adde ed the device wrapped w in Seran f foil, and positio oned a clay arm m, so that the silicone s assumed th he correct sha ape.
We then affixed the artificial a skin to u users' arms using ADM Tro onics Pros-Aid de medical grad de a adhesive.
The final f layer of artificial a skin measured m 4.5" x 2 2"  and was 1-2m mm thick above e the device .
Overal ll, participants found the dev vice easy to use e. All liked the tap p sensor  and d button , but none enjo oyed the pressu ure sensor.
For ou utput compone ents, all ranked the LED lowest for percep ption relative to the other output compo onents, the er medium, and d the vibration n motor best .
While these results suggest that the device might work better i in environmen nts quieter and d/or darker he noisy city setting in dire ect sunlight, p participants than th were ab able to see the L LED blinking w when looking a at it.
While participants m mentioned receiving curious l looks from ting with their arm, no exter rnal person others when interact ached a partici ipant, even tho ough they spe ent time in approa casual settings .
Most i importantly, th he results of ou ur study demon nstrate that nted user interf faces can be us sed to support interactive implan tasks.
T This evaluation n also provide es a methodolo ogy to pave the wa ay for future ev valuations and mockups of m more elaborate de evices and appl lications of imp planted user in nterfaces.
For the most part, these devices could be implanted deep into the skin in the subcutaneous tissue anywhere in the body where the devices are accessible and can transmit signals.
This includes the upper and lower limbs, the chest wall, abdomen, etc.
Areas covered by thick skin, such as the palms and soles of the feet, would not be suitable for implantables, as the skin is too thick and tough to interact.
The thickness of human skin ranges between 0.5mm on the eyelids to 4+mm on the palms and soles of the feet .
The superficial placement of the devices, directly under the skin, facilitates device activation and signal transmission.
The devices can be inserted between the skin and subcutaneous tissue, providing a minimally invasive approach.
The deep underlying tissues, e.g., muscle, would not be disrupted.
Similarly, pacemakers are placed under the skin in the chest or abdominal regions and the wires that are extending from the heart are connected to the pacemaker.
Only a small skin incision that is later closed with sutures is needed to insert the pacemaker.
The device remains stationary in its implanted location due to the fibrous nature of subcutaneous tissue.
The tracking ball was the only device we implanted that required surface exposure.
The device worked very well under the experimental conditions, but much work needs to be done to assess the medical implications of a long-term insertion of an exposed device.
All of the input and output devices were functional under the experimental conditions of this study.
Further cadaveric study is needed to determine if gender, skin color and site of implantation affect device function.
In the next phase, testing would also be carried out on unembalmed tissue, although the skin of lightly embalmed and unembalmed specimens is similar, loose and pliable in both cases.
Finally, the medical implications of long-term insertion of devices of this nature require detailed study.
Tissue fluid will penetrate a device that is not encased in a protective hull, and affect its function.
The hull's material must be carefully chosen to be pharmacologically inert and nontoxic to body tissues.
For examples, pacemakers are typically made from titanium or titanium alloys, and the leads from polyether polyurethanes.
In vivo testing would need to be carried out to determine what materials are most suitable.
The device should be as small as possible, so it is easily implantable and cosmetically acceptable to the recipient.
Functionality and minimal disruption of the contour of the skin are important considerations.
The main medical risk of implanting devices is infection.
Infection can be caused by the procedure of implanting the devices.
There are also possible risks to muscles if the device is implanted any deeper than the subcutaneous tissue.
The material used for the casing could also possibly cause infections, so it will be important that the material being used passes through proper testing.
It is very difficult to hypothesize about other types of risks without performing testing.
The wear of skin depends on the pressure applied to it; while paraplegics get sore skin from body weight resting on single spots through bones, skin is unlikely to wear from manual pressure.
The proposed input with implanted devices is short and low in force and intensity, making skin unlikely to wear.
One risk that is relatively low is that of the skin actually tearing.
Skin is very strong and it is unlikely the small devices would cause any damage.
The results of our study shows that traditional user interfaces for input, output, wireless communication and powering function when embedded in the subcutaneous tissue of the forearm.
Having obtained an evaluation of common components establishes the foundation for future investigations into more complex devices to explore the many other aspects of implanted user interfaces.
For example, we disregarded security concerns in our exploration.
Wireless implanted devices need to prevent malicious activities and interactions from users other than the host user, such as stealing or altering stored information and manipulating the devices' operating system .
The processing capabilities of the devices that were implanted during the technical evaluation, as well the 3in3out device, require only simple processing on the microchip.
More work is necessary to investigate if and how implanted devices can perform more computationally intensive operations  and how this affects the needs for power supply.
Social perception of implanted interfaces, both by host users as well as public perception requires more studying.
Although this has been studied with implanted medical devices , social perception of invisible and implanted user interfaces and devices remain to be examined.
We conducted our qualitative evaluation with participants in the summer, which is why all participants wore shortsleeve shirts.
In the winter, cloth will additionally cover implanted input and output components  and interfere with interaction, which raises new challenges.
Our technical evaluation comprised a single specimen.
In addition, we carried out the staircase evaluations with a single participant.
As such, the metrics we have collected can serve as baselines for future experimentations, but should be generalized with caution.
Furthermore, our evaluation captured technical metrics from the devices, and not human factor results.
In the future, it may be interesting to have external participants interact with the implanted devices and study task performance levels.
Several experts have predicted that cyborgs are coming , and devices will become indistinguishable from the very fabric of our lives .
If we look at how much has changed, it should not be hard to believe that we will one day interact with electronic devices that are permanent components of our body.
Our work takes a first step towards understanding how exactly this might be accomplished, and begins to ask and answer some of the important technical, human factors, and medical questions.
