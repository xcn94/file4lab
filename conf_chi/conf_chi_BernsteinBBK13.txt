While established media producers can estimate their audience through surveys, television ratings and web analytics, social network sites typically do not share audience information.
This design decision has privacy benefits such as plausible deniability, but it also means that users may not accurately estimate their invisible audience when they post content.
Correct or not, these audience estimates are central to media behavior: perceptions of our audience deeply impact what we say and how we say it.
We act in ways that guide the impression our audience develops of us , and we manage the boundaries of when to engage with that audience .
Social media users create a mental model of their imagined audience, then use that model to guide their activities on the site .
However, with no way to know if that mental model is accurate, users might speak to a larger or smaller audience than they expect.
This paper investigates users' perceptions of their invisible audience, and the inherent uncertainty in audience size as a limit for users' estimation abilities.
We survey active Facebook users and ask them to estimate their audience size, then compare their estimates to their actual audience size using server logs.
We examine the folk theories that users have developed to guide these estimates, including approaches that reverse-engineer viewership from friend count and feedback.
We then quantify the uncertainty in audience size by investigating actual audience information for 220,000 Facebook users.
We examine whether there are reasonable heuristics that users could adopt for estimating audience size for a specific post, for example friend count or feedback, or whether the variance is too high for users to use those signals reliably.
We then test the same heuristics for estimating audience size over a one-month period.
While previous work has focused on highly visible audience signals such as retweets , this work allows us to examine the invisible undercurrents of attention in social media use.
By comparing these patterns to users' perceptions, we can then identify discrepancies between users' mental models and system behavior.
Both the patterns and the discrepancies are core to social network behavior, but they are not well understood.
Improving our understanding will allow us to design this medium in a way that encourages participation and supports informed decisions around privacy and publicity.
We begin by surveying related work in social media audiences, publicity, and predicting information diffusion.
We then perform a survey of active Facebook users and compare their estimates of audience size to logged data.
When you share content in an online social network, who is listening?
Users have scarce information about who actually sees their content, making their audience seem invisible and difficult to estimate.
However, understanding this invisible audience can impact both science and design, since perceived audiences influence content production and self-presentation online.
In this paper, we combine survey and large-scale log data to examine how well users' perceptions of their audience match their actual audience on Facebook.
We find that social media users consistently underestimate their audience size for their posts, guessing that their audience is just 27% of its true size.
Qualitative coding of survey responses reveals folk theories that attempt to reverse-engineer audience size using feedback and friend count, though none of these approaches are particularly accurate.
We analyze audience logs for 222,000 Facebook users' posts over the course of one month and find that publicly visible signals -- friend count, likes, and comments -- vary widely and do not strongly indicate the audience of a single post.
Despite the variation, users typically reach 61% of their friends each month.
Together, our results begin to reveal the invisible undercurrents of audience attention and behavior in online social networks.
Posting to a social network site is like speaking to an audience from behind a curtain.
The audience remains invisible to the user: while the invitation list is known, the final attendance is not.
Feedback such as comments and likes is the only glimpse that users get of their audience.
That audience varies from day to day: friends may not log in to the site,
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Social media users develop expectations of their audience composition that impact their on-site activity.
Designing social translucence into audience information thus becomes a core challenge for social media .
In response, speakers tune their content to their intended audience .
On Facebook and in blogs, people think that peers and close online friends are the core audience for their posts, rather than weaker ties .
Sharing volume and self-disclosure on Facebook are also correlated with audience size .
However, as the audience grows, that audience may come from multiple spheres of the user's life.
Users adjust their projected identity based on who might be listening  or speak to the lowest common denominator so that all groups can enjoy it .
Social media users are thus quite cognizant of their audience when they author profiles , and accurately convey their personality to audiences through those profiles .
Our notion of the invisible audience is tied to the imagined audience in social media .
The imagined audience usually references the types of groups in the audience -- whether friends from work, college, or elsewhere are listening.
In this paper, we focus not on the composition of the audience but on its size.
Both elements play important roles in how we adapt our behaviors to the audience.
Cues can be helpful when estimating aspects of a social network, but there are few such cues available today.
For example, to estimate the size of a social network, it can be helpful to base the estimate on the number of people spoken to recently  or to focus on specific subpopulations and relationships such as diabetics or coworkers .
However, it can be difficult to estimate how many people within the network will actually see or appreciate a piece of content.
Public signals such as reshares  and unsubscriptions  give users feedback about the quality of their content, but users often consume content and make judgments without taking any publicly visible action .
In addition, there are consistent patterns in online communities that might bias estimates: for example, the prevalence of lurkers who do not provide feedback or contribute  and a typical pattern of focusing interactions on a small number of people in the network .
Questions of audience in social media often reduce to questions of privacy.
Users must balance an interest in sharing with a need to keep some parts of their life private .
However, early studies on social network sites found no relationship between disclosure and privacy concerns .
Instead, people tended to want others to discover their profiles , and filled out the basic information in their profile relatively completely .
However, young adults are increasingly, and proactively, taking an active role in managing their privacy settings .
Design decisions with respect to audience visibility can influence users' interactions with their audience .
Visualizations can also support socially translucent interactions by making the members of the audience more salient  or displaying whether an intended audience member has already seen similar content .
BlackBerry Messenger, Apple iMessage, and Facebook Messenger all provide indicators that the recipient has opened a message, and online dating sites OkCupid and Match.com reveal who has viewed your profile.
Few studies have addressed users' reactions to this explicit audience indicator , though some users of the social networking site Friendster expressed concerns that they were uncomfortable with this level of social transparency and would consequently not view as many profiles .
Our work pushes the literature forward in important respects: we augment previous research with quantitative metrics, we focus on contexts where the intended audience is friends and not the entire Internet, and we empirically demonstrate that audience size is difficult to infer from feedback.
We also contribute empirical evidence for the wide variance in audience size, something not previously possible for blogs or tweets, because we can track consumption across the entire medium.
To study audiences in social media, we use a combination of survey and Facebook log data.
Most Facebook content is consumed through the News Feed , a ranked list of friends' recent posts and actions.
When a user shares new content -- such as a status update, photo, link, or check-in -- Facebook distributes it to their friends' feeds.
The feed algorithmically ranks content from potentially hundreds of friends based on a number of optimization criteria, including the estimated likelihood that the viewer will interact with the content.
Because of this and differences in friends' login frequencies, not all friends will see a user's activity.
We logged audience information for all posts  over the span of June 2012 from a random sample of approximately 220,000 US Facebook users who share with friends-only privacy.
We also logged cumulative audience size over the course of the entire month.
To determine audience size, we used client-side instrumentation that logs an event when a feed item remains in the active viewport for at least 900 milliseconds.
Our measure of audience size thus ensures that the post appeared to the user for a nontrivial length of time, long enough to filter out quick scrolling and other false positives.
However, being in the audience does not guarantee that a user actually attends to a post: according to eyetracking studies, users remember 69% of posts that they see .
So, while there may be some margin of difference between audience size and engaged audience size, we believe that this margin is relatively small.
Furthermore, we note that univariate correlations are unaffected by linear transformations, so the correlations between estimated and actual audience are the same regardless of whether a correction is applied to the data.
Figure 1: Comparisons of participants' estimated and actual audience sizes, as percentages of their friend count.
Most participants underestimated their audience size.
The top row displays each estimate vs. its true value; the bottom row displays this data as error magnitudes.
Left column: The specific survey, where participants were shown one of their posts, comparing estimated audience to the true audience for that post.
Right column: The general survey, where participants estimated their audience size "in general," comparing estimated audience to the number of friends who saw a post from that user during the month.
Our logging resulted in roughly 150 million distinct  pairs from roughly 30 million distinct viewers.
All data was analyzed in aggregate to maintain user privacy.
The number of distinct friends providing feedback, given in terms of likes and comments, was also logged for each post.
In our analysis, we did robustness checks by subsetting our data, e.g., active vs. less active users, and users with different network sizes.
We saw identical patterns each time, so we report the results for our full dataset.
We advertised the survey to English-speaking users in our random sample who had been on Facebook for at least 90 days, had logged into Facebook in the past 30 days, and who had shared at least one piece of content  in the last 90 days.
The general audience survey had 542 respondents, and the specific audience survey had 589.
To compare actual audience to perceived audience, we surveyed active Facebook users about their perceived audience.
Participants might estimate their audiences differently when they anchor on a specific instance than when they consider their general audience, so we prepared two independent surveys: general and specific audience estimation.
In the general survey, participants answered the question, "How many people do you think usually see the content you share on Facebook?"
In the specific survey, participants clicked on a page that redirected them to their most recent post, provided that post was at least 48 hours old.
Specific survey participants then answered the question, "How many people do you think saw it?"
In both surveys, participants then shared how they came up with that number.
In this section, we investigate how users' perceptions of their audience map onto reality.
This investigation has three main components.
First, we quantify how accurate users are at estimating the audience size for their posts.
Second, we perform a content analysis on users' self-reported folk theories for audience estimation.
Third, we explore users' satisfaction with their audience size.
We compared participants' estimated audience sizes to the actual audience size for their posts.
Figure 1 plots actual audience size against perceived audience size for the two surveys.
The cluster of points near the xaxis indicates that the majority of participants significantly underestimated their audience.
For participants considering a specific post in the past , the median perceived audience size was 20 friends ; the median actual audience was 78 friends .
Transformed into percentages of network size, the median post reached 24% of a user's friends , but the median participant estimated that it only reached 6% .
In fact, most participants guessed that no more than fifty friends saw the content, regardless of how many people actually saw it.
We note that this data is skewed and long-tailed, as is common with many internet phenonema: as such, we rely on medians rather than means as our core summary statistic.
We quantify the relative error as 1 - The median relative error is 0.73, meaning the median estimate was just 27% of the actual audience size.
In other words, the median participants underestimated their actual audience size by a factor of four.
Table 1: The relative prevalence of folk theories for estimating audience size.
Participants most often used heuristics based on the amount of feedback they get on their posts or their number of friends.
The categories and their relative popularities across both surveys appear in Table 1.
Nearly one-quarter of participants said they had no idea and simply guessed.
The magnitude of this number indicates how little understanding users have of their audience size.
The most popular strategy  was based on feedback: the number of likes and comments on a post.
Participants explained, "I figured about half of the people who see it will `like' it, or comment on it," or "number of people who liked it x4."
Others made a rough guess at how many people might log in to Facebook: e.g., "I'm guessing one hundred of my frieds  actually read facebook daily" and "not a lot of people stay up late at night."
Many respondents based their estimates on a fixed fraction of their friend count: "figure maybe a third of my friends saw it."
Others assumed that the people they typically see in their own feeds or chat with regularly are also the audience for their posts: "Judging by the number of people that regularly share with me", "I assume the number of people who see me are the same people that show up on my news feed."
Finally, some respondents mentioned their close friends or family, or friends who would be interested in the topic of the post: "I'm sure a lot of people have blocked me because of all the political memes I've been putting up lately,", "Friends that are involved with paintball would catch a glimpse of me mentioning MAO."
A small number mentioned their privacy settings: "Based on the privacy and sharing rules I have set-up, I would imagine it's close to that number."
Particularly savvy users transferred knowledge from other domains, like "based on the FB page of a business that i'm admin on."
We compared the audience estimation accuracy of each group.
Despite the variety of theories of audience size, no theory performed better than users who responded "guess".
Participants in the general survey also underestimated their audiences .
The median perceived audience size in the general survey was 50 , while the median actual audience  was 180 .
The median relative error was 0.68, indicating that participants underestimated their general audience by roughly a factor of three.
Figure 1  shows the distribution of errors in both surveys.
In both cases, participants tended to underestimate their audiences, and there was greater variance in the general version of the survey.
Not surprisingly, estimates of audience size "in general" were significantly larger than those for a specific post in the past .
As disjoint sets of friends may see different pieces of content, it makes sense that in a month, more people would see a given user's content than would see any single post she made.
Survey participants correctly accounted for this.
To further quantify this relationship, we can fit a linear model to measure the correlation between estimated and actual audience size.
What heuristics are guiding users' estimates, and why are users underestimating so much?
To answer these questions, we investigated the theories that participants reported when estimating their audience size.
We performed a content analysis on the survey responses for how participants came up with their estimates.
The authors inductively coded a subset of the responses to generate categories, then iterated on the coding scheme until arriving at sufficient agreement .
Though users have limited insight into their own audience size, their perceptions may play a strong role in their satisfaction with their posts' reach.
In this section, we investigate survey participants' responses to the question, "How many people do you wish saw this piece of content?"
Table 2 reports summary statistics for our survey results.
Table 2: Summary statistics for survey participants who desired smaller, the same, or larger audiences.
Perceived and actual audiences shown as a percentage of friend count.
The fifteen individuals who wanted smaller audiences had large variance in their responses: those who wanted "far fewer people" had the smallest perceived audience  and those who wanted "fewer people" had the largest perceived audience .
Given the small number of people who wanted smaller audiences, we combined the two groups that desired larger audiences and ended up with two comparison groups: those who were satisfied with their audience size , and those who wanted a larger audience .
Those who desired the same audience size typically estimated that 9% of their friends would see a post , while those who wanted "more people" or "far more people" typically estimated 5% of their friends .
A nonparametric Wilcoxon rank-sum test comparing these means is significant , indicating that those who wanted to reach a larger audience estimated that their reach was smaller.
The survey results suggest that people do a poor job of estimating the size of the invisible audience in social networks.
Is audience size too uncertain to estimate accurately?
In this section, we investigate sources of uncertainty when estimating the invisible audience, broadening our view from survey users to our entire dataset of over 220,000 users.
We investigate the audience for individual posts in our dataset, then the cumulative audience size for each user over a month.
We demonstrate that there is a great deal of variability in audience size, and that audience size is difficult to infer using visible signals.
These results suggest that audience size can be quite unpredictable and that users simply do not receive enough feedback to predict their audience size well.
Figure 2: Users with the same number of friends have highly variable audience sizes.
Panels show the distribution of the number of friends  and fraction of friends  who saw a post as a function of friend count.
The line and bands indicate the median, interquartile range, and 90% region.
Across all posts in our sample, the mean and median fraction of friends that see a post among users is 34% and 35%, respectively.
However, this quantity is highly variable.
As Figure 2 demonstrates, the interquartile range for the fraction of friends that see a post is approximately 20%, and the 90th percentile range can be as large as 84% .
While the fraction of friends who see a post remains relatively stable, it is important to note that if we consider a user with a fixed number of friends, the actual number of friends who see the post is quite variable.
Figure 3 illustrates this relationship: the standard deviation in the audience size increases with the number of friends.
As a result, post produced by a user with many friends has more variability in the audience size than one produced by a user with few friends.
Audience size grows most rapidly as a function of number of friends for users with fewer than 200 friends, then tapers off for users with more friends .
Likewise, the fraction of friends who see a user's post is greatest when users have fewer friends .
To quantify this uncertainty, we can fit a linear model to predict the fraction of friends viewing a post using the number of friends as input.
The mean absolute error of the model is .08, meaning that the average actual audience is 8% of friends away from the prediction.
Feedback is the main mechanism that users have to understand their audience's reaction to a post.
It was also one of the most popular folk theories in our survey.
Does feedback actually help users understand their audience size?
Figure 4 reports the median audience sizes for posts, depending on the amount of feedback they get from friends liking and commenting on the post.
Audience size grows rapidly as posts gather more feedback, though this growth slows when a post has feedback from five unique friends.
Posts with no likes and no comments had an especially large variance in audience size: the median audience was 28.9% of the user's friends, but the 90% range was from 1.9% to 55.2% of the user's friends.
So, while users may be disappointed in posts that receive no feedback, the lack of feedback says little about the number of people it has reached.
Like with friend count, we can fit a linear model that uses feedback indicators such as unique commenters and unique likers to predict the fraction of friends that see a post.
Like the previous model, its mean absolute error is 8%, so the average prediction is off by 8% from the actual percentage of friends who saw the post.
These results are nearly identical to those for the linear predictor based on friend count.
Figure 4: The number of unique friends leaving likes  and comments  is positively associated with audience size, but has large variance.
The mean absolute error for this model was 7% of the friend network.
So, even using all three signals that users can view, it is difficult to predict actual audience size.
Neither friend count nor feedback individually are very accurate predictors of audience size.
However, they may be contributing data that is jointly informative.
Audience size estimates for the general survey were significantly higher than those specific to a single post.
Likewise, users evolve their understanding over extended periods of time.
To capture these longer-term processes, we analyzed cumulative audience: the total number of distinct friends who saw or interacted with each user's content over the span of an entire month.
Three quarters of the users in our sample produced more than one piece of content during the month, and half the users in our sample produced five or more pieces of content.
Figure 6: The distribution of cumulative audience sizes across all content produced over one month for users at the 25th, 50th and 75th percentile of friend count in our sample .
61% of that user's friends, compared to 35% for a single post.
The relationship between friend count and monthly cumulative audience as a fraction of friend count appears in Figure 5.
Again, this relationship can be quite variable: the interquartile range is 31% and the 90% range is 65%.
The more friends the user has, the larger the variation .
Figure 7: The distribution of the fraction of friends who had seen at least one post by a user as a function of the number of distinct users who had liked  or commented on  at least one piece of the user's content during a one month period.
Horizontal axis extends to the 95th percentile of likes and comments for users in our sample.
Furthermore, only a small fraction of users' audiences provide feedback over the month: 95% of the users in our sample have 40 or fewer friends who like their posts, and 18 friends who comment on their posts.
If users develop a sense of their invisible audience over time by observing the number of friends who provide feedback, how much can they learn about their audience size?
Figure 7 shows the fraction of friends that consitute a user's cumulative audience over the span of one month, given a certain number of unique friends who have provided feedback.
For example, approximately 60% of a typical  user's friends will see at least one of their posts in a month, given that exactly two distinct friends commented on their posts.
Though the cumulative audience is much larger than the audience for single posts, it exhibits no less variance.
We trained a linear model to predict audience size, using the same predictors as with previous models  and one new predictor: the number of stories the user produced that month.
The model explains no more variance than the joint model for individual posts .
However, the actual audience cannot be predicted in any straightforward way by the user from visible cues such as likes, comments, or friend count.
The core result from this analysis is that there is a fundamental mismatch between the sizes of the perceived audience and the actual audience in social network sites.
This mismatch may be impacting users' behavior, ranging from the type of content they post, how often they post, and their motivations to share content.
The mismatch also reflects the state of social media as a socially translucent rather than socially transparent system .
Social media must balance the benefits of complete information with appropriate social cues, privacy and plausible deniability.
Alternately, it must allow users to do so themselves via practices such as butler lies .
The mismatch between estimated and actual audience size highlights an inconsistency: approximately half of our participants wanted to reach larger audiences, but they already had much larger audiences than they estimated.
One interpretation would suggest that if these users saw their actual audience size, they would be satisfied.
Or, these users might instead anchor on this new number and still want a larger audience.
Our study methodology carries several important limitations.
Some concerns are associated with the limits of log data.
First, techniques for estimating whether a user saw a post have a precision-recall tradeoff: depending on how the instrument is tuned, it might miss legitimate views or count spurious events as views.
However, the instrument would need to be overestimating audience size by a factor of four for our conclusions to be threatened, and we believe that this is unlikely.
Second, just because a user saw a status update, we cannot be certain that they focused their attention on it or would remember it .
Our survey attempted to be clear that we were interested in how many people saw the content, but some participants may have blurred the distinction.
Finally, we focused on one month of data; changes to site features or norm evolution may impact audiences over longer periods.
Our survey methodology has limitations as well.
To validate the instrument, we tested different formulations of the audience estimation question.
Variations included comparing "saw the content" to "read the content", as well as different wordings asking for raw numbers, percentages, and Likertstyle radio button responses.
The results were similar for all formulations.
However, it is possible that some participants still filtered out users who they think might not have paid attention to the content.
In addition, the survey format did not go into depth on participants' perceptions: interviews could further explore this phenomenon.
Our methods introduce sampling bias.
Our log data selects for active users, in particular those who produce content.
The survey also selects for users who produce content, those who log in to Facebook, and those who care enough about Facebook to participate in a survey advertised at the top of the News Feed.
One known bias is that active users can have larger friend counts than the typical Facebook population.
Why do people underestimate their audience size in social media?
One possible explanation is that, in order to reduce cognitive dissonance, users may lower their estimates for posts that receive few likes or comments.
A necessary consequence of users underestimating their audience is that they must be overestimating the probability that each audience member will choose to like or comment on the post.
For these posts without feedback, it might be more comfortable to believe that nobody saw it than to believe that many saw it but nobody liked it.
Our data lend some support for this belief: users estimated smaller audiences when we showed them a specific recent post than when they considered their posts in general, and we found the same results when we piloted a separate survey that focused users on a specific post they might create in the future.
Several of the folk theories suggest that users are influenced by whom they have interacted with recently.
So, some underestimation may also be due to reliance on the availability heuristic, which suggests that prominent examples will impact peoples' estimates .
If true, the underestimation might be due to the fact that many social systems have more viewers than contributors .
Specifically, users might base their estimates on whom they see on Facebook, not accounting for those who might be reading but not responding.
Finally, users' estimates may be affected by the ranking and filtering Facebook performs on the News Feed.
Other social network sites have different filter designs: Twitter shows content in an unfiltered reverse-chronological order, while Google+ gives users a slider to choose how much content to filter from each circle.
One might hypothesize that not filtering users' feeds  might increase diversity and thus increase audience size.
However, we believe that fil-
This research raises the question of whether showing actual audience information might benefit social media.
This design might come in many flavors: highlighting close friends who saw the post, showing a count but no names or faces, or  showing a complete list of every person who saw the post.
Some Facebook groups now display how many group members have seen each post, while sites such as OkCupid show who has browsed your profile.
Adding audience information could certainly address the current mismatch between perceived and actual audience size.
Our results do not paint a clear picture as to whether audience information would be a good addition.
Some measure of social translucence and plausible deniability seems helpful: audience members might not want to admit they saw each piece of content, and sharers might be disappointed to know that many people saw the post but nobody commented or "Liked"
Underestimating the audience might also be a comfortable equilibrium for some users who feel more comfortable speaking to a relatively small group and would not post if they knew that they were performing in front of a large audience.
On the other hand, many users expressed a desire for a larger audience, and demonstrating that they do in fact have a large audience might make them more excited to participate.
Pragmatically, this work suggests that social media systems might do well to let their users know that they are impacting their audience.
Because so many members of the audience provide no feedback, there may be other ways to emphasize that users have an engaged audience.
This might involve emphasizing cumulative feedback , showing relative audience sizes for posts without sharing raw numbers, or encouraging alternate modes of feedback .
We have demonstrated that users' perceptions of their audience size in social media do not match reality.
By combining survey and log analysis, we quantified the difference between users' estimated audience and their actual reach.
Users underestimate their audience on specific posts by a factor of four, and their audience in general by a factor of three.
Half of users want to reach larger audiences, but they are already reaching much larger audiences than they think.
Log analysis of updates from 220,000 Facebook users suggests that feedback, friend count, and past audience size are all highly variable predictors of audience size, so it would be difficult for a user to predict their audience size reliably.
Put simply, users do not receive enough feedback to be aware of their audience size.
However, Facebook users do manage to reach 35% of their friends with each post and 61% of their friends over the course of a month.
Where previous work focuses on publicly visible signals such as reshares and diffusion processes, this research suggests that traditionally invisible behavioral signals may be just as important to understanding social media.
Future work will further elaborate these ideas.
For example, audience composition is an important element of media performance , and we do not yet know whether users accurately estimate which individuals are likely to see a post.
We can also isolate the causal impact of estimated audience size on behavior, for example whether differences in perceived audience size cause users to share more or less.
Finally, these results suggest that there are deeper biases and heuristics active when users estimate quantities about social networks, and these biases warrant deeper investigation.
