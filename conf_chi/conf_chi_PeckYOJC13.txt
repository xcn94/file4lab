Nevertheless, there are limitations to evaluating performance in a visual interface without directly monitoring the brain's cognitive processes.
Finally, cognitive state can change even as performance remains stable, meaning that performance metrics may not always accurately reflect cognitive processes .
As a result, there has been a renewed interest in objective methods to evaluate cognitive processes during interaction with a visual interface .
In particular, functional nearinfrared spectroscopy   has received increased attention as a lightweight brain sensing technology in HCI because in comparison to other brain sensing methods, it is portable , resistant to movement artifacts , and observes similar physiological parameters to fMRI .
While previous fNIRS experiments in HCI have studied cognitive state at various stages of interaction , these experiments largely omit a critical component of interface design: How do different visual designs and interfaces affect the user's ability to perform visual judgment at a cognitive level?
The potential of using fNIRS to inform the design of interactive interfaces for visualization is appealing.
If fNIRS can successfully measure the impact of visual design on the user, then it can provide access to physiological parameters that have not previously been analyzed in this context.
Furthermore, it can do so in ecologically sound settings that allow users to interact naturally with an interface .
However, there are concerns as to whether fNIRS may be capable of monitoring brain activity in these scenarios.
The physiological parameters which fNIRS monitors  typically peak 5-7 seconds after interaction, meaning that the signal is slow-moving in comparison to the massively-paralleled processes employed by the brain's visual system.
In addition, tasks that leverage the perceptual system may not induce measurable activity in the prefrontal cortex , the area of the brain most commonly monitored by fNIRS.
We show how brain sensing can lend insight to the evaluation of visual interfaces and establish a role for fNIRS in visualization.
Research suggests that the evaluation of visual design benefits by going beyond performance measures or questionnaires to measurements of the user's cognitive state.
Unfortunately, objectively and unobtrusively monitoring the brain is difficult.
While functional near-infrared spectroscopy  has emerged as a practical brain sensing technology in HCI, visual tasks often rely on the brain's quick, massively parallel visual system, which may be inaccessible to this measurement.
It is unknown whether fNIRS can distinguish differences in cognitive state that derive from visual design alone.
In this paper, we use the classic comparison of bar graphs and pie charts to test the viability of fNIRS for measuring the impact of a visual design on the brain.
Our results demonstrate that we can indeed measure this impact, and furthermore measurements indicate that there are not universal differences in bar graphs and pie charts.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
While the field of HCI has seen an increased acceptance of physiological sensing in evaluation, to date, this push has not translated to the evaluation of visual interfaces and visual form.
Historically, recording behavioral metrics or administering questionnaires have been used to evaluate visual design.
However, Riche  notes that the exploratory nature of tasks in infovis systems, coupled with the "the difficulty to decompose  into low-level and more easily measured actions" makes analysis problematic.
To overcome some of these obstacles, Riche proposes the use of physiological measures to evaluate visual interfaces.
Unfortunately, to our knowledge, there have been only two significant attempts to explore this space.
Investigating the impact of visual variables on heart rate, galvanic skin response , and respiratory rate, Causse and Hurter found that interactions with text v. angle-based visual forms elicited different signals with GSR .
Few other significant interactions were observed.
Work by Anderson et al.
However, there are notable caveats to the use of EEG.
While EEG has a high temporal resolution, it also has a low spatial resolution, meaning that the origin of recorded electrical activity is difficult to locate.
Additionally, EEG has traditionally been considered to be extremely sensitive to movement artifacts, although recent developments have lessened this issue .
In this work, we test the viability of using fNIRS to observe how visual design modifies brain activity in complex tasks.
We conducted three experiments to  examine how participants process bar graphs and pie charts differently in their brains,  determine the efficacy of using fNIRS as a technique for evaluating mental workload in visual tasks, and  classify visual tasks that are most suited for using fNIRS in evaluation.
To investigate this, we employ a classical comparison in the field of visualization - bar graphs and pie charts - and ask users to perform a difficult task on the information contained in those graphs.
Based on our results, we make three contributions: * Our findings suggest that fNIRS can be used to monitor differences in brain activity that derive exclusively from visual design.
We find that levels of deoxygenated hemoglobin in the prefrontal cortex  differ during interaction with bar graphs and pie charts.
However, there are not categorical differences between the two graphs.
Instead, changes in deoxygenated hemoglobin correlated with the type of display that participants believed was more difficult.
In addition, participants reacted differently to pie charts and bar graphs at a cognitive level, but exhibited the same performance characteristics.
We conducted an experiment that compares brain activity observed in bar graphs and pie charts with activity from a visuospatial n-back task - a wellcharacterized task from the psychology literature for modifying load on working memory.
Our results are consistent with the existing fMRI literature and agree with participant response data , indicating that fNIRS signals correlate with cognitive workload.
We find that fNIRS can provide insight on the impact of visual design during interaction with difficult, analytical tasks, but is less suited for simple, perceptual comparisons.
An alternative technology to objectively monitor activity in the brain is functional near-infrared spectroscopy , an optical brain sensing device that has the potential to lend insight to visual interactions .
Light is sent into the forehead in the near infrared range , where it is diffusely reflected by the scalp, skull, and brain cortex.
At this wavelength, oxygenated and deoxygenated hemoglobin are the primary absorbers of light.
A very small percentage of the light sent into the head returns from the cortex to the detector on the fNIRS probe.
By measuring the light returned to the detector, researchers are able to calculate the amount of oxygen in the blood, as well as the amount of blood in the tissue.
Since changes in blood flow and oxygenation indicate activation levels in the brain we can use fNIRS to measure activity in localized areas of the brain.
In general, fNIRS is quick to set up and more tolerant of user movement than other brain sensing techniques such as fMRI or EEG - a critical feature for ecologically valid evaluation .
Investigating the use of fNIRS in user studies, Solovey et al.
However, Simkin and Hastie found that pie charts and bar graphs performed equally well in part-to-whole comparisons .
Spence and Lewandowsky demonstrated that pie charts perform reasonably well in a direct comparison with other basic visual forms .
In more complex tasks - when comparisons consist of combined proportions  - pie charts can outperform bar graphs .
For a more extensive history of the pie chart, see Spence's article "No Humble Pie: The Origins and Usage of a Statistical Chart" .
Recently, there have been a handful of studies that utilize Cleveland and McGill's comparison as a baseline to investigate various dimensions of interaction.
Using pie charts and bar graphs, Hullman et al.
For example, showing a user a histogram of previous responses to a visual comparison would dramatically skew the user's own judgment.
They found that varying the orientation of the display surface altered visual comparisons .
Despite the sizable body of research that has investigated bar graphs and pie charts, these studies also indicate that as the task or environment change, performance differences between the two forms become less clear.
Therefore, we find this familiar comparison to be a sufficient baseline for objectively exploring users' cognitive processes with fNIRS.
Additionally, minor head movement, respiration, and heartbeats are correctable, as they can be filtered out using known signal processing techniques.
Only major head and forehead movement  are disruptive to the signal .
FNIRS readings have been validated against fMRI and the device is sensitive to physiological parameters that are not accessible by other brain sensing techniques .
Because it measures the relatively slow hemodynamic response of blood to the brain , fNIRS has a slow temporal resolution in comparison to EEG, which indirectly measures the electric activity of the brain.
However, this light-based sensing technique allows fNIRS to have a spatial resolution of 13cm, which is much sharper than EEG .
As a result, fNIRS has seen increased use for research in HCI as a complementary device to EEG .
They then used that protocol to measure the syntactic workload of users while interacting with two different interfaces.
One of the most recent examples is from Solovey et al.
This led to the system Brainput which can identify different brain signals occuring naturally during multitasking and use these to modify the behavior of the interface .
FNIRS has also been used to monitor workload changes in air traffic control tasks and piloting a virtual unmanned aerial vehicle  .
These studies have been important in the development of fNIRS within HCI.
However, the cognitive effects of different visual displays on the user is a yet unexplored area.
Our primary goal in this work was to investigate the viability of using fNIRS to evaluate visual design by having participants perform the same complex task on both bar graphs and pie charts.
We theorized that in a complex task, bar graphs and pie charts would support the cognitive processes of the user differently.
Thus, our principal hypothesis was as follows: * Hypothesis: We will observe different brain signals during interaction with bar graphs and pie charts, indicating that bar graphs are easier to use.
Depending on the outcome of our experiments, our secondary goal was to further specify the use of fNIRS in visualization research.
First, we compared fNIRS signals from participants in a well-established psychology task  to those observed in bar graphs and pie charts.
We combined those observations with previous fMRI literature and participant survey responses to surmise the underlying cognitive processes associated with our fNIRS signal.
Additionally, we performed an auxiliary study using simple comparisons on bar graphs and pie charts to identify a lower bound for using fNIRS in visualization research.
We present these results below, after the main experiment.
We chose the visualization of bar graphs and pie charts as a suitable testbed for monitoring the user's cognitive processes because it is a familiar, well-studied comparison in the field of information visualization.
In this section, we briefly outline the body of research that studies interaction with bar graphs and pie charts.
In Cleveland and McGill's ranking of visual variables, participants were presented with either a bar graph or pie chart  and asked to estimate the proportion percentage of a smaller value in the graph to a larger value .
We used an unweighted NASA-TLX questionnaire , a subjective rating that has been successfully used to capture workload since the 1980s .
The questionnaire collects six components of workload - mental demand, physical demand, temporal demand, performance, effort, and frustration.
In total, we collected two surveys reflecting the two conditions bar graphs and pie charts.
We focus primarily on the questionnaire's mental demand dimension.
Although originally inspired by Cleveland and McGill's classical position v. angle experiment, we modified the complexity of their task in order to reconstruct the memory-intensive, analytical reasoning that is performed on high-performance visual interfaces.
For that reason, we modeled our task loosely after the n-back task, a well-characterized psychology task that is meant to increase load on working memory.
In this task, participants were presented a series of slides, each displaying either a bar graph or pie chart, to view sequentially.
They were instructed to estimate the size difference to the nearest ten percent of a smaller section of the graph  in the current slide to a larger section  in the previous slide.
Estimates were entered using a single keystroke on the keyboard .
Figure 3 shows an example of three slides using the pie chart condition.
Each trial lasted 40.7 seconds and consisted of 11 slides , with each slide being presented for 3.7 seconds.
Participants viewed 8 trials where the task depended on bar graphs and 8 trials where the task depended on pie charts.
Trials were shown in random order.
To construct the graphs, 88 datasets  were randomly generated at the time of the experiment using the same constraints as those outlined in Cleveland and McGill's classical angle v. position experiment.
Accordingly, the same datasets were used for both bar graphs and pie charts.
Comparisons were chosen at run-time by randomly selecting one of the largest two graph elements in the current slide and one of the smallest three elements in the next slide.
This final constraint was necessary to guarantee that the two marked segments of each graph would not overlap and that percentage estimates would not exceed 100%.
We used a multichannel frequency domain OxyplexTS from ISS Inc.  for fNIRS data acquisition.
Two fNIRS probes were placed on the forehead in order to measure the two hemispheres of the PFC .
Each distance measures a difference depth in the cortex.
Each source emits two light wavelengths  to detect and differentiate between oxygenated and deoxygenated hemoglobin.
The sampling rate was 6.25Hz.
For each of the two fNIRS probes, we selected the fNIRS measurement channels with source-detector distances of 3cm, as the light from these channels is expected to probe deepest in the brain tissue, while the closer channels are more likely to pick up systemic effects and noise.
To remove motion artifacts and optical changes due to respiration and heart beat we applied a folding average filter using a non-recursive time-domain band pass filter, keeping frequencies between 0.01Hz and 0.5Hz.
The attenuation of light is measured by how much light is absorbed by oxygenated and deoxygenated hemoglobin .
As the attenuation of light is related to the levels of hemoglobin, given A, we can derive the changes in the levels of oxygenated and deoxygenated hemoglobin .
Finally, to remove noise artifacts, we smoothed the data by fitting it to a polynomial of degree 3 and applied a low-pass elliptical filter .
We logged all key-strokes and response times.
We defined response time as the number of milliseconds from a graph's appearance to the final keystroke  before the next graph.
For accuracy, we used Cleveland and McGill's log absolute error measures of accuracy : error = log2  
In a user study involving bar graphs  and pie charts , we found that a group of participants that subjectively rated bar graphs as more mentally demanding than pie charts  exhibited reserved fNIRS signals from those who rated pie charts as more mentally demanding than bar graphs .
The differences between signals in each graph demonstrate that brain sensing with fNIRS can monitor neural activity derived exclusively from visual.
The plots represent the mean change in deoxygenated hemoglobin across all trials of each condition.
The width of the line represents the standard error at each time point.
16 participants took part in the study .
Participants had a mean age of 20 years  and were incentivized $10 for participation.
The study used a within-subjects design.
All participants completed a fifteen minute bar graph v. pie chart task in which the independent variable was the data visualization technique: bar graphs, pie charts.
Participants also completed a fifteen minute visuospatial n-back task in which the independent variable was the number of slides the participant needed to remember at once: 1-back, 3-back .
At the conclusion of each section, participants completed an unweighted NASA-TLX questionnaire for each condition.
The order of sessions  was counterbalanced and the order of conditions  in each session was randomized.
The study was conducted in a lab setting, with stimuli presented on a single monitor under controlled lighting conditions.
Contrary to our initial belief, these results indicate that there were no categorical differences in brain activity between the two visual forms.
However, during the examination of data from NASA-TLX questionnaires, we encountered an interesting trend.
In this section, we discuss and analyze this.
Isolating the mental demand dimension of the NASA-TLX survey, we found that 7 out of 16 participants believed pie charts to be more mentally demanding than bar graphs while an additional 7 participants expressed that bar graphs were more mentally demanding than pie charts .
These responses were largely unexpected, as our hypothesis indicated that we would likely find a categorical difference between bar graphs and pie charts.
For the sake of clarity, those who thought pie charts to be more mentally challenging will be referred to as pie high demand and those who thought bar graphs to be more mentally demanding will be referred to as bar high demand.
Investigating the differences in these two groups, we found that the levels of deoxygenated hemoglobin exhibited by participants who found bar graphs more mentally demanding were the reverse of those participants who found pie charts more mentally demanding.
Figure 4 shows that in the bar high demand group, we observed a decrease in deoxygenated hemoglobin in both the left and right hemisphere during tasks completed on bar graphs.
In comparison, these same interactions induced a slight increase in deoxygenated hemoglobin in the pie high demand group.
Thus, we performed an ANOVA on the mean change in deoxygenated hemoglobin using a 2  x 2  split plot design.
This finding shows that participants in the pie high demand group and the bar high demand group showed significantly different patterns of deoxygenated hemoglobin while performing the two tasks .
Note that while the mean provides a suitable metric for analysis, it can miss some trends in timeseries data.
Specifically, Figure 5 suggests that both groups recorded similar changes in deoxygenated hemoglobin while interacting with bar graphs.
However, Figure 4 shows that the fNIRS signal was trending in opposite directions.
Despite a clear separation in brain activity between the bar high demand group and the pie high demand group, we observe very little difference in response time and error.
The whiskers represent the max/min values, excluding outliers.
Outliers are assigned by being more/less than 1.5 times the value of the upper/lower quartiles.
Our results show that changes in deoxygenated hemoglobin during the use of bar graphs in a complex task are statistically different from those observed during the use of pie charts.
However, this distinction was not categorical.
Instead, brain activity depended on the individual and correlated with reports of mental demand in a NASA-TLX questionnaire.
These differences between participants may call into question the conventional wisdom to always use bar graphs instead of pie charts.
In light of these group differences, we performed another analysis on response times by running a similar ANOVA on mean response time using a 2  x 2  split plot design.
After ensuring that the data fit a normal distribution, we found no significant interaction between groups and tasks  = 2.425, p = .145.
Similarly, an ANOVA on log error as shown in equation  found no significant difference in the interaction between group and task  = .51, p = .4907.
We display a box-plot of log error and response time for each of the two groups in Figure 6.
These results suggest that although there were significant differences in brain activity between bar graphs and pie charts, there was no observable differences in performance, either categorically  or between group .
This is a very different result from those observed by Cleveland and McGill , in which position judgments  were found to significantly outperform angle judgments .
However, given the complex nature of the task, it is not surprising that performance corresponds more closely to findings from Spence and Lewandowsky that pie charts can perform as well, or better than bar graphs in difficult tasks .
In the background, we outlined studies that used performance metrics of speed and accuracy to compare the use of bar graphs and pie charts.
We expected that self-reports of mental demand would roughly resemble performance trends, and following previous research, one visual form would be categorically favored over the other.
However, we discovered that 14 out of 16 participants found one chart to be more mentally demanding than the other.
Therefore, we reject our initial hypothesis that brain signals would indicate that bar graphs are easier to use for most people.
Subjectively, there was no indication that either bar graphs or pie charts were superior across all participants on this particular task.
7 participants reported pie charts to be more mentally demanding and 7 participants reported bar graphs to be more mentally demanding .
The graph that participants reported to be more mentally demanding recorded decreased levels of deoxygenated hemoglobin, validating the use of fNIRS to procure meaningful information about cognitive state.
Additionally, the results indicate that participants were generally well-tuned to their own cognitive processes and accurately externalized their cognitive load.
We discuss the implications of this observation in the following section.
A comparison of NASA-TLX responses and speed and accuracy demonstrates a dissociation between performance and cognitive state during the use of bar graphs and pie charts.
Performance measures on both graphs were statistically indistinguishable from each other, regardless of whether participants found one graph to be more mentally demanding.
However both questionnaire responses and fNIRS readings showed that the two designs influenced brain activity differently.
Given these results, it is possible that participants were exerting different amounts of mental effort on a given graph to achieve the same levels of performance.
Furthermore, this observation suggests that evaluating performance metrics without considering cognitive state might have led to different conclusions about the efficacy of bar graphs and pie charts in this experiment.
In the next section, we investigate whether the fNIRS signals we observed reflect levels of mental demand.
In the n-back task, participants were shown a series of slides, each with a distinct visual pattern, and asked whether the current slide matched the pattern from either 1 slide previously  or 3 slides previous to the current slide .
Thus, the 3-back task strains the participant's visuospatial working memory by forcing him or her to constantly remember  3 images at once.
By comparison, the 1-back task is relatively simple, requiring participants to remember only visual pattern from the previous slide.
Figure 7 shows an example of 6 slides from the n-back test.
For each slide, the visual pattern remained on the screen for 300ms followed by a blank response screen for 1550ms in which participants answered `yes' or `no' using a single keystroke.
Participants were given 8 trials of each condition with each trial consisting of 22 slides.
Each trial lasted for 40.7 seconds and trials were separated by 12-second rest periods.
This experimental timing mirrors the timing in the bar graphs/pie charts task, enabling us to compare equal slices of time for the fNIRS data.
During the course of this paper, we have been intentionally ambiguous about assigning a specific cognitive state to our fNIRS readings.
The brain is extremely complex and it is dangerous to make unsubstantiated claims about functionality.
However, for fNIRS to be a useful tool in the evaluation of visual design, there also needs to be an understanding of what cognitive processes fNIRS signals may represent.
In our experiment, we have reason to believe that the signals we recorded correlate with levels of mental demand.
We share three legs of evidence that support this claim: 1. fMRI studies have suggested that decreases in deoxygenated hemoglobin are indicative of increased brain activity .
Active regions of the brain require more oxygen to function.
Thus, as levels of oxygenated hemoglobin increase to meet these demands, levels of deoxygenated hemoglobin decrease.
Self-reports of mental demand from the NASA-TLX results during the bar-graph and pie chart task correlated with levels of deoxygenated hemoglobin.
Graphs that were reported to require more mental effort were accompanied by lower levels of deoxygenated hemoglobin.
Nonetheless, questionnaires can be problematic as they depend on the assumption that people can sense and externalize their subjective feelings without being biased by external influences .
In comparison, brain sensing provides an objective snapshot of cognitive state and short-cuts the rating process by directly measuring the brain during interaction.
As opposed to post-hoc questionnaires, neurophysiological measures require no additional effort or time from the participant.
Furthermore, physiological measures can be used in more complex or time-consuming tasks for fine-grained observations of cognitive processes.
Instead of a single workload metric for the entirety of a task, physiological measures can provide time-sensitive evaluations, potentially identifying periods of mental demand.
We recommend that visualization researchers carefully weigh the nature of their comparison to select an appropriate technique.
An example of comparing the n-back signal with those recorded in the bar graph v. pie chart experiment.
The signal recorded during the more demanding 3-back resembles the signal recorded during bar graphs for the bar high demand group - participants who found bar graphs to be more mentally demanding than pie charts.
Given the results of our study, we suggest that fNIRS may be well-suited for the analysis of complex interactions that are common in visual analytic systems.
In this section, we highlight three other factors that point to fNIRS being wellsuited for analytical tasks: * The extended timeline of complex tasks mitigates the slow temporal resolution of fNIRS, which occurs because of the delayed  physiological response to brain activity.
These higher-level cognitive functions typically drive analytical thought and include  selection, comparison, the organization of material before encoding, task switching, holding spatial information `online', and introspective evaluation of internal mental states .
Given these factors, we believe that fNIRS will provide the most insight to visual interfaces that require complex, analytical thought.
However, fNIRS is not without its limitations; as we demonstrate in the next section, short, low-level tasks are difficult to detect using fNIRS.
When placed side-by-side with the fNIRS readings from out bar graph/pie chart task, we notice that signals from the more mentally demanding 3-back resemble those from the graph that participants identified as requiring more mental effort .
Similarly, the signal recorded from the lessdemanding 1-back task resembles those observed in the graph that participants identified as requiring less mental effort .
Given these three legs of evidence - previous observations noted in fMRI studies, correlations with survey data, and correlations with signals observed in the n-back task - we feel confident that the fNIRS signals observed during use with bar graphs and pie charts correlate with mental demand in the brain.
Furthermore, these results suggest that fNIRS can be used to monitor mental demand in other visual interfaces.
We have shown that we can successfully differentiate fNIRS signals during the interaction of bar graphs and pie charts in a complex task and that these signals likely indicate workload in the brain.
In this section, we synthesize our results, previous literature, and an auxiliary study to explore when fNIRS is an appropriate tool for the evaluation of visual design.
Cognitive state is often overlooked in evaluation, partially because it is difficult or cumbersome to quantify.
We found that a simple survey agreed with fNIRS readings and accurately captured the participant's mental workload.
This is good news for simple evaluations of mental demand.
Questionnaires do not require an unreasonable time investment, and the strength of our observations were based on a single dimension in the NASA-TLX questionnaire.
If more objective measures are not available, questionnaires can provide insight into a user's cognitive state.
To explore the limits of using fNIRS to evaluate visual interfaces, we constructed an experiment that is closer to Cleveland & McGill's original comparison of position v. angle, which is based on more perceptually-driven interactions.
Thus, for each trial, four small pieces on a graph were sequentially compared to the largest piece in the graph .
To compare the changes in deoxygenated hemoglobin with our previous study, we ran an additional 8 participants and plotted the fNIRS signal using the axis of the same scale as the complex task.
Looking at Figure 11, we can see that both pie charts and bar graphs caused very little activation in the PFC, with little to no differentiation between signals.
These results are not surprising.
Quick visual and perceptual tasks are not likely to be observed by fNIRS.
Tasks that rely heavily on preattentive processing use very little of the processing power of the PFC.
Additionally, it takes a couple of seconds to observe the hemodynamic response resulting from brain activity, and 5-7 seconds in total for the oxygen levels to peak in the brain.
This means that we are unlikely to observe quick and subtle interactions with a visualization.
We therefore recommend that fNIRS will lend the most insight during more complex analytical interactions.
While recent work in visualization has begun to pay careful consideration to the impact of a user's personality and cognitive traits, using tools like fNIRS, we hope that visual interfaces can be designed to also be attentive to the user's current cognitive state.
The strengths of fNIRS are appealing, however, there are also limitations.
While we identified periods of high or low workload, more specific mappings of fNIRS signals to cognitive states are needed to promote fine-grained evaluations of visual interfaces.
Additionally, we found that fNIRS is less suited for quick visual tasks that are driven by the user's perceptual system.
Despite these drawbacks, fNIRS provides a suite of benefits that are distinctive and complimentary to those offered by other physiological sensors.
With the decreasing cost of brain sensing technology and its increasing use in HCI, we believe that the door has finally opened to directly explore the impact of visual design on cognitive state.
We have demonstrated that fNIRS is a viable technology for investigating the impact of visual design on a person's cognition processes.
Using the classical comparison of bar graphs and pie charts, we found that decreasing levels of deoxygenated hemoblogin correlated with the visual form that participants found to be more mentally demanding.
We suggest that these changes in deoxygenated hemoglobin, detected in the PFC, indicate the amount of mental effort associated with the visual design.
As we demonstrated in our study, these differences in workload are not necessarily reflected in traditional performance metrics.
Exploring the use of fNIRS in visualization research, we suggested that fNIRS is well suited for the evaluation of visual interfaces that support analytical reasoning tasks.
This advantage should be particularly appealing for interface designers, as the complexity of visual analytic systems often make it difficult to apply traditional performance metrics.
Additionally, the resistance of fNIRS sensors to movement artifacts allows users to interact naturally with an interface, resulting in more ecologically sound evaluations.
We thank Dan Afergan, Andrew Jenkins, Francine Lalooses, and Garth Griffin who are students in the HCI group at Tufts; Sergio Fantini and Angelo Sassaroli from the Biomedical Engineering Department at Tufts; Jordan Crouser from the VALT group at Tufts; and Erin Solovey from the Humans and Automation Lab at MIT.
