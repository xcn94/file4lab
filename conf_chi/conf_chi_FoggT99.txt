Given the importance of credibility in computing products, the research on computer credibility is relatively small.
To enhance knowledge about computers and credibility, we define key terms relating to computer credibility, synthesize the literature in this domain, and propose three new conceptual frameworks for better understanding the elements of computer credibility.
To promote further research, we then offer two perspectives on what computer users evaluate when assessing credibility.
We conclude by presenting a stt of credibility-related terms that can serve in future research and evaluation endeavors.
Simply put, credibility can be defined as believability.
Credible people are believable people; credible information is believable information.
In fact, some languages use the same word for these two English terms.
Throughout our research we have found that believability is a good synonym for credibility in virtually all cases.
First, credibility is a perceived quality; it doesn't reside in an object, a person, or a piece of information.
Therefore, in discussing the credibility of a computer product, one is always discussing the perception of credibility.
Next, scholars agree that credibility perceptions result f?om evaluating multiple dimensions simultaneously.
Although the literature varies on how many dimensions contribute to credibility evaluations, the vast majority of researchers identify two key components of credibility:
Like many aspects of our society, credibility is becoming increasingly important for computer products.
Today, the assumption that computers are credible seems to be eroding.
As a community of HCI professionals, we should be concerned about the credibility of the computer products we create, research, and evaluate.
But just what is credibility?
And what makes computers credible?
This paper addresses these and other issues about computer credibility.
In doing so, we don't suggest easy answers; we certainly don't offer a "how to" checklist for credible computer products.
Instead, this paper  outlines key terms and concepts that relate to credibility,  synthesizes the existing literature on computer credibility,  provides new conceptual frameworks for understanding computer credibility, and  suggests approaches for further addressing computer credibility in research, evaluation, and design efforts.
By doing these things, this paper can serve as a key step toward more credible computer products-that is, more credible desktop applications, web sites, specialized computing devices, and so on.
To copy O~~WCSC,IO republish, to post on servers or to redistribute to lists.
What this means is that in evaluating credibility, a person makes an assessment of both trustworthiness and expertise to arrive at an overall credibility assessment.
Trustworthiness, a key element in the credibility calculus, is defined by the terms well-intentioned, truthful, unbiased, and so on.
The trustworthiness dimension of credibility captures the perceived goodness or morality of the source.
Rhetoricians in ancient Greece used the terms ethos to describe this concept.
Expertise, the other dimension of credibility, is defined by terms such as knowledgeable, experienced, competent, and so on.
The expertise dimension of credibility captures the perceived knowledge and skill of the source.
Taken together, these ideas suggest that highly credible computer products will be perceived to have high levels of both trustworthiness and expertise.
Many, but not all, of the above eight categories have been the focus of research on computers and credibility, as synthesized in the following section.
First of all, trust and credibility are not the same concept.
Although these two terms are related, trust and credibility are not synonyms.
For example, users may have trust in a computer system designed to keep financial transactions secure.
We suggest that one way to interpret the word trust in HCI literature is to mentally replace it with the word dependability.
One helpful  summary is as follows:
The semantic issues get slightly more complicated.
We propose that these phrases are essentially synonyms for credibility; they refer to the same psychological construct.
Table 1 shows some of the most common phrases in HCI research that refer to credibility:
One cluster of research investigates the idea that people automatically assume computers are credible.
In framing these studies, the authors state that people perceive computers as "magical" , with an " `aura' of objectivity" , as having a "scientific mystique" , as "awesome thinking machines" , as "infallible" , as having "superior wisdom" , and as "faultless" .
But what does the empirical research show?
The studies that directly examine assumptions about computer credibility conclude that.
Computers are 9oJ perceived as more credible than human experts .
As a result of these semantic issues, those who read the research on trust and machines must note if the author is addressing "trust"-dependability-or if the author is addressing "trust in information"-credibility.
We suspect that the confusing use of these English terms has impeded the progress in understanding credibility as it applies to computer products.
Now that we have defined key terms relating to credibility, we next outline when credibility matters in human-computer interactions.
Quite frankly, in some cases computer credibility does not seem to matter-such as when the computer device is invisible  or when the possibility of bias or incompetence is not apparent to users .
However, in many situations computer credibility matters a great deal.
Another cluster of research examines the dynamics of computer credibility-how it is gained, how it is lost, and how it can be regained.
Although these conclusions seem obvious, we find this research valuable because it represents the first empirical evidence for these ideas.
Other findings on the dynamics of credibility are less obvious, which we summarize in the following paragraphs.
A few studies have investigated the effects of computer errors on perceptions of computer credibility.
Although researchers acknowledge that a single error may severely damage computer credibility in certain situations , no study has clearly documented this effect.
Another research area has been the effects of large and small areas on credibility.
Virtually all researchers agree that computer errors damage credibility-at least to some extent.
Findings from these studies and other work  suggest that* Small computer errors have disproportionately perceptions of credibility.
Next, researchers have investigated how user a.cceptance of computer advice changes when users understand how the computer arrives at its conclusions.
One study showed that knowing more about the computer actually reduced users' perception of computer credibility .
These experiments have shown that-at least in laboratory settings-certain interface design features, such as cool color tones and balanced layout, can enhance users' perceptions of interface trustworthiness.
Although these design implications may differ according to users, cultures, and target applications, this research sets an important precedent in studying the effects of interface design elements on perceptions of trustworthiness and credibility.
An additional research strategy has been investigating how credibility findings from human-human interactions apply to human-computer interactions.
The following paragraphs explain key findings using this research strategy, while the final paragraph in this section outlines additional possibilities.
Common affiliation leads to credibility Psychology research shows that in most situations people find members of their "in-groups" 
Researchers demonstrated that this dynamic also held true when people interacted with a computer they believed to be a member of their "in-group" .
Specifically, users reported the "ingroup" computer's information to be of higher quality, and users were more likely to follow the computer's advice.
One type of similarity is geographical proximity.
In researching this phenomenon in HCI, an experiment showed that computer users perceived information from a proximal computer to be more credible than information from a distal computer .
Applying this phenomenon to the world of technology, researchers labeled a technology as a specialist.
Phvsical attractiveness  - Making the computing device or interface attractive.
Association  - Associating the computer with desirable things or people.
Nonverbal cues  - Endowing computer agents with nonverbal markers of credibility.
The next type of credibility, reputed credibility, describes how much the perceiver believes someone or something because of what third parties have reported.
This applies very much to computer technologies.
For example, a nonprofit consumer magazine may run tests that show Company XYZ makes highly accurate tax software.
This third-party report would give Company XYZ's computer products a high level of reputed credibility.
The third type of credibility is surface credibility, which describes how much a perceiver believes someone or something based on simple inspection.
For example, a web page may appear credible just because of its visual design .
Or the solid feel of a handheld computing device can make users perceive it as credible.
So far, our paper has defined key terms and reviewed the relevant research on computers and credibility.
We now change focus somewhat.
In this next section we offer three new conceptual frameworks for viewing computer credibility.
They are  the four types of credibility,  the two credibility evaluation errors, and  the three strategies for evaluating credibility.
We believe that having new ways to think about-and a greater vocabulary for-computer credibility will enhance our HCI community's ability to research, evaluate, and design credible computers.
Presumed credibility describes how much the perceiver believes someone or something because of general assumptions in the perceiver's mind.
For example, people presume that most people tell the truth, but we also presume car salespeople may not be totally honest.
The most notable aspects of this conceptual framework are the two errors.
The first type of error is what we call the "Gullibility Error."
In this error, even though a computer product  is not credible, users perceive the product to be credible.
Various individuals and institutions, especially those in education, have taken on the task of teaching people to avoid the Gullibility Error.
Often this is under the heading of "information quality."
The second type of error is what we call the "Incredulity Error."
In this error, even though a computer is credible, users perceive the product to be not credible.
The conceptual framework in Table 2 outlines two types of evaluation errors, but it doesn't account for different evaluation strategies people might use for assessing credibility.
For most people, evaluations of credibility are not simply accept or reject decisions, as Table 2 may imply.
Figure A illustrates these three models by making the level of user acceptance a function of the theoretical credibility of the computer product.
The most sophisticated-and most difficult-evaluation strategy is what we call Spectral Evaluation.
This model offers no black or white categories; each evaluation is a shade of gray.
The simplest strategy for evaluating a computer product is what we call YBinary Evaluation" ; users perceive the product as either credible or not credible-no middle ground.
Users are more likely to adopt the Binary Evaluation strategy when users have.
Most people use all three credibility evaluation models in different situations, with the threshold model being the most flexible and the most common.
But what determines which model people follow?
According to the ELM, people can process information through two routes: central and peripheral.
People opt for the peripheral processing route when they have little personal involvement with the issue or when they lack ability or motivation to process the information.
In contrast, people process centrally when they have high personal involvement in the issue and are able to devote adequate cognitive resources.
The Threshold Evaluation strategy includes upper and lower thresholds for credibility assessments.
If a computer product exceeds the upper threshold, users deem it credible; if it falls below the lower threshold, it is deemed not credible.
The models of credibility evaluation and the ELM have design implications for computer products.
For example, if the computer product is intended for users with low involvement or limited cognitive ability, then designers concerned about credibility need only focus on peripheral cues such as attractiveness of source, number of arguments, likability of source, and so on.
If, on the other hand, the computer product is one that is highly involving and very important to the user, then users will tend toward spectral evaluations of credibility.
In this case, users are likely to focus heavily on the content and less on peripheral cues when assessing trustworthiness or expertise.
Although HCI professionals can-and should-parse out different aspects of a computer product's credibility, people who use computers are unlikely to make these distinctions easily.
Research suggests that people may not naturally separate the credibility of one aspect of a computer product from another .
Subsequently, the credibility perceptions about one part of the computer-good or bad-will likely affect credibility perceptions of the entire product.
For a common and anecdotal example, consider perceptions of the early Macintosh computer.
The industrial design was perceived as " cute."
Because cuteness does not likely correlate with credibility, many people dismissed the entire Macintosh computing system.
Throughout this paper we have discussed users evaluating the credibility of "computer products," a general phrase we use to describe many types of computer devices, systems, and applications.
So now we ask, "What precisely are users focusing on when they evaluate the credibility of a `computer product'?"
No existing research fully answers this question, so below we offer two perspectives: a systems perspective and a psychological perspective.
In assessing credibility, we hypothesize that people can evaluate four different aspects of a computer product: the device, the interface, the functionality, and the information.
Device credibility relates to the physical aspect of the computing product.
For example, a pocket calculator can have a physical design, a density, and button detents that induce perceptions of credibility.
Interface credibility relates to the display of the computer product as well as to the interaction experience.
For example, an interface is likely to be perceived as less credible when it contradicts user expectations or mental models.
Functional credibility relates to what a computer product does and how it is done.
This includes performing calculations, services, or processes.
Functional credibility is most closely related to a strict definition of trust, as discussed earlier.
Information credibility relates to how believable the information is from the computing product.
For example, information that contradicts what a user views as "correct"  will reduce credibility.
By pairing these four aspects of a computer product with the two dimensions of credibility, one can isolate specific issues for research, evaluation, and design .
In addition to the systems perspective, we also propose that computer users adopt a psychological perspective in evaluating credibility.
For example, if a computer product provides information, who or what is the perceived source of the information?
Below we propose four "psychological targets" for credibility assessments, listed from the most psychologically immediate to the least: On-screen characters - If on-screen characters are part of a computing product, they are likely the most immediate psychological target for credibility evaluation .
Computer qua computer - The next most immediate target of credibility evaluation is the computer itself.
Brand - The brand of the computer product may be the next psychological target for evaluation.
This includes the company or institution that promotes the computer product.
Expert creator - The expert who created the computer product is perhaps the most rational target for credibility evaluation, but we propose that for most computer users the expert creator may be the least immediate psychological target of the four.
By pairing these four psychological targets of credibility evaluations with the two dimensions of credibility, one can isolate specific issues for research, evaluation, and design .
People who research, evaluate, or design computer products with credibility in mind can benefit from differentiating aspects of a computing system, as shown in Table 3.
For example, hardware designers may accept the challenge of making the device seem trustworthy, one cell in the matrix.
Web site evaluators would likely target other issues, such as the six cells that relate to the interface, the function, and the information.
HCI researchers may focus on just a single cell of Table 3 .
This may mean highlighting the product brand, if the brand has a high reputation for credibility, or it may mean highlighting the experts who created the product.
How to enhance the credibility perception for each cell in Table 4 is an important area for additional research and design.
In this way, our HCI community can not only increase our understanding about the elements of computer credibility, but we can also use this understanding to enhance our research, evaluation, and design efforts.
We hope this paper has suggested profitable areas for discovery about computers and credibility-and we hope to inspire others to join us in these endeavors.
To this end we now suggest terminology that can serve in evaluating and researching credibility.
Table 5 offers specific terms for assessing credibility of computer products, as well as assessing the two dimensions of credibility: trustworthiness and expertise.
The Effects of Human Versus Computer Authorship on Consumers' Perceptions of Psychological Reports.
Is Knowing More Really Better?
Effects of System Development Information in Human-Expert System Interactions.
Communicator Chaiken, S. Attractiveness and Persuasion.
Charismatic Computers: Creating more likable and persuasive interactive technologies by leveraging principles from social psychology.
Persuasive Computers: Perspectives and research directions.
In using the above terminology, investigations into computer credibility can either examine the credibility of the computer product as a whole, or they can probe the credibility of a specific aspect .
In doing so, investigators can use the terminology in Table 5 in a variety of ways-as Likert-type scales  or as semantic differentials .
As an HCI community, we do not yet have a standard credibility scale for our work in evaluation, design, and research; therefore, we suggest using the items in Table 5 as a step toward creating a valid and reliable " Computer Credibility Scale."
Our intent in this paper has been to raise awareness in the HCI community about the elements of computer credibility in order to encourage additional work in this area.
To the best of our knowledge, this paper makes a unique contribution to the field of human-computer interaction because it is the fast document to synthesize the previous research in computer credibility, to suggest new frameworks for understanding this domain, and to propose various issues for continued research, evaluation, and design of credible computing products.
The scope of this paper has been as broad as possible in order to capture credibility issues common to most computer products.
Attitudes Towards Specific Uses of the Computer: Quantitative, decision-making and record-keeping applications.
Designing Towards Emotional Usability in Customer Interfaces: Trustworthiness of cyber-banking system interfaces.
