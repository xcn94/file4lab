Previous lab-based studies have indicated interesting trends in people's preferences for certain gestures to accomplish particular actions .
However, to observe how gestures emerge as part of people's individual and social interactions around the digital display, we found it important to study the use of multi-touch gestures in a real-world walk-up-and-use context.
We focused on the following questions:  What characterizes multi-touch gestures that people apply in walkup-and-use scenarios?,  How do gesture types differ between different visitor groups such as adults and children?, and  What factors influence the choice of multi-touch gestures in walk-up-and-use scenarios?
This study of multi-touch gestures in the wild provides a detailed picture of real-world gestures to inform the design of multi-touch gesture sets.
Our observations have led to new insights into the composition of gesture sequences.
While previous work generally establishes one-to-one mappings between actions and gestures that trigger them , our findings indicate that multi-touch gestures are part of integrated interaction sequences.
The flow and physical ease of transitions between gestures affect the formation of the subsequent gesture.
Also, we found that contextual social factors  and social encounters that emerge during exhibit exploration influence the choice of multi-touch gestures.
We therefore argue for enabling a variety of gestures for each action  to support fluid gesture sequences and social interactions.
In this paper we describe our findings from a field study that was conducted at the Vancouver Aquarium to investigate how visitors interact with a large interactive table exhibit using multi-touch gestures.
Our findings show that the choice and use of multi-touch gestures are influenced not only by general preferences for certain gestures but also by the interaction context and social context they occur in.
We found that gestures are not executed in isolation but linked into sequences where previous gestures influence the formation of subsequent gestures.
Furthermore, gestures were used beyond the manipulation of media items to support social encounters around the tabletop exhibit.
Our findings indicate the importance of versatile many-to-one mappings between gestures and their actions that, other than one-to-one mappings, can support fluid transitions between gestures as part of sequences and facilitate social information exploration.
The recent interest in multi-touch interaction has led to a plethora of gesture-based interaction techniques, e.g.
At the same time, there is a growing use of interactive surfaces in public exhibition spaces such as museums , galleries , and urban spaces .
Previous findings have indicated that public walk-up-and-use displays benefit from multi-touch interaction by providing pleasurable and playful experiences .
However, the design of multi-touch gestures for such scenarios is still a significant challenge due to short interaction times and diverse audiences with varying expectations toward technology.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Since the seminal work of Kruger in the 1970s advocated for the design of responsive interactive systems  there has been a large number of research and commercial systems that rely on touch and gesture to provide interactivity .
In the following sections we summarize previous work on the design of multi-touch gesture sets, empirical and theoretical studies on the use of touch interaction as well as observations of people's touch interactions in public settings.
To investigate the spontaneous use of multi-touch gestures in public walk-up-and-use settings, we accepted an invitation from the Vancouver Aquarium to study their newly acquired interactive tabletop exhibits.
This was an ideal opportunity to observe how people freely interact with multi-touch displays as part of their visit through the aquarium.
The multiple investigations into the design of multi-touch and multi-point gesture sets include Ringel et al.
Previous systems generally pursue the design of parsimonious gesture sets where a single action is performed through a unique gesture.
This approach was expanded by Wobbrock et al.
This approach has been further applied to other contexts .
Although in this work we do not address the design of a gesture set , our findings are relevant for the design of future gesture sets and depart in several ways from predominant paradigms.
The Vancouver Aquarium features a vast amount of information about the Canadian Arctic, which is a fragile habitat that is rich in biodiversity.
With a height of 86cm, the digital tables invite interaction of both children and adults.
In our study, we focused on visitor interactions with the Collection Viewer because it features an unstructured and dynamic interface that allows for more free-form gestures than the Arctic Choices application which is mostly based on sliders and dials.
Guiard's work on bimanual manipulation  forms the foundation for much of the current empirical work on multi-touch gestures .
The work of Nielsen et al.
Because we focus on walk-up-and-use scenarios, we are not as concerned with performance and efficiency; however, our observations echo some of these findings and propositions, as well as the results from other work comparing the manipulation of physical and digital artifacts .
We build upon this work and bring to the front the influence of gesture sequences and the social context of interactions for the choice and use of multi-touch gestures.
This collection of media items covers topics about the Arctic environment, including living creatures and environmental issues.
The content is constantly in flux: items are removed and replaced depending on how much visitors interact with them.
For every media item that disappears, another one appears in a different location close to the center of the table.
A movie reel icon is used to distinguish videos from static media items.
Contextual relations between media items are visualized through labeled connection lines.
Several field studies have investigated people's approach and interaction with large direct-touch surfaces in public settings .
At a basic level, our work corroborates many of the valuable findings from these studies; e.g., like Peltonen et al.
However, previous research in this area has not focused on the choice and use of multi-touch gestures, and only reports high-level findings.
We expand on this by investigating the sequential nature of gestures, an approach that has not yet been addressed previously.
We also provide a detailed analysis of the range of gestures that were performed and discuss the effects that the presence and interactions by other people introduce on the use of gestures.
In addition, each media item is equipped with buttons to bring up additional textual information or to delete it from the table surface.
The Collection Viewer does not feature any help system or guiding instructions to explain functionalities or interaction techniques, but lets visitors discover interactions through exploration.
Our study is based on an ethnographic approach .
This enabled us to observe visitors' interactions while minimizing intrusion that might have biased their activities.
We are not affiliated with the Vancouver Aquarium or the digital table manufacturer.
Therefore, there were no conflicts of interest between our observations and the success of the exhibit.
The study was conducted approximately two months after the first deployment of the interactive tables at the Arctic exhibit.
We installed two small high definition video cameras in unobtrusive locations above and beside the Collection Viewer table.
The collected video recordings of visitors' gestures on the interactive surface from different perspectives form the basis for our interaction analysis .
The study took place during eight days: one weekend before, and six consecutive days during the Christmas school holidays.
During this time we collected field notes and video data on-site for three to four successive hours each day.
Study sessions took place between 11am and 5pm during both high and low visitor traffic.
A static sign in the proximity of the table informed visitors that observations were taking place and that video was being recorded.
An observer from our team was present during each study session, taking notes of the interactions and activities that took place around the table.
The observer wore casual clothes to blend in with the visitor crowd and kept sufficient distance from the table to avoid affecting visitor activities.
In total, approximately 20 hours of video data was collected with each camera.
We also recruited groups of visitors and accompanied them on their aquarium visit.
This shadowing technique  allowed us to learn about visitors' experiences of aquarium exhibits firsthand.
In this paper, however, we focus on the findings that resulted from our analysis of the collected video data in conjunction with our field observations.
Gestures included in our analysis were performed by 20 children  and 20 adults .
The age of these visitors ranged from toddlers interacting with their parents' help to elderly visitors.
Each gesture was coded according to intended action , number of hands used, hand posture , hand and finger movement, and the targeted interface element .
We occasionally transcribed activities and verbal comments cooccurring with gestures.
From our initial set of 943 gesture instances, 17 could not be clearly identified and were therefore excluded from our data analysis, leaving us with 926 coded and classified gesture instances .
We quantified some of this qualitative data by counting particular activities and gesture occurrences to help characterize interactions further.
Visitors engaged in a large variety of activities while exploring information on the Collection Viewer, both individually and collaboratively.
Activities included browsing through media items, taking a closer look at images, playing videos, or playfully tossing items back and forth between each other.
From our observations, it became apparent that these activities can be decomposed into sequences of low-level actions.
The intent of these low-level actions was generally apparent from the context; for example, the ongoing conversation, repeated attempts, or the expression of satisfaction or frustration often clearly exposed visitors' intentions.
In our terminology, the higher-level intent is executed through a sequence of low-level actions, or sub-tasks.
For instance, curiosity could spark intent to examine a media item .
To achieve this, visitors might drag the item toward themselves, rotate it into the desired orientation, and enlarge it .
We classified these low-level actions in which visitors commonly engaged into seven categories: drag/move, enlarge/ shrink, rotate, tap, sweep, flick, and hold.
Typically, transitions between such low-level actions would happen smoothly and rapidly, often blurring the boundaries between actions and appearing as a unified activity.
To execute each of these possible low-level actions, visitors applied a large variety of gestures.
The drag/move action, for example, was performed at different times and by different people through single-handed, bimanual, single-finger and multi-touch gestures.
We noticed general trends in the choice of gestures for low-level actions but, most interestingly, we observed that the visitors' choice of gestures was strongly influenced by the sequence of actions they had just performed.
We call this the interaction context.
Usually, visitors chose gestures that are physically easy to perform as a continuation of the ongoing gesture sequence.
Further, we also found that the choice of gesture is influenced by social factors such as number of visitors and social relationships between visitors that we call the gesture's social context.
In the following we describe the low-level actions, noting the variety of gestures applied to each action and their composi-
We followed a two-pass video analysis strategy .
To gain an overview we fast-forwarded through all video data, broadly transcribing interaction times and activities.
These broad transcriptions were then used to select an hour-long subset of video data for an in-depth coding for different types of multi-touch gestures and activities.
This data subset was selected from two different days to provide data from a broad range of visitors of different age and gender and a range of interaction times and activity levels around the table.
For our multi-touch gesture analysis we analyzed 943 gesture instances in-depth, regardless of whether they led to successful responses of media items or not.
3 and 4 show, visitors mostly applied single-handed gestures to drag/move media items.
The enlarging or shrinking of media items was the second most common action.
Visitors applied gestures similar to those observed by Wobbrock et al.
We categorized all coded 926 gesture instances based on the observed low-level actions .
3 shows an overview of the amount of single-handed  and bimanual gesture instances that were applied for each action.
4 shows the number of observed visitors that engaged in each action using single-handed and bimanual gestures.
The following descriptions of each observed lowlevel action are accompanied by figures showing example hand postures used for each action.
The arrows in these figures indicate movement; the circles touch points.
Note that some of these percentages include posture variations  unless stated otherwise.
Due to space constraints we do not provide figures for all gesture variations that were applied.
They usually affected several media items at once.
Mostly children engaged in sweep actions, often in phases of playful information exploration.
3 and 4 show that adults applied single-handed sweeping gestures only, while children also frequently used bimanual gestures.
For sweeping, visitors generally preferred gestures that take up a lot of space.
When applying bimanual sweeping gestures visitors sometimes did not move both hands simultaneously across the table surface but, instead, alternated rapidly between both hands.
However, visitors also used their hands in asymmetric ways .
In these cases, the motion of hands remained symmetrical and both hands engaged in the same action targeting the same item.
In other cases, each hand was engaged in a different lowlevel action at the same time, targeting different media items.
As in an earlier study , it seems that visitors adopt this asymmetrical use of both hands from their previous experiences with manipulating objects on physical tables.
Most visitors applied hold actions  to make a media item stay in place, e.g., when someone else tried to grab it or when it slid away unintentionally.
We also observed instances where visitors used each hand for different low-level actions targeting the same object.
For instance, media items often slipped away due to some unintended interactions by other visitors.
Although our data does not allow the identification of visitors' dominant and non-dominant hands, this asymmetrical use of hands suggests the adoption of interactions styles from the physical world: the non-dominant hand  creates a frame of reference for the dominant hand  .
Visitors combined the aforementioned seven low-level actions to achieve higher-level goals such as browsing through a group of media items, finding and playing video items, or taking a closer look at a media item.
For example, to achieve the latter visitors would drag the media item toward themselves and, while dragging, rotate and enlarge the item simultaneously into the desired position.
In other cases, visitors would rapidly switch between enlarge, hold, and drag/move actions to enlarge the media item in several passes while preventing it from sliding away to a different position of the table.
Transitions between such low-level actions happened fluidly and near instantaneously: in 9% of all observed gesture instances the exact point of transition between actions could not be identified.
We found that visitors' choice of gestures was strongly influenced by the context in which the current action occurred and not only based on preferences for a given gesture for a particular action.
This interaction context is determined by the type of gesture that a visitor has just performed for the previous action, because the characteristics of this previous gesture  influence how comfortably and smoothly the transition into the next action can be achieved.
We observed that visitors often tried to keep their hand postures, only changing their hand or arm movement to transition fluidly from one action to the next.
Such transitions were observed, e.g., between enlarge/shrink and rotate actions.
13 shows a visitor enlarging an item and rapidly transitioning to rotation.
Also, visitors fluidly transitioned between single-handed and bimanual gestures, but again, without changing the hand posture of the first hand.
In some cases, even unpopular gestures were chosen specifically to facilitate fluid transitions between actions.
We observed equivalent strategies with bimanual move gestures in the context of bimanual rotation.
Similarly, visitors would use a full hand flick gesture right after full hand move and resize actions.
Our observations of how visitors fluidly transitioned between actions through the choice of gestures can be discussed in light of compound tasks: activities composed of a sequence of low-level actions or subtasks .
For instance, trying to bring a media item closer to oneself to take a closer look can be described as a compound task including a drag/move, enlarge, and rotate action.
Commonly, people do not consciously think about these subtasks, but consider the compound task as a single entity .
Similarly, our observations indicate that visitors did not plan their activities on the Collection Viewer in advance, but followed their high-level intention while spontaneously reacting to the response of media items, and fluidly adjusting their subsequent gestures accordingly.
It is therefore important to design multi-touch gestures not only as a one-to-one mapping between actions and gestures, but to also consider how they can be embedded into, and support smooth transitions between sequences of low-level actions.
We found that children usually engaged in playful interaction, such as tossing media items back and forth between each other, gathering as many media items as possible, or trying to delete all media items by frantically flicking them toward the surface boundaries.
Similarly to Jacucci et al.
Our quantitative analysis comparing the occurrence of lowlevel actions of adults and children shows that the frequencies of drag/move and enlarge/shrink actions are relatively similar among both adults and children.
This is an indication for adults' stronger interest in the content of media items, since rotate and tap are more content-oriented actions.
We also noticed differences regarding gesture types.
Furthermore, they engaged in coarsegrained gestures involving the flat hand or even arms and sleeves more frequently than adults.
In contrast, adults more often applied single-handed gestures involving one or two fingers, enabling more fine-grained interaction.
These findings are in keeping with the notion that children explore the physical world in a more hands-on way.
Previous studies showed that children quite assertively enforce their intentions and try to retain control through gestures on and above the table in small-group collaborative scenarios  as well as in the context of physical museum exhibits .
Expanding on these findings, we observed that children frequently made use of gestures to express or claim a dominant role around the Collection Viewer table when interacting within a group of other visitors .
In contrast, adults would restrain themselves to single-handed gestures, especially when the table was crowded, probably to not interfere with other visitors' interactions.
We also observed parents physically restraining the large-scale hand movements of their children to try and prevent them from dominating the interaction around the table.
The number of visitors interacting with the Collection Viewer influenced children's and adults' use of gestures in different ways: while children made use of gestures to keep their interaction radius relatively large, adults' use of gestures shows a  respect of other visitors' personal territories that has been observed in previous research .
Through our study observations we noticed that public multi-touch interaction is also deeply embedded in a social context.
People usually visit exhibition spaces, such as aquariums and museums, in groups and, during their exploration of exhibits, encounter interactions of other people .
This social context defined by the presence of other visitors influences if and how people approach public exhibits  and how they experience and react to them .
Expanding on these findings, we found that this social context also has an influence on the choice and use of multi-touch gestures.
As we describe in the following sections, multi-touch gestures evolved to express a personal opinion about information or to collaboratively explore information in a group.
Furthermore, the way that people interacted with the Collection Viewer was influenced by the observation of other visitors interacting at the same time, and by direct guidance from peers.
Similarly, we found that the choice of gestures and the way they were conducted often went beyond object manipulation but served as a means for expressing opinions and emotions.
18, for instance, pushes away an image that her brother had brought up showing a bug-like creature.
Vividly demonstrating her repulsion against the image, she used a bimanual flat hand gesture to forcefully push the item away, and even extended the gesture by lifting both her hands up into the air with the palms pointing away from the item.
She emphasized her gesture by yelling: "No!
In this instance, however, the bimanual flicking gesture is used to not only flick the media item away but to emphasize an emotion.
In such collaborative contexts, gestures were chosen particularly to serve the group: for example, holding gestures included the finger tips only rather than the flat hand and were applied on the edge of the media item to not obscure the group's view of the item.
Although the Collection Viewer does not provide any instructions on how to interact with media items, hands-on exploration was not the only way in which visitors became familiar with the various multi-touch gestures.
Some visitors demonstrated gestures to other people, even to strangers.
Also, as mentioned earlier, we observed parents restraining their children from applying gestures that could interfere with other visitors' interactions.
Furthermore, we observed some instances of imitation.
In one case, an adult visitor used both arms to herd as many media items as possible into his own corner.
In another case, a boy watched a girl sweeping items across the table surface using her sleeves.
Shortly after, he tucked away his hand inside his sleeve and tried to interact in a similar way.
While we only observed few cases of gesture imitation that were that obvious, we believe that this sort of learning-through-imitation occurs frequently on more subtle levels.
Visitors' experience of an exhibit is greatly shaped by how they observe other visitors experiencing it.
The way people apply multi-touch gestures on a tabletop exhibit can tell a story of how they experience this interaction or even the content they interact with.
The ability to apply multi-touch gestures in a versatile way to communicate opinions and emotions can therefore be highly important for the success of multi-touch exhibits.
All of these examples show how visitors' choice of gestures was strongly influenced by other visitors and the current social interaction.
Although it is likely that the social context plays a similar role in environments other than public exhibition spaces, it is especially important to consider the social context in walk-up-and-use scenarios where people only interact for brief periods of time and without any instructions or practice.
In these situations they are more likely to turn to other people's interactions as a frame of reference.
In exhibition spaces such as aquariums and museums the social aspect of information exploration plays an important role as it greatly shapes visitors' overall experience of the exhibition .
It is therefore crucial to design for versatile multitouch gestures that can be chosen and adjusted flexibly to facilitate group interaction and mentoring, and to communicate emotions and personal opinions.
Instead, the way how other visitors reveal their personal experience of a piece  influences people's own reactions .
This visibility of other visitors' reactions can be quite important for the success of an exhibit .
We therefore recommend supporting a range of versatile multi-touch gestures that, while enabling the manipulation of interface items, can facilitate a variety of social encounters that evolve around the exhibit.
We have discussed how multi-touch interaction is deeply embedded in an interaction and social context that can influence both the choice and use of multi-touch gestures on walkup-and-use interactive exhibits.
Our findings point toward three design considerations that are directly applicable to multi-touch tabletop exhibits and are likely to have an impact on the design and evaluation of multi-touch interaction with large displays in general.
While previous work on multi-touch gestures has led to a number of design implications and principles , examples of multi-touch gesture sets have mostly focused on finding a sensible one-to-one mapping between an action  and a gesture.
These gestures are often differentiated from each other by the number of touch points, hand movement, and posture.
However, our study findings indicate that multitouch gestures are deeply embedded in an interaction context, i.e., sequences of actions that are characterized by fluid transitions in-between and lead up to a compound task .
The choice of a gesture for a specific action is therefore not only dependent on personal preference or the quality of the gesture-action mapping, but also on the gestures applied for prior low-level actions.
Since our findings indicate that people try to transition between gestures in smooth, physically easy ways, gestures sets must be designed to facilitate these transitions and enable fluid action sequences that support high-level tasks.
This involves taking into account the required changes in posture, movement, and number of hands and fingers used.
As in dance, for a gesture to be comfortable', it is important to be able to adjust gestures to fluidly transition from one gesture to the next.
Exhibition spaces such as the Vancouver Aquarium target a large and diverse audience.
Our study shows vast differences in the choice and use of gestures, especially between children and adults.
At the same time, walk-up-and-use interactive exhibits only have a few moments to attract visitors' attention and provoke an interaction with the presented information.
It is therefore important to support a variety of single-handed and bimanual multi-touch gestures for each single action to make sure that the different gesture choices of visitors lead to a rewarding experience.
In that way, the design of multi-touch gestures on the Collection Viewer is a successful example because gestures are defined in a flexible way that allows for different hand postures and different numbers of touch points to get the same result.
Designing for flexible multi-touch gesture sets that incorporate a variety of hand postures, number of touch points, and number of hands is also important to consider for scenarios other than exhibition spaces.
As we have shown, interaction and social contexts, even within a single environment, can be diverse and fluidly changing.
To account for this, each low-level action that people might engage in would benefit from being mapped to a variety of gestures instead of just one.
We document examples of how, in an exhibition space, social factors influence people's choice and use of multi-touch gestures.
Visitors interacting with the table in close proximity directly or indirectly influenced each others' choice of multitouch gestures.
Furthermore, we found that visitors chose particular multi-touch gestures to communicate their opinion about certain content or to socially explore media items within a group.
We have described and discussed the findings of a field study that investigated factors that influence the choice and use of multi-touch gestures on large horizontal displays in a walkup-and-use exhibition space.
The main contribution of our work is the finding, supported by our observations, that a whole variety of gestures may be natural for any given intended action and that the choice of these gestures is influenced by their interaction context and their social context.
In other words, gestures should not be considered in isolation from previous and subsequent gestures, and different people will use different alternative gestures for the same action depending on the social context, their age, and their overall intention.
We also present complementary data showing differences between children and adults, single- and bimanual interaction, and symmetric and asymmetric actions.
Although the implementation and circumstances of the exhibit that we studied necessarily constrain the immediate generalizability of our results, we believe that our observations provide solid evidence and have important implications for the design of future gesture sets.
ACKNOWLEDGMENTS We thank the Vancouver Aquarium, in particular Jeff Heywood, for supporting our study at the Canada's Arctic exhibit.
We also thank our study participants.
Special thanks go to Miguel Nacenta for his invaluable advice and help with this this paper.
We thank Lindsay MacDonald and Jagoda Walny for their help with editing.
We thank our iLab colleagues and our funding agencies  for their support.
J. Blomberg, J. Giacomi, A. Mosher, and P. Swenton-Wall.
Participatory Design, chapter Ethnographic Field Methods and their Relation to Design, pages 123-155.
H. Brignull and Y. Rogers.
Enticing people to interact with large public displays in public spaces.
Chunking and phrasing and the design of human-computer dialogues.
A comparison of user-generated and automatic graph layouts.
Shadowguides: Visualizations for in-situ learning of multi-touch and whole-hand gestures.
M. Frisch, J. Heyekorn, and R. Dachselt.
Diagram editing on interactive displays using multi-touch and pen gestures.
Asymmetric division of labor in human skilled bimanual action: The kinematic chain as a model.
M. Hancock, S. Carpendale, and A. Cockburn.
Shallow-depth 3d interaction: Design and evaluation of one-, two- and three-touch techniques.
C. Heath, P. Luff, D. vom Lehn, and J. Hindmarsh.
U. Hinrichs, H. Schmidt, and S. Carpendale.
EMDialog: Bringing information visualization into the museum.
Interactions around a contextually embedded system.
G. Jacucci, A. Morrison, G. Richard, J. Kleimola, P. Peltonen, L. Parisi, and T. Laitinen.
Worlds of information: Designing for engagement at a public multi-touch display.
B. Jordan and A. Henderson.
Interaction analysis: Foundations and practice.
C. Latulipe, C. Kaplan, and C. Clarke.
Bimanual and unimanual image alignment: an evaluation of mouse-based techniques.
