We propose Augmented Letters, a new technique aimed at augmenting gesture-based techniques such as Marking Menus  by giving them natural, mnemonic associations.
Augmented Letters gestures consist of the initial of command names, sketched by hand in the Unistroke style, and affixed with a straight tail.
We designed a tentative touch device interaction technique that supports fast interactions with large sets of commands, is easily discoverable, improves user's recall at no speed cost, and supports fluid transition from novice to expert mode.
An experiment suggests that Augmented Letters outperform Marking Menu in terms of user recall.
Keyboard shortcuts are remarkably fast, but are difficult to learn  and are not available on many typical mobile devices.
In contrast Marking Menus, which support a seamless transition from novice to expert mode, are very well suited to touch-based interaction.
However, they rely on an arbitrary mapping between commands and directions, meaning that mappings need to be learned from scratch.
Another limitation is that they cannot accommodate more than eight directions or so , making a hierarchical organization necessary.
Some variants use additional parameters like curvature or shape  to increase menu width, but the command/gesture mapping remains arbitrary.
We describe Augmented Letters, a novel gesture shortcut that combines unistroke letters with Marking Menus.
The aim is to simplify command memorization and to reduce the cognitive load by using the initials of command names as gesture shortcuts.
The stroke is augmented with a tail that can be oriented in up to eight directions, so as to handle conflicts amongst commands that share the same initial.
Augmented Letters flatten the command hierarchy, reducing it to a mnemonic plus a direction.
Using the novice mode of the technique, users can fluidly turn into experts through rehearsal.
Present the design of Augmented Letters and *!
Report the results of a user study suggesting that a set of commands is easier to memorize with Augmented Letters than with Marking Menus.
This is the author's version of the work.
It is posted here by permission of the ACM for your personal use.
The definitive version was published in CHI '13: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, April 27 - May 2, 2013, Paris, France.
Augmented Letters capitalize on the fact that the various skills that constitute the human language are considerably overlearned .
In the literate adult, owing to a considerable amount of sustained practice, naming, reading, typing, and handwriting are remarkably automatic, despite the well-known arbitrariness of the linguistic sign .
In this regard, the classic psychology of reaction time  teaches some interesting lessons.
As expressed by the Hicks-Hyman law , choice RT increases linearly with the logarithm of the number N of alternatives.
But no less important is the fact that the slope of that linear dependency strongly depends on training: for example, Fitts and his colleagues  have shown that the slope of the HicksHyman law virtually zeroes out if the task is to utter the name of visually presented characters: the duration of such a reading reaction is not just short, it is hardly affected at all by the size of the stimulus set.
This class of findings is of relevance to HCI when it comes to the design of input vocabularies.
In general, the larger the set of possible commands, the more difficult the choice, yet if the memory link has been trained to the point it becomes automatic, the number of alternatives matters no longer.
Hence our general argument that the design of gesture shortcuts for touch screens should leverage over-trained linguistic mappings as much as possible and introduce new mapping conventions parsimoniously.
It should take the user of a mobile device little effort, having retrieved from long-term memory the name of a known command, to identify its initial letter, and to sketch its shape on a touch screen, as such a sequence involves no extra arbitrariness whatsoever.
Or, shifting the emphasis from speed to contents, it should be relatively easy to master a pretty large vocabulary of commands with a gesture code that relies on old handwriting habits.
HCI researchers, having only recently fully realized the considerable potential, for input on mobile device, of the gestures that consist of cursive fingertip tracing , still face a very large design space.
The present paper presents a preliminary exploration of the possible advantages of jointly exploiting the merits of marking menus, known to minimize the effort in movement space , and handwriting, known to rely on over-trained linguistic associations.
In fact there are a few conflicts, e.g.
We counted about six of them depending on the recognizer, leaving 208-6=202 different commands.1 Two cases are possible.
If the user knows the tail, he will trace the complete augmented letter.
Otherwise, he will just draw the letter and then wait 500ms  for a marking menu to appear, showing the possible tails and the corresponding commands .
Thus, just as with Marking Menus, Augmented Letters allow a fluid transition from novice to expert mode , with the same gestures serving to invoke the same commands in either mode.
Our implementation relies on the $1 recognizer .
In novice mode the recognition, performed before the tail is drawn, uses a specific recognizer of  letters.
In expert mode, in which the whole gesture  needs to be recognized, we found that using a different recognizer depending on the direction of the gesture's tail minimized the probability of recognition error.
Augmented letters have a potential to provide quick access to a large set of commands.
We conducted an experiment focusing on learning inspired by .
The goal was to evaluate the performance of Augmented Letters  relative to Marking Menus , a widely-accepted baseline.
Our instructions emphasized memory accuracy over performance speed.
Accordingly, the primary dependent measure was the percentage of correct recall.
An augmented letter is a Graffiti-like unistroke letter  which is 'augmented' with a tail that may point in up to eight directions .
The letter typically is the initial letter of the associated item, thus allowing a straightforward semantic mapping between the gesture and the command.
On the other hand the tail makes it possible to differentiate between items that start with the same letter, hence handling name collisions.
Up to eight commands can thus be specified with one handwritten letter.
Being interested in the memorization of large item sets, we wanted to be sure we exceeded users' short-term memory, plausibly estimated at 5-9 items .
Non-hierarchical MM can hardly exceed eight angular sectors.
Our MM thus had one special sector, labeled "others", that gave access to a second level with eight additional items.
This yielded a total of 7+8=15 possible items for the MM.
We would have preferred a larger item set, but this would have disadvantaged the MM technique.
Item vocabulary were chosen in order to form 5 groups of items starting by the same letter, making 5 different AL with 4 possible tail directions.
1 In a complementary study, we inventoried the number N of commands available in 32 Macintosh applications.
Using this real-world corpus, the probability p of the initial letter referring to more than eight commands increases linearly with N, the best-fitting equation being p=0.0019N -0.07, r=.92.
Mobile devices use relatively lightweight software, and so the concern about command conflicts with AL is almost certainly manageable.
For example with 50 commands, the predicted probability of the initial letter being shared by more than eight commands is a modest 0.025.
Two sets of items containing country names and animal names were used.
In order to avoid memory interference, the two techniques were not intermixed.
The experiment was divided into two successive parts, one dedicated to each technique.
Technique order was balanced amongst participants using a Latin square.
The corresponding mean performance speeds are presented in Figure 5.
The recall time in expert mode was the same with AL and MM .
Parsing the response time into a reaction time  and a gesture-execution time , there were differences.
This latter finding is consistent with the view that the initiation of an AL benefitted from the high familiarity of the cognitive path leading from a word, be it a country name or of computer commands, to its handwritten expression.
The participant was instructed to try to memorize as many gestures as possible.
Each block started with the name of the technique involved and the block type .
Each trial was preceded by a circular countdown.
The name of the target was then displayed in the top region of the screen and the participant was to then perform the corresponding gesture.
The trial ended when the user released the finger from the tablet, triggering the next trial.
Our design protocol is schematized in Figure 2.
The same 12 items were served in three successive learning blocks, each item being presented three times in a row .
In a learning block, the participant was free to wait for the menu or to respond in expert mode.
A test block immediately followed each learning block .
In this mode no menu was available, the participant having to recall the items from memory.
We examined novice-mode recall time data from the first learning block of the experiment to see how the participants managed with the two techniques when first discovering them.
Although marginally significant, this outcome is certainly not inconsistent with the view that the benefit entailed by recourse to an over-trained code was immediate.
In learning blocks the participants were free to either wait for the menu  or to perform the hierarchical gesture straightaway .
It was easier for our participants to learn letter tails than two freshly defined mappings at both the first and second level of MM.
We do not wish to over-interpret the results of this small exploratory experiment, which we just offer as an illustration for a tentative point.
The logic of the classic graphical user interface  , with its desktop metaphor, its direct manipulation paradigm, and its menu plus mouse-pointing protocol, is hard to extend to tablets and smartphones.
Many basic commands like cut-and-paste are cumbersome on current smartphones.
The remarkable efficiency on the PC of keyboard shortcuts, which rely on language associations, may not have received all the attention it deserves in HCI research.
Solutions to the input problem offered by the GUI have been enormously successful, allowing millions of novices to get acquainted with computers.
However, expert users still prefer to resort to keyboard shortcuts, and the uninterrupted proliferation of commands in the GUI has become problematic .
Increased awareness that language is a major underexploited input resource in mobile computing might usefully encourage HCI research to further explore the potential of handwriting, along the lines currently suggested by Li and his colleagues .
The larger the set of commands, the greater the benefit that can be expected from the over-learned skills of language such as drawing letters.
Users being able to memorize more AL than MM gestures, at apparently no speed cost, the AL technique seems well-suited to touch-screen interfaces, which badly miss keyboard shortcuts.
