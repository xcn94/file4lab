Tangible User Interfaces are well-suited to handling threedimensional data sets by direct manipulation of real objects in space, but current interfaces can make it difficult to look inside dense volumes of information.
This paper presents the Handsaw, a system that detects a virtual cut-plane projected by an outstretched hand or laser-line directly on an object or space and reveals sectional data on an adjacent display.
By leaving the hands free and using a remote display, these techniques can be shared between multiple users and integrated into everyday practice.
The Handsaw has been prototyped for scientific visualizations in medicine, engineering and urban design.
User evaluations suggest that using a hand is more intuitive while projected light is more precise than keyboard and mouse control, and the Handsaw system has the potential to be used effectively by novices and in groups.
Expert knowledge is usually required to interpret these complex visualizations, in part because it can be difficult to map the `slice' to its three-dimensional position and orientation on the physical environment or volume.
Three-dimensional data sets are common tools for visualizing spatially complex information which cannot be represented adequately in two dimensions.
One source of volumetric data sets is magnetic-resonance imaging , which represents biological structures as a sequential set of parallel slices.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
For example, a radiologist needs to interpret an MRI for patients to understand which part of their tissue is damaged.
Architects make many decisions based on sectional drawings, but clients are shown perspective renderings and floor plans.
Two main problems are the difficulty of relating sectional images to three-dimensional space, and the inability for experts to share their interpretation of sections with novices.
Tangible User Interfaces  can facilitate collaborative interaction with 3-dimensional data by using hands to grasp and manipulate real objects in space .
But most TUIs for exploring volumetric data rely on using tools detached from the object being investigated, complicating the mapping and reducing collaboration possibility.
A doctor and her patient can use the system to communicate the specifics of an injury while making it clear for both where the relevant region occurs directly on the patient's body.
The technique can be used to investigate a gaseous or liquid medium with complex dynamics, such as local atmospheric conditions or temperature flows.
The Handsaw has been prototyped for applications in medicine, product design and earth science and was evaluated in comparison with mouse-and-keyboard controls.
Direct cut-place projection is a promising technique for reducing the complexity of three-dimensional data sets and more intuitively revealing the points of interest in a volume to multiple users.
Using one's hand to `slice' a volume can be more intuitive than using a mouse, while using a laser can be more precise.
We will expand the system to support more flexibility in a variety of real-world diagnostic and design applications.
Despite the fact that the slices do not represent the actual body of the user, the direct mapping of the hand-held hoop to the body creates the illusion that users are seeing their own insides represented on the adjacent screen.
One-to-one mapping makes it possible for novices and by-standers to understand the relationship of the medical images, yet the distance between the body and hoop makes it difficult to establish a precise location for the slice on the body.
One tangible design interface uses the outstretched hand to define a complex surface without the use of additional tools .
By using the hand as a control interface it may be easier to intuitively decide cross-section location.
Intuitive direct mapping to a real object and the use of the hand as input could make sectional information easier to define and understand.
Cross-sections are a conventional graphic technique for looking inside volumetric data, and a number of graphical and tangible interfaces have been developed to facilitate `slicing' volumes of information.
Graphical user interfaces commonly rely on abstract keyboard and mouse controls to move a virtual cut-plane through an on-screen volume, revealing the specific makeup of each slice.
Tangible User Interfaces  can facilitate three-dimensional design by seamlessly integrating digital information with physical objects .
In one TUI, landscape designers can sculpt a terrain by directly interacting with a sandbox .
The physicality of such an interface makes it easy to map threedimensional information and allows multiple users to interact at the same time, regardless of skill .
A number of TUIs have been proposed to help define slice planes through abstract objects, but they can be difficult to use collaboratively.
In the first, a doctor can explore on-screen slices of a brain scan by manipulating a doll's head in one hand with reference to an acrylic plane held in the other .
In a similar TUI, a cube held in one hand represents the object being sliced while an oversized hoop held in the other defines a cut-plane .
Both of these interfaces require both hands and rely on decoy objects to represent both the volume being explored and the cut-plane.
While they allow for complete three-dimensional rotation of the object and its cut-plane, these interfaces are too opaque and to share the information with an observer.
In a different approach, a cubic volume of sugar cubes is projected with sectional information, and as cubes are added or subtracted the projection changes to reveal the sections lying above or below .
Another interface uses a vertical acrylic sheet sliding along a tabletop to represent a cut-plane through a building, with the resulting section projected directly on the sheet .
These techniques are simpler because they require only one hand and can be used by groups; but they rely on decoys of the objects being investigated: a pile of sugar cubes in one, and thin air in the second.
The Handsaw is developed as a tool for direct volumetric slicing with special regard for making the interaction intuitive and non-intrusive enough to be integrated in everyday practice.
The system is designed to expand the tangible manipulation of volumetric data to slice real objects as well as invisible volumes such as air with greater precision than existing systems.
The use of symbolic tokens such as scale models or abstract shapes is replaced by directly slicing the volume being investigated whenever possible so that the user and spectators can intuitively locate sectional information, as in the body scanner.
Our system is designed to provide precise mapping of the section-cut line by projecting a crisp line directly onto the envelope of the volume from a handheld projector, revealing the location and shape of the slice.
The Handsaw can also be used to slice an invisible volume such as the air in a room by orienting an outstretched hand in space.
Finally, the Handsaw is designed to require as few hands as possible and to be simple to use so that participants are free to act normally and concentrate on the task of sharing information with each other.
The Handsaw uses a vision recognition system based on a webcam so that it can be oriented at a workbench, onto an object or body, and in a larger space.
In all cases, the item being sliced is directly acted upon and the resulting section shown on an adjacent display.
The camera detects a linear red shape emitted by laser line projector or an outstretched hand.
In either case the system needs to be calibrated for distance, contrast, and brightness depending on the ambient light and the object being studied.
The Handsaw was developed primarily to help novices and experts interpret sectional data together, as when a doctor and a patient discuss an MRI together.
Special care is taken so that both can explore and locate the injury on the body.
The doctor or patient can then `scan' the laser line or their outstretched hand over the body, at which time the corresponding slice is displayed on the adjacent screen.
A wire-frame envelope of the body is drawn around the individual slice to help position it on the body and to describe the extents of the MRI scan.
Prior TUIs have only dealt with two-dimensional data representation, limiting the phenomena that could be explored.
In one urban design simulation, three-dimensional models can be arranged, but wind and light information is only shown at the ground plane.
Urban air currents need to be understood in three dimensions because they can have complex, unpredictable patterns that vary significantly between adjacent sections.
The way trees are planted around an asphalted area can greatly impact night-time temperatures downwind.
Our climate design scenario was designed around a workbench where urban designers simulate the effect of green space around an airport to avoid the urban `heat island' effect caused when concrete mass retains heat at night.
The system was designed so that experts and the public could evaluate different options - in this case by distributing zones of green paper on a printed map of the area being discussed.
By slicing the area above the map with an outstretched palm, they are able to see the resulting temperature distribution in the air of that slice on an adjacent screen.
The climate designer could also be generalized as a means of slicing empty space at any scale, from a room to a city.
The design dissection application of the is geared at helping product designers with different specialties work together to design a product around a shared workbench.
In our scenario, a radio engineer needs to communicate the radiation pattern emitted by a particular antenna so that the industrial designer working on the casing provides RFshielding in the correct areas.
The two work around the prototype cell phone on a workbench under a webcam.
The engineer uses the laser line projector to `slice' through the air surrounding the phone.
A pilot study was conducted to explore the potential of the Handsaw system and to compare hand- and laser-based slicing.
Three methods of sectional browsing were compared: using a mouse on a desk, projecting a laser line on the dummy and holding an outstretched hand on the dummy.
As these were moved up and down, different sectional slices appeared on the screen.
Our current system only allows slicing in one dimension because subtle variations in hand or finger orientation could have confusing impact on the slice shown.
As with prior systems, the Handsaw requires that sectional information be hard-coded into the system for each case.
And we require a calibration of the system for each object to be studied, although this has been built into the software.
Our studies are encouraging enough to prompt future development of this platform to provide the robustness that would be called for by generalized application.
The pilot study indicated promising trends that confirm our hypothesis that the Handsaw system is more intuitive than traditional mouse-based controls.
We found that hand-based slicing, though novel, took less time to get accustomed to and less time to complete the task than either the laser or mouse.
The mouse was fastest for finding the section, but it took the longest time to convert the location on screen to its corresponding point on the torso.
The laser and the mouse performed equivalently in time, but the laser led to the most accurate location of the slice on the torso, whereas the mouse was the least accurate.
However the sample size was to small for our results to show statistical significance.
We conclude from this pilot study that direct sectional cut-plane projection with an outstretched hand has the potential to be more intuitive and faster than using a mouse, and using a laser line projector can be more accurate in helping locate a critical section on a real-world volume than using a mouse.
Tangible interaction has been limited with regard to the design and exploration of truly three-dimensional data, and we aim to develop the Handsaw as a diagnostic tool used in synthesis with a tangible three-dimensional design interface.
We aim to expand the system to the design of air flow in a naturally ventilated house, a complex task that relies on a synthesis of three-dimensional design and simulation to explore the possible options.
