We examine the effect of coarse-grained vs. fine-grained location sharing options on users' disclosure decisions when configuring a sharing profile in a location-sharing service.
Our results from an online user experiment  indicate that users who would otherwise select one of the finer-grained options will employ a compensatory decision strategy when this option is removed.
This means that they switch either in the direction of more privacy and less benefit, or less privacy and more benefit, depending on the subjective distance between the omitted option and the remaining options.
This explanation of users' disclosure behavior is in line with fundamental decision theories, as well as the well-established notion of "privacy calculus".
Two alternative hypotheses that we tested were not supported by our experimental data.
Consequently, some researchers suggest that LSS need to give users more control over who sees what and when .
Even though an increase in control may also increase the complexity of the LSS user interface, these researchers suggest that users would rather not share their location at all without fine-grained controls .
However, existing LSS such as Google Latitude do not offer fine-grained sharing controls.
Are they missing out on a wealth of location data that could be used, e.g., for better personalization?
Our study provides a deeper insight into users' choice behavior in coarse-grained vs. fine-grained location sharing systems.
When providing users with fewer location-sharing options in an online experiment , we saw an increase in the number of users choosing the option that are subjectively closest  to the removed option.
This result suggests that users who would otherwise choose the removed option made a deliberate choice between a more secretive and a more revealing option, depending on their perception of the remaining options in relation to the removed option.
If system designers want to improve location-sharing, they therefore should take users' perception of the presented sharing options into account.
In this paper, we first define our scope and discuss related work.
We then present two theories about what happens when certain sharing options are removed, and develop our research hypotheses based on these theories.
The next section describes our user experiment to test these hypotheses.
We then show that neither of the two theories is supported by the data, present an alternative explanation of the effects, and provide additional evidence for this explanation.
We conclude with design implications, limitations, and suggestions for future work.
As smartphones become pervasive, location-based services are becoming increasingly popular.
As of May 2011, 74% of smartphone owners use their phone to access locationbased information.
Despite this, location-sharing services  are far less popular: only 18% of smartphone users "check in" to services like Foursquare to share their locations with their friends .
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
In LSS, control over one's location sharing comes in two flavors.
On the one side there are "check-in" based LSS such as Foursquare.
These systems use an active form of location sharing: the user has to actively check in to share her location.
Users of such LSS have a high level of control over their location sharing, at the price of having to check in every time they want others to know where they are.
On the other side there are "always on" LSS such as Google Latitude.
These systems use a passive and continual form of location sharing: the phone periodically pushes its location to a server without any user intervention.
In such systems, users usually control their location sharing by setting and updating their preferences in a sharing profile.
This profile typically has a set of user-defined rules that determine what the system will share when, and with whom .
This paper primarily applies to "always on" LSS.
Since external factors often influence users' privacy decisions, it is quite likely that the available options in a sharing profile will have an influence.
In this section, we juxtapose two theories of what happens when sharing options are made coarser-grained .
From a privacy perspective, the sharing profile is an essential element in "always-on" LSS, and has been the topic of extensive research.
Looking at how users specify such sharing profiles, some researchers have concluded that users need adequate feedback about who tried to access their location  and about the implications of existing and new disclosure rules .
An important question is whether it is possible to create accurate sharing profiles at all: location-sharing preferences may be so wayward or ephemeral that no stable rules can accurately capture them.
Several researchers found though that there seems to be enough regularity in users' locationsharing behavior that a sharing profile could capture their underlying preferences .
Another important question is how detailed sharing profiles should be.
More detailed profiles will better reflect users' location-sharing preferences, but they may be too difficult and time-consuming to specify manually  or to infer automatically .
Less detailed profiles, on the other hand, may reduce users' perceived control .
Moreover, since simpler profiles may not be able to capture users' exact sharing preferences, they increase the risk of over-sharing , and/or the lost opportunity of under-sharing .
In terms of accurately capturing users' sharing preferences, researchers have argued that, up to a certain point, more options are better .
For example, Benisch et al.
Their results show that users' profiles are most accurately captured when users make separate settings for each different user group, time of day, and location.
Users' decision behavior may be a complicating factor though.
Privacy decisions are among the hardest decisions to make, because they have delayed and uncertain repercussions that are difficult to trade off with the possible immediate gratification of disclosure .
Empirical privacy research demonstrates that users' decisions are influenced by the way the decision is presented to them.
Some researchers suggest that users who would normally go for one of the finer-grained options will "err on the safe side" when their preferred option is omitted, and rather not share their location at all .
Several researchers use this point to even argue that finer-grained options are necessary to increase users' level of location-sharing .
Some evidence for this "err on the safe side" argument  comes from Sadeh et al.
They asked participants to write rules that could be targeted to a certain time/day, location or mood.
Half of the participants could merely choose to either share their exact location  or nothing at all; the other half could additionally choose to disclose their general semantic location , specific semantic location , or general geographic location .
Participants in Tang et al.
E.g., the "general geographic location" option is defined as "city or neighborhood", but how does the system decide between the two?
Due to its vague definition, users may have interpreted this option flexibly, in the way that was most favorable for them.
This may explain the increased appeal of this option , and the simpler rules in this condition.
A real system would need to resolve such ambiguous options.
Moreover, the widgets of a real UI would give users cues of the type of rules that can be created, rather than receiving instructions to that extent from an experimenter.
Finally, a mobile sharing-profile interface should arguably offer a more structured interaction than the rule definition interface emulated by Tang et al.
The sharing options offered by the system are discrete points on this same scale.
ESS, users will choose the option that is closest to, but never more revealing than, their true preference.
For instance, in line with Tang et al.
In example 1, the user's "true" preference is somewhere between City and Block, hence this user chooses the City option.
However, if the City option were not available , the user would choose to share Nothing.
Importantly, adding or removing the City option should only affect how many users choose Nothing and not how many users choose Block or Exact.
And since users are only expected to move between N and C, the sum of N+C  should remain the same.
The ratio N+C : B+E is constant between +C and -C. Example 2 of Figure 1 presents a corollary, which is not explicitly suggested by the proponents of ESS but follows the same logic.
In this case, we examine the addition or removal of the most extreme option, Exact.
Again, removing the Exact option should lead some users to share Block instead , but nothing should happen with users who choose to share Nothing or City.
Users are only expected to move between B and E, i.e.
The ratio N+C : B+E is constant between +E and -E.
However, such a non-compensatory strategy for privacyrelated decisions is incompatible with the commonly accepted idea that people use a privacy calculus  for making disclosure decisions.
In privacy calculus, users see privacy as a commodity  and explicitly weigh the plusses and minuses of a privacy-related decision, i.e., they trade off Privacy and Benefit.
The privacy calculus is rather in line with a compensatory style of decision-making .
The fundamental theory of compensatory decision-making is Luce's choice axiom  : for a rational decision maker, the probability of selecting an item from a pool of items is not affected by the absence or presence of any specific other item.
Thus, in the absence of the City option , LCA predicts that users should "err" on both sides proportionally, as the relative share of the remaining options  does not change.
The ratio N : B+E is constant between +C and -C. The same should be true for the Exact option; in the absence of this option , LCA predicts that the other options should maintain the same ratio, or: H2b.
The ratio N+C : B is constant between +E and -E.
ESS describes a non-compensatory decision strategy .
In such strategies, the superiority of one select attribute of the decision cannot be offset by an inferiority in another attribute, and vice versa.
Let us assume that the sharing options have the attributes Privacy and Benefit, e.g., sharing nothing is good for your Privacy, but sharing your exact location may result in additional Benefit.
In ESS, the Privacy attribute trumps the Benefit attribute at any cost.
Our online user experiment considers a fictitious locationsharing app named "LocStep", which automatically shares users' location based on their sharing profiles.
The profile specifies when and with whom LocStep should share location data at what granularity.
We recruited 300 participants through Amazon Mechanical Turk, a recruitment source that has become very popular for conducting user experiments .
To avoid cultural effects, we restricted participation to adults in the US.
We also restricted participation to Turk workers with very good reputation, and we used several comprehension-testing questions to filter fake and careless contributions.
This left us with 291 valid responses.
The responses showed an adequate distribution of gender  and age .
Participants were first given a short introduction to LocStep, including an example of how the system would display the location of its users on the phone screen.
Participants were asked to list the names of 3-5 of their best friends , 7 of their other friends , 3-5 of their close colleagues , and 7 of their distant colleagues .
These circles were used in the profilesetting task to make the decisions more concrete and realistic.
Participants were then randomly assigned to one of 2x2x3x2 experimental conditions .
Depending on their assigned condition, participants created several profile settings.
Note that these decisions had no default value: participants had to explicitly select one of the radio buttons for each decision.
After making the decisions, participants were asked about the reasons behind several of their sharing decisions .
To make our study more generalizable, one-third of our participants received a version of LocStep that could only be used to share one's location with friends and colleagues, while twothirds received a version with a wider rage of capabilities that could also share one's location to get coupons  and services from third-party apps .
Participants in the "wide range" condition were also asked how they would share with "all other colleagues" and "all other friends", and with "anyone else".
Moreover, half of them set their preferences for friends/colleagues first, and for coupons/apps thereafter; for the other half this order was reversed.
Table 2 shows the order in each of the conditions.
Each row in Table 2 had its own "page" in the system mockup.
The main manipulations of this paper are the availability of the sharing options City  and Exact .
All participants were offered the option to share either Nothing or their city Block, but only users in the +C condition also had the option to share their City, and only users in the +E condition also had the option to share their Exact location.
This leads to the four conditions in Table 1.
Again to make our results more generalizable, we manipulated whether LocStep would ask users to evaluate each friend, colleague, coupon service and app individually, or in groups.
Decisions were always shown as belonging to a certain circle, but whereas participants in the "individual" condition made separate decisions for each member of the circle, participants in the "grouped" condition made a single decision per circle.
The circles are shown as bullets in Table 2.
Availability of city  Availability of exact  Range/order of who  Closeness of person  Type of person  When  The interaction of the latter two variables Availability of city  Availability of exact  Range/order of who  Grouping of circles  When 
We logged each decision in the profile-setting task, and also asked participants in the evaluation task to assess the reasons why they had made certain decisions.
Specifically, we asked: "With , you decided to share  during work hours, and  outside work hours.
Please explain why you did this by answering the questions below."
We evaluated the following circles in the individual / grouped condition: * your friend  / your best friends  * your friend  / your other friends  * your colleague  / your close colleagues  * your colleague  / your other colleagues  * the food coupon service / coupon services  * the BlueShield fitness tracker / 3rd party apps  The last two circles were only evaluated where applicable.
For friends/colleagues, the questions consisted of the following statements, which were rated on a 7-point scale: 1.
I have nothing to hide from .
My location could be useful for .
I do not want  to know where I am.
I have nothing to hide from .
I can benefit from .
My location is not useful for .
I do not want  to know where I am.
The dependent variable is different for each of the two theories.
For ESS, we test the ratio N+C : B+E by modeling participants' choices as 1 whenever the participant chooses N or C, and 0 for B and E. In this model, the coefficient for -C vs. +C tests against H1a: "the ratio N+C : B+E is constant between +C and -C".
Since participants in the -C and +C conditions have a similar distribution in their true sharing preferences , this ratio should be 1 if ESS holds true.
If it is however significantly smaller than 1, then people chose the more revealing side as well .
Similarly, the coefficient for -E vs. +E tests against H2a: "the ratio N+C : B+E is constant between +E and -E".
Again, if ESS holds, this ratio should be 1.
If it is however significantly greater than 1, then participants evidently not only choose Block more often in the absence of Exact, but also Nothing and City.
For friends/colleagues, Figure 3 shows how the distribution of choices differs between the participants in conditions -C and +C.
Although the share of Nothing is higher in the -C condition , the share of Block is also higher , as is the share of Exact .
Without the City option, participants became slightly more open on average.
In terms of our hypotheses: H1a.
The ratio N+C : B+E is 55.4% lower in the -C condition than in the +C condition.
This difference is significant , so H1a has to be rejected.
We tested our hypotheses by estimating the disclosure decisions using a generalized linear mixed model  with a random intercept and a log link function.
We modeled the decisions for friends/colleagues separately from the decisions for coupons/apps.
For friends/ colleagues, we used the independent variables:
Figure 4 shows the same comparison for sharing with apps/coupons.
The share of Nothing is only 4.3pp higher in the -C condition  while the share of Block is much higher .
The share of Exact is slightly lower .
Without the City option, almost all participants became more open on average.
In terms of our hypotheses: H1a.
With regard to the availability of City, neither of the two theories seems to fit the data.
In ESS, we would expect a higher percentage of participants to share Nothing only when City is removed.
In LCA, we would expect the ratio of other options to remain constant.
In our data though, the percentage of participants sharing Block increases more than the percentage of participants sharing Nothing.
For friends and colleagues, Figure 5 shows how the distribution of choices differs between the participants in conditions -E and +E.
In the -E condition, the share of Block is higher , but the share of Nothing and City are also higher .
So, not only did participants in the -E condition shift from Exact to Block, but there were also shifts further down the list.
In terms of our hypotheses: H2a.
This effect is not significant; H2b cannot be rejected.
Figure 6 shows the same comparison for sharing with apps/coupons.
The share of Block is 18.7pp higher, but the shares of Nothing and City are also higher .
Again, not only did participants in the -E condition shift from Exact to Block, but there were also shifts further down the list.
In terms of our hypotheses:
Neither ESS nor LCA tells the entire story.
This is no surprise though: some researchers who coined ESS have proposed to further "examine whether fine-grained privacy controls result in more or less data sharing" , and decision-making researchers have found several effects that qualify the choice axiom .
More recent decision making research has shown that people do not follow strictly compensatory or non-compensatory strategies, but that their decisions instead depend on their subjective perception of the available choice options.
Below we present two theories that originate from this research, and demonstrate that they present a more accurate explanation of the results of our experiment.
If instead A is closer to C, the effect will be reversed.
To measure the perceived Privacy and Benefit of each sharing option, we asked participants for a subset of their decisions how they perceived the benefits and privacy of the chosen option.
Specifically, for their friends/colleagues, we asked them to indicate their agreement on a scale from -3 to +3 with the statements: "I do not want  to know where I am"  and "My location could be useful for " .
For apps/coupons, we asked them to what extent they agreed with "I do not want  to know where I am"  and "I could benefit from " .
TSE leaves us with one problem: Since the Exact option is by definition closer to Block than to City and Nothing, the Exact option should always be a substitute for Block.
This would bring us back to the point where ESS holds, and thus the ratio N+C : B+E should not change when Exact is introduced.
Figure 5 and 6 show however that in the -E condition, the percentage of participants who choose Nothing or City goes up as well.
Is there an effect at play that counteracts the substitution effect?
Moreover, the distance between Block and Exact will determine the relative strength of each effect.
Specifically, we can specify H2: * If and only if Exact is subjectively close to Block, its availability will mainly affect B due to the substitution effect.
Due to the compromise effect.
In this case, introducing the "extreme" option Exact increases sharing across the board.
The size of the bubbles, as well as their labels, represents the relative number of times each option was chosen.
The position reflects the average perceived Privacy  and Benefit  of each option.
The top two panels in the tables represent the Without City  conditions, while the bottom two panels represent +C.
Similarly, the left two panels represent the Without Exact  conditions, while the right two panels represent +E conditions.
In +C , however, only Block  and City  are affected by the availability of Exact, despite the fact that users perceive Exact to be far away from these options .
This is against our expectations; the compromise effect predicts that Nothing would also be affected.
For friends and colleagues, Table 3 shows that the change in proportions between the -C and +C conditions is indeed related to the subjective position of City.
In the -E condition , participants perceived City to be closer to Block  than to Nothing , and hence only the share of Block differs significantly between -C and +C  due to the substitution effect.
In the +E condition , the distance from City to Nothing and Block is more equal, and hence both Nothing  and Block  differ between -C and +C due to the choice axiom.
The effect on Nothing is more pronounced, because City is somewhat closer to Nothing .
The overall results are in line with our expectations.
For coupons and apps, Table 4 again demonstrates that the effect of the availability of City depends on its subjective position: participants perceived City to be much closer to Block  than to Nothing .
Hence, due to the substitution effect, only the share of Block differs between -C and +C .
This is again in line with our expectations.
In this paper we examined the effect of coarse-grained vs. fine-grained sharing options on users' decisions when configuring a sharing profile in an LSS.
We show that when a finer-grained sharing option is removed, users do not just "err on the safe side", but instead deliberately choose the subjectively closest remaining option.
Moreover, if an "extreme" option is introduced that is sufficiently distinct from the existing options, this does not only cause some users to switch from the previously most extreme option to this new option, but it also causes some users to switch from a less extreme option to the previously most extreme option, as this option has now become a compromise instead of an extreme.
In other words, such an extreme option may increase sharing across the board.
The perception of sharing options plays an important role in users' decision process.
This has several implications for the design of sharing options in LSS.
First of all, when designing the `optimal' set of options, it is important to realize that users' choice for a certain option depends on the other available options.
Specifically, assume that designers of a location-sharing app who want to know what sharing options to give to the user decide to run experiments to determine how users would react to different combinations of sharing options.
With more than a few sharing options, this approach would result in a combinatorial explosion of the experimental conditions.
Our findings suggest a more efficient approach: the designers could simply ask a sample of users about the perceived Privacy and Benefit of the available options.
For each option they could have users rate the statements "I would share  if I don't want the other person to know where I am"  and "I would share  if my location could be useful to the other person" .
They could then map the options on a plane and measure the distances between options.
This allows for the following design strategies : 1.
The developers can omit any options that score so low on both Privacy and Benefit that they are dominated by other options.
For options that are subjectively very close, the developers can select the option that is most beneficial from a system perspective, and omit the other options.
The developers can identify regions on the graph that are not covered by a sharing option, and offer a sharing option that covers that region.
If the developers want to promote a certain sharing option, they can remove surrounding options.
The developers can specifically design new options to replace old options.
Similarly, the effect of Exact also depends on its subjective position relative to the other options.
For friends and colleagues, Table 3 shows that in the -C condition , Exact is subjectively close to Block , and hence the availability of Exact mainly affects the share of Block  due to the substitution effect.
In +C , Exact is slightly further away from Block , and hence due to the compromise effect, Block  regains some share at the expense of Nothing  when Exact is introduced.
This is also in line with our expectations.
For coupons and apps, Table 4 shows that in the -C condition , Exact is subjectively close to Block .
Hence the availability of Exact mainly affects the share of Block  due to the substitution effect.
This is again Again, all pp differences are tested using a GLMM with the option as a binary dependent variable, and statistically significant  unless marked ns.
Developers can introduce "extreme" options , to increase or decrease overall sharing.
Furthermore, designers could use persuasive strategies to change users' perception of certain sharing options.
For instance, they could give users a justification by highlighting the benefits, or downplaying the privacy implications, of sharing their location with coupon services or apps .
Adding an "extreme" sharing option  is another persuasive strategy, which increases the chance that users will share some information.
Acquisti, A. and Grossklags, J.
What Can Behavioral Economics Teach Us About Privacy?
In A. Acquisti, S. De Capitani di Vimercati, S. Gritzalis and C. Lambrinoudakis, eds., Digital Privacy: Theory, Technologies, and Practices.
Acquisti, A. Privacy in Electronic Commerce and the Economics of Immediate Gratification.
Anthony, D., Henderson, T., and Kotz, D. Privacy in Location-Aware Computing Environments.
Balebako, R., Leon, P.G., Mugan, J., Acquisti, A., Cranor, L.F., and Sadeh, N. Nudging users towards privacy on mobile devices.
CHI 2011 Workshop on Persuasion, Influence, Nudge and Coercion Through Mobile Devices, .
Benisch, M., Kelley, P.G., Sadeh, N., and Cranor, L.F. Capturing location-privacy preferences: quantifying accuracy and user-burden tradeoffs.
Bokhove, W., Hulsebosch, B., Van Schoonhoven, B., Sappelli, M., and Wouters, K. User Privacy in Applications for Well-being and Well-working.
Boyles, J.L., Smith, A., and Madden, M. Privacy and Data Management on Mobile Devices.
Pew Internet & American Life Project, 2012.
Brandimarte, L., Acquisti, A., and Loewenstein, G. Misplaced Confidences: Privacy and the Control Paradox.
Social Psychological and Personality Science, .
When More Is Less and Less Is More: The Role of Ideal Point Availability and Assortment in Consumer Choice.
Finally, a system could try to model users' perceptions in an effort to automate location sharing.
Specifically, we could try to predict users' relative preference for privacy and benefit in a given situation, and then suggest to them to select the sharing option that most closely fits these preferences.
This method would be even more useful for check-in based LSS.
In the introduction we mentioned that researchers suggest that LSS users need more control over who sees what and when.
This paper makes a case to simplify the what-part of LSS profiles, but the who and the when can arguably also be simplified.
For example, "privacy faces" can be used to simplify the creation of different profiles for different audiences .
Our results may be limited to the specific LSS used in our study.
However, the universal nature of the underlying decision-making theory suggests that these results could be extended to other kinds of privacy preference configuration interfaces.
This may be the most valuable contribution of our work: based on a fundamental theory from the field of decision-making, we were able to qualify existing research in the field of LSS privacy.
Decisions about privacy are inherently difficult; if we want to make privacy more usable, we will have to understand and assist users' decision-
