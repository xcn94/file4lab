This paper reports the results of a recent survey of usercentered design  practitioners.
The survey involved over a hundred respondents who were CHI'2000 attendees or current UPA members.
The paper identifies the most widely used methods and processes, the key factors that predict success, and the critical tradeoffs practitioners must make in applying UCD methods and processes.
Results show that cost-benefit tradeoffs are a key consideration in the adoption of UCD methods.
Measures of UCD effectiveness are lacking and rarely applied.
There is also a major discrepancy between the commonly cited measures and the actually applied ones.
These results have implications for the introduction, deployment, and execution of UCD projects.
It also sheds light on the usefulness and usability of common UCD methods, which is expected to lead to practical guidelines and evaluative criteria.
Whereas a recent survey has focused on "strategic usability" in terms of embedding usability engineering in organizational processes and culture, and contributing to corporate-wide decision making and product decisions , our study addresses product usability itself.
More specific research questions include: Which UCD methods are most widely used and why?
What are the benefits and weaknesses of each method in the eyes of the practitioners?
What are the organizational impacts of UCD and what measures are in place to assess progress?
Results of this research were expected to provide an empirical basis for UCD planning, training, adoption and execution.
For example, future UCD practice could benefit from knowledge of key success factors for the most widely used methods and techniques, common difficulties and concerns with various methods, and cost-benefit tradeoffs.
In addition, it was expected that results could confirm the importance of UCD as well-established and widely accepted as an informal survey by Hudson  has indicated.
Our study attempted to further Hudson's work by conducting a large scale, carefully designed and executed survey.
The focus of the study was on the perspectives of individual UCD practitioners in terms of their personal perception and experiences working within their respective companies.
The objective of this research was to investigate the actual use of user-centered design  methods in practice across the industry.
Much has been written in the research literature about UCD.
User-Centered Design had its origins with the seminal work of Norman and Draper .
Others have further operationalized and optimized the basic approach .
However, an examination of practice at major companies from across the industry discovered that many of the methods that are discussed in the literature are not effective or practical for a variety of reasons .
There is a need for practical UCD guidelines based on the collective wisdom of the industry-wide community of UCD practitioners.
This paper intends to provide the UCD community empirical evidence on what works versus what does not, and what is practical and what is not.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Prior studies are generally in agreement that traditional software development tools and practices have disappointingly small effects on improving software development .
Further, Nielsen  argued that many developers do not use usability engineering techniques because they are considered intimidating in their complexity, too time consuming and expensive.
It is of critical importance to the UCD community to determine whether the situation has changed over the past few years.
It was found that major obstacles to creating greater strategic impact include resource constraints, which were mentioned by 28.6% of the respondents, resistance to user-centered design or usability, lack of knowledge about usability.
Partnering with marketing was identified as a very effective approach.
Hudson, along with Bevan, conducted an email-based informal survey of UCD .
Questionnaires were posted to several mailing lists of HCI groups, and resulted in 102 responses from mostly usability practitioners.
The most commonly used methods, as reflected in the percentage of respondents using them, include informal usability testing, user analysis/profiling, evaluating existing systems, low-fidelity prototyping, heuristic evaluation, task identification, navigation design, scenario-based design.
It appears that informal and less structured methods tend to be used much more widely than more formal and structured methods.
For example, ranked on top are informal usability testing, low-fidelity prototyping, and heuristics, whereas more formal methods are ranked at the bottom such as focus groups, cognitive walkthrough.
A 10-question web survey was conducted recently involving 100 usability practitioners .
The most successful activities identified by the respondents included usability testing, which was mentioned by 39% of the respondents, prototyping, and heuristic evaluation, confirming Hudson's finding .
In addition, they identified the top three best selling activities across the development lifecycle include customer interviews, paper or other prototyping, and usability test.
This survey also examined several key aspects of the organizational context of UCD such as developer resistance to UCD and the interaction between the UCD specialist and developers, design team composition and mission, and successes and failures with UCD processes.
These prior surveys have produced valuable insights about UCD practice, and each of them has its own focus and viewpoint.
Our survey has several unique features most notably the assessment of the overall organizational impact of UCD and measures of UCD success, the profile of and processes used in a typical UCD project, a comprehensive assessment of the strengths and weaknesses of UCD methods as they are currently practiced in product development environments.
It allowed us to investigate the typical costs and benefits of carrying out UCD, and empirically determine the factors most related to the effectiveness of UCD.
A working definition of UCD was given at the beginning of the questionnaire as follows: "UCD is herein considered, in a broad sense, the practice of the following principles, the active involvement of users for a clear understanding of user and task requirements, iterative design and evaluation, and a multi-disciplinary approach.
UCD methods are modular or identifiable processes involved in UCD practice.
You should NOT think of UCD as merely usability testing or software engineering."
The questionnaire consisted of several general questions on the overall impact of UCD methods in practice, and specific questions on a representative UCD project, and detailed assessment of five commonly used UCD methods to be identified by respondents based on their own experience1.
There were Likert-type scales, multiple choice and qualitative questions in the free text form.
The questionnaire was extensively pre-tested by members of IBM's UCD Advisory Council and by members of the TeleCHI list.
The questionnaire was revised based on the feedback from these tests.
The target respondents were experienced practitioners of UCD who had at least three years of experience with UCD, and considered UCD as their primary job.
The invitation and questionnaire were distributed to CHI'2000 attendees and Usability Professional Association  members.
In the invitation, the required qualification was highlighted and only those who qualified were asked to participate.
The survey was first distributed to CHI'2000 attendees towards the end of 2000.
In early 2001, the UPA management office emailed our invitation and questionnaire to their members directly.
A week after the distribution, a reminder was sent to the non-respondents to encourage response, along with the questionnaire.
The response rate in both cases was about 3%.
Since we have no information on how many of the CHI'2000 attendees and UPA members actually belonged to the target sample of practitioners with at least three years of experience, the response rate is different from the typical response rate reported in other surveys.
The real response rate could be many times higher than 3%.
The two samples were compared and no statistically significant differences were detected in the quantitative answers.
Therefore, they were combined for data analysis.
We did not ask our respondents to identify their companies expecting some might not wish to release the information despite our promise of anonymity.
However, judging from respondents' email addresses, we know 10 individuals from three of the largest companies in the IT industry participated in this study.
No other respondents appeared to be from the same company, but we cannot be certain about this as some respondents used generic email servers.
UCD, and the current state of practice in their organizations.
Respondents were also asked to describe their sources of UCD knowledge and expertise.
The top three are books and journals , professional conferences or workshops , and colleagues .
Internal training was not a major source of UCD knowledge, although the interaction with colleagues was.
Sixty percent of the 103 respondents worked in the United States and the rest in Europe primarily.
Most of them had a Master's or PhD degree, 46% and 24% respectively.
Table 1 illustrates respondents' UCD-related background.
Essentially all of them were very familiar with UCD practice.
Thirty-six percent of the respondents indicated 6 on a 7-point scale, and 48% of them indicated 7, which stands for extremely familiar with UCD practice.
In addition, over the past 12 months, on average they participated in five projects involving UCD and the most common number of projects that they have had participated in was also five.
The large standard deviation scores in Table 1 with the exception of respondents' familiarity with UCD practice may be considered a reflection of the diverse background of our respondents, representative of a broad range of UCD practitioners.
In several instances, the standard deviation scores are larger than the means because the distributions are not normal.
For example, whereas most respondents worked on about five UCD projects over the past 12 months, a few individuals reported much larger numbers.
Therefore, for most measures in this paper the medians and modes are also reported, which could be more meaningful than the means in some cases.
Therefore, respondents appeared to be truly experienced practitioners because of their multiple years of experience and familiarity with UCD, and the fact that they attended the CHI conference or were members of the UPA.
They were likely opinion leaders in the UCD community, playing a leading role in their own organization's UCD practice.
Furthermore, it is safe to assume that they were well aware of the state-of-the-art, and in the right position to provide an assessment of the organizational impact of Table 1.
When asked to consider a representative project that used UCD in which they had participated, over the past 12 months, nearly 63% of the respondents chose an Internet/Intranet project, whereas the rest reported mainframe, PC applications, or other systems.
The most common size of the project team was 10 people.
In fact, 31% of the projects had a team of 6 to 10 people, followed by the second common range of over 20 people in 21% of teams.
Twenty percent of the teams were small with fewer than 5 people.
In 65% of the cases, one or two team members  were charged with UCD activities as their primary responsibility, and the rest had more.
The median percentage of UCD personnel defined as those with the primary responsibility in UCD was 17%.
Interestingly, on average over 19% of the total project budget was spent on UCD, whereas the most common case was 10% and an equal number of projects spent over or under 10% on UCD.
About 40% of the respondents reported that their projects spent 20% or less of the total budget on UCD, 20% of them spent more than 20% on UCD.
Unfortunately, the remaining 40% of the respondents did not specify a number for the two questions on project budget and UCD percentage.
Whereas a few years ago Nielsen  cited 6% without giving the source, our numbers are significantly higher.
Overall Assessment of Organizational UCD Practice  Description Mean Mode Std.
Table 3 shows the overall assessment of UCD practice.
The degree of the application of UCD methods in product development varied widely.
However, 72% of the respondents agreed that UCD methods had made a significant impact on product development by indicating 5 or higher on a 7-point scale.
The overwhelming majority of the respondents, 79% and 82%, respectively, considered that UCD methods have improved the usefulness and usability of products developed in their company.
About 80% of them chose 5 or 6, and a quarter of them chose 7, on the 7-point scale.
However, 32% of the respondents were not sure if UCD methods had helped save product development costs.
Among those with a definitive opinion more people believed that UCD methods actually saved product development costs than those who thought that UCD increased it .
A nearly identical pattern holds for product development time.
This is a major surprise, as it is UCD gospel that in the long run applying UCD saves development time and money by reducing the rework needed.
Perhaps respondents focused only on development time and cost for a given release and did not look at the big picture including service cost and redesign.
Respondents were asked to "characterize the organization of UCD staff."
In 41% of the companies, UCD staff were "centralized in one organizational unit," 15% decentralized, 34% mixed, and 10% unclear.
It appears many organizations value having UCD staff be close together organizationally perhaps to share experiences and new approaches.
Recall that 82% rely on colleagues for their UCD knowledge and expertise.
Statistical analyses reported later in this paper show that this factor is most closely related to UCD impact on product development.
The top 10 responses are presented in Table 4.
As shown in Table 4, measures of UCD effectiveness were idiosyncratic and sparse.
The 103 respondents mentioned a total of 191 indicators of UCD effectiveness, but there was little consensus.
Fifteen individuals reported that there was no measure in place at all.
Results were scattered in 16 different categories.
Only seven of them  were reported by more than 10% of the 103 respondents.
However, other than external  satisfaction none of them was mentioned by more than 20% of the respondents.
The other 12 indicators were either rarely used or questionable measure of UCD success.
Subsequently, respondents were asked to "describe the success of UCD practice in your company along the dimensions identified in your answer to the previous question."
Their answer on each of the dimensions was coded at three levels, poor, good, and excellent.
The top 10 applied measures are listed in Table 5.
The lack of standardization in measuring UCD success is even more evident in Table 5 than in Table 4, as many respondents were unable to apply the criteria they just identified to assess their own UCD practice.
Only three of the measures were reported by more than 10% of the respondents and none of them was higher than 20%.
Then, they were also asked to "rank the five most important UCD methods on the basis of their actual impact on product development ."
Responses were coded in a bottom-up manner without any pre-specified coding scheme or expectation.
Results fit into thirteen distinct categories as shown in Table 6 below.
Several interesting observations can be made from Table 6.
For example, five of the UCD methods were considered commonly used, as they were mentioned by about a third of the respondents or more .
They were iterative design, usability evaluation, task analysis, informal expert review, and field studies.
All of these five methods were believed to have the most important impact in practice, except informal expert review, as reflected in the average ranking score.
In other words, informal expert review was widely used , but not considered to have a high impact.
In contrast, user requirements analysis, which is typically more expensive and difficult to do, was mentioned by only few people as commonly used, but was considered very important in practice by the few believers.
It appears that in both cases respondents were mindful of a strong cost-benefit tradeoff.
Our finding is consistent with Hudson's informal survey  in that informal low-cost methods were more widely used, but it goes further by revealing UCD practitioner's belief about the practical importance and impact of various methods.
Furthermore, it is interesting to note that two of the top three effective UCD methods identified by Gunther et al   appear high in our list.
Moreover, our results show that two of the methods, field studies  and user requirements analysis were considered most important in practice, although not widely used.
A comparison between Tables 4 and 5 shows several interesting patterns.
Whereas in Table 4, more respondents mentioned external customer satisfaction or critical feedback sought from customers than internal satisfaction or critical feedback within the company, in Table 5 the design team's perception became the most commonly used gauge of UCD success.
External consumer satisfaction was the only commonly mentioned measure in Table 4 that was applied by more than 10% of the respondents.
From Table 4 to 5 there is a shift from external objective measures to internal and design team's perceptions.
In fact, respondents were so hard pressed to find applied measures of UCD success, they identified several new criteria such as acceptance of UCD by designers and design for user requirements .
Respondents were also asked to "identify several of the most commonly used UCD methods in your practice."
Respondents were asked to list the top five benefits and weaknesses of "the most commonly used UCD methods in your practice."
A total of 18 key considerations were identified.
They were then categorized into three major groups, input -, process-, and outcome-related factors.
The UCD professionals were more mindful of the factors directly associated with the Process, followed by Outcome, and Input : The total numbers of mentioning are 439 , 344 , and 153 , respectively.
Table 7 shows the top three benefits and weaknesses of each of the 13 UCD methods listed in Table 6.
The sequence of the rows within each of the three groups reflects the relative importance of various factors in terms of how frequently they were mentioned by the respondents.
Only the factors that were mentioned by 15% or more respondents are included in the table.
For example, speed was perceived both a strong benefit of informal expert review and a strong weakness of iterative design.
In fact, the same factor might be considered a strength or weakness of a UCD method by different practitioners, e.g., the case of validity/quality of results of iterative design and field studies, which reveals the lack of consensus among practitioners.
The factors of speed, low cost, and validity/quality of results were ranked high by the respondents.
Understanding the task context was also considered a key benefit associated with many UCD methods.
However, validity/quality of results had some mixed ratings, and part of the reason could be its broad nature, which covers insights, depth, completeness, and volume of issues and data.
This result echoes the concern with the complexity and usability of UCD methods in the UCD community .
Furthermore, Rosenbaum et al  also found that the top two obstacles were resource constraints and resistance to UCD.
Our results further substantiate their findings.
Respondents were asked to describe in free text form a representative project involving UCD.
The responses were compared to a representative end-to-end UCD process .
Many of the results were perhaps not surprising.
For example, task analysis and iterative prototyping were used widely.
However, given the widespread endorsement of applying UCD to the total user experience , it was surprising that it was not referenced even once.
The majority of respondents referred exclusively to UCD for the user interface narrowly defined .
There were many references to user involvement during Discovery, Design or Development phases, but only 13% of the projects engaged in a full UCD approach in the sense of user involvement at all three stages of the development cycle.
Task analysis was a common activity, but was usually derived from indirect sources, not from users directly .
Assessment of competitor products was referenced by 18% of respondents, but only 6% of them involved users in their assessments.
User involvement in the activities of product development was somewhat selective.
Only 5% referenced a multidisciplinary team approach as defined by the involvement of more than three unique disciplines.
This compares to 86% who responded "Yes" when explicitly asked if they considered their representative project to be multidisciplinary.
Probably the most accurate depiction of the nature of these teams comes from an analysis of the job titles that were listed for the team.
According to the criterion of more than three unique disciplines, only 21% of the teams were multidisciplinary.
This raises a question of what makes a team multidisciplinary.
Clearly, the practitioners believed that three or fewer disciplines was enough.
In answers to other questions in the survey, many respondents referred to customer satisfaction as a primary measure they tracked .
However, in describing their typical process, there were no references to setting satisfaction targets or comparing user feedback results to them.
This suggests that the measurement of customer satisfaction was seen as outside their UCD process.
Also observed in the responses to this question were the following: Heuristic evaluations were frequent.
Some statistical inferences were made for further insights.
First, we compared the responses received before and after the reminder to test any non-response bias, as commonly done in survey-based studies.
It turned out no statistically significant difference was found in all of the quantitative answers.
Based on this result, it is reasonable to assume that the opinions of our respondents were representative of that of their colleagues in the field.
In addition, a series of hierarchical regression analyses was conducted to examine potential organizational properties and characteristics of UCD processes as possible factors affecting the impact of UCD at the organizational level.
The dependent variable was the impact of UCD, which was one of the 7-point scales on the overall UCD success at the organization level .
All of the independent variables were categorical.
The power of the model measured by the R-Square is .217, which means the model explains 22% of the variance in UCD impact.
It appears that a multidisciplinary team is a key factor of high impact.
Centralized UCD staff is also important.
These two factors together accounts for 16% of the variances in UCD impact, whereas task analysis with user input contributes another 6% as it is highly correlated with UCD in all three stages .
Adding other organizational factors did not increase the explanatory power of the model, e.g., the percent of project budget on UCD and absolute amount of UCD expenditure.
This result is surprising and calls for further studies, but it is generally consistent with Rosenbaum et al.
We also compared the level of UCD impact on product development among projects with one, two, or more UCD members.
The impact of two or more UCD members is significantly higher than that of just one .
However, UCD spending as a percentage of overall project budget is not correlated with other measures except the percentage of UCD personnel on a project team .
Perhaps respondents focused only on short-term development time and costs but not on longer-term savings.
Nevertheless, it was the perception of respondents that UCD methods are gaining momentum across the industry and that they will likely achieve even wider use and greater impact in the next five years.
Interestingly, UCD staff in many organizations, 41% of our sample, is centralized, and only 15% of the organizations have completely decentralized UCD staff.
Moreover, centralized organization also emerged as a predictor of perceived UCD effectiveness.
This likely reinforces the need for UCD practitioners to have a home base for their professional development To our knowledge, this is the first empirical study that has identified the profile of a typical UCD project.
Of particular interest is that on average spending on UCD constitutes 19% of the total project budget, whereas the most common scenario is 10%.
In fact, in 20% the projects, UCD actually makes up more than 20% of the overall project budget.
Another key finding is the lack of measurement of UCD effectiveness and any common evaluation criteria across the industry.
Respondents emphasized external objective measures but often reported the use of internal and subjective measures if any measure was used at all.
This is likely a challenge for the UCD community, and for the continuing growth and acceptance of UCD practice, in light of the resistance and obstacles identified by Rosenbaum et al.
Some common characteristics of an ideal UCD process were not found to be used in practice, namely focusing on the total user experience, end-to-end user involvement in the development process, and tracking customer satisfaction.
Other noteworthy results include:  A multidisciplinary approach to UCD appears to be closely related to perceived UCD effectiveness, although practitioners were not always clear about what constituted multidisciplinary;  UCD was perceived to have higher impact if there were two or more UCD specialists on the project team compared with only one; and  a set of commonly used UCD methods was identified, along with perceived key benefits and weaknesses.
This could be useful for practitioners' adoption and promotion of UCD methods.
Lastly, our results clearly suggest that cost-benefit tradeoffs play a major role in the adoption of UCD methods.
This would explain for the most part similar results found in other recent surveys of UCD.
For example, field studies were generally ranked high on practical importance but relatively infrequently used likely because they were costly, whereas heuristic evaluations were heavily used because they were relatively easy and less costly.
Results of the study are informative and provide many interesting insights.
However, the results should be interpreted with some caution given that they are based on practitioner self-reports.
In conclusion, user-centered design appears to be making an impact across the industry and a focus on the findings of this study will help organizations further optimize their deployment of it.
Gunther, R., Janis, J., & Butler, S., The UCD Decision Matrix: How, When, and Where to Sell User-Centered Design into the Development Cycle, http://www.ovostudios.com/upa2001/, accessed on June 29, 2001.
Nielsen, J., Usability Engineering, AP Professional, 1993.
Nielsen, J., Using discount usability engineering to penetrate the intimidation barrier, in R.G.
Mayhew , Cost-Justifying Usability, academic Press, 1994.
Norman, D. A, and Draper, S.W.. User-Centered System Design: New Perspectives on HumanComputer Interaction.
Vredenburg, K., & Butler, M. B., Current Practice and Future Directions in User-Centered Design.
Usability Professionals' Association Fifth Annual Conference, Copper Mountain, Colorado, 1996.
