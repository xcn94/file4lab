We present Minput, a sensing and input method that enables intuitive and accurate interaction on very small devices - ones too small for practical touch screen use and with limited space to accommodate physical buttons.
We achieve this by incorporating two, inexpensive and highprecision optical sensors  into the underside of the device.
This allows the entire device to be used as an input mechanism, instead of the screen, avoiding occlusion by fingers.
In addition to x/y translation, our system also captures twisting motion, enabling many interesting interaction opportunities typically found in larger and far more complex systems.
ACM Classification: H.5.2 : User Interfaces - Input Devices and Strategies, Interaction Styles, Graphical User Interfaces.
General terms: Human Factors Keywords: Mobile devices, touch screens, optical tracking, pointing, input, sensors, spatially aware displays, gestures.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Buttons, for example either begin to consume a significant fraction of available surface area, or become too small for comfortable and effective use.
Techniques such as touch screens become less effective, especially for fine-granularity operations, when the size of a human finger begins to take up a significant fraction of the entire display.
Considerable work has attempted to address issues in this area.
Although many approaches can operate in small to medium form factors, each suffers from at least some drawbacks.
These, however, require the integration of a camera into, e.g., the backside, forcing the user to grasp the  device in a very particular fashion.
Furthermore, vision processing is computationally expensive and error prone in dynamic contexts such as walking or waiting for the bus .
Acoustics offer another approach , although such methods will always have to contend with environmental noise and face privacy and social issues in shared settings.
Accelerometers also suffer from high false positives in dynamic contexts, such as walking and riding on public transportation.
Moreover, they tend to offer a lower level of fine control and expressivity - barring them from applications requiring varied and high accuracy interactions.
Several point solutions have attempted to address this problem.
Of note is SideSight , which uses infrared proximity detection around the device periphery to perform multitouch tracking.
NanoTouch  cleverly incorporates a touch-sensitive surface on the underside of a device, allowing for direct finger manipulation without screen occlusion.
On a very small device, the focus of our efforts, it is not clear if one can even comfortably place two fingers on the underside for accurate multitouch gestures, such as pinching.
More important, however, is that both systems essentially provide a 1:1 control-device  gain, tightly coupling the resolution of input to the size of the device.
The mass production of optical mice has made the highly sophisticated sensors on which they rely very inexpensive.
Additionally, advances in electronics and optics have yielded sensors that are both small and extremely precise.
A generic optical mouse, costing only a few dollars, is capable of capturing and comparing surface images several thousand times per second.
Often, this high resolution enables their use on a variety of surfaces - both traditional  and ad hoc  .
Vision-based interaction techniques  tend to heavily tax even modern mobile device processors and batteries.
Fortunately, the optical sensors we employ have dedicated, highly efficient processors that handle most of the computation with negligible power consumption.
The central idea behind Minput is simple: place two optical tracking sensors on the back of a very small device.
This allows the whole device to be manipulated for input, enabling many interesting interactions with excellent physical affordances .
This could allow for the creation of e.g., a matchbook-sized media player that is essentially all screen on its front side.
The device could be operated using any convenient surface, e.g., a table or palm.
The use of two tracking elements enables not only conventional x/y tracking, but also rotation , providing a more expressive design space.
The latter motion is calculated by taking the difference in velocities of the two sensors.
This configuration allows Minput to operate like a spatially aware display .
Previous systems, however, have tended to be large and complex.
For example,  and  were tethered to high-cost and stationary tracking systems, while  used an equally immobile augmented table and vision system.
Minput provides much of the same capability, but in an inexpensive, low-power, compact and mobile form.
To investigate the usability and accuracy of our input approach, we constructed a small prototype device .
For a display, we used a NHJ VTV-101 TV wristwatch modified to receive video from a conventional desktop computer .
On the underside of the device, we mounted optical sensors extracted from two SlimG4 mice.
The sensor and optics package is a diminutive 9x17x3mm, allowing it to be readily integrated into mobile device hardware.
At the heart of the sensor is an ATA2198 processor, manufactured by AtLab , which samples at 3.4kHz .
Translation data from the two sensors is transmitted over USB to the aforementioned PC.
Minput is an enabling technique on top of which numerous, distinct input modalities can be built.
To illustrate this, we highlight three interaction techniques we believe to be of particular utility: gestures, virtual windows, and cursor control.
We also introduce a new interaction: twisting for zooming and selection.
The high precision motion captured by our approach makes gestures a strong candidate for input.
As a proof of concept, we developed software that detected two basic forms: flicking and twisting .
To flick, users simply rapidly swipe the device in a particular direction.
We primarily used up, down, left and right, but diagonals and other angles are possible.
Twisting is achieved by rotating the device around its center point.
This feels much like twisting a physical knob, and offers many of the same affordances.
More complex gestures are, as they are with mice or styli, eminently performable.
In piloting, we observed two distinct ways people perform such gestures.
Some users held the device above the surface.
When a gesture was to be performed, it was only then that the device made contact with the surface .
It then returned to a central, hovering position.
Conversely, some users tended to prefer resting the device on the surface.
This allowed gestures to be performed immediately.
However, after the gesture was complete, users lifted the device, re-centered it, and placed it back on the surface.
The latter is similar to clutching in mice .
In both methods, contact with the surface acts as a clutch for input.
Minput also allows for the device to be treated like a window looking onto a larger physical space .
Consider, for example, four virtual sliders situated on a common surface, as depicted in Figure 4 .
Users can switch between these different controls by physically moving the device left or right, to the corresponding spatial locations.
Once situated on the desired control, they can alter the value by manipulating the device .
Minput also offers very fluid interaction with zoomable interfaces .
Twist is used for zoom - an analog operation for which it is well suited.
Finally, it is possible to map the device's spatial position on a larger surface to a cursor position on the screen.
As illustrated in Figure 4 , to move the cursor to the bottom right of the screen requires translating the device to the bottom right of the surface.
Unlike  and conventional touch screens, which are forced to operate with a 1:1 C-D gain, we can appropriate large surfaces from the environment to offer a high C-D gain , offering extremely precise interaction .
For example, it is possible to hit one-pixel targets with Minput without special mechanisms .
We also created a simple photo album viewer to illustrate an alternative, gestures-only, navigation interface.
Instead of a continuous lists, flicks are use to traverse between different albums.
Once a desired album is located, it can be entered with a clockwise twist.
Users are then limited to navigating photos in that album.
To leave the "directory", users can perform a counterclockwise twist at any time.
Additionally, the two aforementioned applications are entirely gestural, and require no "clicks".
This allows users to contiguously grip the device with a single hand, and without the need to reposition  or reach for buttons.
This motion-only interaction also means users can grip the device in any number of configurations they find comfortable or convenient.
The prevalence of large content and small screen sizes has made scrolling and zooming common operations on mobile devices.
Apple's iPhone, for example, uses finger drags to move the focus and pinch gestures to change the scale.
Minput can replicate this capability through one-handed positional movement and twisting gestures.
The latter is responsible for controlling the zoom level; a clockwise twist is used to zoom in, while counterclockwise rotation zooms out .
After completing a zoom gesture, the device can be lifted and reoriented.
If desired, the interface can be graphically counter-rotated such that the content remains properly oriented on screen.
We created two demonstration, Minput-driven, photobrowsing applications.
The first displays a single, highresolution photograph.
The device acts like a small window, looking at only a part of a much larger image .
Foremost, Minput readily supports hierarchical navigation.
This capability opens the interface design space to nearly everything seen on contemporary mobile devices.
Our first application was an iPod-like audio player.
We employ vertical lists of items , which are navigated by dragging the device upwards and downwards .
Selecting an item  is achieved with a right flick.
Users are able to traverse backwards by left flicking.
A volume control acts as a home screen, the value of which can be altered by turning the device like a knob .
Users are able to explore the picture by moving the device in any direction; twisting controls zoom.
The second photo application lays out a grid of photographs.
Flicks allow users to move up, down, left and right, one photo at a time.
Twisting gestures control how much of the grid is visible at any given moment .
We also created a mock web browser .
Minput, coupled with the ability to click , enables an immediate method for navigating the web on very small displays - ones without directional inputs or touch screen ability.
We describe our robust prototype and applications developed for it.
We conclude with a brief overview of feedback from eight users, who uniformly understood and appreciated the interactions.
Minput's ability to act like a high-precision mouse makes conventional WIMP-like interfaces readily possible.
This could allow devices with very small displays to support potentially rich interfaces - ones that would breakdown with touch screen input .
Additionally, Minput's highaccuracy positional movement could also prove useful in other, more specialized contexts, where gestures and virtual window interactions are too coarse.
For example, selecting a sentence of text from a paragraph  requires precise two-dimensional positioning.
In order to get a preliminary understanding of the sensitivity and usability of our approach, we presented our prototype to eight beta testers  who had not seen or used the device.
The testers were allowed to play with each application, including the music player, photo album browser, single photo navigation with zoom, photo grid navigation with zoom, and mock webpage navigation.
During the session, users were encouraged to provide commentary on their impressions.
When needed, verbal instructions were given to help users operate the applications.
Questions were also asked to elicit feedback.
People consistently used words like "natural" and "intuitive" to describe the interactions, with several noting that they "understand completely how to use it" within a few minutes of using the device.
The twist feature was particularly popular.
Most testers found it to be very natural to perform and conceptually logical.
People, unprompted, likened it to the twisting of a lens on a camera, or the twisting of a screw .
However, users found it less intuitive for selection, instead, finding flicking more natural.
Finally, several users commented that the physicality of the device was a nice property, offering many of the affordances of their corresponding physical counterparts.
One tester suggested that this property made flicking with Minput more intuitive than the finger flicking as implemented on the iPhone.
