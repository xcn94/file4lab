Mobile interaction is shifting from a single device to simultaneous interaction with ensembles of devices such as phones, tablets, or watches.
Spatially-aware cross-device interaction between mobile devices typically requires a fixed tracking infrastructure, which limits mobility.
In this paper, we present SenseBelt - a sensing belt that enhances existing mobile interactions and enables low-cost, ad hoc sensing of cross-device gestures and interactions.
SenseBelt enables proxemic interactions between people and their personal devices.
SenseBelt also supports cross-device interaction between personal devices and stationary devices, such as public displays.
We discuss the design and implementation of SenseBelt together with possible applications.
With an initial evaluation, we provide insights into the benefits and drawbacks of a belt-worn mediating sensor to support cross-device interactions.
Copyrights for third-party components of this work must be honored.
For all other uses, contact the Owner/Author.
Copyright is held by the owner/author.
People increasingly interact with information through various devices , ranging from laptops, tablets, smartphones, and large surfaces to wearable technologies such as smartwatches and head-mounted displays.
This proliferation of devices has led to situations in which individuals or groups interact with multiple devices simultaneously , both in collocated meetings and in mobile scenarios when users are on the go.
Prior work introduced techniques and infrastructures to facilitate cross-surface interactions .
However, these techniques often require fixed infrastructures to enable sufficiently accurate tracking , or are specific to certain applications or combinations of devices .
Infrastructure restrictions limit the possibilities for nomadic and mobile interactions in the wild.
These techniques are designed around the principle of an augmented space  rather than from an ego-centric perspective  in which multi-device collocated interaction is centered around a person's body.
There is a need to explore how these mediating tracking infrastructures can be designed, built and deployed in more naturalistic settings and mobile environments .
In this paper, we introduce SenseBelt, a belt-worn sensor device that supports ad hoc proxemic interactions  between groups of people and a wide range of different devices.
SenseBelt is augmented with sensors to detect configurations of devices and people and support cross-device interaction techniques between ecologies of personal devices, stationary devices and spaces.
The central goal of SenseBelt is to provide a new wearable personal mediating device that can detect various con-
SenseBelt's design is based on the observation that the vast majority of personal and group interactions with devices happen within the action and observation space of a person, i.e., the space an individual can reach with their arms and clearly see .
To support collocated interactions, a system needs to be aware of what is happening in this region for one or more users.
We therefore designed SenseBelt around three main design goals: egocentric wearable tracking; proxemic interaction; and control and configuration.
Egocentric Wearable Tracking SenseBelt takes an egocentric perspective  in which a person's body acts as a reference for their interaction with their own personal devices and other devices and people in their environment.
The person's own devices are connected to SenseBelt in a body area network .
SenseBelt provides an embodiment of a personal information space around a person and enables communication with nearby devices and people in that person's visible surroundings.
SenseBelt can send a person's identity and their orientation to nearby devices and people, allowing for interpersonal device tracking and enabling identification of people on the go without requiring instrumentation of the environment.
As the pelvic girdle is the most spatially stable part of the body and generally oriented forward, it is the most suitable place for a body-worn spatial tracking device .
Similar to prior work , we therefore leverage the belt form factor for egocentric interaction.
Proxemic Interaction To allow for proxemic and spatially-aware interaction, SenseBelt is able to sense multiple proxemic dimensions : SenseBelt can track a person's proximity to another device, as well as their orientation and identity.
Tracking of a person's identity allows devices to react specifically to that person: for example, a digital whiteboard can automatically load a person's previous session when they are identified via the belt .
Tracking orientation and proximity allows a device to react only to people that are close to and facing the device.
Furthermore, multiple SenseBelts can be merged when people interact in groups .
While currently only implemented in a limited way to explore the concept, our goal is for SenseBelt to track the 3D spatial position of each device relative to the belt.
This, together with the belt's other sensing capabilities, could enable a rich set of mobile cross-device interaction techniques.
Control and Configuration SenseBelt was designed to provide users with control over their personal data and prevent surprises.
We avoid exploiting knowledge of proxemics to the detriment of the user  .
To address privacy concerns, the user must actively show their intent to make a connection to another device  and can opt-out of that interaction at any time.
As a wearable device, SenseBelt should be unobtrusive to wear and use and be acceptable in social situations, avoiding pitfalls of other wearable technologies such as smart glasses  .
The unit pushes information from sensors to a Node.js server where a world model of a person's body area network of connected devices is kept.
Each sensor's values are read at the same time.
For person-to-person interactions, we use a threshold to ignore distances beyond the personal zone  .
In future iterations, we will support larger distances for person-to-device interactions.
If two of the three sensors have similar readings , then the position of the device is treated to be in-between both positions .
This gives us five detectable directions around the user: left, front-left, front, front-right, right.
Tracking Identity and Detecting Other Devices A unique identifier  is created for each SenseBelt and can be exchanged using the IR LED and IR receiver on the belt.
In addition to being worn by people, the SenseBelt sensing components can also be integrated into other devices such as a public display .
SenseBelt can detect nearby belts and devices by exchanging IDs.
When a nearby SenseBelt-enabled target device is detected, the target's ID is forwarded to the server.
The Node.js server is also aware of each user's paired devices to their SenseBelt.
In our current implementation, users can configure and connect their personal devices to the belt in a web interface on the Node.js server.
Cross-Device Gestures A user can perform recognized cross-device gestures from any of their paired devices.
If the two people's belts are "looking" at each other, the gestures performed by both users' groups of devices are compared.
If they form an interactive gesture, a connection between both devices is initiated.
To explore the feasibility of these cross-device gestures, we implemented an example gesture to easily share images from one device to another .
Note that for the sake of simplicity, a SenseBelt currently does not track the spatial orientation of its paired personal devices.
Gestures are detected on each device separately and transmitted together with a timestamp to the Node.js server.
Discoverability and Feedback using Vibration Motors Discoverability of possibilities for interaction, i.e., knowing which devices are available and can be interacted with, is an important issue in cross-device interaction .
SenseBelt features three vibration motors distributed in the front half of the belt.
Vibration motors have been explored previously in a belt form factor for navigation  and vibration patterns have shown potential for wayfinding .
We implemented several prototype applications to demonstrate the possible applications of SenseBelt.
Location- and Identity-Aware Notifications SenseBelt's identification capabilities and its coarse orientation sensing feature enable public displays to show relevant and targeted information to passersby.
As shown in Figure 6, SenseBelt can augment the existing affordance of standing in front of an airport information display to provide targeted personal flight information on the user's personal device.
A SenseBelt tracking component  can be positioned near the public display to sense SenseBelt users when they approach and face the display.
After transmitting the user's SenseBelt ID, the display can then notify the user of the availability of targeted information.
The information is pushed to the user's belt, which can then be transferred to and shown on the user's preferred mobile device .
Similarly, a SenseBelt-enabled bus stop can sense a nearby user's belt and provide localized and targeted information .
The bus stop could ask permission to access the person's agenda stored in their smartphone and use this to show the next bus that can take the user to their destination on time.
SenseBeltenabled exhibits could also be used to enhance museum visitors' experiences .
The SenseBelt tracking component can provide additional information regarding the viewed exhibit, such as multimedia content, background information or a translation of the description.
People You Met Today We implemented an application for SenseBelt to keep track of people you have met during the day, which could be useful for large conferences or business events .
Public contact information can be configured to be automatically collected, or only after an initial gesture such as a handshake while wearing a smartwatch.
The availability of this feature could be suggested to the user using geofencing when they enter the conference or by a SenseBelt tracking component near the door.
At the end of the day, the user can access a log of all people they have met at the event on one of their personal devices .
Ad-Hoc Cross-Device Interactions We implemented two cross-device gestures to facilitate person-to-person content transfer using people's mobile devices .
These gestures are available once people are facing each other and their belts have exchanged IDs.
Holding the phone  and slightly titling it towards the target acts as an offer of information to another user .
Another user can then perform a pick-up gesture to transfer the content to their own device .
Note that the need for an explicit offer gesture means that people are not sharing things without deliberately choosing to.
When the receiver's phone is upside down, the device vibrates to indicate that the gesture has been recognized.
The two gestures do not require perfect synchronization between the two ends of the interaction.
Each user can perform their corresponding gesture almost asynchronously to the other.
If the two gestures overlap at a certain point in time, the interaction begins.
We conducted a small study with 10 participants  to gather feedback on the prototype.
Form Factor and Design When trying on SenseBelt for the first time , participants had mixed feelings about the prototype.
The design and form factor of the belt was considered important by most participants.
Since a belt is a fashion item, participants expected a finished product.
Overall, participants who tend to wear belts found the system natural.
In the final interview, several participants suggested their own form factors to avoid having to always wear a belt .
As shown in Figure 11, participants suggested several ideas, such as an clip-on sensor connected to a bag strap, stickers to be placed on top of existing outfits without modifying them, and other form factors such as gloves, vests and sensing buttons on shirts .
Participants did not seem restricted in their movements while wearing the belt.
They could use their paired smartphones as they usually would without SenseBelt getting in their way.
Discoverability via Vibration Feedback We began by exploring whether vibration feedback could suggest the direction of a target device.
Participants received light vibrations in different patterns and were asked to identify the direction of the target de-
All participants could easily identify stationary targets and had an approximate idea of where the target device was located in the study environment.
Cross-Device Interaction Experience Participants were then asked to share an image from the experiment smartphone paired to the belt to the experimenter's smartphone.
The hand-over and pick-up gestures  seemed natural for most participants.
To share an image between the experiment smartphone and the laptop, some participants tried tilting the phone's display towards the laptop keyboard  while others oriented the image on the phone's display towards the laptop screen.
Ease of Use and Privacy In the final semi-structured interview, participants praised SenseBelt for its gentle learning curve.
Participants were generally not concerned about privacy issues, although one participant expressed concern about the amount of data that SenseBelt would collect.
Form factor - The study demonstrated the importance of the device's form factor, convenience in everyday situations, and its overall design.
People may find themselves in situations where it is inconvenient to wear a belt.
A limitation of our current prototype is that the sensors can be occluded by clothing or the user's hands.
It is an open question what the right form factor is for such a device.
A promising direction is to explore miniaturizing the SenseBelt components into a clip-on version that can be worn on any clothing , similar to the Narrative Clip  or Opo .
Gradual engagement - We can further refine discoverability feedback provided by the belt's integrated vibration motors.
SenseBelt's egocentric perspective is well-suited for supporting gradual engagement  via continuous proxemic sensing.
With gradual engagement, decreasing distance and increasing mutual orientation towards nearby devices and people signals increasing engagement.
The system accordingly provides peripheral awareness of interaction possibilities , which the user can then act upon by simply approaching.
This can be a way to avoid overwhelming the user in crowded environments with many devices and people that could potentially be interacted with.
Enhancing mediating capabilities - SenseBelt could be further extended to serve as a configuration mediator for an ecology of personal devices .
We believe there is much potential to further explore the use of a wearable mediating device to enable rich and truly mobile cross-device interaction.
Our SenseBelt prototype raises several further questions and opens directions for future research.
Spatial tracking of personal devices - To enable advanced cross-device interaction techniques that are possible with fixed tracking infrastructures , SenseBelt needs to be able to track the relative 3D spatial positions and orientations of its paired devices.
We are experimenting with integrating an Inertial Measurement Unit  into the belt and calibrating and aligning the readings from the belt IMU to existing IMUs in the paired mobile devices.
Another promising direction is the use of acoustic signals .
Sonja Rumelin, Enrico Rukzio, and Robert Hardy.
NaviRadar: A Novel Tactile Information Display for Pedestrian Navigation.
Dominik Schmidt, Julian Seifert, Enrico Rukzio, and Hans Gellersen.
A cross-device interaction style for mobiles and surfaces.
Kashyap Todi and Kris Luyten.
In CHI 2014 Workshop on Inconspicuous Interaction.
Koji Tsukada and Michiaki Yasumura.
ActiveBelt: Belt-Type Wearable Tactile Display for Directional Navigation.
Jo Vermeulen, Steven Houben, and Nicolai Marquardt.
Fluent Transitions Between Focused and Peripheral Interaction in Proxemic Interactions.
In Peripheral Interaction, Saskia Bakker, Doris Hausen and Ted Selker .
Narrative Clip 2 - the world's most wearable camera.
