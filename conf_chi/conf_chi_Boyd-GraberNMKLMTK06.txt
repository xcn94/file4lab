In this paper, we describe the design and preliminary evaluation of a hybrid desktop-handheld system developed to support individuals with aphasia, a disorder which impairs the ability to speak, read, write, or understand language.
The system allows its users to develop speech communication through images and sound on a desktop computer and download this speech to a mobile device that can then support communication outside the home.
Using a desktop computer for input addresses some of this population's difficulties interacting with handheld devices, while the mobile device addresses stigma and portability issues.
A modified participatory design approach was used in which proxies, that is, speech-language pathologists who work with aphasic individuals, assumed the role normally filled by users.
This was done because of the difficulties in communicating with the target population and the high variability in aphasic disorders.
In addition, the paper presents a case study of the proxy-use participatory design process that illustrates how different interview techniques resulted in different user feedback.
Aphasia is a cognitive disorder affecting approximately 1.1 million North Americans .
It is usually acquired as a result of a stroke, brain tumor, or other brain injury and results in impairment to the production and comprehension of spoken and written language.
Rehabilitation can reduce the level of impairment and mitigate its impact, but a significant number of individuals are left with a life-long chronic disability that influences a wide range of activities and prevents full re-engagement in life.
The long-term impact of aphasia varies across individuals; however, given the importance of language communication in virtually all aspects of daily life, it is not surprising that most, if not all, individuals experience a reduction in their ability to participate in everyday activities with the result that social isolation and depression are relatively common .
There is great variability across individuals with aphasia resulting both from differences in severity and from differences in relative impairment of language modalities .
For example, some aphasic individuals have relatively good auditory and reading comprehension but very limited output in either speech or written language.
Others may have fairly fluent speech, albeit with numerous semantic errors, accompanied by relatively poor comprehension of both spoken and written language.
In addition, there can be accompanying motor and visual field deficits .
Many individuals with aphasia use alternative modes of communication.
For example, some are able to write out the names of desired objects but are unable to verbalize them.
Others use appropriately timed gestures and facial expressions to convey ideas.
In addition, many individuals carry props and prewritten cards to assist them in communication; for example, many carry a card introducing themselves and describing their aphasia.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
The user searches through the image library to retrieve a desired item; once selected, its written and spoken forms are made available to use for communicating with others.
The Lingraphica System by Lingraphicare is one such device  .
Lingraphica consists of interactive icons representing over 5,000 elements of natural language.
Nouns are represented by an image and sound clip, while verbs are represented by an animation depicting the action.
The central metaphor of the Lingraphica system is a "storyboard," a collection of visual symbols arranged to approximate English syntax.
Figure 1 illustrates a Lingraphica storyboard for the phrase "I like to eat."
Users of Lingraphica perform hierarchical searches for pictorial representations of concepts they want to express.
They move these graphical icons to the storyboard portion of the screen, combining them to create phrases.
Lingraphica uses prerecorded sounds, pictures, and their associated words giving the user a tool for basic communication needs and for practicing natural speech.
The Lingraphica software comes pre-installed on a dedicated-use Apple iBook and can be operated using a conventional mouse, track-ball, or touch screen and thus is accessible to a wide range of users.
Although Lingraphica is a successful product, there is concern that its use is predominately limited to the home.
Speech-language pathologists familiar with Lingraphica have noted that their clients tend to use the device to practice phrases they will later need in conversation away from the home  but do not take the device with them for use in these conversations.
One reason for the device's lack of use outside the home may be its form factor.
There are several reasons why this form factor may be limiting use:  the size and weight of a laptop makes it cumbersome and inconvenient to transport, especially for someone with motor impairments;  the time required to take out and start up a laptop can reduce the timeliness of the support it provides; and  the obtrusiveness of a laptop may undesirably interfere with social interactions.
It has been noted that assistive technologies that draw attention to the disability often create a stigma hindering adoption .
Other communication devices have adopted handheld technology, otherwise referred to as personal digital assistants , such as the Pocket PC or PalmPilot.
The GUS Communicator software  and the Impact Series software  are two examples of devices using these technologies.
While PDAs are advantageous due to their discreet, compact size and quick start up time, there is concern that their limited screen size and reduced input capabilities can make them difficult and tedious to use.
ESI Planner   is a multi-modal daily planner that allows aphasic users to independently manage appointments using a PDA.
It supports the needs of aphasic individuals by incorporating triplets of images, sound, and text to represent appointment data within the planner.
ESI Planner was evaluated in a study with nine aphasic participants that compared it to an equivalent text-based planner.
The results of this evaluation suggested that the multi-modal design was beneficial for users with moderate to severe communication impairment.
However, there were several limitations to the ESI Planner design.
Most notable was that many individuals struggled with appointment creation because of the limited screen size and interaction capabilities afforded by the PDA.
Other work  has also noted difficulties encountered by individuals with limited motor abilities when interacting with PDAs.
Nonetheless, we believe PDAs are potentially useful in supporting individuals with aphasia.
Davies, Marcella, McGrenere, and Purves  extensively studied one individual's use of a PDA for daily communication.
Although this particular individual was perhaps exceptional in his enthusiasm for the PDA and his ability to incorporate it into his existing communication strategies, we believe this work demonstrates the PDA's potential.
Our vision for harnessing the advantages of a PDA, while overcoming its limitations, is to incorporate the PDA into the existing Lingraphica system as an addition rather than a replacement.
In this approach, the computer is used for compositional tasks and the PDA as a portable extension with which the user can transport his or her compositions.
We hypothesized that allowing users to perform input using the computer--with its larger screen and greater input capabilities--would help alleviate many of the motorrelated problems previous PDA-based systems have encountered.
In addition, we would be able to take advantage of Lingraphica's existing extensive computerbased visual communication language.
In designing such an extension, it is crucial that the system be organized to ensure the easy retrieval of stored compositions.
Although this work is chiefly guided by the previous work on Lingraphica and ESI Planner, other efforts have also been critical to conducting this research.
In this section, we present that research in two categories: technology developed specifically for individuals with aphasia, and mobile technology developed for individuals with other cognitive impairments.
In recent years, several investigators have applied computer software technology to meet specific needs of individuals with some retained communicative ability.
The TalksBac system  and a related system, PROSE , target the ability of some higher-functioning aphasic individuals to recognize familiar words and short sentences.
In a longitudinal study, TalksBac was shown to be helpful for some individuals, although its reliance on caregivers to maintain the system was problematic.
Another system developed to support story telling is described by Hine, Arnott, and Smith .
They developed a multi-media communication system for story-telling designed to help users with speech and language impairments participate in conversation by providing an easy-to-use interface for selecting multi-media based stories consisting of video clips, audio clips, and images.
Finally, a prototype file facility was developed as a result of an ethnographic field study examining the incorporation of an off-the-shelf PDA into one individual's communication strategies .
This file facility was designed specifically to assist that user in the management of his story telling communication media.
ESI Planner II redesigns ESI Planner to enable it to leverage the strengths of Lingraphica with the intent of providing an easy to use yet portable communication aid and daily planner.
Our system uses the lexical elements of Lingraphica for the task of composing appointments, reminders, phrases, and checklists on a desktop computer.
These are then transferred to ESI Planner II for portable use.
That is, our initial vision was that aphasic users would use our system independently as follows:  they would create phrases using Lingraphica,  they would associate these phrases with a particular date and time using standard Lingraphica icons for date and time, and  they would automatically transfer these phrases and appointments to the PDA through synchronization.
These phrases would then appear within ESI Planner II as notes or reminders organized by day and time.
For example, an individual might want to remember to tell a doctor about the effect of a new medication at her next appointment and to ask about the pain in her side; both of these could be phrases in the storyboard associated with her doctor's appointment.
In this work, we have drawn on a variety of research methodologies.
First, we employed participatory design, using speech-language pathologists as proxies to our target population.
Our initial design drew heavily from the results of the evaluation of ESI Planner, which tested the system on nine aphasic individuals.
We then used a semi-structured interviewing approach to solicit feedback on our design ideas using speech-language therapists as proxies for our target users.
Although we gained much useful information from these interviews, the development and the overall focus of the system changed when we engaged the speechlanguage pathologists in ethnographic interviews that allowed them to tell us their daily stories of therapy and interactions with aphasic patients.
Finally, we tested our final design in a four week study conducted with seven aphasic individuals with varying degrees of impairment.
One of the outcomes of our participatory design with proxies approach was the discovery that for our target population to use ESI Planner II independently, we needed to design a simplified version of Lingraphica, which we called LgLite.
Thus, the paper also describes the design of LgLite and discusses how the various methodologies we used in working with the speech-language pathologists first hid and then revealed key aspects of the care infrastructure that demonstrated a need for LgLite.
There has been a modest amount of research conducted examining the development of reminder and planning systems for individuals with other cognitive impairments, including other acquired impairments such as Alzheimer's and amnesia, as well as developmental cognitive disorders such as Down syndrome.
Wu, Baecker, and Richards  developed the OrientingTool, a software application for PDAs that can be used by amnesic individuals to keep track of tasks and orient themselves when feeling lost or disoriented.
The CLever Project is investigating the development of a prompting system to support individuals with developmental cognitive disorders .
Although there is much to learn from the research endeavors described above, our research differs in that none of these projects have focused on the development of a system for people with language impairment.
ESI Planner II was designed in collaboration with three speech-language pathologists from the Kessler Rehabilitation Center.
Other researchers have also examined the use of non-target individuals in participatory design.
Both  and  suggested using advocate users, that is, aphasic individuals who are, for one reason or another, better able to contribute in a participatory design setting.
Our work can be distinguished from the above mentioned in that we have used specialists, who we believe have a variety of advantages.
We chose to use these individuals as proxies in the design process for a variety of reasons.
First, in addition to being experts in aphasia they were all very familiar with the alternative and augmentative communication devices available and all regularly prescribed the use of Lingraphica in their professional practices.
In this capacity, their job is to first determine whether or not Lingraphica is suitable and appropriate for the client, and if it is, to train that individual on its use.
An important part of this process is assessing the support network of the patient and generating an initial collection of Lingraphica phrases for the patient to practice.
The experience of the speechlanguage pathologists showed that adopting the new technology may depend on the presence of a caregiver or a member of the family who has the time and enthusiasm to learn the technology and assist the patient at home.
In addition, aphasia takes many forms and is often accompanied by other impairments.
Because of the speechlanguage pathologists' years of involvement with individuals with aphasia, they could provide us with a broad, integrated understanding of the challenges of aphasia; in particular, who would most benefit from the system we were building and what difficulties they might encounter in using the system.
Furthermore, speech-language pathologists must spend considerable time with each patient and their family in order to assess an individual's overall condition.
They work not just as speech therapists but as social workers who help build strategies and support networks for coping with the changes aphasia will bring to their lives.
Thus, the therapists are very familiar with many family situations and patient needs.
Moreover, this approach allowed us to research the needs of people with aphasia at a distance, allowing those of our researchers who did not have prior experience in working directly with individuals with aphasia to gain a deeper understanding of the problem and prepare for interacting directly with individuals.
Finally, the very nature of the career attracts an incredibly empathetic and sympathetic group of individuals because of the need to understand people who cannot speak.
They were thus able to offer deep insights about our users.
In addition, the particular speech-language pathologists involved were all enthusiastic about participating in the development of a new technology to help people with aphasia.
Two limitations of the original ESI Planner prototype were the lack of support for developing a vocabulary of appointment data and difficulties using the PDA's limited interaction capabilities to construct appointments.
As a speech-aid, we predicted our use of a calendar as the main navigation interface to the preconstructed speech segments to be an improvement over the standard hierarchical folder structure used in Lingraphica.
The first stage of our design process was to present paper prototypes of variations of our initial vision to the speechlanguage pathologists.
For each proposed design, we asked them to  rank the designs relative to one another,  qualify their rankings, and  identify each design's strengths and weaknesses.
From this feedback, we identified the following design requirements: Ensure icons clearly indicate their underlying use.
We proposed schemes that used color to reinforce information , but the speechlanguage pathologists preferred the use of spatial relationships to supplement visual or audio cues, .
Although having easily understood icons would be considered good practice in any project, we include it here given its increased importance for individuals with language impairments and to reinforce that for many user groups, clear, logical icons that describe functionality are preferable to stylized ones that emphasize visual appeal.
Associate a sound clip with every visual item on the screen to supplement visual recognition.
Wherever practicable, the speech-language pathologists wanted to have every item on the screen convey its function aurally to the user to supplement visual recognition of elements and to ensure that the user would know when he or she has interacted with the interface.
Allow phrases to be played both at the phrase level and at the word level.
The speech-language pathologists pointed out that playing a whole phrase is used in communication, but it is also important to be able play each word individually in order to practice pronouncing it Use visual cues to reinforce the relationship between images, sound, and text.
For example, when playing the sound clip for "dog," emphasize the text "dog" , and the image of the dog .
Keep interface elements balanced in the center of the screen.
Designs that followed this rule were preferred over conventional designs that placed elements such as scrollbars and buttons on the right-hand side of the screen.
Include an option that allows users to access from the home screen a written and spoken description of aphasia.
It is important for individuals with aphasia to be able to describe their condition quickly to a new conversation partner so that the visible effects of aphasia are not misinterpreted.
Restrict the use of menus and the depth of hierarchy.
Because our target population is mostly older and, thus, less likely to remember options that are not immediately visible, the speech-language pathologists recommended that we do not follow the Lingraphica hierarchical model for navigating through the categories of icons as well as remove all menus and options that could not be activated from the main screen.
In addition to all of the above requirements, a key design choice for which we collected feedback was whether to rotate the PDA display to provide enough space for the display of a pictorial phrase or to retain the traditional PDA orientation.
We were concerned that having to rotate the PDA would confuse users ; however, using the standard orientation often results in the phrase being split into two columns, as shown in Figure 2B.
The speechlanguage pathologists felt that rotating the PDA would not confuse users, but that breaking the text may cause those who favor one side of their visual field  to view the columns as relating to distinct phrases.
Figure 3: Screenshots of ESI Planner II:  the home screen,  day-view of appointments,  storyboard display of an appointment appointment was associated with one or more storyboards  that were accessible from the day view by tapping on the appointment.
Reminders were similar to appointments but were also associated with alarms.
The addition of support for phrases and checklists that were not associated with a specific appointment was done to allow for greater flexibility and to provide a location for items that might be needed on a daily basis.
The platform chosen for development was the HP iPAQ rx 3700, which has an integrated camera.
All of the usercustomizable data was permanently stored in the unit's nonvolatile memory and loaded into the existing Pocket Outlook Object Model  system.
Once stored in POOM, these data can be quickly accessed and displayed based on the times associated with the storyboards.
Specialized classes were written to load the images from Lingraphica.
Images were taken using the camera software that comes installed on the PDAs.
We then constructed a series of tasks to test our revised design.
We met again with the speech-language pathologists and asked them to complete each of the tasks as a group imagining the difficulties an individual with aphasia might have while interacting with the system.
Based on the feedback from the low fidelity paper prototype, we implemented a medium-fidelity working prototype in C# using the .NET Compact Framework.
The revised design centered on a home page  that provided access to the key functionalities identified in our paper-prototyping session.
Launching the appointment functionality brought up a day view listing the appointments for the current day .
Each appointment was displayed on the day's timeline with the appropriate hours highlighted.
The majority of suggestions we received pertained to aspects of design: increasing spacing between buttons to take advantage of white space and changing certain icons to indicate their use more clearly.
However, we also received feedback that directly contradicted with that of the paperprototyping session, underscoring the limits of paperprototyping and the need for medium-fidelity software prototypes in the design process.
For example, the speechlanguage pathologists had initially suggested scrolling arrows not be displayed  if there were no "next" or "previous" element but felt differently upon seeing the medium-fidelity prototype In addition, when shown paper prototypes, they had preferred the preview of storyboards that used four small icons  to indicate the storyboards content.
However, upon seeing this functionality implemented in a software prototype, they preferred a single, larger icon .
In this session, we also allowed time for unstructured conversation.
During this time, the speech-language pathologists began to share amongst themselves their experiences with Lingraphica.
Unexpectedly, this led to discoveries, which contradicted some of their responses in the structured interviews and fundamentally changed the direction of this work.
Surprisingly, when the speechlanguage pathologists realized they were talking amongst themselves, they apologized for "chatting" about the mundane frustrations of their work, unaware of how much pertinent information was contained in their stories.
This was particularly interesting to us as it indicated that much of their expertise was tacit, that is, embedded in the context of their work.
As a result, they were unable to articulate it when asked directly.
It was only through the sharing of stories that they were able to share with us this information.
For example, one speech-language pathologist recalled how a user had wanted a picture of a coffee cup customized with the phrase, "I'd like a venti caramel macchiato."
Another user had attached an entire story about his summer vacation to a picture of a tent.
Most concerning, however, was the discovery that in addition to having a steep learning curve, there are funding constraints that create a major access barrier to Lingraphica.
Because most individuals' insurance only provides a limited number of therapy hours, time spent learning a system like Lingraphica comes at the direct expense of other therapy activities--often ones that could potentially increase natural language.
As a result, many of the higherfunctioning individuals who we envisioned benefiting from ESI Planner II would not receive the necessary prerequisite training on Lingraphica.
Given these discoveries, we began to think about how we might create a system that would retain the strengths of Lingraphica--most notably its customizability and flexibility--while presenting the user with an easily learned interface .
This motivated us to develop an alternative to Lingraphica that we could use with ESI Planner II to create appointments, a system that we call LgLite.
Our design for LgLite sought to minimize the complexity of Lingraphica by eliminating many of the hierarchical menu searches needed to access Lingraphica's extensive vocabulary.
We chose a limited subset of Lingraphica's symbols that were relevant to appointment management and organized this information around the components that describe appointments: who, where, and when.
Although replacing Lingraphica with LgLite required us to scale back the scope of our initial ESI Planner II prototype , we were able to incorporate some features that we were very interested in exploring but that had not been possible with Lingraphica.
One such feature is the introduction of personal photographs into the image gallery.
The first LgLite prototype was an HTML mock-up of the calendar portion of the system.
A set of web pages represented the consecutive steps in the process of creating an appointment.
One could navigate through the mock-up by clicking on hyperlinked buttons that simulated the responses that LgLite would provide to the user.
Our HTML mock-ups of LgLite elicited an overall very positive response from the speech-language pathologists.
In particular, they especially liked the ability to incorporate personal photographs into appointments, as they felt this would be important to most users.
In order to get the speech-language pathologists to expand on what we discovered from their casual work conversations and to gain a better understanding of how Lingraphica is used in real world settings, we presented them with a series of open ended scenarios and asked them to expand on specific difficulties that they had encountered in training individuals to use Lingraphica.
During our exploration, we realized some of our initial assumptions were not supported.
They reported that very few individuals with aphasia become fluent with Lingraphica; most depended on a caregiver or therapist to set up new phrases.
Moreover, many were using the system to practice, not to create phrases for communication.
Thus, they were creating far fewer sentences than we had imagined: on average, only a couple each week.
We additionally learned that Lingraphica's most popular feature is the ability to personalize images with recorded sound and text.
They predicted that personal photographs would make this expression easier.
Our initial design allowed the user to delete appointments by pressing on a minus button on the left side of the appointment storyboard, an approach that approximated Lingraphica's interface.
However, the speech-language pathologists shared with us their experience that this--as in Lingraphica--would often lead to the accidental deletion of work in progress.
We also received feedback on the elements to include in our who and where categories.
For example, the speechlanguage pathologists pointed out that in addition to common everyday locations such as a favorite restaurant and the post office, popular travel destinations such as Florida should also be included.
Based on this feedback we built a software prototype of LgLite that implements the appointment input functionality of the envisioned hybrid system.
This prototype works as follows.
To schedule an appointment, the user goes through the stages of choosing whom she is meeting, where the meeting is going to take place, and when it is going to happen.
The first two stages are optional, but, intuitively, the time for an appointment needs to be determined for it to be noted on a calendar.
The who and where categories provide a collection of images from Lingraphica's vocabulary of people and places  that can be used to form the basis of a new appointment.
A pictures category brings up the user's personal photo gallery.
This photo gallery is automatically updated each time the user takes a picture with the PDA's built in camera.
The when category leads the user through the steps of selecting the month, the day, and the start and end time of an appointment.
Once the meeting date and time have been specified, the user can transfer the appointment to the PDA by clicking a button that causes ESI Planner II and LgLite to synchronize .
Our next step was to conduct a preliminary pilot evaluation of our hybrid ESI Planner II-LgLite system.
The primary reason for moving directly to this phase without performing further evaluation of LgLite with the speech-language pathologists was that we felt that the feedback we can get by piloting the system with real users is likely to be a better use of our limited time resources.
Moreover, because LgLite is largely based on Lingraphica  and because we used richer HTML mock-ups instead of static paper prototypes to present our initial design ideas, we were confident that we received sufficient feedback during the initial LgLite design session.
Two used computers primarily for the software available to help individuals with aphasia: Bungalow , a suite of therapy programs for practicing natural language, in addition to Lingraphica  and Dynavox , two alternative and augmentative communication devices.
One of the participants had a background in graphics design, and all but two participants were regular users of email .
Although our participants were similar in their computer experience, they had a wide range of verbal and motor functions.
Two participants had severe motor impairments on the right hand side of their bodies requiring them to work with their non-dominant hand.
Another had severe right-field neglect, which tested our efforts to produce a design sensitive to such deficits.
One individual had near fluent speech but was unable to recognize or produce written text.
Because many previous assistive technologies have performed well in lab studies but have subsequently received little or no adoption in the field , we chose to use a longitudinal field study methodology lasting for four weeks.
For the study, we loaned each participant an iPAQ with ESI Planner II installed.
We installed LgLite on one of the computers at the Adler Aphasia Center where each participant is involved in day-long activities at least twice a week.
The first session was dedicated to training the participant on the use of both systems.
In particular, they were taught how to  create appointments on LgLite and view them within ESI Planner II,  personalize the text and sound of icons in LgLite, and  take pictures with the PDA and incorporate them in an appointment.
Before training, we administered the ASHA Quality of Communication Life Scale  to each of the participants; the average score was 3.8 and the scores ranged from 3.2 to 4.1.
The average score showed that our participants were all moderately impaired.
The remaining three sessions were dedicated to meeting with the participants to help them with any difficulties they were having and to get feedback from them about the system.
In addition, we collected logs of the participants' usage of the PDA that we examined at the end of the study.
In the following section, we highlight the feedback we have received.
Users also had some difficulty differentiating between the who, where, and when options and would sometimes click on the wrong image; however, upon hearing the category aurally, they usually realized their mistake and recovered quickly.
Users also had difficulty timing the record option: because they often had to mentally prepare themselves before speaking, there was often a long pause between when they hit the record button and when they started speaking.
This lag between pressing an icon and hearing the sound was perceived as slow, unresponsive behavior by several participants.
Some confusion was also observed in distinguishing between the functions of the stop and cancel buttons on the sound record menu.
Our mechanism for specifying the start and end times of an appointment was particularly problematic.
The original ESI Planner used independent widgets to specify start and end times.
This approach was error-prone for those with difficulty with numbers as they could not use the relation between the start and end time to help them confirm their entries.
We thus chose a design that presented the times of day laid out in 15 minute increments , allowing for the use of the position of the start and stop times relative to each other and the day to help users choose correct times.
However, there was disagreement on how the end time should be specified.
Some felt that to specify an appointment ending at 10 am, the user should select 9:45 am--the last 15 min block within the appointment--while others felt that 10 am should be selected.
Further work is needed to determine how best to address this problem.
A major difficulty that users had with our system was its context within the Windows operating system both on the PC and the PDA.
Although we designed our system to discourage users from exiting ESI Planner II , a number of our users successfully exited our programs and entered Windows.
Although it took them considerable effort to again find either LgLite or ESIPlanner II, they were usually able to do so.
Although we intentionally limited appointment creation to LgLite for simplicity, four of our users requested the ability to create appointments on the PDA.
One user, who had regained enough reading and writing capability to use his PDA's calendar application, but could not speak, was disappointed at the limited capabilities of our program.
Though he could use a regular calendar application, he did feel that he would benefit from the speech and text capability of our program, provided it can be customized to display information without images.
These findings point to the need for customization mechanisms allowing the complexity of the system to be scaled to the abilities of each user.
All except one user took the PDAs home and used them in the four week trial, but they did not use them to create appointments as expected.
Initial reactions to the training session were positive.
We had scheduled 45 minutes for training; nevertheless, all but one user wanted to practice and ask questions beyond the allotted time.
One Lingraphica user said that it was much easier to find what he was looking for in LgLite than Lingraphica, and users not only wanted to adopt the technology but were also thinking of new uses and ways to further extend the software.
For example, one user wanted to use the software to remind him to send an e-mail, while another was disappointed that we had not yet developed the capacity to record sounds and have them attached to pictures in the photo gallery.
He envisioned using the PDA to take someone's picture and then have that person record a sound clip associated with the picture.
There were some difficulties in using the system, however.
Some users had difficulty understanding the transfer of information between the PDA and computer; they expected new appointments to automatically appear on the PDA.
Others had difficulty pressing precisely or hard enough on the PDA's touch screen.
However, the option of integrating pictures taken with the PDA's camera was an instant success.
All but two of the users took dozens of photographs, and one user accumulated over one hundred.
Users tried to tell us stories using only the images they had collected, but were hampered by their limited communication abilities and by the inability to enter in the PDA comments or cues associated with pictures.
This confirmed the need for an efficient tool that allows the user to personalize images with text and sound on their mobile device.
A final issue with our integrated system was the large differences in how aphasia had affected our users.
Because some users were able to read or write, they felt the icons used in our system were inappropriate and wanted a handheld system that could convert a typed message to speech.
Other users had high levels of speaking skills but no reading and writing skills.
They needed speech support for navigating through complicated symbols such as setting appointment times or dates.
This again highlights the importance of being able to tune the system for different abilities to be effective.
Although these difficulties show that our hybrid system still requires more work, we were encouraged that all but one of the participants were eventually able to perform all the necessary tasks independently.
For example, in several instances a user deftly navigated to a day and pressed the button to play a phrase associated with that day.
The system, however, was still playing the sounds generated by pressing the navigation elements required to get to the day view.
Addressing this issue may require a context sensitive design because in some instances it may be desirable for the user to be able to queue up a number of sounds; for example, a user may want to play a subset of an existing phrase by clicking on some of the images.
In addition, users commented on the lack of variety in each of the who and where categories, noting that common meeting locations like coffee shop and park were missing.
While designing and building LgLite, our desire to build a system that was structurally similar to Lingraphica was at times in direct conflict with our desire to build a very simple system.
As a result, some features of LgLite are unnecessary or redundant.
For example, one feature of Lingraphica that we retained is the ability to retrace your steps through a navigation panel that keeps track of the buttons that have been pressed to reach the current location.
The initial feedback we have received from users is that in LgLite this feature is unnecessary given LgLite's shallow hierarchy; it thus wastes valuable screen real estate.
During the process of creating a new planner system to give people with aphasia more independence and confidence, we demonstrated the value of scenario-based design  when using proxies to a target population.
Although the speechlanguage pathologists had a wealth of information that was useful to our designs, much of it was tacit--that is, they did not think of it as being important or useful.
By engaging them in story-telling, we were able to get them to share essential information that we had not been able to access though more structured interviewing techniques or by having them evaluate paper prototypes of proposed designs.
The speech-language pathologists were very useful in addressing the day to day life needs of our user population, but they were relatively poor at evaluating paper prototypes because they could not envision the problems users would have with the detailed interaction with the systems.
We suspect that if we trained them in usability evaluation techniques, their developed communication skills would also provide us more insight into the problems our users could experience.
Although users seemed to enjoy and were able to use the system, there are still elements that should be refined.
The authors would like to especially thank Bernadette LaFond, Eileen Head, and Julie Jacobs of Kessler for their support in design and testing; Andrew Gomory and Richard Steele of Lingraphica for software and advice; and Karen Tucker, Chrysa Golashesky and, above all, the members of the Adler Aphasia center who participated in the study for their tremendous help and enthusiasm.
The aphasia institute: What is aphasia?
Beukelman, D.R., and Mirenda, P. Augmentative and alternative communication: Management of severe communication disorders in children and adults .
Carmien, S. MAPS: PDA scaffolding for independence for persons with cognitive impairments.
Cohene, T., Baecker, R., Marziali, E., Designing interactive life story multimedia for a family affected by Alzheimer's disease: a case study.
Davies, R. The Ethnographically Informed Participatory Design of a PDA Application to Support Communication.
Master's Thesis, University of British Columbia, Canada, 2004.
The ethnographically informed participatory design of a PDA application to support communication.
The assessment of aphasia and related disorders .
Design issues encountered in the development of a mobile multimedia augmentative communication service.
The ELDer project: social, emotional, and environmental factors in the design of eldercare technologies.
Issues Surrounding the User-Centred Development of a new Interactive Memory Aid.
Aphasia, depression, and non-verbal cognitive impairment in ischaemic stroke.
Martin, C., Dellatolas, G., Viguier, D., Willadino-Braga, L., and Deloche, G. Subjective experience after stroke.
Moffatt, K. Designing Technology For and With Special Populations: An Exploration of Participatory Design with People with Aphasia.
Master's Thesis, University of British Columbia, Canada, 2004.
Moffatt, K., McGrenere, J., Purves, B., and Klawe, M. The participatory design of a sound and image enhanced daily planner for people with aphasia.
American Speech-Language-Hearing Association, Rockville, MD, USA, 2004.
Rosson, M. B., and Carroll, J. M. Usability Engineering: Scenario-Based Development of Human-Computer Interaction.
Thorburn, L., Newhoff, M., and Rubin, S. Ability of subjects with aphasia to visually analyze written language, pantomime, and iconographic symbols.
Evaluating the use of TalksBac, a predictive communication device for nonfluent adults with aphasia.
Waller, A. and Newell, A.
Towards a narrative-based augmentative communication system.
Wu, M., Baecker, R., and Richards, B. Participatory Design of an Orientation Aid for Amnesics.
