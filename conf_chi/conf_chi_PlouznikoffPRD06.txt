Alexandre Plouznikoff 1, Nicolas Plouznikoff 2, Jean-Marc Robert 2, Michel Desmarais 1 Human-Machine Interactions Laboratory  Department of Computer Engineering  & Department of Industrial Engineering  Ecole Polytechnique de Montreal C.P.
This paper studies a novel approach advocating the virtual alteration of real-world interfaces through a form of augmented reality.
Following an introduction reminding the need for easy to use and more consistent interfaces across our many day to day devices, this paper makes the case for using wearable computers to enhance the interactions between humans and conventional appliances.
We present the rationale behind our research and summarize our current prototype's functionalities, architecture and implementation.
Preliminary results suggest that virtually altering the interface of real world devices improves execution times for simple tasks using these devices.
Moreover, even though appliances pertaining to the same class of devices sometimes share common interface components or layouts, no widespread standards exist and many challenges remain to achieve consistency.
As a result, users usually have a good general understanding about the use of a familiar class of appliances but still have a hard time and become confused in front of the unfamiliar interface of a specific device of this class.
Designing appropriate interfaces for the numerous devices and appliances we use everyday  is not an easy task: among other things, a good conceptual model has to be provided, the controls need to be visible and easily accessible, and the device must offer a meaningful feedback.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
A major problem plaguing many current appliances is functionality overload.
In order to sway consumers, appliances are often loaded with as many features as possible even though 80% of the users will typically use only 20% of them.
As a result of this ever growing number of functionalities, appliances become increasingly complex.
Such complexity is reflected internally but also visually and in the interface as interaction paths need to be created to access all these functionalities.
The mostly hardware and relatively static nature of the appliances' interfaces only exacerbates this functionality overload.
Every user, regardless of experience or tasks, has to use the same all-inone interface as physical buttons and controls cannot appear or disappear at will as in software interfaces.
Without redesigning an appliance, we would like to improve task execution times by altering its interface to enhance interface components identification and selection times.
Our objective is clearly not purely cosmetic as we want to improve efficiency and user satisfaction without, ideally, creating additional requirements for user attention.
This kind of in-place modification contrasts with interface virtualization for common appliances  as our goal is not to uncouple, abstract and transpose the appliance's interface to another medium .
Adaptable interfaces provide mechanisms enabling users to personalize them according to their needs.
For example, in most conventional graphical human-computer interfaces, end users can directly modify the layout and features of an application's interface, use "skins" to customize the appearance of a media player or even switch between a standard and a personalized interface .
Users strongly support adaptable interfaces and personalized interface design because they are able to effectively customize an interface and remain in control .
Adaptive interfaces automatically adjust the interface in ways that are expected to satisfy each individual user's needs, sometimes according to collected environmental or user data and often in real-time.
Smart appliances  can for example be attentive to their environment  and respond accordingly.
Such an approach has been applied to kitchen appliances .
Both approaches are quite interesting but cannot readily be applied to current appliances as there are usually no simple means to physically modify an appliance's interface.
A wearable computer's role is to assist a user carrying out real-world tasks in an environment where human-wearable computer interactions are not the primary focus.
Information projection has already been investigated for the external alteration of a real work environment  .
The information was projected onto appliances, objects and surfaces to successfully direct the users' attention, to orient them and to coordinate between multiple tasks.
Low attention, overt, real-world information cueing using wearable computer displays  has also been investigated and can be useful to isolate real-world patterns or remember information as it improves short term memory recall rate as well as execution times for simple visual search tasks.
This "artificial synesthesia", a form of subtle and personal realworld information alteration, could help enhance an appliance's interface without retrofitting or modifying the target appliance.
Thanks to its fundamental characteristics and its close proximity to the user, a wearable computer can directly influence a user's perception, actions and decision making process.
Thus, it is a very attractive platform for the external alteration of an appliance's interface; the goal being to add an additional virtual layer on top of the real appliance's interface to highlight interface components or even insert information.
This "virtual skinning" of a real interface is in fact quite similar to an artificial digit-color synesthesia , though digits are replaced by interface components.
The new virtual layer, which is generated by the wearable computer, subtly alters the perceived appliance's interface .
Real appliance's controls are used normally but the user's actions involving these components 
The human-wearable computer interactions are entirely implicit as there is no direct and explicit exchange between the user and his/her wearable computer.
New kinds of interface components emerge as byproducts of the alteration of real world objects' properties.
Conventional interface components, while retaining their usual properties and attributes, also gain new ones.
The real part of an object  is complemented by its virtual part .
This novel approach could improve our interactions with our everyday devices and appliances by countering functionality overload, improving consistency between interfaces and enabling person specific interface enhancements.
By creating a cognitive link between dissimilar interfaces and contributing to their unification and by taking into account a user's preferences and reflecting them into an interface to speed-up man-machine interactions, virtual alteration could lessen a user's perceptual and cognitive work.
To better understand the power of the idea, imagine perceiving on/off buttons on all appliances as being the same color, imagine seeing on the interface of every vending machine the correct key sequence  needed to obtain your known favorite snack, or imagine using your desk phone more efficiently with a person's picture replacing each speed dial button.
Of course, this concept works well to alter an interface component's color, label and to some extent shape but not its placement or the internal workings of an appliance.
In the end, a user will be able to interact more efficiently with devices augmented by subtle virtual information provided through the wearable computer.
We then recorded for each participant of the first group the time taken to complete the task.
We repeated the same experiment with the second sub-group  but this time with an altered view of the world rendered in the wearable computer's display.
Though not mentioned to the users of the second sub-group before the experiment, the CookTime button was altered and displayed in orange in the rendered view of the world to help them pinpoint it.
The color orange was selected as it is often associated with heating.
Figure 2 shows an altered view of the stove interface, as seen through the wearable computer's display.
A field experiment has been devised to assess and quantify if the virtual alteration of specific machine interfaces can improve a user's performance.
For this study, we selected a family of devices with which everyone is familiar but which is heterogeneous enough so that each device would present significant differences with the other; this to correctly gauge the effectiveness of virtual interface alteration and its propensity to bring closer different mental models of a same family of devices.
More precisely, we focused our experiment on human-stove interactions to assess if the virtual alteration of their interfaces could lead to significant time gains for a specific task.
Our wearable computing platform was built around a PC104+ core module, with a Transmeta Crusoe 1.0GHz processor and 256MB of RAM.
A MicroOptical SV6 opaque display  was used as the video see-through device.
A low power miniature point-of-view video camera with a color CCD was mounted on the user's glasses to acquire live video for interface components detection and was connected to a video capture add-on board.
All the hardware and wirings were integrated into a vest so as to be easily worn and not to hamper the user's movements.
We recruited 8 test subjects  with no familiarity about the specific stove to be used in the study but with general knowledge about cooking appliances.
During the selection process, we ensured that each selected participant owned a stove but only seldom used it .
The group was then randomly divided in two subgroups of 4.
The participants were not aware of the group to which they were assigned.
Each participant of the first group  was asked to start a 5-minute cooking program on the selected stove.
Each participant was first briefed about the task to accomplish and the different steps to do so, along with the different buttons to press for each step without disclosing their location .
Though our current application is specific to the appliance's interface we chose to enhance, our architecture  was devised so as to be easily adaptable to enhance other similar interfaces.
Our C++ application relies on IntelTM OpenCV library for image processing.
The main processing loop is built around a simple real-time Hough transform algorithm to isolate every round button in the acquired image.
Once the buttons have been found, their centers and radiuses obtained, and the CookTime button isolated, a nice shade of orange is blended with the button's pixels.
The altered image is finally presented to the user on the wearable computer's display.
Execution times to complete the given task for each participant of the first and second sub-groups are summarized in the table below.
As Table 1 shows, virtual interface alteration seems on average to greatly decrease the execution time to complete the given task .
A one-tailed unpaired T-test assuming equal variances with =0.05 led to a p-value equal to 0.0012, which shows that the increased performance between the two subgroups is statistically significant.
Though our application is currently device-specific and confined to a controlled environment, our preliminary results indicate that virtual interface alteration can significantly decrease the execution time for the given task.
The 30% decrease in response time can be explained by the information cueing reducing the search time for the CookTime button.
In light of the current study and previous research, we may hypothesize that man-machine interactions can benefit from virtual interface alterations in various fields.
To further validate our hypothesis, we will concentrate in the short term on leading a thorough study with our current prototype, including larger study groups and satisfaction evaluations.
We will then strengthen and enrich our current detection algorithms so as to put to use the benefits of virtual interface alteration in an uncontrolled and mobile setting.
Our feature detection algorithms will be expanded to support more interface components.
We will also focus on implementing a text recognition algorithm to interpret more efficiently both known and unknown interfaces; this to detect which component to alter and in what way.
In the future, we could end up with a virtual interface alteration platform that will not only be able to cue additional information to the user but guide him step by step by highlighting only possible choices at the right time.
In the near future, this concept will surely bring forth new tools to support virtually altered context sensitive and adaptive hardware interfaces.
Our novel approach could, for example, help improve the learnability and intuitiveness of appliances' interfaces, especially for novice users.
Virtual interface alteration can be seen as the happy medium between the complete modification and standardization of current hardware interfaces and the design of standalone virtual interfaces, each specific to a given user's needs.
