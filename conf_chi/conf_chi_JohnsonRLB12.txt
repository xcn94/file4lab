Alternatively if participants disagree with the perceived hypothesis they may take care to act in a way that disproves it.
This leads to the question: how can researchers account for and manage their influence on participants in-the-wild when so many other factors are at play?
Instead of trying to minimise their effect on participants by distancing themselves, researchers could try to understand this effect by getting more involved - perhaps, even joining in.
Being in the thick of in-the-wild studies may offer other benefits as well.
For example, sensitising the researcher to key elements of the participant experience to guide interviews or observations.
This paper looks at what happens when the investigator becomes a participant, and asks: - What roles does the researcher play in an in-wild study and how do these vary?
We address these questions by describing and reflecting on two exploratory studies of two prototypes designed to help people practice bowing stringed instruments, like the violin.
The prototypes are intended to help players by using realtime feedback, either visual or vibrotactile, that responds to players' movements.
The idea is to help people adapt their playing as they go, encouraging them to practice good habits.
Each study shows a different level of researcher participation.
One, where the researcher is participant observer in the sense of sharing a similar perspective to the participants as a fellow orchestra member, and, two, where the investigator actually participated as a player during the study.
In comparing these two studies we are able to reflect on how different levels of researcher participation affected what data was available to the researcher and how this was collected and interpreted.
We describe the insights and challenges offered by researcher participation in in-the-wild studies through the comparison of two prototype evaluations with varying levels of researcher participation.
By reflecting on these studies we expose different facets of the researcher's role when interacting with participants in in-the-wild studies.
We also demonstrate the value of researcher participation in contributing to the way a researcher understands participant responses: aiding rapport, promoting empathy and stimulating the researcher to reflect on their own assumptions.
In-the-wild studies are increasing in prevalence as ways of understanding how new technologies may potentially disrupt, support or enhance our everyday activities.
In this paper we use the term in-the-wild as Rogers  uses it to mean studies which involve deploying new technologies in real-use, real-world situations and studying how they are used in this context often with the intention of improving a design.
Implicit within this type of methodology is the idea that physical and social context will have a critical effect on usage.
However, as Brown et al.
For example, participants will have certain expectations about what investigators are looking for in an experiment, known as demand characteristics, which can affect the way they behave.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Participant observation is widely used in social sciences and anthropology, most commonly associated with ethnography .
It is prized for giving researchers an insider perspective allowing them to interpret their observations with an intimate understanding of the values, beliefs, social norms and experiences of the group or culture being studied.
The ethnographic tradition within HCI is that of "realist ethnographies"  which concentrate on giving an authentic and authoritative description of the group or context being studied.
In doing so, the investigator's voice is removed from the text preventing discussion of how the researcher's presence in the field, their interactions with participants and their own background and experiences, have shaped the ethnography.
By removing this voice the role of participant-observation within ethnography is de-emphasised by eliminating the means to discuss what is in essence an experiential research process .
Recently there have been calls for HCI to embrace a more reflexive approach to ethnography, such as that found in digital anthropology .
Reflexivity means reflecting upon the way the ethnographer is part of the ethnography itself, their background and perspective is as much part of the research as those of the culture being studied.
Although this call for more reflexivity has mainly been addressed towards ethnographers studying existing contexts, it is just as relevant to those doing studies of deployments of new technologies in-the-wild.
Perhaps, more so, because deploying a new technology requires hands-on intervention into the daily routines of a setting.
Participant observation "can be seen as an attempt to build up the kind of relationship, both participant and observer, both closed and separate, that allows people to understand what it is like to be the other."
We suggest the empathetic relationship built up between participant-observer and user through shared experience can be a fruitful way to study the experience of users testing prototypes in-the-wild.
There are not many examples where the researcher becomes a participant in a deployment where a prototype is being evaluated.
The work of Kientz and Abowd  is a rare example in which a designer, having trained and worked as a therapist for 10 months, continued to work as part of the therapy team during the evaluation of a prototype system.
Their paper details the potential danger that investigator participation might have in biasing the uptake of a system.
They justify the researcher's involvement by arguing that she took role of 'champion', described by Grudin  as being critical to the uptake of new technology.
Additionally the researcher's position in the therapy team was valuable as technical support.
We would argue that even when the investigator does not come into contact with participants they are implicitly asking participants to use their prototype by providing it.
By agreeing to take part in the study the therapists are already showing their intention to use the system and be `good participants' .
The researcher's relationship with the therapy team and first-hand experience with the prototypes may have produced rich qualitative data and an insightful analytic perspective; however this is not discussed in their paper.
The real-time feedback we are studying with our prototypes offers learning through experience rather than being a more theoretical or reflective learning process.
As Light  points out, gaining access to and understanding another person's experience is very difficult; interviewees often analyse or try to account for their actions rather than talking about their experience at the time.
Light advocates a particular type of interview method to get around such obstacles, which is similar in style to the "second person interview" method  used in cognitive science to access accounts of subjective experience.
This method appears particularly good at accessing fleeting thoughts which often do not appear in standard interviews.
However there is a danger that unpacking experience into a layered chronology of actions and thoughts could lose a holistic view on experience, that may be equally as important.
Wright and McCarthy  have a different take on how designers may gain access to users' experiences: empathy.
In-the-wild studies, which evaluate prototypes in ways that acknowledge the realities of their intended context of use, offer different findings to those from laboratory studies .
For example, new and unexpected uses , long term behaviour change , the process of interpreting new technology  and the ability for a technology to suggest its use and interaction mode in a setting .
Some in-the-wild studies have the feature that the researcher interacts very little with participants.
One such example is the deployment of a multi-touch table in a tourist office to help people plan a day in Cambridge .
During this study, researchers observed participants using the table in a fly-on-the-wall manner.
By keeping this distance they were able to evaluate how people naturally approached the table-top, and found this to be different to the way people congregate around them in lab studies.
The tourist centre is a public place and participants behave in the knowledge that strangers may be watching.
Indeed, some of the more self-conscious first interactions with the system show this.
In public settings the presence of the researcher is unlikely to affect people's behaviour because they are already putting on a public face.
This means that fly-on-the-wall observations would no-longer produce true representations of how people naturally interact with a system.
In-the-wild studies have approached collecting data from non-public settings in a number of different ways.
In some ways this could be criticised as enhancing the amount of self-censorship participants may perform because they are presenting a public face.
On the other hand, participants may become less preoccupied with trying to please the researcher because they now perceive their audience as the film-maker and the general public.
Participants are instead trying to help the film-maker by talking in sound-bites and presenting a coherent story.
This new perspective may be particularly productive when taken in conjunction with the ethnographic observations they also conducted.
Another approach is to build up a familiar relationship with participants so that the researcher is no longer a stranger for whom they have to perform, but a normal part of the setting.
In our previous study  we were careful to build a close relationship with the teachers before and during the study.
We worked as a team during lessons: as they taught we acted as technical support making sure the prototypes did what was needed.
We consider that this collaboration meant we became a familiar part of that teaching setting.
There are other roles the researcher can take in their relationship with participants.
For example, action research advocates the role of "friendly outsider" working with the community rather than for them .
Another example is ethnography where the researcher attempts to become an insider, the success of which is measured through the perception of those being studied .
What is important in all these roles is not how researchers view themselves but how they are perceived by participants.
The studies described here present many different roles the researcher may take within a study.
A common role within many of these studies is the researcher as facilitator facilitating the user by providing the technology.
In some cases, this role extends beyond providing the technology to acting as "champion"  - encouraging its use.
Related to the facilitator role is that of the researcher as technical support ; a role which can also act as a way of building up positive relationships with participants.
A difference is whether the researcher takes the role of explainer of the technology and the study.
In some cases, this is an integral part of the study .
In others, the research question means that the researcher decidedly avoids this role .
In a third type , the intention is to avoid explaining a particular use for a system; here the researcher takes a borderline role explaining some things while leaving others open for interpretation.
The researcher's role when observing can take many forms, based on how closely he or she interacts with participants.
For example the role of the researcher in Marshall et al.
The literature shows that there is an on-going debate within HCI about how to study the way people interact in the realworld.
A central question is the extent to which research findings are the product of the way data is collected by the researcher and how this should be accounted for in the way research is presented.
Here, we aim to contribute to this debate by presenting and reflecting on two studies that use researcher participation to investigate the deployment of technologies to help violin practice.
Both studies can be considered to be in-the-wild; they examine the deployment of technology in the greater context of the learning and practicing process of the participants.
The first study aimed to help university orchestra players to practice individually by introducing a new technology addressing a request from the conductor for longer bowing.
The second study aimed to explore the potential for similar technology to be used in group practice where the tasks could be determined by the participants.
This took place at a week-long orchestral summer school.
In our description of these studies, we give details of the prototypes and the findings to provide understanding of the purposes and outcome of each deployment.
However, this is not our main focus.
Instead we concentrate on the way the researcher interacted with participants and the setting and how this affected the way the data was collected and understood.
The aim of this study was to explore different modalities of real-time feedback for use in music practice.
Previous research showed the efficacy of vibrotactile feedback to aid teaching violin .
However most people spend more time practising than in lessons, therefore, this study chose to focus on individual practice.
The different modalities investigated were vibrotactile feedback and visual feedback.
Both modalities have different qualities in terms of the complexity of information that can be displayed, how they reference the body, and how intrusive they are.
This study investigates how these aspects are important when designing real-time feedback.
The study was carried out with a university orchestra and the intervention was motivated by comments from the conductor during rehearsals asking the violinists to use longer bows in certain sections of the pieces.
The MuSense prototypes used in this study focussed on the amount of bow used by the participants.
As with many other aspects of technique there is no single ideal - players don't always want to use full bow lengths, but there are cases where this is essential.
To give a clear task we used sections of the music chosen by the conductor where full-bows are important.
Feedback was given to participants either as a vibration on the wrist of the bowing arm or as a visual display.
The vibrotactile feedback came on once the player had done a sufficiently long bow-stroke and stayed on until the player's bow changed direction.
Two alternative visual mappings were used in order to explore the different levels of complexity visual feedback has to offer.
A simple visual display was used to show the visual equivalent of the vibrotactile feedback.
Once the bow had moved through a certain length, the entire row lit up green.
A more complex display was designed to provide more detailed feedback.
Once past a certain point the lights change from blue to green to show the point where the player is using a 'good' amount of bow.
The orchestra was made up from university staff and people from the local area, with a range of abilities and ages .
The researcher was at the lower end of this age group, and a mid-level player among the second violin section.
This meant that she was often working with players who were more experienced.
Each session took a similar format: The participant played the selected sections for five minutes as they would normally practice them.
They then played the same sections this time focussing on maximising their bow strokes.
They were asked to play the same parts three more times using each type of feedback for about five minutes each.
They finished by playing each section twice without the feedback.
During the session, bowing data was recorded and at the end there was a short semi-structured interview lasting ten minutes.
Participants were able to quickly learn to use and understand the feedback in the context of the task.
The bow length data suggests that the introduction of the feedback changed their bow usage.
In some cases, this meant more bow was used.
In others, a wider variation in the amount of bow used, which related to the players experimenting with different bowing styles.
People who liked the complex visual feedback said they did so because it showed them how close they were to reaching the target each time.
However, other participants criticised it for not catching their attention enough, saying the changes in the display were too subtle.
The simple visual feedback was considered more noticeable than the complex one, but some found the flashing too off-putting and difficult to interpret.
People who liked the vibrotactile feedback did so, because it did not interfere with them reading the music and they found the vibrations easier to interpret than visual signals.
However, those who preferred the visual feedback claimed they found the vibrations difficult to interpret and the visual line fitted better with their mental model of the bow.
A gyroscope linked up to an Arduino Pro Mini  and positioned on the player's lower arm was used as a way to infer the length of bow being used.
The gyroscope signal was integrated to get the angle the arm moves through as the player bows.
This angle is closely related to the length of bow used and gives accurate enough feedback for this link to be readily apparent to the player.
This data was then transmitted using a wireless serial connection .
The vibrotactile feedback was delivered using 10mm shaftless DC motors controlled by an Arduino.
The visual display was made from 22 RGB LEDs controlled by an Arduino and two TLC5940 PWM chips.
The following account describes how the researcher used individual emails and her personal relationships to encourage participation in the study: "Initially an email was sent to all string players through the orchestra organisers.
This produced some replies but not enough for the study.
Therefore I resorted to sending individual emails to people I knew within the orchestra .
I do not believe people necessarily felt pressurised to participate by these emails, but personal emails do imply a need to reply in the way a group email does not.
People have to actively make a decision whether to participate and generally they were willing to.
I believe that some of the motivation for people to participate was to help me as a person as well as to find out about and support the research itself.
A 5 gift voucher was also offered however it did not seem a primary motivation - some even said that they did not want it."
Building on personal relationships with participants during recruitment sets-ups an atmosphere of familiarity, which continued into the study and affected the way participants interacted with the researcher.
For example, criticism of the devices was often phrased in a constructive way, giving enough detail to enable improvements or balanced with a positive comment.
This kind of interaction shows participants are responding to the researcher, both on a personal level and as a data gatherer and that they recognise that she has an emotional interest in the long-term success of the design.
The researcher's position as fellow member of the orchestra also gave her particular insights into the way the participants felt about being asked to carry out the tasks for the study as the following reflections discuss: "Nearly all participants seemed nervous.
I could empathise with this nervousness, playing on your own is revealing something very different about yourself to playing in an orchestra.
I offered reassurance by admitting that I couldn't play these parts myself and joking that maybe the conductor had chosen the hardest parts to get us to practice.
Being a member of the orchestra gave me the facilities to identify with the emotions of the participants and offer reassurance in a way a stranger could not."
We chose a week long adult music summer school as a setting to explore the concept of real-time feedback in ensemble playing.
This summer school offers a wide range of courses, including orchestral, folk, jazz and chamber ensembles.
The study was planned so that a researcher would be at the summer school attending some courses and meeting with participants in groups during their free time to try out the prototypes.
This participatory approach was chosen in order to get an insider view of what it is like to be a student there and to build a rapport with participants outside of the study setting.
The researcher also participated in playing with participants during the study, using the prototype like one of them.
The idea was to share the experience of playing in an ensemble with the prototypes.
Unfortunately, due to timetable constraints, participants were only free to meet singly or in pairs.
This meant the role of the researcher as ensemble player became more valuable than initially expected because in many cases it was her participation which changed the setting from the participant playing alone to playing in a group.
To test the device, the tasks in the study needed to focus on long bowing.
Tasks also needed to be useful to participants outside the study itself in order to make practice meaningful to participants.
To choose such tasks and say that they will be useful requires authority that comes from a high level of musical knowledge.
However, as the previous sections suggest, the researcher presented herself as being a musical equal to the participants.
For this reason it was very useful that the tasks themselves were sections of the current repertoire selected by the conductor as being relevant.
This meant the researcher could use the conductor's authority to justify the need for long bows without the need to claim any access to special knowledge herself.
This is something she used during the study as many participants pointed out that this was not how they would choose to play those sections otherwise.
Prototype II was designed for flexible group usage: flexible in the sense that it could be used to support a number of different goals on the theme of bowing; group meaning that it supports ensemble playing.
The original MuSense prototype was altered and used sensors that were networked so they could contribute to a group visualisation.
Each bow stroke was represented as a petal-like shape which gets wider over time and longer with the length of the bow used.
Each player produces petals of a particular colour on a particular axis.
Petals from the last 4 bow strokes remain on screen to allow people to practise bowing patterns.
The flower-like layout was designed to let players see at a glance if they were using similar amounts of bow to others by looking at its symmetry, and to give the sense that everyone's bowing combined made the overall shape - displaying individuals as part of a group.
The visualisation aimed to be nonjudgemental, presenting information that can be interpreted in different ways depending on the learner's goal.
The vibrotactile feedback was not made into a shared display.
This is because the vibrations were seen as personal, being felt on the individual's body.
Changes were made to the vibrotactile feedback to allow more flexible use.
This study did not have a specified task; participants could aim for different styles of bowing as they saw fit.
To allow this choice, an adjusting knob was added which changed the place along the bow where the vibrations were triggered.
This meant that participants could aim for long bows or they could change the settings and aim for short bows by avoiding the vibrations.
Adjusting this knob also changed the scale on the visual display to keep the two types of feedback consistent with one another.
A side-effect of these changes in implementation was that the vibrotactile feedback was slightly less intense than in the study 1.
There was an even split in the participants over whether people were aware of the vibrotactile feedback while playing.
Those who said they could feel the feedback while playing preferred it to the visualisation because they could use it more easily while reading music.
The reports of not feeling the feedback contrast with the results from study 1 where no participants reported being unaware of the vibrotactile feedback to this extent.
This may be because the task in study 1 placed the feedback in the foreground; whereas the activities in study 2 placed the feedback in the background.
Initially, six participants agreed to take part in the study at the summer school, four violinists; one viola player and one cellist.
They came from a variety of musical backgrounds: including jazz, folk and classical music.
All participants were older than the researcher and many of them were better practiced musicians than her.
Five of them had been to the summer school before.
This shows that in this setting the participants were more expert than the researcher and the researcher tried to work in a way that respected this.
The summer school lasted five days plus a day of concerts.
The original intention was to meet with participants for approximately 40 minutes every day, although as the week progressed, other demands such as tiredness and concert preparation meant that most participants chose to have at least one day off from the study.
We also had some more serendipitous participation, for example, another student joined one session because she heard about it over lunch and one the tutors also came and tried it out.
Sessions were held in the common room of one of the residential buildings.
Over the week, the researcher kept a journal of her reflections on her experience at the summer school.
The findings become more meaningful when taken as part of the study as a whole, bringing into account the context of the summer school and the researcher's experience conducting and participating in the study.
The following includes extracts from the researcher's reflections on the study and shows how they contribute to the overall impact of the results on her on-going inquiry into how to design real-time feedback for musicians.
The visual feedback did not work well during the sessions because most people said they were not aware of it once they started playing .
This contrasts with the findings from study 1 in which the visual feedback was noticeable and useful to the players.
This could be accounted for by the differences in position and representation of the feedback.
In study 1, it was fixed to the music-stand in players' peripheral vision.
In study 2, it was projected on the wall beyond players' peripheral vision.
In study 1 the feedback came on or changed colour to indicate a goal achieved, while in study 2, there was no sudden change like this to grab the participant's attention.
Participants did think it could be useful for exercises not involving written music and for working on ensemble pieces once the music had been memorised.
It was an incredibly busy place.
Courses were timetabled between 8am - 8pm  most participants only had an hour spare during this time.
I also experienced this attending 4 hours of courses each day, running the study the rest of the time.
In to the evening there were student concerts and entertainment.
Additionally there were informal jam sessions, people grabbing one-toone time with tutors, even a midnight rendition of Mendelssohn's violin concerto arranged for octet.
In every corner of the place people were making music.
This is what they came for; it felt peculiar to be here for another reason.
Such full days meant that as the week continues, I and others around me, began to become tired.
I also began to suffer from pain and numbness in my shoulders .
As I started to take pain-killers myself I began to notice the odd packet of pills on other people's tables at lunch.
Then, one participant asked to miss a session due to back pain.
No-one wanted to give in to these physical demands though - a sign of how much people love playing at the school."
These incidents demonstrate that participants' time was precious.
Time is not of equal value in every context; time at the school was much more valuable than it would be in many other places.
Taking part in the study asked participants to give up time which could be spent on many other activities.
The researcher came to understand this through participating in the summer school.
It meant that she interpreted missed sessions differently because she understood the contextual reasons for them.
It also meant she valued the compliment when one participant chose to attend every session and saying how useful she found it.
The example of the aches and pains also shows how things become salient to the researcher through participation.
Another aspect of the researcher's role is explaining what the prototypes do and what the study is about.
The following extract describes how the researcher approached this and some of the dilemmas that arose.
In particular, finding a middle way between explaining a system and encouraging users to build their own interpretation of it: "Presenting the prototypes to participants was difficult.
This study was not about completing tasks, it was about finding where or whether the prototypes could be useful in real-world ensemble practice.
For this reason I did not want to present a fixed interpretation of the feedback.
This gave the initial challenge of how to explain what the prototypes do without explaining how to use them.
This is difficult because for most participants music practice is purposeful activity.
This means that for participants to truly engage with the system, it has to be seen to be useful.
So as I was explaining the system I felt I had to also explain its usefulness.
I did this by giving scenarios of usage for example aiming for long bows or aiming for short bows.
However, I believe that the participants found this ambiguity disconcerting.
Particularly, because it expects people to judge how they want to use it when they are not yet familiar with what it can do."
Often in research the researcher comes across as authoritative, even omniscient within the domain of the study.
However, in this study the researcher took a different approach: "I did not wish to take on the role of authoritative researcher as I was interested in what participants chose to do with the feedback themselves rather than instructing them or enforcing any particular task upon them.
Nor was I in any position to take on the role of a teacher, most participants were considerably better players than myself.
In some ways this felt uncomfortable as I do not think this fitted with their expectations, however, I felt that by giving up the authoritative position I became a more equal participant."
The following reflections show how the researcher found it difficult to achieve her intention to facilitate practice with the prototypes rather than encourage a particular type of practice.
Gradually through the week things changed and the participants became more willing to suggest pieces they would like to work on.
When this happened the session went much better in many ways.
The relationship between us became more collaborative.
The technology moved from the foreground , to the background .
Of course, this made it more difficult for the prototypes to have an effect, but this was part of the research to know whether people were still aware of them when focussing on the music.
I tried to be proactive in encouraging participants to make suggestions trying to think of things they might like to practice and suggesting them.
However this has drawbacks; when you are getting to know people it is difficult to stop a suggestion from implying an instruction."
This shows how it takes time to build a relationship and confidence with participants where they feel comfortable suggesting their own ideas.
The issue of authority brings up questions of confidence.
In the following extract, the researcher discusses how her rapport with the participants, belief in the prototypes and self-confidence were interconnected.
We also had a lot of previous contact via email and she played a style of music I was more familiar with.
All this meant I felt I could give some advice and point out areas where she could improve or should try and listen to the prototype.
This sometimes reversed when she pointed out that I was not making as large shapes on the visual display as she was and this motivated me to try harder to use longer bows in my own playing."
This meant I did not have the confidence to give advice.
Similarly, I knew I was not a good example of bowing as I did not trigger the feedback very regularly.
Instead I tried to be a good example of selfanalysis by saying aloud whether I had managed to trigger the feedback and what I thought that meant."
These reflections show how confidence and a shared belief in the potential success of the study created a positive rapport between the researcher and participant.
This in turn caused the researcher to have the confidence to contribute in a more hands-on way.
J had the most successful experience with the prototypes, whether the positive rapport described here is a symptom or a cause of this success is difficult to distinguish - most likely it is both.
Participating in the study made several things more difficult; the researcher could not observe the other participants in the normal way and was often too busy to ask questions.
However as the extract below describes, the experience of participation gave her a different perspective on her designs which will have a larger impact on her future research than the initial findings would suggest.
Study 2 has taught me to focus on designing for the in-the-moment experience of using the feedback, this is where the design will hold-up or fall-down.
Before, as I built the prototypes I imagined users in the third person; now, I imagine user experience in the first person.
I had tested the prototypes on myself before but never under the same level of cognitive load or with the same seriousness.
Never before in the belief that I was one of the participants, one of the users."
The researcher can play a variety of roles when conducting an in-the-wild study.
However, it may be more helpful to think of the researcher's role as being characterised by their position along several dimensions, rather than discrete roles.
These go beyond the idea of the researcher being either more or less involved in a study.
Instead, they try to characterise the ways the researcher is involved and how this is perceived by participants.
These are:  facilitating or encouraging,  explaining,  level of authority,  familiarity with participants, and,  relationship with their research.
This can be thought of as how the researcher involves themselves with participants to ensure the technology is used or a study fits a certain format.
At one end of the spectrum, the researcher may simply facilitate use by providing the technology in an accessible place  at the other a researcher may schedule sessions , offer rewards, or champion the technology  to potential participants.
In both studies, the researcher was closer to the encouraging end of the spectrum.
It is very difficult to be otherwise when you are in direct contact with participants since a simple question very easily has a subtext which implies a request.
This is best illustrated with an example from the researcher's reflections about study 2: "At the end of each session I asked if we could meet the next day.
It is clear from the context of this question that I want to meet them tomorrow - they know I want to collect as much data as possible, it leaves them in the position where they need a reason not to come rather than a reason to come.
There were cases where participants mentioned they wanted a particular day off and once I knew about this I felt it was my responsibility towards them to make sure not ask this question at the end of the session but to confirm "you're not coming tomorrow" to show that this is all right."
It is important to recognise that often a participant's motivation is to help the researcher as much as the research.
As can be seen from the example above the effect of this is nuanced and the researcher must be aware how this provides a particular subtext to all their conversations.
A similar example can be found in the reflections from of study 1.
This issue relates to facilitation and encouragement in that explaining a system facilitates its use, and depending on the context, may also encourage it too.
It also implies authority as explaining how to use something shows the researcher has additional knowledge to the participant.
In both studies it was part of the investigator's role to explain how to use the prototypes.
The difficulty of this role changed with the aim of the study.
In study 1, the prototype could be described as a system to help you practice long bowing.
What each display meant was described in terms of this aim, for example, a vibration meant you had succeeded in using a long bow.
In study 2, there was no fixed task.
The explanatory role of the researcher was a much more difficult one: to give an explanation of what the prototype does without attaching a fixed interpretation to the feedback.
Comparing the two studies, the goal based explanation in study 1 was a more effective way to communicate what the prototypes did, and did not prevent participants from suggesting a multitude of alternative uses in the interviews.
We would argue that initially presenting prototypes through structured task-based experiences may be the most appropriate way of explaining technologies like real-time feedback, as having a concrete experience of using the prototype to achieve one goal appears to inspire re-imagining it in new situations.
By authority we mean the extent to which the researcher is seen as having authority over the participant or being their equal or inferior.
In traditional lab experiments, the researcher acts with authority over participants, telling them what to do and having superior knowledge in knowing the true intentions of the study.
In some cases, this may be useful to a study; in others this inequality may obstruct building a rapport with participants.
In an in-the-wild study, authority may come from different types of knowledge and act in different ways.
For example, in study 1 musical authority had to be 'borrowed' from the conductor to make the tasks meaningful.
That the researcher was musically an equal also proved useful, as participants said they would have been more nervous playing for the conductor.
However completely relinquishing the researcher's authority also runs the risk of undermining the study; participants are giving time to the researcher too and they need to believe that the researcher has the expertise to use their time appropriately.
In many studies, the researcher and participants are strangers to one another and never move beyond this point.
In other cases researchers may build a much closer relationship with participants.
This can potentially lead to a clearer understanding of their motivations and a familiarity with the way they communicate.
It may mean that participants are willing to confide in the researcher, revealing things they would not in a first meeting.
However, part of forming a friendship with participants involves being responsible towards them and the researcher must judge when that responsibility takes precedence over their research agenda.
In study 1, the researcher already knew the participants; in study 2, this was not the case but she did build up a friendship with them over the week.
This was rewarding both personally and in terms of research.
However, it does also produce anxiety when writing up, for example about analysing interactions with participants because it does not give the holistic view of the genuine goodwill between both sides.
The audience in that case is not only the CHI readers but also the participants who took part in both studies.
The two studies also show how becoming familiar with the context and sharing the participant's experiences also enables the researcher to better understand and empathise with participants.
For example, in study 1, the researcher was able to recognise and empathise with the nervousness of her participants because she was a fellow orchestra player.
In study 2, she came to understand the preciousness of participants' time through participation in the summer school.
Gaining this kind of contextual knowledge facilitated better communication with participants.
The researcher's feelings about the research affect the way s/he interacts with participants.
For example, in study 2, there were times where the researcher felt confident that the feedback was helpful for a participant and this made her more confident in her interactions with them.
In study 1, the participants phrased their criticism in a way that recognised the researcher's involvement in the design and creation of the prototypes and their future intentions to improve them.
Even in less involved studies, participants' perceptions of the relationship between the researcher and the study may have consequences for the results.
This comes back to the idea of demand characteristics.
If the participants believe that the researcher has an emotional investment in the success of that particular prototype, they will be kind about it.
If they believe instead that the researcher needs to be able to build a successful system in the future, they may be more forthcoming with criticism.
This is one reason among many  why the research community needs to embrace failure as much as success; because if a prototype has to be a success for the research to be valued, then researchers will always have an emotional investment in the success of a prototype - one that they may not be able to help communicating to participants.
Current methods employed in in-the-wild studies do not normally show this level of reflexivity or consideration for the social and personal context beyond the boundary of the interaction being studied.
Dourish and Bell ask  - "how many ubicomp papers or presentations account for the author's stance?"
By joining with participants in their activities, the researcher can start to have their own perspective transformed and learn a little about what it is like to be a participant.
For example, in study 2, the researcher learnt through participation how valuable time at the summer school was to the participants and how tired they were feeling.
These may seem like small findings, but this is what participation reveals - many small details.
These details are invaluable as the researcher tries to interpret the actions and words of those around her.
They are also important for building rapport with participants - as Rode  puts it "when in the field they  must make a hundred little decisions to gain rapport".
How could the researcher sensibly discuss how to make the prototypes more useful to participants at the summer school without this kind of contextual understanding?
Without a shared understanding of the value of time and playing together; without knowing what repertoire is being played - where the difficult parts are and what the conductor said in the last rehearsal - these things can only be known by being present and involved.
These benefits do not necessarily come from taking part in the study; they come from participating in the context the study sits in, i.e.
We would argue that there is additional value in a researcher participating in the study, itself.
The primary one is the way the first-hand experience of using the prototypes under research conditions surprised the researcher and changed her perspective on her designs as well as her interpretation of the feedback from other participants.
One may argue that such experience threatens researcher impartiality because the researcher will assume that other participants' experiences are variations of her own.
However, it is common for designers and researchers to test prototypes on themselves to check that they work.
These kinds of tests are often in a completely different setting, and create similar but less accurate preconceptions about what participants' experiences will be like.
By using the prototypes together with participants under the same conditions, the researcher has the opportunity to both gain the first-hand experience of using the prototypes and have the generalizability of that experience directly challenged through discussion with the participants around them.
Gaining first-hand experience, using prototypes, provides additional means to empathise with participants - to see the world from the participant's perspective.
For Wright and McCarthy the value of empathy to the designer is not about becoming the user but about responding "to what they see as the user's world from their own perspective."
Similarly, the value to the researcher of participating in a study is about gaining the breadth of experience that allows them through dialogue to imagine the world from the perspective of the participant and respond to this.
Participating in a research study needs a lot of practical consideration.
A participating researcher uses a lot of their mental and physical energy in participating - they cannot expect to be as aware of things around them as they might in a purely observational study.
While participating, the researcher cannot take the long-view and spot patterns as they emerge.
Just as ethnographers factor time into their days to write-up notes and think over their experiences so a researcher participating in a deployment needs to allow themselves this time, ideally, with an opportunity to followup their thinking in the field with the same participants.
Researcher participation in-the-wild offers a new perspective on deployments, offering insights which arise from understanding context, building rapport with participants and empathy based on shared experience.
It is also a method that has reflexivity at its core and cannot be effectively used without the researcher constantly reflecting on their role within the research.
Atkinson, P. & Hammersley, M. "Ethnography and participant observation," Handbook of qualitative research, vol.
Brown, B., Reeves, S. & Sherwood, S. "Into the wild: challenges and opportunities for field trial methods," in Proc.
Dourish, P. & Bell, G. "Divining a digital future: mess and mythology in ubiquitous computing" MIT Press, 2011.
Gaver, W., Bowers, J., Kerridge, T., Boucher, A., & Jarvis, N. "Anatomy of a failure: how we knew when our design went wrong, and what we learned from it," in Proc.
Gaver, W. "Cultural commentators: Non-native interpretations as resources for polyphonic assessment," International Journal of Human-Computer Studies, vol.
