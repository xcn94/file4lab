Iterative prototypes of a cord that senses how it is pulled, twisted, and where it is touched.
Left: Version used for studies.
Center: Second version with smaller rotary encoder, conductive thread, and integrated electronics .
Right: Third version with stretch potentiometer embedded in cord and integrated electronics .
A cord, although simple in form, has many interesting physical affordances that make it powerful as an input device.
Not only can a length of cord be grasped in different locations, but also pulled, twisted and bent--four distinct and expressive dimensions that could potentially act in concert.
Such an input mechanism could be readily integrated into headphones, backpacks, and clothing.
Once grasped in the hand, a cord can be used in an eyes-free manner to control mobile devices, which often feature small screens and cramped buttons.
In this note, we describe a proof-ofconcept cord-based sensor, which senses three of the four input dimensions we propose.
In addition to a discussion of potential uses, we also present results from our preliminary user study.
The latter sought to compare the targeting performance and selection accuracy of different cord-based input modalities.
We conclude with brief set of design recommendations drawn upon results from our study.
Mobile devices with significant computational power are now easily carried with us.
To access their functionality, people repeatedly pull these out from their pockets and bags to do something as trivial as change the volume of the currently playing song.
Researchers have long explored how wearable computing can make such interactions more fluid.
Commercial products, such as Apple's third generation iPod shuffle, now place buttons on headphone cords, hoping to reduce the time to reach for and manipulate the device.
However, buttons provide a small number of discrete inputs, and in order to keep the devices on which they reside small, tend to be even smaller themselves.
In this note, we consider an alternative input method that is far more accessible and expressive than buttons.
Rather than using small buttons specially integrated into headphone cords, one could appropriate the entire cord as the input device.
Cords are particularly appropriate because they are often external and have a large surface area.
Furthermore, while buttons provide primarily binary input, a cord could potentially provide continuous input along at least four dimensions .
These four potentially continuous input dimensions a cord provides enable a wide range of applications.
In addition to providing navigation and controls for audio players and other mobile devices, a cord could be used as a joystick to play eyes-free games on mobile devices.
This cord could also be integrated into clothing to control devices or measure motion, and into everyday items such as backpacks and lampshades.
Finally, an array of these cords could be woven into a cloth to detect how it is being manipulated.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
To explore these interactions, we built a prototype cord that senses how hard it is being pulled, how much it is being twisted, and where it is touched.
It is also possible to include bend as a fourth, independent dimension, but we leave this to future work.
Our cord is not only far more expressive than a button; it is also easy to access, eyes-free, and unobtrusive.
In our implementation, very thin insulated wires are hidden inside it, connecting the sections of conductive thread  to the electronics.
Twist sensing is done using a mechanical rotary encoder.
In future work we hope to manufacture a small hollow rotary encoder.
Stretch sensing is performed using an elastic cord manufactured to increase in resistance as it is stretched .
We use a small section of this cord, protected by a bit of polyethylene tubing to prevent snags.
This is in turn attached to a longer non-stretching string attached to the bottom of the stretchable knitted cord.
In combination, these sensors make it possible to tell when the user is pulling on, twisting, or touching the cord.
There has been previous exploration into using cords and strings as input devices.
Researchers have also built electromechanical systems using two rotary transducers , and a retractable cord to measure pull distance .
These allow the systems to localize the end of the string in free space .
The main commonality in this previous work is the focus on using retractable passive cords and sensors outfitted at one end.
Our method, however, looks primarily at augmenting the cord itself .
Our approach allows us to capture three dimensions of motion - pull force, twist, and touch location.
Unlike free space gestures, these can be combined in straightforward ways to provide highly accurate navigation and selection mechanisms.
For example, twist to navigate a linear list, with pull  for selection.
In fact, our technique could be combined with the aforementioned projects to provide additional expressiveness.
Evaluation of cord-driven interactions has been limited.
To contribute to this area, we present results from our 14 participant user study, which evaluated three input modality combinations.
We conducted a user study to test which combination of twist, pull, and touch is most effective for targeting, and to test how the number of targets affects targeting performance in different conditions.
Targeting refers to the combination of navigating to a target and selecting it.
Performance includes speed and accuracy.
After a brief overview of the project, participants sat in front of a table with the first prototype cord sensor hanging from one side.
Participants were told use the cord sensor to navigate to a series of targets.
Each goal target was presented to the user as a number on screen, along with information about how many total targets there were.
After a short practice round, participants were told to navigate as quickly and accurately as possible to the goal.
After navigating to one goal participants were immediately given another goal, and continued navigation from their previous target.
The sensor was located below the table and participants were instructed not to look at it, to simulate eyes-free use.
Prerecorded verbal prompts were played to simulate a realworld audio menu.
For example, if at target 2 and needing to go to target 5, twisting from 2 to 5 would cause the software to speak "3, 4, 5".
Once at a target, participants actuated the selection method for that condition .
Targets were evenly spread along the virtual space represented by each continuous sensor, with no padding between targets.
As stated earlier, the prototype being tested could sense pull, twist, and touch, each on a continuous scale.
The experiment was divided into six conditions, two for each type of sensing.
In three conditions, selection was done with the spacebar so that the impact of sensing condition  on navigation performance could be tested independently of selection.
The other three conditions tested plausible combinations of navigation and selection all using the sensor, namely Twist+Pull , Touch+Pull, and Pull+Twist.
Each condition was divided into 4 blocks of 10 trials each .
To explore our interaction concept we built a set of three prototypes.
Our first prototype was fully functional, but did not have a final polished form , and was used for user tests.
We then constructed a pair of smaller prototypes which explored additional sensing approaches and solutions for size reduction.
Our final prototype includes an integrated electronics package which could be placed inside a section of knitted cord.
The first prototype used an Arduino , a linear potentiometer and spring arrangement for sensing pull, a rotary potentiometer for twist, and a SpectraSymbol Softpot sensor for touch .
The remaining prototypes were implemented using a Cypress Semiconductor CY8C21234 PSoC microcontroller  on custom printed circuit boards.
The cord was knitted using a hobby cord knitting machine.
Touch+Pull, which we found were less sensitive during pilot studies, were subdivided into blocks containing 2, 3, 4, and 5 targets.
All other conditions were subdivided into blocks containing 2, 4, 6, and 8 targets.
Condition order was counterbalanced and block order was randomized.
Within each block, the target to be selected for each trial was also randomized.
Measures: We calculated the time  it took participants to complete a targeting task from trial start, when the goal target was presented on screen, to trial end, when selection was complete, averaged over each block , the number of times a goal target was passed over before it was selected, averaged over each block , and how many times participants successfully selected the correct target, calculated as a percentage per block .
We chose to count overshoots because a large number of overshoots could indicate that the input technique was too sensitive.
Our data provided insight into selection success rate, targeting error, and targeting time.
Data preparation: As just described, the measures were calculated at a per-block level.
We checked for outliers by looking for data that was two standard deviations outside the mean per block on the targeting time measure.
We found one outlier, which we attribute to a combination of hardware and user error.
All data for the affected user were removed from our analysis.
Our results are broken into two parts.
First we explore the impact of conditions  on navigation performance.
Then we explore which combination of sensors worked best for navigation and selection combined.
As expected, navigation time and overshoots increased as the number of targets increased .
Twist was most consistent  as the number of targets increased.
Both the Touch and Pull conditions were about 50% slower when more than 3  or 4  targets were present.
Surprisingly, Touch had much higher overshoot rates than pull and twist even for 2 targets, while the corresponding targeting times were mixed - being comparably as fast for 2 or 3 targets and slower for 4 or 5.
A lack of tactile feedback in the Touch condition made it difficult to identify different target locations.
One participant in our study noted "It would be nice if we had some texture feedback about what area we were touching".
The average success rate across all users and blocks exceeded 93% in all conditions except Pull+Twist, which was only 70%  .
We found this result consistent with user reactions.
Several users complained that it was difficult to pull and twist at the same time.
One participant noted, "The springiness  makes it hard to twist."
After our study we piloted a small test to see if twisting had the same effect on touch location, and found that it did not seem to.
Therefore, we believe that this low performance was due to the physical challenge of maintaining tension in a cord while twisting.
We conducted a small survey with the same participants to determine which dimensions  worked best for continuous input  and for toggling values.
We asked users to describe how they would use the cord to do one of two tasks, and then coded their descriptions as requiring twist, pull, touch, or several of these.
Table 1 illustrates our results, and indicates that users thought twist was most appropriate for continuous input, while pull was most appropriate for toggling between values or making selections.
Based on results from our survey and user study, we would recommend that future implementations use touch location or twist for continuous input, and pull to toggle between values or make selections.
We have presented the notion of using cords for input.
These can sense one or more independent dimensions, including grasp location, twist, bend and pull.
To explore this novel approach, we developed a proof-of-concept cordbased sensor, which senses three of these four dimensions: twist, pull, and touch location.
This cord can be used as an eyes-free, readily available, and unobtrusive yet expressive input method for mobile devices.
We ran a small study to compare each input type  in terms of selection accuracy and targeting performance.
We also provide a set of design recommendations based on results from our study and a survey.
We hope our results demonstrate the feasibility and utility of cords as an input device and inspire researchers and practitioners to integrate this sensor into everyday devices and future research projects.
Blasko, G., Narayanaswami, C., and Feiner, S. Prototyping retractable string-based interaction techniques for dual-display mobile devices.
An interface for creating and manipulating curves using a high degree-of-freedom curve input device.
Koch, E. and Witt, H. Prototyping a chest-worn stringbased wearable input device.
Kulik, A., Paneque, D., and Hochstrate, J., Vectorix: A Low-Tech Mechanical Tracking System.
In IEEE VR `04 Workshop: Beyond Wand and Glove Based Interaction, 25-27.
Smart Clothing Prototype for the Arctic Environment.
