During everyday office work we are used to controlling our computers with keyboard and mouse, while the majority of our body remains unchallenged and the physical workspace around us stays largely unattended.
Addressing this untapped potential, we explore the concept of turning a flexible office chair into a ubiquitous input device.
To facilitate daily desktop work, we propose the utilization of semaphoric chair gestures that can be assigned to specific application functionalities.
The exploration of two usage scenarios in the context of focused and peripheral interaction demonstrates high potential of chair gestures as additional input modality for opportunistic, hands-free interaction.
Taking this evolution further, we believe that interaction through furniture has high potential to open a new input domain beyond the current mouse-and-keyboard paradigm.
Thus, in a common desktop workplace for example, where we are surrounded by functional furniture of various kinds, we believe that these readily available elements  could actually become part of the computer interface.
The ubiquity of seated activities in our daily lives, for example, provides an excellent context for the development of alternative human-computer interfaces.
Thus, we have only recently begun to explore the potential of chair-based interaction as novel input dimension for desktop interfaces .
Extending this concept in the present work, we explore the potential of gestural chair interaction during regular desktop activities.
By tracking the movements of a seated person, specific gestures can be identified, and transformed into input commands .
This way, a chair becomes a ubiquitous input device providing us with the opportunity to use the movements of our body for operating a computer .
While working on a desktop computer, we are used to traditional mouse and keyboard input.
We have learned how to handle these devices and utilize them as powerful tools for our daily computer-based activities.
Their operation, however, involves making the same small repetitive movements with our hands over and over again, while the rest of our body remains largely unchallenged .
On the other hand, with computing interfaces becoming more and more ubiquitous, we see increasing numbers of input technologies making their way into the user interface that support free-form manipulation of digital objects through touch, speech, gaze, or body gestures .
In this paper, we investigate the integration of gestural chair interaction into the desktop computing experience.
We describe an iterative design process from the definition of a basic set of semaphoric chair gestures to their application for focused and peripheral interaction scenarios.
The results of two explorative studies provide implications on the benefits and limitations of the proposed concept.
User feedback and performance show high potential of chair gestures as additional input modality for ubiquitous, hands-free interaction with a desktop computer.
Following the trend of designing more natural ways of interaction with computer systems, several attempts have been made to develop technologies that extend interaction beyond long-established mouse-and-keyboard input.
Along with that, we see more and more devices with embedded sensing and communication capabilities .
While early work in the field of smart office environments has demonstrated the ubiquitous integration of interactive technology , research interest has more recently also considered the extension of interaction into the periphery.
The Unadorned Desk is an example for this kind of interaction, which used the physical space around a desktop computer as input canvas .
Similarly, our work adds to the research conducted within this field by proposing the utilization of a chair as ubiquitous input device.
Interactive chair interfaces have been used for unobtrusive measurement of body movements to infer a person's physical and emotional state , or support everyday activities .
Besides that, chairs have been used in computer-based scenarios, where body movements are sensed and interpreted as implicit input to a system.
The Internet Chair for example, used orientation tracking to support social situation awareness through spatialized audio .
The Chair Mouse translated natural chair rotation into large-scale cursor movement for navigation on large displays .
Rather than exploiting existing user behavior, however, our work focuses on the encouragement of new interaction metaphors that are currently not possible with traditional input devices.
Based on a similar concept, ChairIO introduced a gaming interface that allows users to navigate virtual environments by controlling a flexible chair with their body .
In contrast to this, we are interested in the application of input metaphors for more general scenarios beyond the gaming context, which have the potential to enrich and facilitate user interaction during everyday desktop work.
In particular, our work explores chair input in the context of gestural interaction, which has been proposed as alternative human-computer interface in the context of hand, finger, or full-body gestures .
Integrating our physical body into interactions with digital interfaces , it has been shown that such gestural interfaces can potentially provide wide-reaching benefits over traditional input devices, including naturalness and expressiveness of interaction, learnability, directness of interaction, available degrees of freedom, and exploitation of existing dexterous skills .
Based on that, we have only recently come up with the idea of applying different gesture styles to flexible chairs , since we believe that many of the benefits seen in in other body-based gestural interfaces can transfer to the desktop environment.
Building upon this work, we are further exploring the specific subset of semaphoric chair gestures, as they provide high flexibility for a variety of computer functionalities and have proven particularly beneficial for secondary task interactions .
While chairs can be found everywhere, embedded into our daily lives, growing focus on the ergonomics of sitting  has evolved with the emergence of innovative products that provide increased freedom of movement and dynamic transition between postures .
Based on the inherent characteristics of such flexible chairs, we believe they can provide attractive features that recommend them as alternative input technology in a desktop environment.
First of all, chair-based gestures can be used to expand the input bandwidth of desktop work.
Relying on simple kinesthetic movement patterns of the lower body , such semaphoric chair gestures can be mapped directly to specific input commands.
This concept of chairbased application control can be integrated into a multitude of interactions that take place in the focus  or periphery of attention .
While sitting in front of a computer, motion gestures on an interactive chair can potentially be detected anytime, providing always-available access to application functions without switching windows or losing visual focus on the current task.
Rather than applying multiple clicks on the graphical user interface, interaction can be reduced to a simple onestep chair gesture.
By using a chair as hands-free input device, users can be provided with a true additional input dimension, as their hands can remain on keyboard and mouse, or are available for other tasks .
Moreover, it can be operated eyes-free , as the input is based on motion-based input that provides functional feedback, but requires no attention to a visual interface.
Finally, chair-based interaction can support opportunistic physical activity by leveraging our physical body as a means of interaction with the system.
Resulting dynamic, complex movements  can help breaking up the physical monotony of daily desktop work, and smoothly integrate light physical activity into the work routine .
While chair gestures have many theoretical advantages, the goal of this work was to explore their feasibility as novel input technique for desktop computing.
During an iterative participatory design process, we designed two application scenarios in the context of focused and peripheral interaction.
First, to explore the design space of semaphoric chair gestures, we elicited user input on possible movements and suitable gestures.
Next, to collect early user feedback on the concept of chair-based application control, we conducted a first experiment where participants used semaphoric chair gestures to control a web browser.
Finally, to gain insights on the performance and user experience of chair gestures in comparison to more common input devices , we conducted a second experiment where we applied semaphoric chair gestures to a peripheral music control scenario.
To understand the design space of semaphoric chair gestures for interactive application control, we conducted a guessability-style user study  where we asked 10 unpaid participants  to demonstrate movements on a 3DeeTM office chair, which they would associate spontaneously with common web browser commands .
Among the resulting 210 gestures observed, 54% included tilting, 19% rotating, and 17% bouncing movements.
Tilting was performed by briefly swinging the hips to a specific direction along the left-right, front-back, or diagonal axis of the chair.
Rotating involved swinging the chair counterclockwise  or clockwise  by an angle of up to 90 degree, and some cases of full rotations by 360 degree.
Bouncing was performed through a sweep downward movement to compress the elastic spring of the chair.
Overall, the majority of proposed gestures consisted of unique, repeated, or combined execution of the above described movements.
Few gestures included other metaphors like position changes , or symbolic motion patterns .
Regarding the assignment of the gestures to specific browser commands, the majority of participants suggested simple tilting/rotating along the left-right axis to navigate between websites, or along the front-back axis to scroll content within a website.
Bouncing was preferred for more specific functionalities such as launching/quitting the browser, bookmarking, or opening/closing tabs.
Based on these results, we determined a set of seven basic chair gestures that most occurred during the initial study: tilt left, tilt right, tilt forward, tilt backward, rotate right, rotate left, and bounce .
The 3DeeTM office chair incorporates an active suspension system that provides three degrees of freedom in horizontal and vertical direction.
This provides users with dynamic operation through tilting, rotating, or bouncing movements.
Adjustable features of the chair include height, horizontal flexibility, vertical flexibility , and tension of the backrest .
To detect movements along any axis of the chair, we use a motion-sensing smartphone  attached to the backrest of the chair .
To calculate the relative position of the sensor, accelerometer and gyroscope measurements  are transmitted via Bluetooth to a desktop computer, where a custom background application processes the motion data to recognize the different chair gestures and invokes corresponding application-specific input commands via the Microsoft UI Automation Framework that provides programmatic access to interface elements in Windows applications.
To recognize the user-suggested chair gestures, we implemented a real-time gesture recognition algorithm that was trained with a sequence of sample measurements collected from participants in a follow-up session.
The data samples were analyzed for characteristic patterns in the raw motion data , and served as a basis for the development of a threshold model algorithm that recognizes a gesture once the corresponding threshold values are exceeded.
While this could also have been implemented with other algorithms, our primary focus in this early design stage was mainly on the interaction perspective.
During the next steps of the design process, our main goal was to collect initial user feedback on the idea of chairbased application control, and gain insights into user acceptance of gestural chair interaction in general.
Therefore, we conducted a Wizard of Oz experiment that integrated semaphoric chair gestures into web browsing experience.
12 unpaid participants  took part in the experiment.
All participants were experienced users of web browsers, who usually invoked browser commands through mouse input or keyboard shortcuts.
During the experiment, participants performed a simple navigation task where they interacted with a web browser through chair, mouse, and keyboard input.
The experimental task was a web search and planning scenario where participants were asked to plan for a city roundtrip.
Thereby, they were given step-by-step instructions to search for basic facts, figures, images, and locations .
To simulate a casual web browsing scenario that supports opportunistic chair interaction, the task was designed to balance searching and reading activities with content navigation through mouse, keyboard, or chair input.
Thereby, chair gestures were assigned to the following browser functionalities: previous website , next website , previous tab , next tab , and start page .
The experiment was conducted in a calm desktop environment on a workstation with a Windows PC and a 3DeeTM flexible chair .
Application control was simulated to avoid any potential bias from recognition errors in this early design stage i.e., corresponding input commands being remotely invoked by the experimenter.
User feedback was collected through interviews and questionnaires, where participants rated their experience with the chair in the following areas: satisfaction, ease-of-use, learnability, and engagement.
Task load ratings  were collected for physical, mental, and temporal demand.
Initial user feedback showed that participants were positive about the concept of chair-based application control in general .
On a five-point Likert scale , participants rated the chair interaction as overall satisfying .
Most participants agreed that the gestures were easy to use, and easy to learn .
During the experiment participants did not experience any problems in operating the chair to issue browser commands, and strongly agreed that the body-based interaction supported engagement with the web browsing task .
Most of them enjoyed the possibility of utilizing the flexible chair for invoking actions on the computer, and described the novel interaction technique as futuristic and playful.
Eight participants mentioned, that the chair gestures added a welcome feeling of activity to the otherwise joyless ones of pointing and clicking.
Overall, participants stated that they could imagine using the chair gestures in real-world situations, and largely agreed to the statement "I would like to use the chair control as additional input modality during everyday computing activities."
Regarding the perceived task load, ratings were overall low for physical and temporal demand , and moderate for mental demand .
During the experiment, participants were able to use the chair interface without considerable effects of mental or bodily fatigue.
Yet, four participants mentioned they would not like to use the gestures too extensively in real-world situations , as they thought this could be exhausting or annoying over time.
Two other participants raised concerns on social acceptance of the chair gestures in real-world settings, as they might seem awkward to other people .
Besides that, a common problem was raised with the participants' varying ability to accommodate to the pre-defined gesture mapping.
As reflected in the mental demand ratings, some participants pointed out that they did not feel confident with using front/back-tilting gestures to navigate among browser tabs.
Therefore, gaining further understanding of people's mental models for gestural chair interaction, and addressing inconsistencies through user-defined gestures will be part of our future research.
Summarizing, the initial feedback indicates that the chairbased gestures were overall easy to learn, and did not require excessive levels of physical or cognitive demand.
While most participants were skeptical about the novel interaction technique in the beginning, they seemed to become more and more positive when they realized that the gestures actually invoked the desired actions in the web browser.
This observation indicates that reliability and robustness must be considered critical factors for user acceptance of future gestural chair interfaces .
While it is worth to mention that user feedback regarding future use of the novel input technique might have been influenced by the good participant effect to some extent, the questionnaire ratings and additional comments still provide valuable insights for the further design process: First of all, participants seemed to be concerned about accidentally triggering actions on the computer through naturally occurring movements or posture changes : "I wonder how using such an intelligent chair would work out during everyday usage.
So, for example, would it trigger actions on my computer when I'm leaning to the side to grab something out of a bottom drawer, or when I'm leaning back to stretch my arms?"
Indeed, since users are constantly moving while seated- especially on ergonomic, flexible chairs-a major challenge for chair-based interaction is how to effectively distinguish chair gestures from natural body movement that may occur unconsciously during regular work .
A common method to avoid such unintentional input is to let the user decide when input happens by providing mechanisms to toggle gesture recognition on demand.
In the current system, we experimented with different methods of coupling chair-based interaction with other input modalities to enable/disable gesture recognition .
Further investigation of this kind of manual mode-switching  will be part of our future research.
Moreover, some participants had reservations regarding the chair gestures becoming annoying or tiring when used over longer periods of time: "You know, I would like to use the chair if I can use it in a way that somehow eases my work, and makes it less boring.
Of course, I wouldn't want to swing around my hips all day long!
As a matter of fact, since moving the whole body to perform gestures with an active chair involves more muscles than mouse or keyboard interaction, a certain level of fatigue may occur with frequent gestures over a long period of time .
Results of the initial evaluation show that participants were able to use the chair gestures without considerable effects of mental or bodily fatigue.
Keeping this in mind, we think the chair gestures have to be designed as optional input modality that people can make use of on a rather occasional basis.
To achieve that, gestures should be concise, quick to issue, and avoid movements that require high precision over extended periods of time.
Closely related to the above stated concerns, some participants mentioned that they would prefer chair gestures for usage scenarios where commands can be triggered on a rather occasional basis: "I could imagine using the chair for rather small actions, which are not occurring too often.
This statement is largely confirmed by participants' comments during the post-experiment interviews.
When asked which other usage scenarios they could imagine for gestural chair interaction, seven participants suggested applications for common system-level functions such as task- or window management , and five participants mentioned application-specific functions such as text editing or media control .
Based on the insights gained in this first explorative experiment, we identified a number of implications for the design of gestural chair interaction:  Chair gestures should serve as opportunistic input technique that users can smoothly integrate into their computing activities.
Consequently, the body-based gestures are most likely suitable for casual, occasional usage in situations where it is desirable for a user to break up the monotony of continuous desktop work.
Chair gestures could therefore serve as additional interaction technique rather than substitution for common input devices such as keyboard and mouse.
Provided the handsfree operability, a true additional input dimension can be introduced.
Along with that, however, it will be necessary to provide sufficient solutions that prevent accidental activation of the chair control through natural movements.
Chair gestures should be utilized as discrete rather than continuous input to avoid effects of fatigue or annoyance during long-term usage.
While discrete input has relatively few parameters to control, continuous input would require careful design considerations on the mapping to a control parameter .
Chair gestures are most suitable for non-precise interactions that take into account the imprecise nature of the seated body-movements in comparison to high-accuracy input from traditional pointing devices.
If a task requires precise control , chair gestures might not be appropriate in most cases.
The results from the first experiment motivated us to consider the application of gestural chair interaction for computing activities where interaction is not the primary focus of a user's attention, but rather in the periphery .
Existing work in the emerging field of peripheral interaction has investigated the design of inattentive interaction techniques that can be easily performed in the periphery of attention, and demonstrated significant benefits for such secondary task interactions .
Similarly, in the next step of the design process, we conducted an experiment to explore the potential of chair gestures for such peripheral interaction scenarios.
With this experiment, we wanted to gain further insights into the applicability of chair gestures for peripheral interaction in terms of performance and user acceptance, and explore how it compares to common input techniques like keyboard and touch.
To provide input devices within easy reach, the arrangement on the desk surface was adjusted to participants individually.
All participants used their dominant right hand for touch input , while twelve participants  used their non-dominant hand for keyboard input.
The experiment was conducted in a calm office workspace with a Windows PC, wired keyboard and mouse, wired headphones, a tablet device , and a 3DeeTM flexible chair .
A custom application displayed task instructions, processed the user input, and recorded performance measures in the background.
15 paid volunteers  participated in the experiment.
All participants were experienced computer users, who listened to music while working at the computer on a moderately to highly frequent basis.
During the experiment, participants performed an attentiondemanding primary task, while at the same time interacting with a music player in the periphery.
To successfully resolve a square, participants had to click on it, and then type the corresponding number within a time limit .
In the peripheral task, participants controlled music playback as indicated by random-interval  onscreen notifications.
To simulate a realistic scenario where users control the music in a spontaneous manner, we instructed participants to focus on the primary task, and respond to notifications within a reasonable timeframe.
Building upon previous studies in the context of peripheral interaction , the experiment supported three interaction techniques , assigned to frequently used music player commands that were mapped to the four canonical directions: left/right to play the previous/next track, and up/down to increase/decrease volume.
To keep interaction consistent among all techniques, chair input was based on simple directional tilt gestures.
Touch input was mapped to directional swipe gestures on a tablet, and keyboard input was invoked using the arrow keys1.
For each interaction technique, five blocks of four different music player commands occurred in randomized order.
At the beginning of the experiment, participants completed a short primary task training to become accustomed to the square-click task.
They were introduced to the music control for every technique in a peripheral task training with 20 randomized commands .
Thereafter, both tasks had to be carried out in parallel  during a combined training, and during the experimental task.
To avoid learning effects, the order of techniques was counterbalanced.
After each task, participants completed a questionnaire asking for the perceived task load and user experience.
In a final questionnaire, participants provided additional subjective feedback on the different input techniques.
Primary task performance and peripheral task performance were measured in terms of completion time  and success rate .
Recovery time was measured as the time taken from the end of interaction in the peripheral music control task to the resumption of the primary square-click task .
User feedback was collected through questionnaires and informal interviews, where participants were asked for quantitative  and qualitative  feedback.
Primary task performance was not significantly different among input techniques, showing similar results for completion times , and success rates .
Peripheral interaction thus seemed to cause a similar degree of distraction on the primary task for all three input techniques.
Six participants stated the chair gestures made them perceive the task less monotonously, whereas four others mentioned that the motor body movements somehow distracted them from the primary task.
Peripheral Task Performance  was significantly different among interaction techniques .
Looking at these times in detail, we found that the input time to execute a music control command  was longest for chair interaction, as participants needed on average 1.28 s  to execute a chair gesture, while input time was only 0.11 s  for touch, and 0.10 s  for keyboard.
For touch and keyboard, this response time may be partially attributed to the homing time  needed for physical hand movements towards input devices2.
In contrast to that, almost all participants positively mentioned the convenience of hands remaining on mouse and keyboard while performing gestures with the flexible office chair.
While participants seemed to be equally successful in building cognitive models of the music control commands associated with the different input techniques, additional comments indicate that recognition issues in the gestural chair and touch conditions were perceived to influence task performance negatively to some extent.
Recovery Time  was significantly different among techniques .
Participants stated that it was comfortable to keep visual focus on the primary task during chair and touch interaction.
With keyboard in contrast, we observed most of them briefly turning focus off the screen to locate the arrow keys.
User feedback was collected through questionnaires and post-experiment interviews.
Similar to the first experiment, perceived task load and user experience were rated on 5point Likert scales .
In addition, we asked participants for qualitative feedback on the most positive/negative aspects of each input technique.
User experience ratings  show overall moderate satisfaction  with peripheral chair interaction.
It was easy to learn  and easy to use during the peripheral music control task .
Although ratings were slightly higher for familiar touch and keyboard input, participants stated that it was easy to perform the directional tilt gestures with the chair.
Nevertheless, it took a while for some of them to get used to the rather unconventional novel input technique, and gestures were not recognized correctly in a few cases.
As reflected in the moderate satisfaction ratings, these factors might have influenced feedback negatively.
On the other hand, similar to the first experiment, participants were positive about the playful aspect of the chair gestures, which resulted in higher engagement ratings  than for touch and keyboard interaction.
Task load ratings  for chair input were similar to touch and keyboard on all scales .
In some rare cases participants experienced problems in linking the chair gestures to the given music control commands, and handling the egocentric mapping of the chair gestures along the front and back axis .
Yet, there was no considerable increase in overall cognitive and physical effort with the chair gestures.
Success rates in the peripheral task showed no significant difference in the number of incorrect commands issued with the three input techniques .
Participants were equally successful in associating chair gestures, touch gestures, and arrow keys with the given music control commands.
Recognition accuracy of gesture-based input was 93.83%  for chair and 97.00%  for touch, with most errors being attributable to imprecise user input .
Most commonly mentioned positive aspects of chair input were hands-free control , engagement , and activity promotion .
On the negative side, comments referred to recognition issues , practical restrictions , and unconventionality of the interface .
Example comments included "no alternating between devices", "fun to control the PC through movement", "welcome change for the body", "could bring up the wrong action", "constrains natural movement", and "probably needs time to familiarize" Most commonly mentioned positive aspects of touch and keyboard input were ease-of-use, and familiarity with the input technique, while negative aspects referred to the loss of focus during interaction, or physical restrictions: "more used to controlling a computer with my hands", "additional device occupies valuable desk space".
In the present peripheral interaction scenario, no difference in primary task performance or perceived task load was found between the chair gestures and more familiar touch or keyboard input.
Therefore, it appears that-despite the novelty of the chair-based input technique-no additional complexity was added to the primary task.
Clearly, as people were much more familiar with the keyboard and touch interfaces, it seems natural that the chair interactions demanded more time and effort in the short term experiment.
In the course of the experiment, however, we observed participants getting more and more confident with the chair control once they got used to performing the tilting gestures.
This indicates promising potential for performance improvement with further practice, which should be evaluated in a future long-term field deployment.
Despite the fact that execution of chair gestures required more time than the hand-mediated input techniques, reduced requirements on visual and motor channels  allowed for short response and short recovery times.
With digital information and communication technologies finding their ways into the work environment, people spend increasing time in managing various activities simultaneously.
Therefore, being able to minimize recovery times with hands-free, eyes-free chair interaction can provide significant benefits for users by minimizing distraction, and supporting effortless transitions between primary and secondary tasks.
User feedback indicates that participants appreciated these above-mentioned attractive features recommending chair gestures for peripheral interaction scenarios.
Similar to the first experiment, nevertheless, participants were slightly skeptical about the novel interaction technique, and raised practical concerns .
Additionally, the present experiment added further insights regarding the gesture recognition, which was not sufficiently reliable for some participants during the experiment: "When I used the chair to control the music player, there was a situation when nothing happened, although I had performed the tilt to the correct direction.
When I repeated the movement with more power, it finally worked."
One specific problem was that the force at which different users tilted the chair varied a lot.
In some cases, gestures were at first not detected when the movements were performed with too little force.
This confused some participants, and in some rare cases led to unnecessary repetitions of gestures.
Consequently, as our recognition was tuned to look for clear peaks in the motion data, any oscillation effects or additional accelerations disturbed the recognition.
User feedback, however, points out the importance of reliable recognition and real-time response for successful adoption of chair-based interaction.
Summarizing, the results of the second experiment largely confirm previous research demonstrating peripheral usage of touch- and keyboard-based interfaces , and show that chair gestures are another promising alternative to extend the design space for peripheral interaction.
Regarding the recovery time needed to return to the primary task after a peripheral input command, they even outperformed touch and keyboard interaction.
This supports previous findings indicating that semaphoric gestures can support secondary task interaction as target acquisition is less demanding for gestures than keyboard, visual focus remains on the primary task, and the threshold for recovering focus can be reduced significantly .
Besides that, chair gestures can potentially be detected anytime a user is sitting in front of the computer, thereby maintaining a persistent number of steps for completing a peripheral task, whereas traditional handmediated input may not be readily available in some situations .
This supports our assumptions that gestural interaction with chairs opens a broad design space for interaction with a desktop computer when the user's hands or eyes are be occupied with other tasks , or when quick access to specific application functionalities is required .
Closely related to that, some participants mentioned they would rather avoid chair gestures for critical interactions: "I like the chair, but there's certain things I wouldn't want to use it for.
What if it is triggered somehow accidentally?
Then the message is gone, and I cannot undo it anymore."
Therefore, we think that chair gestures are most suitable for non-critical usage scenarios, where consequences of unintentional command activation are negligible.
If making an error during a task presents any serious risks for users, chair input might not be appropriate in most cases.
In addition, more research is needed to support mediation of ambiguous input , and provide easy ways of undoing falsely recognized gestures.
Clearly, there is a trade-off between sensitivity and robustness of the gesture recognition.
In the current implementation of our gesture recognition algorithm, we tried to optimize the balance between high rates of recognized gestures and low rates of misclassified gestures with careful threshold selection.
However, recognizing specific human movements and complex actions solely with the help of accelerometer and gyroscope represents a technical challenge.
While the focus of the present work was on a gesture recognition that was practical to implement with minimal hardware requirements, we will continue exploring ways to increase the reliability of our system, including experiments with additional sensors .
Besides that, with constantly improving recognition algorithms and insights from machine learning, we are confident that with modern recognition approaches , we will be able to overcome these issues and provide a more robust gesture recognition.
Concerns regarding social acceptability go in line with existing research pointing out potential problems of gestures that are publicly visible  but the effects of the actions  remain hidden to others .
This issue, however, might be reduced in environments where flexible chairs are already established, as they afford sitting "in-motion"  even without the goal of triggering specific actions.
Therefore, we believe the benefits of flexible  chairs can outweigh or even eliminate potential social awkwardness.
Also, enabling users to perform the gestures with more subtle movements may increase acceptance.
The embodied aspects of chair-based input  seemed to facilitate interaction, which indicates high potential to enrich the computing experience and capture the interest of a larger audience.
However, as with other gestural interfaces, there are some challenges when designing for chair-based gestural interaction , such as distinguishing between natural behavior and gestural input, revealing the gestural input scope, creating understandable metaphors for actions invoked by the gestural input, or providing reliable real-time system feedback .
Further, ergonomic aspects regarding the effects of physical body movements to perform gestures with a flexible chair will have to be taken into account for future design of gestures and applications.
Summarizing, as for any other input modality, there are always trade-offs: While input time and physical effort may be higher for chair gestures than traditional hand-mediated input devices, this must be balanced against the benefits of always-available, eyes-free, hands-free operation that an interactive chair can provide in a computing environment.
Based on these unique features, chair gestures seem highly promising for opportunistic interaction in a desktop environment.
Particularly suitable in the context of peripheral interaction, interactive chairs could therefore serve as platform for a whole range of applications that enable users to quickly issue commands to an application and rapidly return to their other ongoing activities.
In addition, the introduction of technologies integrating the body into our interactions is a strategy with great potential to avoid physical inactivity .
Chair gestures are certainly not a panacea for every potential input problem faced by end users.
Still, the gestures can serve a valuable purpose as alternative input modality in situations that afford eyes- or hands-free interaction, or when we simply want to break up the monotony of the mouse-and-keyboard desktop paradigm.
Future work will focus on solving practical challenges that arise with gestural chair interaction, including improvement of recognition robustness, further exploration of the gestural input scope, and definition of suitable applications that integrate chair gestures into the computing experience.
Therefore, we will investigate the application of gestural chair input for other usage scenarios besides the proposed web browser and music player control .
Finally, as for a novel input technique it is always the question of longterm acceptance and use, we plan to conduct a long-term insitu deployment to further explore the integration of semaphoric chair gestures into the computing experience.
In this paper, we presented the iterative design process of a novel input technique based on gestural interaction with a sensor-equipped flexible office chair.
A basic set of semaphoric chair gestures was defined, which can be mapped to specific functions for controlling applications on a desktop computer.
We explored the application of these chair gestures as additional input modality for focused interaction with a web browser, and peripheral interaction with a music player.
Corresponding experimental results indicate overall positive user feedback, and comparable task performance as with more familiar keyboard or touch input.
Anttonen, J. and Surakka, V. Music, Heart Rate, and Emotions in the Context of Stimulating Technologies.
Baudel, T. and Beaudouin-Lafon, M. Charade: Remote Control of Objects Using Free-Hand Gestures.
Beckhaus, S., Blom, K., and Haringer, M. ChairIO - The Chair-Based Interface.
In Concepts and Technologies for Pervasive Games.
Van Beurden, M., Ijsselsteijn, W., and De Kort, Y.
User Experience of Gesture Based Interfaces: A Comparison with Traditional Interaction Methods on Pragmatic and Hedonic Qualities.
The KeystrokeLevel Model for User Performance Time with Interactive Systems.
Cohen, M. The Internet Chair.
Dourish, P. Where The Action Is.
Endert, A., Fiaux, P., Chung, H., Stewart, M., Andrews, C., and North, C. ChairMouse: Leveraging Natural Chair Rotation for Cursor Navigation on Large, HighResolution Displays.
The SenseChair: The Lounge Chair as an Intelligent Assistive Device for Elders.
Hart, S. and Staveland, L. Development of NASA-TLX : Results of Empirical and Theoretical Research.
Peripheral Interaction: Embedding HCI in Everyday Life.
Hausen, D., Boring, S., and Greenberg, S. The Unadorned Desk: Exploiting the Physical Space around a Display as an Input Canvas.
Comparing Input Modalities for Peripheral Interaction: A Case Study on Peripheral Music Control.
Hausen, D. Comparing Modalities and Feedback for Peripheral Interaction.
Healy, G., Lawler, S., Thorp, A., Neuhaus, M., Robson, E., Owen, N., and Dunstan, D. Reducing Prolonged Sitting in the Workplace.
Human Factors and Ergonomics Society, 2012.
Karam, M. and schraefel, m.c.
A Study on the Use of Semaphoric Gestures to Support Secondary Task Interactions.
