Wikis are collaborative systems in which virtually anyone can edit anything.
Although wikis have become highly popular in many domains, their mutable nature often leads them to be distrusted as a reliable source of information.
Here we describe a social dynamic analysis tool called WikiDashboard which aims to improve social transparency and accountability on Wikipedia articles.
Early reactions from users suggest that the increased transparency afforded by the tool can improve the interpretation, communication, and trustworthiness of Wikipedia articles.
This participation model has resulted in a highly popular site with a large amount of content .
Despite their tremendous success, collaborative models of knowledge building are still viewed with skepticism.
The quality, accountability, and trustworthiness of the articles in Wikipedia has been debated heavily in the press .
Wikipedia itself keeps track of these issues and openly discusses them.
Even Wales, a co-founder of Wikipedia, said that he would like to make it known that he does not recommend it to college students for serious research .
The opposite point of view, however, has not been debated or expressed nearly as much: Precisely because anyone can edit anything and that anyone can examine the edit history and see who has made them, it can  become a reliable source of information.
Because the information is out there for anyone to examine and to question, incorrect information can be fixed and disputed points of view can be examined side-by-side.
In fact, this is precisely the academic process for ascertaining the truth.
Scholars publish papers so that theories can be put forth and debated, facts can be examined, and ideas challenged.
Our research was motivated by the fact that social transparency and the attribution of ideas and facts to individual researchers is a crucial part of scientific progress.
Collaborative knowledge building has become a highly successful paradigm for creating, finding, and consolidating content online, with popular examples such as Digg.com, del.icio.us, and Wikipedia.
Such systems allow virtually anyone to add content and even to change content that others have added.
Wikis exemplify this paradigm of user involvement, in which any page can be edited by anyone.
The Wikipedia community is well aware of these issues and tries to address the problem by requiring attribution , which is a key official Wikipedia policy.
Wikipedia mandates that all presented information must be verifiable through established sources.
Furthermore, revealing the source of information, which is a form of social transparency, has been recognized as an important factor influencing trust in many online interactions  and it plays an increasingly important role in collaborative knowledge systems such as wikis .
Systems which store transaction logs can provide a rich data source for aggregate information that can provide a meaningful history to users and help them judge the trustworthiness of other users or information .
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Indeed, wiki-like systems may be especially fruitful targets for increasing trust through aggregating and surfacing relevant accountability information.
Wikipedia is a prime candidate for information aggregation and surfacing, as the history of every edit is stored in the system.
Recently, WikiScanner  brought the issue and idea of social transparency to the forefront.
It uncovers the organizations where anonymous edits in Wikipedia are coming from.
Another site, WikiRage , helps identify the hottest trends in Wikipedia.
The WikiRage idea itself was derived from the "Recent Changes" page on Wikipedia.
IBM has developed a tool called History Flow  that visualizes the edits to article pages in Wikipedia, and the Content-driven trust coloring  demonstrates how trust can be visualized on a line-by-line basis.
On the other hand, provenance of information also has been used as an important factor for assessing the quality of knowledge .
These are all examples of how improving social transparency can increase the ability of readers to use the histories of writers to judge the quality of the content, and also possibly encourage writers to be more responsible.
In this paper we discuss how to increase accountability and social transparency by surfacing hidden editing information through an unobtrusive "dashboard" embedded in each Wikipedia page.
The open participatory model of wiki systems - allowing anyone change anything - makes them inherently dynamic and encourages them to have a large number of editors with various points of view.
Furthermore, although users can access past revisions of every page, it is difficult and time-consuming even for dedicated users to make sense of the history of a page, because many page histories run into the thousands of edits .
Our goal here is to investigate how providing access to this type of accountability information, i.e.
If so, the approach can result in reducing the risks many perceive as inherent to a system  in which anyone can contribute or change anything.
To address this challenge, we designed WikiDashboard , a tool that helps users to identify interesting edit patterns in Wikipedia pages, patterns that may be very hard to detect otherwise.
As shown in Figure 1, the site provides a dashboard embedded within each page in Wikipedia, while proxying the live content from Wikipedia.
The dashboard provides a visualization overlay onto every live Wikipedia page, enabling users to be aware of social dynamics and context around the page they are about to read.
The prototype can be used just as if users are on the Wikipedia site itself.
All of the functions  work just as in Wikipedia.
Based on the type of Wikipedia pages, the prototype provides two types of dashboards: Article Dashboard and User Dashboard.
Each article has an associated article dashboard that displays an aggregate edit activity graph representing the weekly edit trend of the article, followed by a list of the top active editors for that page .
The top summary graph shows two trends: a gray line graph representing the edits made on the article and a blue bar graph denoting the edits on the corresponding "Talk" discussion page.
This graph can help users to easily identify any interesting incidents in the article history, e.g., a sudden burst of edits that might correspond with some heavy discussion.
Below the article edit summary, the active users of the article are ordered by the number of edits they made on the page and its talk page combined, allowing users to easily identify the top editors.
Furthermore, the weekly edit activity graph of each editor on the right side of the dashboard enables users to investigate when the edits by that editor were made.
A darker red bar denotes more activity in a particular week.
With this graph, the tool can help users to examine patterns on how an article evolves over time between multiple editors,
WikiDashboard is a visualization overlay for live Wikipedia pages.
The dashboard provides a useful visual digest about who edits how many revisions on each Wikipedia page.
It allows users to easily evaluate social activities and patterns around the page, which may be hard to detect otherwise.
This figure shows an example of the tool applied to the Wikipedia article "United States presidential election, 2008"
The top summary graph shows the weekly edit trend of this page.
Below the summary graph, there is a list of active editors and their activities on the article.
In this example, it is easy to identify that user Zz414 is the most active editor of the article.
It is interesting to see that Zz414 suddenly stopped editing as of Feb. 2007.
A user page is a special space like a home page to display information relating to a user.
In WikiDashboard, each user page has a User Dashboard embedded, displaying the article contribution and editing patterns of that user .
The summary graph is followed by the list of Wikipedia pages where the editor has made edits.
The list is ordered by the volume of contribution and includes the corresponding article-editor activity graphs on the right side.
Article titles and user names in both dashboards are clickable links, allowing users to browse through them for further exploration.
For example, clicking on an article title brings up the corresponding article and article dashboard.
Clicking on the statistics summarizing the number of edits for a user launches the Detail Edit Log , which displays the list of every edit that a specific editor made on the article.
This drill-down tool enables readers to examine each individual revision for validity, which is hard to accomplish when only provided with aggregate visual summaries.
Figure 4 Detail Edit Log is provided for detail investigation of individual edits made by a particular editor on a selected page.
Figure 3 User Dashboard is embedded in each user page of Wikipedia.
The dashboard displays weekly edit trend of an editor as well as the list of articles that the editor made revisions on.
This example shows a user, "Wasted Time R" made significant edits on articles related to New York politicians and pop singers.
As shown in Figure 3, User Dashboard is designed to facilitate an easy inspection of topics of interest that the editor might have.
Furthermore, the dashboard allows investigation of the evolution of editor's topics of interest.
For example, the editor in Figure 3 recently developed interest in the Rudy Giuliani article.
Theories of social translucence  state that three building blocks are necessary for effective communication and collaboration: making socially significant information visible and salient; supporting awareness of the rules and constraints governing the system; and supporting accountability for actions.
The idea of social translucence suggests that WikiDashboard could benefit not only readers but also improve the effectiveness of active writers.
Indeed, we are very interested in analyzing the impact of improved social transparency on both readers and editors.
Even though WikiDashboard has only been available to the public for a week, we have had already 2,388 visits and 12,157 page views.
Thus, we have already been able to capture a number of insightful feedbacks from various users: "WikiDashboard appears to be a valuable tool that can provide some good insights into individual edit patterns and edit conflicts on specific articles.
As a means of learning about the tool I have found it useful to use it on articles that I have an intimate understanding of development in order to get a feel of how it can be used and interpreted."
1 "This is a revolutionary tool for us wiki-watchers."
1 "This is very useful for getting a quick glance of the user's editing interests over time.
I actually think a tool like WikiDashboard presents significantly more utility, and is the beginning of an interesting trend of repurposing metadata to create a trust heuristic."
2 "WikiDashboard  a quick way to find the most active editors of an article.
On  Clinton's article,  Tvoz ranked third highest.
On  Thompson's,  Ferrylodge was unmatched."
In future work, we are considering a number of improvements:  Providing richer social context on the dashboard would be an obvious next step.
For example, showing the last few editors might be useful for readers to evaluate an article.
Some edits clearly are more substantial than other minor fixes.
Simple measures such as number of net words changed might be useful.
One more important aspect of social transparency is to control what and how much to expose.
It is crucial for some information to remain private.
Furthermore, exposing particular types of information could have a negative impact on the system.
Would we encourage editors to game the system to get to the top 10 editor list of many articles?
It is an important question for future research as to which information is better left private vs. made transparent.
In this paper we introduced WikiDashboard, a social dashboard that aggregates and surfaces "under the hood" information in Wikipedia.
WikiDashboard has great potential in impacting users' interpretation of Wikipedia.
We hope the ideas presented in this paper may inform designers aiming to increase social transparency and user trust in other collaborative systems.
