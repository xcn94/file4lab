We present Hover Widgets, a new technique for increasing the capabilities of pen-based interfaces.
Hover Widgets are implemented by using the pen movements above the display surface, in the tracking state.
Short gestures while hovering, followed by a pen down, access the Hover Widgets, which can be used to activate localized interface widgets.
By using the tracking state movements, Hover Widgets create a new command layer which is clearly distinct from the input layer of a pen interface.
In a formal experiment Hover Widgets were found to be faster than a more traditional command activation technique, and also reduced errors due to divided attention.
One approach to address this problem is to require the user to press a physical button to explicitly distinguish between command modes and an ink input mode .
A button can provide an efficient and effective solution , but in some situations it is just not practical.
Many mobile devices or electronic whiteboards lack a suitable button, and even if a button is available, it may be awkward to use .
We seek new strategies and techniques for supporting localized user interface interactions in pen interfaces.
Many pen devices  support a tracking state.
The tracking state senses the pen location while the pen is proximal to the interaction surface.
However, the literature offers few examples of uses for the tracking state other than cursor feedback .
We propose Hover Widgets, a novel interaction technique that extends the capabilities of pen-operated devices by using the tracking state to access localized user interface elements.
A Hover Widget is invisible to the user during typical pen use, but appears when the user starts moving the pen along a path in the tracking state, and then activates when the user reaches the end of the path and clicks the widget with the pen.
For example, the user might form a backwards 'L' shape to activate a marking menu .
Pen-based interfaces are effective tools for a variety of tasks, such as freeform note taking, and informal sketch design.
However, these devices typically lack the keyboard keys, buttons, and scroll wheels that can provide shortcuts for common tasks on the desktop.
As a result, the user must zigzag the pen back and forth between the work area and the system menus.
This slows users down and diverts their visual attention from their actual task at hand.
Localized user interface elements attempt to solve this problem by bringing the interface to the locus of the user's attention, as indicated by the current pen location .
A significant challenge for localized interfaces is that the user must invoke them somehow, such that a pen stroke on the screen activates the interface rather than leaving behind ink.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Figure 1:  When the user starts a Hover Widget gesture , the widget fades in.
The dashed line is for illustration only, showing the pen's path in the tracking state.
Our research contributes a new way of using the pen tracking state to extend the capabilities of pen interfaces.
We discuss the design space of Hover Widgets, consider various tracking state gestures which could be used, and explore various means for activating the Hover Widgets once the associated gestures are performed.
In our prototype application, four `L' shaped Hover Widgets are used to activate localized interactions, compensating for the absence of time-saving desktop items not available in pen interfaces, such as hotkeys, mouse buttons, and scroll wheels.
In our studies, we found that an 'L' shaped gesture could be performed quickly, and had little chance of false activation.
In a task sensitive to the user's focus of attention, we found that the localized properties of Hover Widgets made using them faster and also provided more accurate results compared to using a standard toolbar icon.
In , users could share documents between multiple Tablet PCs by performing a drag gesture from one device to another called a "stitching" gesture.
In one of the designs, this gesture could be done in the display tracking zones.
The tracking menu is an interactive interface widget which relies on tracking state actions .
The menu is a cluster of graphical widgets surrounded by a border within which the cursor moves.
While the cursor is within the border, menu items can be selected via the usual cursor movements.
However, if the cursor reaches the menu's border while moving in the tracking state, the menu is dragged around with the cursor.
This allows for a smooth modeless transition between menu repositioning and menu item selection.
Further, the contents of the menu are always in close proximity to the cursor.
However, unlike Hover Widgets which are modeless, a tracking menu is modal in that an explicit action is required to dismiss it.
As with all modal interface elements, while the tracking menu is active, only commands within that menu can be executed.
This limitation of tracking menus is one motivation for exploring the design space of modeless interface widgets - like Hover Widgets - that leverage the tracking state.
Hover Widgets combine three fields of related work: gestures, localized UIs, and uses for the tracking state.
These systems differ from the gestures used for Hover Widgets, as the gestures are carried out on the surface of the display.
A documented difficulty associated with this technique is that the gestures can be confused with the data input, generally ink, causing unexpected results which must be undone .
Even the most obscure gesture could be falsely recognized - if the user was illustrating the system's gestures, for example, then those illustrations would be recognized as the gestures which they illustrate.
To alleviate this problem, some systems require users to explicitly switch between ink and gesture modes .
In a recent study, it was shown that a button used by the non-dominant hand was most effective for this mode switch .
Other localized interaction techniques, such as pop-up menus, are generally activated with physical buttons.
Two implementations of localized scrolling techniques which were recently developed supported scrolling as the only input mode, so their invocation was not an issue .
The tracking state of the pen, when it is above the display surface, is one of the three states sensed by pen-based systems.
The mouse can also be in the tracking state when it is moved without a button pushed .
Usually, this state is used to track the current position of the cursor, but there has been previous work using it for other functionality.
The Microsoft Windows operating system provides tool tips when users hover above an icon.
These pop-up boxes display information about the icon, but cannot be clicked.
A more interesting example is seen in the Windows XP Tablet PC Edition, which supports a gesture made in the tracking state.
If the user scribbles above the display surface, a character entry tool pops up.
Some users may find this feature irritating.
It can be activated accidentally, and there is no visual guidance showing the user what to do for the gesture to be recognized.
Hover Widgets offer a number of beneficial properties: * New Command Layer: Hover Widgets use the tracking state to create a new command layer which is clearly distinguishable from the input layer of a user interface.
A user does not need to worry about the system confusing ink and gestures.
For example, if a user needs to undo a mistake, instead of traveling to the top of the interface to click an icon, the user could make a gesture while hovering, and then click to activate an "undo" Hover Widget.
If a user is reading the bottom of a page that they are annotating, a gesture in the tracking state could be used to activate a virtual scroll ring , allowing them to scroll as they continue to read.
The user would not have to shift their attention to an icon on the border to initiate scrolling.
For example, a Hover Widget could be used to activate a marking menu or virtual scroll ring.
If a user noticed a mistake in a document while they were scrolling, they could lift the pen and then draw a circle around the mistake.
The user could then activate the scroll tool to continue scrolling.
Using the tunnel boundaries also makes the gesture recognition algorithm relatively simple.
A more elegant recognition system could possibly improve performance, but it would be challenging to visualize complex gesture constraints.
If a gesture in the tracking state will be required to activate the Hover Widgets, then the gesture must be easy to perform.
At the same time, the gesture must not occur in natural tracking state movements.
Otherwise, Hover Widgets would be activated unintentionally.
This presents a trade-off between simplicity and ambiguity.
If the gesture is complex, executing it will be slow.
But reducing the complexity may increase ambiguity, causing unintentional activations.
UniStroke characters  provide a good place to start when searching for appropriate gestures.
The simplest gestures consist of a single directional stroke, but there are also compound stroke gestures with one and two corners .
Although the single-level strokes are simple, they will cause many false activations, as the pen only needs to move in a single direction to activate the widget.
The two-level strokes are less likely to cause false activations, so in our studies we focus on `L' shape strokes, which have 90 degree angles.
These strokes have minimal complexity, and we would not expect the sharp corners to appear in tracking state pen actions.
We verified this intuition by simulating the Hover Widgets on captured pen data from internal users.
We analyze the results of a more formal simulation study in Experiment 1.
While the two-level strokes may be the best shape strictly in terms of the simplicity-ambiguity tradeoff, there is no reason more complex strokes couldn't be used.
Along with three stroke compound gestures, we have also explored other stroke shapes such as spirals .
Although the strokes are more complex, they could be used to increase the vocabulary of an interface.
If the cursor leaves the boundaries of the tunnel, then the origin of the tunnel is repositioned to the earliest point of the current hover stroke which could begin a successful gesture .
As long as a user's stroke ends with the required movements, the Hover Widget will be activated.
This makes, the `L' shaped gesture semi-scale independent, as the first segment of the stroke does not have a maximum length .
A consequence of this algorithm, is that the sections of the tunnel boundaries act similarly to the borders of tracking menus .
The Hover Widget, however, is not simply an `L' shape tracking menu, since intersecting with other sections of the tunnel will reset the origin of the tunnel, ensuring that only `L' shaped pen movements can activate the Hover Widget.
Once the cursor travels through a tunnel, the associated Hover Widget can be activated.
We have explored three methods for activation: pen down, tapping, and crossing.
With pen down activation, the user simply brings then pen in contact with the activation zone after completing a gesture in the tracking state.
In initial user tests, we found that errors caused by overshooting the activation zone could be adequately prevented by making the region twice as long in the direction of movement .
The tunnel is reset if the cursor leaves this activation zone.
Pen down is the default activation method in our application, and is the technique used in our experiments.
Tapping to activate the Hover Widgets is another option which we have explored.
This technique could be used to reduce false activations.
In the case of crossing activation, the Hover Widget is activated as soon as the pen crosses the end of a tunnel, while still in the tracking state.
Implementing this technique increased the frequency of unintentional activations of `L' shaped tunnels, but with more complex tunnels, such as spirals, false activations do not occur.
Two interrelated design issues for Hover Widgets are how they are visualized, and how the system recognizes them.
The issues are associated because the visualization should convey to the user the exact requirement for either invoking the command or preventing the command from occurring.
Our strategy is to use gestures which are constrained and guided by boundary walls surrounding the target stroke, creating a tunnel that the user must traverse .
The visual appearance of the tunnel defines the movements required to acquire the associated Hover Widget.
Earlier we argued that recognition should be correlated to the way that Hover Widgets are visualized.
While we observed that drawing the tunnels is beneficial when learning to use the Hover Widgets, seeing the tunnels at all times would become visually distracting, especially when the Hover Widgets were not in use.
Expert users may not need to see the tunnel at all.
In this section we outline strategies for visualizing the Hover Widgets such that the user sees what they need to see, when they need to see it.
We implemented a painting program, with all functionality of the application accessed via Hover Widgets.
Hover Widgets are not limited to drawing applications; this context was used as a proof-of-concept prototype.
The system allows us to explore how Hover Widgets can replace desktop user interface elements using localized interactions.
The only standard GUI element is a control panel that can be used to modify various parameters of the Hover Widgets.
By using the Hover Widgets for all functionality we are pushing the limits of Hover Widgets, allowing us to see how far we could extend their use.
In an actual application, the Hover Widgets would likely complement standard menus and tool bars.
Four `L' shaped Hover Widgets are used in the application .
We now describe the functionality of these four Hover Widgets.
Figure 4:  The tunnel and activation zone fades in after 40% progress has been made.
Both the tunnel and activation zone can either be displayed or hidden.
When displayed, a fade-in point can be set, which defines how much progress must be made before the widget becomes visible.
For example, a user may only want to see the activation zone or tunnel after they have progressed through 40% of the tunnel .
Once the cursor reaches the fade-in point, the widget slowly fades in.
The activation zone is displayed as a square icon, which illustrates its associated functionality.
Because the activation zone is actually rectangular, the icon will drag along with the cursor until it exits the region .
We have also explored a dwelling fade-in, where the Hover Widget becomes visible if the pen dwells in any fixed location of the tracking zone.
This is especially useful when multiple tunnels are present, so users can see which tunnel to follow to access a certain Hover Widget .
A final visualization technique which we have explored is the cursor trail.
The path that the cursor has taken is shown, beginning at the tunnel origin, and ending at the current cursor location .
If the cursor completes the gesture, the trail turns green, indicating that the Hover Widget can be activated .
The tools Hover Widget  can be thought of as replacing an icon toolbar, found in most drawing applications.
Activating the Hover Widget brings up a single level marking menu.
From this menu, the following command selections are available: selection tool, pen tool, square tool, circle tool, and pen properties.
The pen properties option pops up a localized CrossY Menu , allowing users to select the color and width of their pen.
Multiple Hover Widgets can be used simultaneously, with each one having its own parameters .
When multiple Hover Widgets do exist, each individual Hover Widget is updated independently of the others.
This approach ensures that each Hover Widget will still be activated if and only if its corresponding gesture is made.
The relative positions of the 4 tunnels illustrated in Figure 5 are not locked.
If the pen first moved to the right, it could still move up and then to the left to activate undo icon, without the need to first backtrack.
This is a difference from Tracking Menus, which have a constant interface layout .
The scroll Hover Widget  allows users to scroll, without the need to travel to display borders.
It can be thought of replacing the scroll wheel of a mouse.
Activating this Hover Widget brings up a virtual scroll ring .
With this tool, users can make a circling gesture clockwise to scroll down, and counter-clockwise to scroll up.
The application contains a control panel which is opened by selecting a tab at the bottom right corner of the interface.
This control panel allows users to explore the various Hover Widget settings and parameters.
For example, users can switch to crossing or tapping activation, manipulate the width and length of the tunnels, and enable or disable the various visualization techniques.
Parameters for the visualization techniques can also be modified, such as the fade-in point and the dwelling fade-in time threshold.
We had roughly 10 computer literate users explore the application in short and informal demonstration sessions.
While most users were able to use the Hover Widgets immediately, some needed a few minutes of practice.
One of the most useful features seemed to be the dwelling fadein.
Users understood the required gestures when the tunnels were displayed, and could discover the various functionality of the application.
All users liked the idea of using the tracking state for added pen input functionality.
The application which we developed allowed us to explore various uses of Hover Widgets in an interactive pen-based application.
We now present a pilot study and two experiments designed to answer three main questions:  How do the parameters of the Hover Widgets affect their usability?
The parameters we are primarily concerned with are the shape, orientation, tunnel width, tunnel length, and visualization technique .
The first question, in itself, would require a great deal of experimentation, due to the number of parameters which may affect the Hover Widgets' performance.
To narrow down the number of variables in our experiments, we focused on a single value for some of these parameters.
First, we only tested the `L' shaped hover gestures, as they seemed to perform well in our initial observations.
We set the length of the tunnel for these gestures to a value of 78 pixels, 39 pixels per direction.
This length was found to cause few false activations in our preliminary captured data, and allowed users to complete the tunnels while resting their hand and moving mostly their fingers, with minimal movement from the wrist.
A circle was placed in the center of the screen, which the user tapped to begin a trial.
The user could then begin the required Hover Widget gesture, and the trial ended when the user successfully clicked on the Hover Widget activation zone.
The tunnel and activation zone were displayed at all times, before and after a trial began.
The cursor trail was also displayed once a trial began.
The activation zone was displayed as a red rectangle, and turned green when the pen was above it.
Subjects were told to complete the trials as quickly as possible while minimizing errors.
An error occurred when the pen clicked outside of the Hover Widget activation zone, in which case the user would have to start over from the beginning of the tunnel.
Subjects were also told to avoid colliding with the walls of the tunnel.
The length of the activation zone  was set to two times the value of the Width.
The Width values were fully crossed with all 8 possible Orientation values , resulting in 32 conditions.
A repeated measures design was used - subjects completed 4 blocks, consisting of all 32 Width-Orientation combinations appearing 2 times each in random order.
Regression analyses showed that the data for all conditions fit the Steering Law  with an r2 value of 0.98 .
Although Orientation had a significant effect on movement time, the values only ranged from a minimum of 0.69 seconds for Orientation 5 and a maximum of 0.74 seconds for Orientation 8.
Overall, 11.6% of the trials had collisions, and only 0.78% of the trials had clicking errors.
This is a good result, since a collision only indicates suboptimal performance, while a clicking error in an actual application could cause unexpected results.
The collision rate was so high because of the condition where Width = 12, which had a 26.6% collision rate.
With that condition removed, the average collision rate decreased to 6.7%.
Second, it allowed us to capture pen data to verify our preliminary false activation findings.
The capture sessions were broken up into three tasks, all using Windows Journal.
Task one was to write a grocery list.
In task two, participants drew directions to their house.
In task three, they drew a picture of their dream house.
At this point, participants had no knowledge of the Hover Widgets, and did not know their data would be used to test for false activations.
Although only twelve participants went on to participate in the study, we captured pen data from fifteen participants, resulting in just over three hours of captured data.
The procedure used for this experiment was similar to the pilot study.
Above the starting circle, we displayed an arrow indicating the 'L' shape orientation for the current trial, both before and after the trial began.
The tunnel still had a constant length of 78 and now also had a constant width of 20.
The activation zone length was 40.
We tested all 8 possible values of Orientation.
We also tested the effects of the presence or absence of the Cursor Trail, and the Fade-in Point.
The Fade-in Point values which we tested were 20%  and 70% , indicating the percentage of the tunnel that had to be traveled before the Hover Widget became visible.
A repeated measures within-participant design was used.
A fully crossed design resulted in 32 combinations of Orientation , Cursor Trail , and Fade-in Point .
Each participant performed the experiment in one session lasting approximately 20 minutes.
The session was broken up by the 4 combinations of visualization techniques, with 5 blocks of trials for each of the visualizations.
Each block consisted of all 8 orientations, appearing 2 times each in random order.
Presentation order of the visualization techniques was counterbalanced using a Latin Square design, resulting in four orderings.
Participants were randomly divided into 4 groups of 3, with each group performing one of the 4 orderings.
At the start of the experiment, participants were given a single warm-up block with the Hover Widget and cursor trail always visible, to familiarize them with the technique.
These results give us the required data to choose appropriate parameter values for our full study.
We will include all 8 values of orientation to try to understand the cause for its differing effects on movement time.
The pilot experiment, in addition to our preliminary captured data, shows that a width of 20 produces a good trade-off between minimizing movement time and error rate, while also preventing false activations.
Therefore we used a width of 20 for the remaining studies.
We first discuss the results of the false activation analysis.
We simulated the data from the pen capture sessions on all 8 possible `L' shaped orientations.
We report the results from two tunnel widths , with all tunnels having a length of 78 pixels.
Figure 8 shows the number of false activations which occurred in the 3 hours, broken up by orientation.
Even at the larger width, orientations 6 and 7 had no false activations, while orientations 2 and 5 had 11 each.
The captured data confirms our hypothesis that some gestures in the tracking state will rarely occur, but it also shows that corners in certain directions will be seen.
The results of Experiment 1 gave us a good understanding of how the parameters of the Hover Widgets would affect their performance in a controlled environment.
Average movement times were comparable to those of 2-level simple and compound marking menus reported in the previous literature .
The controlled environment, where the user performed all trials from a constant starting position, was well suited to answer our initial fundamental question about the Hover Widget parameters.
Specifically, we found that the orientation did not have a significant effect on movement time, but did affect the number of observed false activations.
Furthermore, we found that the cursor trail provided no advantage, while the early fade-in point significantly reduced movement time.
In Experiment 2, we explore the benefits gained from Hover Widget's property of being a localized interaction technique.
We designed the experiment to allow us to analyze two potential benefits - faster access to commands and maintained focus on the primary task.
The experimental task is an abstraction of real interface tasks which demand that the user focus their attention on a particular locale on screen, while at the same time requiring command selections.
Examples of such tasks are scrolling or selecting a highlighter while proof-reading a document.
Similar studies in two-handed input have been carried out exploring the effects of visual diversions during a drawing task .
We measured movement time  defined as the time between lifting the pen after clicking to start the trial, and clicking the Hover Widget activation zone.
We discarded trials in which clicking errors occurred in our analysis of MT.
A repeated measures analysis of variance showed a significant main effect for Fade-in Point , but not Cursor Trail or Orientation.
With the early Fade-in Point the average movement time was 1.16s, and with the late Fade-in Point, the movement time was 1.30s.
The average movement time was 1.41 seconds for non-tablet users, and 0.99 seconds for tablet users.
Clicking errors only occurred in 0.92% of all trials.
This error rate was 1.4% for the late visualization, and 0.4% with the early visualization.
This shows that even with the late visualization, the user had enough feedback to know when they could and could not activate the Hover Widget.
The display ran on a 1.4Ghz Windows XP desktop machine.
This large-sized tablet allowed greater variation in the distance variable which we would be testing than the Tablet PC used in Experiment 1.
Post hoc analysis revealed that the Fade-in Point only had a significant effect in block 1 .
This result indicates that the early fade-in point would make for an effective training visualization, which the user could subsequently disable.
A trial was completed by selecting the blue target cell, which was only visible for 0.7 seconds.
The red circle shows the position of the target needed to be selected in the icon condition.
The dimensions of the grid  and its distance from the icon  varied.
The top and left display borders are illustrated.
At the start of a trial set, a square grid consisting of an array of 12x12 pixel square cells was displayed.
The top left corner of the grid was aligned with the top-left to bottomright diagonal of the display, at varying distances.
The user clicked in the grid to start a trial, at which point a target cell in the grid would flash blue for 0.7 seconds.
The target cell only flashed once, after which it returned to being visually indistinguishable from the other cells in the grid.
To complete a trial, the user clicked this cell.
Once the target cell was clicked, a new cell flashed, immediately beginning the next trial .
Before clicking the target cell, the user was required to make a successful command selection.
Two command selection conditions were used.
In the Icon condition, a single red circle was drawn in the top left corner of the screen, representing a traditional menu icon .
The icon had a diameter of 24 pixels, which is about as large as any icon which appears in today's GUIs.
In the Hover Widget condition, users were required to activate a Hover Widget before clicking the cell that had flashed.
The Hover Widget parameters were set based on the results of Experiment 1.
The Hover Widget tunnel had a width of 20, a length of 78, and `L' shape orientation 7 .
No cursor trail was displayed, and the fade-in point was 20%.
Since the target cell was only temporarily distinguishable from the surrounding cells, users had to attend to the grid when it flashed.
Users would also benefit from attending to the grid after the target cell flashed, to reduce the reliance on their spatial memory of the target cell location, in order to successfully select it later.
If participants were unable to recall the appropriate target cell and clicked a different cell, then they had to pause for 2 seconds, after which the target cell was highlighted to be clicked.
This time penalty put it in the participants' best interest to select the correct target cell on their first attempt, allowing us to reliably correlate accuracy with maintained focus of attention.
Because gestures are generally not self-revealing  discoverability may be an issue with Hover Widgets.
To explore this, participants were given no initial verbal instructions as to how to use the technique.
Instead, a small text description and 40 second video clip were shown prior to using the Hover Widgets.
This approach mimics what could be a start-up tutorial for first-time users of an application using Hover Widgets.
If participants had subsequent questions, the experimenter would only repeat instructions that were already given in the video or text.
Each participant performed the experiment in one session lasting approximately 60 minutes.
The session was broken up by the 2 command selection techniques, with 4 blocks appearing for each of the command techniques.
Each block consisted of 24 trial sets, with each GridN-D combination appearing twice in random order.
A trial set consisted of 5 trials on the same grid, with a different target cell for each of the 5 trials.
Presentation order of the command techniques was counterbalanced with half the participants performing each technique first.
A two minute warm-up session was given before each command technique.
We removed subject 5 from the analysis, as the error rate for that subject was disproportionately high, and movement times were much faster, indicating that the subject was racing through the experiment.
We also removed outliers more than 3 standard deviations from the group mean movement time.
A total of 2.01% of the data was removed.
Movement time was defined as the time taken to select the target cell once a trial had started.
Our analysis of movement time does not include trials in which an error was made during the command selection.
Overall movement times were 2.19s for Icon, and 1.76s for Hover Widget.
A repeated measures within-participant design was used.
Independent variables were command technique CT , grid dimension GridN , measured as the grid side length in cells, and distance, D , measured as the distance between the top left corners of the grid and the display in pixels.
A fully crossed design resulted in 24 combinations of CT, GridN, and D.
Figure 11 shows movement times for each of the 12 GridND combinations, illustrating the interactions.
As expected, increased distance had little effect on the Hover Widget, while it increased times for the icon.
Post-hoc analysis shows the Hover Widget technique to be significantly faster for every condition except at D = 300, where the differences were not significant for the 4x4 and 12x12 grids.
This is a good result, showing Hover Widgets to be advantageous, even when the icon is near the grid.
It is interesting to note that GridN had an effect on the Hover Widget technique.
This is in part due to the larger distances being traveled to get to the target cell.
This was the result of users sometimes moving off the grid before activating the Hover Widget.
We believe users did this to prevent their hand and Hover Widget from occluding the grid and target cell when it flashed.
Post Hoc analysis showed that only in the first block were movement times significantly faster , demonstrating that, with practice, users new to Tablet PCs could use the technique just as well as experienced users.
Only one subject took more than 20 seconds for their first successful Hover Widget activation, and after the 6th trial the mean activation time across all subjects was under 3 seconds for each of the remaining trials in the warm-up.
This data, in combination with the fact that Hover Widgets were significantly faster in the first block of the real experiment, shows that if proper system instructions are given, discoverability will not be an issue.
We defined target errors as trials in which users selected the wrong target cell.
Figure 12a illustrates the interaction between CT and GridN.
The data shows that users have the ability to maintain their focus of attention on the grid while activating the Hover Widget, while selecting the icon causes divided attention.
Surprisingly, with the icon technique, target error rate actually decreased with an increase of distance.
This decrease may have been due to users spending more time focusing on the target cell before selecting the icon for larger distances.
Regardless, users had trouble maintaining their focus of attention, even when the icon was close.
We defined a collision error as any time the user aborted a Hover Widget after making at least 40% progress through the tunnel.
Collision errors occurred in 4.1% of all trials.
It is important to note that trials in which collision errors occurred were included in our analyses of movement time.
The errors simply resulted in suboptimal trial performance.
We have presented Hover Widgets, interactive widgets which are activated through simple gestures in the tracking state of pen-based interfaces.
We have shown how Hover Widgets can be integrated into an application, replacing interface elements which can be inconvenient when using a pen.
Users who tried the application liked the idea of using gestures while hovering, and were able to activate the Hover Widgets with little practice.
Furthermore, we have explored a method of pen interaction without the need for a button.
Because our motivation for this is qualitative, as buttons can be unavailable or awkward to use, and not quantitative, our experiments did not compare Hover Widgets to button pressing techniques .
In an initial controlled experiment, we found acquisition times of Hover Widgets closely matched the movement times reported previously for similar simple and compound marking menu strokes.
Our captured data showed that a number of these gestures will rarely occur unintentionally, some not seen once in 3 hours of pen usage.
These results could drive the design of applications which use Hover Widgets.
For example, we have modified our application to use orientations 1, 4, 6 and 7 to minimize false activations.
In the second experiment, we found that Hover Widgets reduced movement time and improved accuracy, when compared to a standard toolbar icon, in a task sensitive to the user's focus of attention.
Movement time was significantly reduced in all conditions when the distance needed to travel to the icon was 600 pixels or greater, or about half the length of most Tablet PC displays.
The analysis of accuracy showed that users were able to activate the Hover Widgets with a minimal shift of attention.
We analyzed the effects of learning on each of the command techniques.
As can be seen in Figure 12b, learning is more apparent with the Hover Widget technique.
Post hoc analysis shows that significant learning occurred after each block with the Hover Widgets, while the only significant change for the icon was between the first and second block .
Also of interest is that the Hover Widget was significantly faster in each of the four blocks, including the first .
The design space of Hover Widgets is very large, and there are a number of paths which we have not yet taken.
More complex gestures could be investigated.
The shape of the gestures could even represent their functionality.
For example, the letter `N' could be traced in the tracking state to activate a `NEW' command Hover Widget.
Sensiva Symbol Commander  contains such gestures, but the pen must be down with a button pushed.
In the application that we developed, users manually controlled the parameters of the Hover Widget.
This approach could be extended to allow users to design their own Hover Widgets, and customize their functionality.
Lastly, we believe Hover Widgets could be a beneficial technique for large display interfaces.
In such setups, it becomes even more critical that a localized user interface is available, since the borders of the display may be difficult or impossible to reach.
Generally, buttons are not available, but some electronic whiteboard technologies do sense the tracking state , so Hover Widgets could be used.
As for the controlled evaluation of Hover Widgets, Experiment 2 provided very positive results for the technique.
However, the task was a simplified usage scenario, as only a single Hover Widget was used.
We would like to explore what happens when the user must choose from multiple Hover Widgets, and how effectively Hover Widgets can be used to activate marking menus.
We would expect to see similar benefits, with a possible overhead cost to learning multiple gestures.
It would also be interesting to evaluate the costs of performing gestures above the display surface.
From our observations, the lack of force feedback when activating a Hover Widget was not problematic.
However when combined with techniques which required the pen to be down, such as marking menus, some users needed practice before remembering that the pen had to be up for the Hover Widget, and down for the marking menu.
Overall, the Hover Widgets are a promising technique for extending the capabilities of pen-based interfaces.
Our studies showed Hover Widgets to have strong qualitative and quantitative benefits which warrant future explorations.
