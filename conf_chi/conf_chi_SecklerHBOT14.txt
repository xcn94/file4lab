Mirjam Seckler1, Silvia Heinz1, Javier A. Bargas-Avila2, Klaus Opwis1, Alexandre N. Tuch1 3 2 3 Department of Psychology Google / YouTube User Dept.
This study reports a controlled eye tracking experiment  that shows the combined effectiveness of 20 guidelines to improve interactive online forms when applied to forms found on real company websites.
Results indicate that improved web forms lead to faster completion times, fewer form submission trials, and fewer eye movements.
Data from subjective questionnaires and interviews further show increased user satisfaction.
Overall, our findings highlight the importance for web designers to improve their web forms using UX guidelines.
Accordingly, website developers should pay special attention to improving their forms and making them as usable as possible.
In recent years, an increasing number of publications have looked at a broad range of aspects surrounding web form interaction to help developers improve their forms.
These studies shed light on selected aspects of web form interaction, but rarely research the form filling process using holistic approaches.
Therefore, various authors have gathered together the different sources of knowledge in this field and compiled them as checklists  or guidelines .
Bargas-Avila and colleagues, for instance, present 20 rules that aim at improving form content, layout, input types, error handling and submission .
Currently there is no empirical study that applies these guidelines in a holistic approach to web forms and shows whether there are effects on efficiency, effectiveness and user satisfaction.
It is this gap that we aim to close with the present study.
The main research goal is to conduct an empirical experiment to understand whether improving web forms using current guidelines leads to a significant improvement of total user experience.
For this we selected a sample of existing web forms from popular news websites, and improved them according to the 20 guidelines presented in Bargas-Avila et al.
In a controlled lab experiment we let participants use original and improved forms, while we measured efficiency, effectiveness and user satisfaction.
This work contributes to the field of HCI in three ways:  The findings of this paper are empirically tested guidelines that can be used by practitioners.
Technological development of the Internet has changed its appearance and functionality drastically in the last 15 years.
Powerful and flexible technologies have added varying levels of interactivity to the World Wide Web.
Despite this evolution, web forms - which offer rather limited and unilateral ways of interaction  - remain one of the core interaction elements between users and website owners .
These forms are used for registration, subscription services, customer feedback, checkout, to initiate transactions between users and companies, or as data input forms to search or share information .
Web forms stand between users and website owners and can therefore be regarded as gatekeepers.
Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
The usability of such forms can vary vastly.
Small variations in form design can lead to an increase or decrease of interaction speed, errors and/or user satisfaction.
It was shown, for instance, that the placement of error messages impacts efficiency, effectiveness and satisfaction.
Locations near the erroneous input field lead to better performance than error messages at the top and the bottom of the form - placements that have been shown to be the most wide spread in the Internet .
Due to the importance of form usability, there is a growing body of research and guidelines published on how to make online forms more usable.
Some publications present empirical data, whereas others are based on best practices of experts in the fields of Human-Computer Interaction and User Experience .
There are extensive reviews on form guidelines research such as publications from Nielsen , Jarrett and Gaffney , and Wroblewsky .
One review that focuses particularly on guidelines that are based on published empirical research is provided by Bargas-Avila et al.
Web Form Design Guidelines Form content 1.
Let people provide answers in a format that they are familiar with from common situations and keep questions in an intuitive sequence.
If the answer is unambiguous, allow answers in any format.
Keep the form as short and simple as possible and do not ask for unnecessary input.
To enable people to fill in a form as quickly as possible, place the labels above the corresponding input fields.
Do not separate a form into more than one column and only ask one question per row.
Match the size of the input fields to the expected length of the answer.
Use checkboxes, radio buttons or drop-down menus to restrict the number of options and for entries that can easily be mistyped.
Also use them if it is not clear to users in advance what kind of answer is expected from them.
Use checkboxes instead of list boxes for multiple selection items.
For up to four options, use radio buttons; when more than four options are required, use a drop-down menu to save screen real estate.
Order options in an intuitive sequence .
If no meaningful sequence is possible, order them alphabetically.
Use only one input field and place  the format requirements with symbols  left or inside the text box to achieve faster completion time.
If answers are required in a specific format, state this in advance, communicating the imposed rule  without an additional example.
Error messages should be polite and explain to the user in familiar language that a mistake has occurred.
Eventually the error message should apologize for the mistake and it should clearly describe what the mistake is and how it can be corrected.
After an error occurred, never clear the already completed fields.
Always show error messages after the form has been filled and sent.
Show them all together embedded in the form.
Error messages must be noticeable at a glance, using color, icons and text to highlight the problem area and must be written in a familiar language, explaining what the error is and how it can be corrected.
Disable the submit button as soon as it has been clicked to avoid multiple submissions.
After the form has been sent, show a confirmation site, which expresses thanks for the submission and states what will happen next.
Send a similar confirmation by e-mail.
Do not provide reset buttons, as they can be clicked by accident.
If used anyway, make them visually distinctive from submit buttons and place them left-aligned with the cancel button on the right of the submit button.
The overall application of these guidelines is meant to improve the form's usability, shorten completion times, prevent errors, and enhance overall user satisfaction .
To the authors' best knowledge, there has been no empirical evidence that the usage of these guidelines accomplishes the established claims.
Therefore a carefully designed experiment was conducted to answer this question.
Guideline Never clear the already completed fields.
Order options in an intuitive sequence.
Texting of error messages:  Show all error messages after sending the form.
Do not provide reset buttons.
State a specific format in advance.
Disable the submit button as soon as it has been clicked.
Separate required from optional fields.
Use checkboxes instead of list boxes  Use checkboxes, radio buttons or drop-down  Do not ask for unnecessary input.
Let people provide answers in a familiar format.
Date entries  Show error messages in red at the right side.
If the answer is unambiguous   only ask for one input per column.
Match the size of the input fields   the year field shoud be twice as long   place the lables above the input field Use of radio buttons and drop-down menu:  Use color to mark required fields.
In order to investigate as to how forms can be improved by the application of the guidelines compiled by Bargas-Avila et al.
Usability was measured by means of objective data such as task completion time, type of errors, effectiveness of corrections as well as eye tracking data , but also by subjective ratings on satisfaction, usability, cognitive load and by short interviews about quality of experience.
Participants were recruited from an internal database, containing people interested in attending studies.
In total 65 participants  took part in the study.
Thirty-two were assigned to the original form and 33 to the improved form condition .
Participants received about 20$ or course credits as compensation.
Independent sample t-tests showed no significant differences between the two experimental groups regarding age, level of education, computer knowledge, web knowledge, online shopping knowledge and Internet usage.
A chi-square test indicated that there are also no significant differences regarding gender distribution.
By screening www.ranking.com for high traffic websites we ensured getting realistic and commonly used web forms to demonstrate that the 20 guidelines work not only for an average website with a form or even for poorly designed forms but also for frequently used ones.
We focused on top ranked German-language newspapers and magazines that provide an online registration form .
We chose high traffic news websites because they often include web forms with the most common input fields  and are of decent overall length.
Subsequently, we evaluated these forms with the 20 design guidelines provided by Bargas-Avila et al.
Expert ratings and guideline violations for each form.
Two raters independently rated for each form whether a guideline was fully, partially or not violated .
Additionally, 14 HCI experts rated independently each of the 20 guidelines on how serious the consequences of a violation would be for potential users .
See Table 2 for these expert ratings.
This example  shows two fields improved through the following two guidelines: * Guideline 4: If possible and reasonable, separate required from optional fields and use color and asterisk to mark required fields.
Copy of the original SpiegelTM form , improved form , improvement example  good quality , one of mediumform two questions:  "What did you like about the form?"
Nonetheless, the pool of websites As the FUS is not a published questionnaire yet, this is a in our ranking is based on top traffic websites - we expect short introduction.
The FUS is a validated questionnaire for that our three web forms represent rather high quality measuring the usability of online forms .
It consists of 9 examples.
In total, the NZZ and the Spiegel form violated 9 items each to be rated on a Likert scale ranging from 1 guidelines each, while the Sueddeutsche form violated 12.
The total FUS See Table 2 for guideline violations for each form.
We refrained from selecting any form from the top third Items:  I perceived the length of the form to be , since these forms had only minor violations appropriate.
By perceived the order of the questions in the form as logical.
Usability was assessed by means of user performance and subjective ratings.
User performance included: time efficiency  and effectiveness of corrections .
Furthermore, we used the KLM Form Analyzer Tool  to compare the different form versions.
Eye tracking data were collected with a SMI RED eye tracker using Experiment Center 3.2.17 software, sampling rate = 60 Hz, data analysis using BeGaze 3.2.28.
We used the following subjective ratings: The NASA Task Load Index  for mental workload , the System Usability Scale   and After Scenario Questionnaire   for perceived usability in general, and the Form Usability Scale   for perceived form usability.
At the beginning, participants had to fill in a practice trial form.
The quality of this form was medium .
Afterwards, participants were randomly assigned to one of the experimental conditions .
Participants were then sent to a landing page with general information about the selected newspapers and a link to the registration form.
They were told to follow that link and to register.
After successful completion of the form, participants rated the form with a set of questionnaires.
This procedure was repeated for each online form.
At the end participants were interviewed on how they experienced the interaction with the forms.
The study investigator asked first for positive  experiences and the participants could answer for as long as they wanted.
Then they were asked for negative experiences .
Average task completion time in seconds.
To further compare task completion times of the two form conditions, we checked the two forms with the Keystroke Level Model  .
We used the KLM Form Analyzer Tool from Karousos et al.
For all improved forms the KLM predicted time was lower than for the original forms .
Nonetheless, participants in our study needed more time than predicted by the KLM analyzer.
Descriptive data showed that errors due to missing format rules specifications were frequent for the NZZ form .
Chi-square tests showed that this error type was significantly more prevalent for the original condition than all other error types for NZZ .
For the two other forms, no significant differences between the different error types and conditions were found.
Descriptive data showed that in the original condition participants often ignored the error messages and resubmitted the form without corrections .
No significant differences between error types were found for the two other forms.
The eye tracking data were analyzed using non-parametric Mann-Whitney U tests, as data were not normally distributed.
The data shown in Table 8 support results found with the user performance data.
The total amount of time participants spent fixating a form before the first submission was shorter in the improved condition, indicating that they needed less time to process the information on screen.
Eye tracking measures for the original and the improved condition by form.
Figures 2 and 3 visualize scan paths of participants in the original and the improved condition .
The participants filling in the improved form show a much straightforward scan path without unnecessary fixations whereas the side-by-side layout with left-aligned labels of the original form provoked longer saccades and more fixations for participants to orient themselves.
As not all data follow normal distribution, we applied the non-parametric Mann-Whitney U test to investigate the differences between the improved and the original versions of the forms.
Overall, the improved forms received better ratings than their original counter parts.
However, when analyzing the three different forms separately, differences emerge.
As shown in Table 9, only the NZZ form received significantly better ratings on all scales.
The Sueddeutsche form, in contrast, only shows higher ASQ ratings.
For the Spiegel form none of the comparisons turn out significant.
Nevertheless, one should notice that all comparisons between the original and improved versions of the forms show a tendency towards the expected direction.
The original versions of the three forms have different usability issues.
Therefore we analyzed the forms separately on single item level of the FUS, which is a questionnaire designed to measure form usability.
Descriptive statistics for questionnaire scales.
The NZZ form shows improvements on five items: "I was able to fill in the form quickly" , "Mandatory fields were clearly visible in the form" , "I always knew which information was expected" , "I knew at every input which rules I had to stick to" , and "In the event of a problem I was instructed by an error message how to solve the problem" .
Finally, the improved version of the Spiegel form shows higher ratings only on the item "I knew at every input which rules I had to stick to" .
As the NASA-TLX measures workload in a rather broad sense, it might be that its overall score is not able to capture the subtle differences in design between the original and improved versions.
Therefore we conducted an analysis on single item level of the NASA-TLX.
There are no effects on workload with the Spiegel form.
Unexpectedly, participants assigned to the improved forms mentioned significantly more often not liking the design of the whole site , 2 = 7.74, p = .005 instead of expressing negative comments about the forms themselves.
Detailed analysis considering the three different forms separately shows that these results are due to differences between the two versions of the Sueddeutsche, 2 = 5.85, p = .016.
No significant differences were found for the other most frequently mentioned issues.
All interview data were analyzed by grouping similar issues for positive and negative comments * Example of a positive comment: "I think the form is clear, I immediately knew what I had to fill in and where.
And I got an error message telling me how to do it right."
We further made subgroups for each form and version.
In a first step, we counted the number of issues per group showing that the most mentioned issues over all original forms were missing format specifications, insufficient identification of required and optional fields and that there were too many fields overall.
Positive comments regarding the original forms were about easy and fast filling, clear identification of required and optional fields, and wellstructured and clearly arranged forms.
The most frequently reported negative aspects over all improved forms were: unappealing design of the whole site, too many fields, and the cumbersome Captcha fields.
The positive comments concerned easy and fast filling in, clear identification of required and optional fields, and the logical sequence of the fields.
See Table 10 for details.
This study showed that by applying the 20 web form improvement guidelines, all three web forms showed improvements in regard to user performance and subjective ratings.
Eye tracking data revealed furthermore that the original forms needed more fixations, longer total fixation duration and longer total saccade duration than the improved forms.
Our findings highlight the importance for web designers to apply web form guidelines.
A closer look at the form submission trials shows that there is great potential for increasing the number of successful first-trial submissions by applying the guidelines.
Thereby website owners can minimize the risk that users leave their site as a consequence of unsuccessful form submissions.
Especially guideline 13  and guideline 17  had a remarkable effect on submission trials.
This finding is in line with previous research on form guidelines .
Furthermore, data for task completion times show an improvement between 18% and 33%.
These values are even better than predicted by the Keystroke Level Model Analyzer Tool from Karousos et al.
Eye tracking data also indicate that participants could fill in the improved forms more efficiently as they needed fewer fixations and saccades .
As the most mentioned issues differ between the original and original versions, we analyzed the comments by means of chi-square tests.
Participants assigned to the original form condition mentioned significantly more often missing format specifications  and insufficient identification of required and optional fields  than participants assigned to the improved form versions.
Detailed analysis considering the three different forms separately shows that these results are mainly due to the differences between the two versions of the NZZ form .
Positive comments easy and fast filling in well-structured and clearly arranged clear identification of required and optional fields logical sequence of the fields Negative comments missing format specifications insufficient identification of required and optional fields too many fields design of the whole site Captcha Suedd.
This result is comparable to findings of former usability studies on forms .
Subjective ratings showed improvement of up to 16%.
Items with a relation to guideline 17  and guideline 13  showed frequent significant improvements.
Finally, interview comments showed that the two conditions differed also regarding subjective feedback.
While participants assigned to the original form condition mentioned significantly more often missing format specifications and insufficient identification of required and optional fields, participants assigned to the improved form condition more often criticize the layout of the whole site and not issues about the form itself.
Therefore, it can be concluded that from the users' point of view, guideline 13,  and guideline 4 , are the most important.
These findings support results of former usability studies on form guidelines .
Furthermore, our study shows that the ratings of experts and users differ remarkably.
While participants assigned to the original form condition mentioned most often missing format specifications and insufficient identification of required and optional fields, experts rated these two aspects as only moderately important .
Furthermore, although Spiegel and Sueddeutsche violate two of the five most important expertrated guidelines , these two forms often performed better than the NZZ form.
To sum up, the effort to improve web forms is relatively small compared to the impact on usability, as shown by our study results.
This study demonstrates how form improvement guidelines can help improve the usability of web forms.
In contrast to former research that focused on the evaluation of single aspects, the present study uses a holistic approach.
In a controlled lab experiment we were able to show the combined effectiveness of 20 guidelines on real web forms.
The forms used were taken from real websites and therefore reveal that web forms are often implemented in suboptimal ways that lead to lower transaction speed and customer satisfaction.
In the worst case, users may not be able to complete the transaction at all.
Our results show that even forms on high traffic websites can benefit from an improvement.
Furthermore, we showed the advantages of a multi-method approach to evaluate guidelines.
We hope this paper animates other researchers to empirically validate existing or new guidelines.
Note that preliminary data on this study has been presented as "Work-in-progress" at CHI 2013 .
In comparison to this publication, we expand these data by investigating more participants and extending our analysis of user performance data  and of questionnaire data and interviews.
Moreover, we compare the ratings from experts and the study data of our participants and discuss the importance of single guidelines.
Alexandre N. Tuch was supported by the Swiss National Science Foundation under fellowship number PBBSP1 144196.
Further, the authors would like to thank Lars Frasseck for the technical implementation and the usability experts and all participants for their valuable contribution to this study.
There are two important limitations regarding this study.
First, the study took place in a lab and therefore controlled aspects that may arise when people fill in forms in real world situations.
Distracting context factors were reduced to a minimum and participants concentrated on filling in forms and did not work in parallel on other tasks.
Furthermore, the study focuses on newspaper online registration forms.
Moreover, it would be interesting to study the implications outside the lab and perform extended A/B testings.
Additionally, from an economic standpoint it would be important to know how the guidelines influence not only usability aspects, but also conversion rates.
Another emerging topic that will be relevant for the future will be guidelines tailored for mobile applications.
FUS - Form Usability Scale.
Development of a Usability Measuring Tool for Online Forms.
Inline immediate feedback in arabic web forms: An eye tracking study of transactional tasks.
Working towards usable forms on the World Wide Web: Optimizing date entry input fields.
Advances in Human Computer Interaction, Article ID 202701.
Working towards usable forms on the World Wide Web: Optimizing multiple selection interface elements.
Advances in Human Computer Interaction, Article ID 347171.
