Rubbing and tapping gestures activate operations while the user is touching the display, so that additional parameter control and functionality can be activated during the fluid interaction.
We introduce two families of techniques, rubbing and tapping, that use zooming to make precise interaction on passive touch screens possible.
Rub-Pointing uses a diagonal rubbing gesture to integrate pointing and zooming in a single-handed technique.
In contrast, Zoom-Tapping is a twohanded technique in which the dominant hand points, while the non-dominant hand taps to zoom, simulating multitouch functionality on a single-touch display.
Rub-Tapping is a hybrid technique that integrates rubbing with the dominant hand to point and zoom, and tapping with the nondominant hand to confirm selection.
We describe the results of a formal user study comparing these techniques with each other and with the well-known Take-Off and ZoomPointing selection techniques.
Rub-Pointing and ZoomTapping had significantly fewer errors than Take-Off for small targets, and were significantly faster than Take-Off and Zoom-Pointing.
We show how the techniques can be used for fluid interaction in an image viewer and in existing applications, such as Google Maps.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Passive touch screens and finger-pointing interaction techniques are well established in public installations, such as information kiosks and automated teller machines.
Additionally, they are gaining popularity in consumer devices, such as cell phones and PDAs.
While passive touch screens are intuitive and easy to learn, there are severe limitations in the precision with which a user can interact with them.
While it is easy to select large objects by finger pointing, it can be difficult to select very small objects or specify pixelaccurate locations.
This type of interaction can be critical in effective selection of small targets on maps or small GUI elements in an operating system .
Touch-screen interaction can be complicated by occlusion of the target by the user's hand, imprecision in selection with a finger that is relatively large compared with the target, poor calibration, and parallax errors caused by the offset between the display surface and the overlaid touch surface.
We are especially interested in touch-screen interaction techniques that support fluid interaction and do not require multiple steps  or rely on on-screen widgets .
We would like our techniques to, as much as possible, behave like the ones from which they are derived, with the possibility of supporting more precise targeting when necessary, without disrupting the overall interaction.
In this paper, we explore how this goal can be achieved by directly integrating zooming gestures with the pointing action.
We address applications in which zooming the display is not problem-
This includes not only fullfledged zoomable user interfaces , but also systems for browsing maps , exploring images or navigating other types of information spaces.
We introduce and evaluate two families of interaction techniques, rubbing and tapping, comparing them with two existing baseline techniques.
Rubbing and tapping both use zooming to make possible precise interaction on commodity passive touch-screen devices.
Tapping takes advantage of unique features of passive touch-screens, whereas rubbing can also be used on devices with active digitizers, such as Tablet PCs.
The rubbing techniques  augment singlehanded pointing with integrated gestural interaction to trigger actions.
One example is Rub-Pointing, in which rubbing the screen zooms in about the targeted location.
The tapping techniques  enable two-handed interaction on single-touch displays, allowing the user's nondominant hand to perform an action in parallel with pointing by the dominant hand.
One example is Zoom-Tapping, in which the dominant hand points, while the non-dominant hand zooms by tapping the screen.
This is accomplished by taking advantage of the ability of many passive touchscreen technologies to average the location of multiple simultaneous points of contact, such that a second touch can be inferred.
We also combine rubbing and tapping to create RubTapping, a hybrid two-handed technique in which rubbing controls zoom, while tapping confirms the selection.
To demonstrate our touch screen techniques in practical applications, we developed TouchView--a zoomable image viewer that avoids the use of on-screen widgets altogether.
To enable the use of our techniques in third-party programs, we implemented a daemon for Windows XP that intercepts touch screen data in the background, listening for gestures.
When rubbing or tapping is detected, the daemon can send various events to the active window.
We demonstrate how we use this to, for example, control zooming and panning in Google Maps in a web browser.
Albinsson and Zhai showed that, averaged over all target widths, Zoom-Pointing was significantly faster than the other techniques they tested, with the same error rate.
As Buxton points out , a touch screen and stylus with a button or tip-switch offers a three-state input model, supporting an out-of-range state , a tracking state , and a dragging state .
In contrast, many finger-operated touch screens provide only two intrinsic states: out-of-range  and tracking .
Like other work, rubbing and tapping make possible through software the recognition of additional states beyond the two supported directly in the hardware.
To avoid overloading tracking with selection on intrinsically two-state devices, MacKenzie and Oniszczak  describe the use of a lift-and-tap gesture to perform selection on a passive touchpad.
Benko and colleagues  instead use a rocking and pressing gesture of the tracked finger to trigger selection on a vision-tracked tabletop, since they are able to detect the full contact area in the camera image.
Their computer vision system also provides support for true multi-touch interaction, enabling sophisticated techniques for controlling precision using multiple hands, which are unfortunately not applicable to common singletouch displays.
The techniques we present here use rubbing and tapping on a single-touch passive touch screen to trigger zooming and selection, and are applicable to traditional single-touch displays, as well as to multi-touch displays.
Vogel and Baudisch present Shift , a technique for single-touch displays that addresses the problems of the TakeOff technique not by offsetting the cursor, but by instead introducing a small offset callout that displays a copy of the area under the finger with its cursor.
The callout is presented automatically when the finger is determined to obscure a sufficiently small potential target, and, in some variants, the small portion of the display in the callout is zoomed for easier selection.
In contrast, rubbing and tapping do not rely on the properties of target objects, but can operate instead on the current position alone .
Rubbing and tapping also provide explicit control over zoom, which is desirable in many browsing applications.
Rubbing could even be combined with Shift to support one-handed user-controlled zooming in the callout.
Potter and colleagues  introduced the Take-Off interaction technique for high-precision touch-screen pointing, in which the user controls a cursor that is located slightly above the finger to ensure its visibility, and the selection is made upon releasing the finger from the surface.
Albinsson and Zhai  compared Take-Off with traditional ZoomPointing and two new touch-screen interaction techniques that do not use zooming.
A right-handed user "rubs in" by rubbing back and forth along the lower-left-to-upper-right diagonal, and "rubs out" by rubbing along the lower-right-to-upper-left diagonal .
We found that rubbing out is slightly less convenient to perform, which gives rise to an effective distinction between the two in kinesthetic memory.
In the implementation used in our study, we mapped "rubbing in" and "rubbing out" to zooming in incrementally in discrete steps and resetting zoom, respectively.
Other prototypes, which we describe later, replace the action of resetting zoom with zooming out incrementally.
Alternatively, different actions could be invoked, such as increasing or decreasing the level of detail displayed, or cycling through different visualization approaches.
We developed the rubbing and tapping gestures through an iterative experimental design process.
Results from a tenuser pilot study allowed us to reject several complicated designs in favor of diagonal rubbing, which was the most comfortable, easiest to learn and practical.
A second fiveuser pilot study allowed us to fine-tune zoom factors, thresholds, behavior, and timeouts .
Rubbing is detected as a series of discrete, roughly diagonal, strokes.
A short quick stroke, followed by another short quick stroke in the roughly diagonally opposite direction identifies rubbing.
We recognize strokes and their directions through simple tests.
The slope of the line between the first and last points of a stroke must be finite and positive for rubbing in, finite and negative for rubbing out.
A stroke must also meet length and time constraints to be considered part of a rubbing action.
A rubbing stroke must be longer than three pixels and shorter than fifty pixels and end within 500 ms of the previous stroke.
An initial pair of these quick strokes in roughly opposite directions  identifies rubbing and triggers initial zooming.
The deliberate nature of the gesture minimizes the risk of the rubbing strokes being accidentally confused with other finger movement on the surface .
Rubbing involves directional gestures, which suggests an interesting comparison to marking and marking menus .
However, unlike the marks of marking menus, the tiny strokes of rubbing are scale-dependent , time-dependent  and always compound .
We also investigated the use of a clockwise circular motion to rub in, and a counterclockwise circular motion to rub out, inspired by a long history of earlier work on rotational gestures .
Rotational gestures take longer to detect, however, requiring the user to perform a relatively precise movement in the form of a full circle to activate the desired action.
We also find it disadvantageous that the circular motion seemed to be most naturally performed around the target, in contrast to diagonal rubbing, in which the user points directly to the target and, if desired, rubs through it.
It is worth noting that rubbing actions become increasingly harder to use when targets are very close to the edges of the touch-sensitive surface.
This could be addressed in software by taking into account the starting position of the rubbing gesture and adjusting its behavior near edges, much like the edge-awareness of Shift .
To enable support for limited multi-touch interaction, we make use of a common passive touch-screen characteristic, similar to the approach used by Matsushita and colleagues .
Many types of passive touch screens, when touched at two locations, will report a cursor position somewhere along the vector between the first and second point.
The reported cursor position will typically be closer to the point where most pressure is applied.
When a location is touched, followed by a sufficiently large cursor movement while maintaining the touch, we can suspect a second touch.
We can conclude that we are not dealing with dragging if the change in reported position exceeds a fixed velocity threshold--it would most likely be caused by a second touch.
A large jump back to the original location then indicates the release of the second touch.
We use the term tap to refer to a quick touch-and-release action with a secondary finger.
Tapping requires that the first touch is not released during tapping with the secondary finger.
The primary finger must remain stationary during the touch-and-release of a tap, but can be repositioned between taps.
Tapping can be used to trigger a range of functionality.
In its simplest form, tapping detected at any location could trigger an action.
For example, this allows touching to be treated only as tracking on a passive touch screen, with tapping mapped to a click.
Furthermore, multiple, spatially distinct tapping zones can be defined, where each triggers different functionality, such as left and right mouse clicks.
It is important that the tap be performed sufficiently far from the first touch, so that it is not confused with a dragging motion; otherwise, it will not be detected as a second touch.
However, the distance at which the second touch is registered depends not only on the distance between the two contact points, but also on the relative pressure applied to each point.
It is important to note, however, that a failed tap will not have critical consequences: It will merely cause the cursor to move back and forth between the locations.
The user can immediately notice that the desired action was not performed and repeat the tap in a less ambiguous fashion.
Zoom-Tapping  allows the user to touch the display with a primary finger, and, if desired, tap with a secondary finger to zoom in.
A selection is performed when the primary finger is released.
Each tap zooms in further around the location specified by the primary finger, with a default magnification factor of four for each tap.
The user can thus quickly gain additional precision with a few taps and select the target of interest by lifting the primary finger.
Our experiments and pilot studies indicated that a larger zoom factor was suitable for tapping, than for rubbing, given its better control over simultaneous pointing  and zooming .
The advantage of Zoom-Tapping is that it is simple to learn and provides a quick means for magnification.
In the interest of keeping the interaction simple for study participants, our implementation maps only one function  to tapping, thus making it impossible to reset the zoom level.
A straightforward extension would employ the previously mentioned tapping zones .
During a pilot study of our techniques, it became clear that participants sometimes unintentionally triggered a selection by accidentally releasing contact.
This can occur quite easily on touch-surface technologies that require that firm pressure be maintained, such as the common resistive touch surface we used.
To address this issue, we have explored the option of confirming selection with a separate gesture.
We use the term click to refer to a quick touch-and-release action with the primary finger following an initial release, the same gesture that MacKenzie and Oniszczak  referred to as "lift and tap."
To trigger selection with a click, the user must quickly touch and release the finger.
If the user touches the surface for longer than a preset timeout, then no select action will be triggered on release.
The default timeout was chosen to be 250 ms.
The user can then retry by quickly clicking with the finger again.
The advantage of this approach is that users are less likely to accidentally trigger a select behavior while the finger is being moved on the surface, as in repositioning or rubbing.
However, an accidental touch and release that happens before the preset timeout will be registered as a click and result in an error.
We also expected the click to introduce a slight performance penalty, since selection will now require an additional confirming click.
Rub-Pointing  allows the user to touch the display and release the finger to select, similar to Take-Off .
However, while touching the display, the user can also execute rubbing gestures: the first pair of rub-in strokes zooms by a factor of two, as does each successive single rub-in stroke, and the first pair of rub-out strokes resets the zoom level.
As in Take-Off, the user can also adjust their finger position, before selecting the object by lifting the finger off the surface.
However, it is important that the user maintain contact with the surface while rubbing to avoid accidental selection.
Rub-Pointing makes it possible to zoom in a fluid direct-manipulation action, and supports repeated zoom-in and zoom-reset actions.
Rub-Tapping  combines rubbing and tapping to create another way to avoid accidental selection caused by an unintended release.
Rubbing is used to zoom in or reset zoom , but a tap with the secondary finger is required to confirm the selection while the primary finger remains on the screen.
In contrast to the techniques that confirm a selection with a click, Rub-Tapping requires that two fingers simultaneously touch the screen to complete the selection .
Twenty right-handed volunteers participated in the study and each received two cinema tickets as compensation.
They were, or had previously been, university students.
The majority of the participants were students in Media Technology at the Royal Institute of Technology.
All participants had used touch screens in public information kiosks, such as ticketing machines for public transportation.
None had previously seen or been exposed to our rubbing and tapping techniques.
Seven used touch screens often, whereas thirteen had only used them a few times.
Prior to performing the study, most participants were positive about using touch screens of the size used in our study, with a few neutral participants and one negative participant.
Four participants mentioned that, in their experience, such touch screens often are not sufficiently sensitive and require hard presses.
Each participant was asked to alternately select two targets placed 250 pixels apart, well away from the edges of the screen, in a reciprocal 1D pointing task, where zoom level was reset after each target selection.
To maximize contrast, targets were green squares of varying size on a black background.
A large grey offset rectangular outline helped the participant identify the position of the target at the beginning of each trial.
The rectangular outline was hidden upon touch.
Auditory feedback was provided with a lowfrequency beep for errors and a high-frequency beep when the participant successfully selected a target.
The software logged times and hit positions, such that completion times and error rates could be derived.
As a first baseline for comparison, we implemented a version of the well-known Take-Off technique , which has also been used as a baseline in previous studies .
Take-Off is the only technique that we tested that does not provide zooming capabilities, which makes it harder to select small targets.
Due to the large size of the finger and the risk of occluding the cursor, Take-Off places the cursor at a fixed offset above the finger.
After touching the display, the user can adjust the cursor position until it is over the target, and then select by releasing the finger .
Additional drawbacks of this approach are the difficulty of knowing exactly where the cursor will appear upon contact and the inability to select objects at the bottom of the screen in an unmodified implementation.
Our second baseline was Zoom-Pointing , implemented to be as close as possible to the version described by Albinsson and Zhai , in which it consists of a button that activates the zoom mode, and a button that resets the zoom level.
Zoom-pointing is a tool-based technique that is common in many modern graphical applications.
If the target is sufficiently large, the user can touch it right away.
Alternatively, the user can enter a zoom mode by touching the zoom button with the finger.
After the finger has been released, the user can specify a zoom area by drawing out a rectangle with the finger.
The application zooms up the screen to this rectangle after the finger has been released.
The user can then select the target by touching it, touch the zoom button to enter zoom mode again , or reset the zoom level by touching the reset button .
In contrast to the other techniques, Zoom-Pointing selects on touch, not on release, making it more error prone:
A repeated-measures, within-subjects study was performed.
The order in which the techniques were presented was randomized, and the order in which sizes were presented was randomized for each block of trials.
An analysis found no significant effects of order on the results.
After seeing a demonstration of a technique, a participant performed an initial block of 10 practice trials  with that technique, where each trial needed to result in a successful selection for the program to proceed, to ensure that the participant experienced successful selections for the technique.
However, the participant was allowed to ask the experimenter to manually advance the test to the next trial after an unsuccessful attempt for difficult conditions, such as Take-Off with 1-pixel targets.
This first block was followed by a block of 15 practice trials  for the technique that behaved as in the real test, where a failed attempt would always proceed to the next trial.
After this preparation, the participant performed a block of 70 test trials for the technique .
It also had significantly more errors than Zoom-Tapping.Click for 2-pixel targets.
No significant difference was found in error rate between the other techniques across the different target sizes and we could thus not verify hypotheses H4 and H6.
These results confirm hypotheses H1 and H2.
Figure 9 clearly illustrates how the error rate for Take-Off decreases with increased target sizes.
Prior to running the experiment, we formulated the following hypotheses: H1: For small targets, Take -Off will have higher error rates than all other techniques, due to its lack of support for zooming.
H2: As target size increases, Take-Off will approach the error rates of the rubbing and tapping techniques.
H3: As target size increases, Take-Off will approach the completion-time performance of the rubbing and tapping techniques.
H4: Rub-Pointing.Click and Zoom-Tapping.Click will have fewer errors than Rub-Pointing and Zoom-Tapping, respectively, due to the added click timeout.
H5: Zoom-Tapping and Zoom-Tapping.Click will be faster than Rub-Pointing and Rub-Pointing.Click, respectively, for small targets, since each rub moves the targeting location and requires reacquisition of the target after zoom.
H6: Rub-Tapping will have the best error rate because it is the only technique where selection requires a simultaneous tap with the secondary finger for selection .
Similar to the experience of Benko and colleagues , we had two blocks without a single completed trial for the smallest targets.
These blocks happened for two of the participants in the difficult condition of Take-Off with 1-pixel targets.
We therefore chose to divide our analysis of completion times into two parts.
First, we conducted an ANOVA on target sizes 2-16 pixels over all techniques, which showed that technique had a significant effect on completion time .
Paired samples t-tests with a Bonferroni adjustment show that Take-Off was significantly slower than all our rubbing and tapping techniques for 2-, 4- and 8-pixel targets.
This result confirms hypothesis H3 with the exception of Rub-Pointing being significantly faster than Take-Off for all target sizes.
Zoom-Pointing proved to be significantly slower than all rubbing and tapping techniques over all sizes, and significantly slower than Take-Off for the 16-pixel targets , as shown in Figure 10.
To mitigate the common skewing associated with human response times, and remove the influence of potential outliers, we analyzed the median  completion times for each block of 14 repetitions per cell .
A within-subjects analysis of variance  was then performed on the median completion times.
In addition, a within-subjects ANOVA was performed on the mean error rate for all techniques over all target sizes.
We used an  of 0.05 to determine statistical significance.
Paired samples t-tests with a Bonferroni adjustment show that Take-Off had significantly more errors than all other techniques for 1-pixel targets.
It was also significantly worse than all but Zoom-Pointing for 2-pixel targets.
Finally, for 4-pixel targets, it was significantly worse than Rub-Pointing.Click.
Paired samples t-tests with Bonferroni adjustment showed that Zoom-Pointing was also significantly slower than the other techniques for 1-pixel targets.
No significant differences were found between the rubbing and tapping-techniques at any target size, and hypothesis H5 could thus not be confirmed.
Several commented that a display with less friction would work better.
Surface acoustic wave touch screens  are typically made of glass and have a more sensitive touch response, reporting both location and a measure of applied pressure.
They are, however, less common in consumer devices than resistive touch screens, such as the one we used.
Rub-Tapping generated friction from rubbing and required two hands, and was disliked by most participants.
After finishing the trials for a technique, the participants filled in a questionnaire in which they ranked the experienced technique on a seven-point Likert scale  with regard to learnability, ease of use, comfort, user experience, and perceived speed.
They were also encouraged to provide written and verbal comments.
At the end of the study, they commented on the techniques they liked the most and the least.
A summary of the results is shown in Figure 11.
The experimenter also took notes, recording events of interest that occurred during the test.
Especially for small targets, there were frequent comments that Take-Off was "impossible to use", while some participants commented that it was easy to use for large objects.
While Rub-Pointing.Click seemed easier to use than RubPointing, this was not the case for Zoom-Tapping.Click and Zoom-Tapping.
The experimenter noticed several cases where the participant would forget to assure that the position of the finger was over the target for the non-click versions, rendering Rub-Pointing.Click more robust than RubPointing.
For Zoom-Tapping.Click, however, the confirming click could result in confusion, since the actions for the dominant and non-dominant hands became similar.
Three participants commented that it was not intuitive to activate selection by tapping outside the target for Rub-Tapping.
Many participants complained that Take-Off demanded excessive visual concentration, which led to eye fatigue.
Visual concentration alone was often not sufficient, and the participant would lean over the display, resulting in shoulder and back strain.
The major disadvantage of the tapping techniques was the requirement of two hands, which participants felt was more complicated and less comfortable.
The use of two hands also appeared to require higher cognitive load to coordinate them, which seemed to be especially evident in ZoomTapping.Click, where the actions of the dominant and nondominant hands were sometimes confused.
Participants were asked to specify and comment on the techniques they liked the most.
Zoom-Pointing , Rub-Pointing , RubPointing.Click , and Zoom-Tapping.Click  were each selected by four participants.
ZoomTapping  was selected by five participants.
The most popular properties cited in the comments  were intuitiveness and speed.
None of the participants that preferred Zoom-Pointing mentioned speed, however.
Participants were also asked to specify and comment on the techniques they liked the least.
Ten participants chose Take-Off , whereas five picked ZoomPointing .
Two participants selected Rub-Tapping .
Two participants disliked all the rubbing techniques .
The two participants that disliked Zoom-Tapping.Click  had ZoomPointing as their favorite .
It is interesting to note that some users did not like the tapping techniques because they required two hands and were more attention-demanding than rubbing, even in the case of the single tap for Zoom-Tapping.
Our results also supported the importance of having a distinct separation of operations, whether in a single-handed gesture  or a bimanual interaction .
Similarity between the dominant hand click and the non-dominant hand tap for Zoom-Tapping.Click, for example, confused several users, and led to a higher error rate Finally, Rub-Tapping provided no advantage, as there was no significant difference in error rate--it merely combined the disadvantages of the rubbing and tapping techniques.
As in previous studies , Take-Off had a high error rate for small targets and was increasingly better for larger targets, approaching the performance of our rubbing and tapping techniques.
However, given Take-Off's poor performance for small objects, it was listed as the least preferred technique by half of the participants.
Zoom-Pointing, which was significantly faster than Albinsson and Zhai's techniques  was significantly slower than all our techniques.
The numerous sequential steps were not only perceived as cumbersome and slow, but also require visual attention and provide multiple opportunities for mistakes, such as not pressing sufficiently hard when dragging out the zoom area or forgetting to activate the zoom button in repeated zooming.
The study shows that all rubbing and tapping techniques were significantly faster than Take-Off for up to 8-pixel targets  and faster than Zoom-Pointing for all sizes.
They also had fewer errors than Take-Off and ZoomPointing for small targets.
There were no significant differences in speed between the rubbing and tapping techniques.
The variations of Rub-Pointing and Zoom-Tapping that used an additional click were not significantly slower, which is encouraging.
The major disadvantage of the rubbing techniques was the fatigue incurred by the friction between the finger and the display.
As an example of a practical application, we developed TouchView, a touch-screen display photo viewer that uses rubbing and tapping .
TouchView was implemented in C++ and OpenGL.
The user can pan the image with a finger, using familiar dragging motions, and control the zoom level, using rubbing or tapping.
In TouchView, we use two tapping zones, where tapping in the upper half of the display zooms in, and tapping in the bottom part zooms out.
TouchView demonstrates how our techniques allow a clean and simple passive touch-screen interface that supports panning and zooming, but avoids the use of on-screen widgets that might otherwise occlude content of interest.
There are many applications for which we do not have control over their source code or cannot otherwise modify their behavior.
To address these, we developed TouchDaemon, a program that can be run in the background under Windows XP to detect rubbing and tapping gestures being performed on a touch-screen display.
TouchDaemon uses Windows hooks along with the Raw Input Model to detect and interFigure 13.
TouchView allows the user to incrementally zoom in and out using two tapping zones.
Here, the user taps in the upper part of the screen to zoom in on the location indicated by the right hand finger.
Upon recognizing rubbing and tapping gestures, it can replace them with appropriately mapped actions.
As shown in Figure 14, we use rubbing to control Google Maps , running in a web browser.
We accomplish this by mapping rubbing gestures to scroll events in TouchDaemon.
When the unmodified JavaScript on the web page receives the synthesized scroll-up or scroll-down event, it initiates a zoom-in or zoom-out action.
We have introduced and evaluated two families of singlehanded and bimanual interaction techniques for interaction on single-touch displays.
Given potential parallax issues and occlusion by the user's hand, these techniques avoid relying on widgets and other on-screen visual artifacts, and instead provide precision through simple gestures.
We believe this is one of the reasons why our techniques have proven to have consistent performance and high selection speeds  for all target sizes.
Our study shows that our techniques perform significantly better than the well-known Take-Off and Zoom-Pointing techniques.
The rubbing and tapping techniques combine pointing and zooming into a single direct-manipulation action , and maintain the possibility of direct and simple touch-screen pointing for large objects, while affording the ability to zoom if additional precision is needed.
Based on the results of our studies, and our own experience, we can make a number of recommendations.
We suggest using tapping when more control is desired, bimanual interaction is acceptable, and the screen is sufficiently large .
We suggest using rubbing when friction isn't a problem , a single finger is preferred, and the screen is either small  or large.
For increased robustness, a confirming click can be added; our study shows no significant speed penalty despite the additional step.
We intend to evaluate our techniques on smaller displays where precise pointing is even harder.
Experiments indicate that our rubbing techniques work well with pen interaction , and we expect that the relative lack of friction in comparison with finger rubbing will eliminate concerns about fatigue.
