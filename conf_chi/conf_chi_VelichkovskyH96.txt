This is an overview of the recent progress leading towards a full subject-centered paradigm in human-computer interaction.
At this new phase in the evolution of computer technologies it will be possible to take into account not just characteristics of average human beings, but create systems sensitive to the actual states of attention and intentions of interacting persons.
We discuss some of these methods concentrating on the eye-tracking and brain imaging.
The development is based on the use of eye movement data for a control of output devices, for gaze-contingent image processing and for disambiguating verbal as well as nonverbal information.
Keywords Attention, eye movements, human-computer interaction , neuroinformatics, levelsof-processing, noncommand interfaces, computer supported cooperative work 
Profound technological changes are sometimes caused by events initially considered to be completely irrelevant.
It seems that we may be well on the eve of such changes in human-computer interaction, and these changes will be brought about by the recent development in the research methods of cognitive neuroscience.
The emerging perspective is that of "subjective age" in the development of telematics.
At this new phase in the evolution of computer technologies it will be possible to take into account not just some statistical characteristics of human beings, but create technical systems sensitive to a broad spectrum of actual states and intentions of a person.
We are going to discuss -- and to demonstrate -- some of these perspectives concentrating on the following domains: brain imaging methods and, particularly, eye movement research.
At the end, we will shortly refer to some relevant issues in the interdisciplinary field of neuroinformatics.
A remarkable development takes place in the eye movement research.
The new generation of eye-trackers replaces the nightmare situation of former laboratory studies 
This implies that the process of eye movement registration does not interfere with other activities a person is involved in.
As the gaze-direction is the only reliable  indices of the locus of visual attention there is an almost open-end list of possible applications of this methodology.
Gaze direction for a control of user-interfaces The first and most obvious application can be called "eye-mouse".
By building in temporal filters, introducing an explicit clutch and/or clustering the fixations resulting from fast search saccades it is possible to guaranty practically errorless use of gaze direction for operating virtual keyboards and managing graphical user interfaces  .
The eye-mouse reduces selection time in general.
Its primary application area is where it is difficult or impossible to use the hands.
In particular, physically disable or elderly persons no longer in command of their limbs and speech mechanisms may improve their communication abilities with this type of system.
Eye movements data can be used to control different electronic devices, including e-mail, fax, telephones, videophones and speech generators.
In contrast to the manually-controlled computer-mouse, an eye-mouse does not need an explicit visual feedback.
However to ensure a high degree of reliability it has been suggested to give a visual feedback on the so-called dwell-time activation of buttons .
Fig.1 shows how this idea of an "Eyecon" may be realized.
A small animation is made up by playing the sequence of buttons within 500 ms, each time the button is activated by a dwell.
Besides from giving the user an opportunity to regret the activation, the animation in itself holds attention of the user at a precise location, which makes it possible to recalibrate the system each time a button is used.
A study of users acceptance performed on the Eyecon system found a spontaneous positive attitude towards the principle .
In general more than 95% of responders evaluated the interaction as "exiting", about 70% expressed their believe that they expect "to see eye tracking in the future as an everyday thing".
Figure 1 A different approach to gaze-mediated interaction is simply to leave the idea of using eye-tracking as a substitute for a mouse.
It has been proposed to term this noncommand interaction principle "interest and emotion sensitive media"  .
The possibility of making a coupling of ocular measurements and the stimuli material allows for a quasi-passive user influence on electronic media.
IES may respond to these continuous measurements at narrative nodes by editing among the branches of a multiplex script board that will in turn influence the composition and development of events being watched.
Of course, several hybrid solutions for a combination of command and noncommand principles are possible.
In Fig.2A traditional GUI-style buttons are used for gaze-pointing.
In the next two pictures alternative selection objects are either explicitly delineated  or their active areas are marked by a higher optical resolution .
Finally, in Fig.2D objects are functioning as implicit  buttons of shifting size and location for the quasi-passive mode of operation.
Figure 2 Towards a new generation of communication tools Our next example is related to communication of intentions.
It is well known that the efficiency of face-to-face interaction is higher than the efficiency of the most sophisticated multimedia forms of communication and CSCW tools, which are in turn better than email or voice communication .
There is a way to narrow  this gape by appropriate management of attentional resources.
This can be done on a modern technological level but in principle along the lines of organization of early mother-child communication: by supporting the "joint attention" state of the partners .
Such a state implies that the partners are to be able to attend -- and therefore to fixate -- the same objects at the same time.
In a series of experiments we succeeded to demonstrate that a transfer of the gaze direction data from an expert to a novice helps in the solution of a puzzle task .
Closely related are tasks of interactive documentation and cooperative support: As a service engineer is performing maintenance or repair work on a device he or she might get advice from a human expert located at a remote site.
Because eye-movement data reveal insights about the central aspects of problem solving, the technology allows us on the one hand to make an expert's way of performing available to novices .
On the other hand it gives the possibility to monitor and, if necessary, correct a novices performance .
Another currently relevant situation may be the so-called key-hole surgery: the eye fixations of a surgeon can be registered on-line when he or she examines the image provided by an endoscope camera.
A colleague controlling the camera would then get a far better support to position the endoscope optimally by knowing from moment to moment what the surgeon is paying attention to.
The second large class of the telematic applications is connected with visualization of users non-verbal perception .
Indeed, in real life we are often confronted with situations in which the knowledge needed to solve a problem is not present in an explicit and/or unambiguous form easily available for verbal communication.
In order to reconstruct the current subjective interpretation of an ambiguous picture we propose, firstly, to build "attentional landscapes" describing  the resolution functions of visual details and, secondly, to use these attentional landscapes as filters to process the physical image.
The usual results are illustrated by Fig.3 where an initial picture  as well as both empirically reconstructed interpretations are shown.
Figure 3C With the proposed technology of the gaze-contingent processing  users will be able to exploit implicit knowledge for teaching, joint problem solving, or generally speaking for communicating of practical knowledge and skills.
The goal of applying this technology to medical imaging is in particular to make the expertise that is implicit in how experts interpret complex and often ambiguous visual information  available to others for a peer commentary and for training purposes.
As the medical diagnostics is a costly and rather unreliable  endeavor any form of such a visualization is deserving a public attention.
The basic idea behind these examples is not to simulate the face-to-face communication but enhance it .
Gaze-contingent processing can be used for several other purposes as well.
One of them can be enhancing low-bandwidth communication, firstly, by an appropriate selection of information channels and, secondly, by transmission with high resolution of only those parts of an image which are at the focus of attention.
In this way also low-bandwidth channels can be optimally exploited, e.g.
There is however a general problem on the way to realization of the most of these applications -- not every visual fixation is "filled with attention" because our attention can be directed "inward", on internal transformation of knowledge.
This is why in many cases one has to think about a control of the actual level of human information processing .
The numbers signify here the coefficients of growth of corresponding regions during the transmission from higher primates to human beings.
These gradients -- from mostly posterior  to anterior  regions of the cortex -- demonstrate an increasing conceptually-driven character of human information processing which becomes  more independent from the physical parameters of an interface.
A half of dozen of the modern brain imaging methods, such as Positron Emission Tomography  or Magnetic Resonance Imaging , belong to the most sophisticated tools of contemporary science.
Though the data obtained with these methods are often difficult to interpret the dominating opinion is that they convey stable and in-depth analysis of physiological states and processes.
However these methods are extremely expensive and cumbersome in use.
Their temporal resolution is also usually very low.
There is hardly a chance that the methods will be used during the next years for practical purposes outside medicine.
As an alternative one can think about a variety of simple algorithms of computing parameters of classical EEG data.
Three brain-coherence images of Fig.5 show how different tasks are performed by the same user with the same visually presented verbal information.
One can easily see that the coherent areas of processing  extend to prefrontal areas of cortex with the change of task from superficial visual analysis to semantic categorization and to an evaluation of the personal significance of the material.
The data are similar to those of conventional imaging methods and they are thoroughly comprehensive from the point of view of neuropsychological research.
The big difference is that the method of evoked coherence analysis is cheap and easier to perform than the standard imaging procedures.
As this new method is rather fast  it may be used for an on-line adaptation of interface characteristics, as it may be necessary for support of direct  or indirect  modes of work.
The second mode of processing have been largely neglected in the modern GUI .
The perspective here is also a support of multilevel interfaces in telerobotics where a combination of the eye-mouse and the evoked coherence analysis to detect intentions gives promises of a truly new interaction principle: point with your eye and click with your mind!
In line with the vision that the ultimate goal of any technology is to optimally support human resources  we are focusing in our investigation on the technology for communication of practical knowledge and skills in geographically distributed environments.
Many of the applications we describe in the paper would be impossible without combining of data and methods from two domains: computer science and cognitive neurophysiology.
For instance, with the novel eye-tracker interfaces based on self-organizing maps it is possible to reach a degree of precision and speed that makes real-time VR's or telematics applications of gaze-contingent processing possible .
There are first reports on the completely non-intrusive solutions for eye-tracking based on neural networks .
Figure 5 The message of neuroinformatics extends to the very core area of HCI by promising a new generation of flexible, learnable and, perhaps, emotionally responsive interfaces.
Such multimodal and multilevel interfaces will connect us not only with computers but also with autonomous artificial agents.
In a similar vein, an eclectic combination of location of fixations, their duration, pupil size and blink frequencies as indices of interests or different subjective interpretations of a scene can be recognized by neural networks, which may be individually pretuned in corresponding learning sessions.
As a whole, the proposed technologies represent a viable alternative to the more traditional  approach of expert systems.
This concerns in particular the availability of human expertise in remote geographical locations: from Vancouver to, at least, Vladivostok.
We wish to thank Eyal Reingold and Dave Stampe  as well as Nancy and Dixon Cleveland  for their help in providing us with some of the modern eye-tracking methods.
Thanks are due also to Marc Pomplun, Matthias Roetting, Andreas Sprenger, Gerrit van der Veer, Roel Vertigaal and Hans-Jurgen Volke who contributed in a very essential way to the described projects.
Baluja, S., and Pomerleau, D. Non-intrusive gaze-tracking using artificial neural networks.
Neural information processing systems 6, Morgan Kaufman Publishers, New York, 1994.
Levels-ofprocessing effects on a variety of memory tasks: New findings and theoretical implications.
Prefrontal cortex and the high cost of symbolic learning.
Lawrence Erlbaum Associates, Hillsdale NJ, 1996.
International Journal of Human-Computer Interaction Studies, 1995.
Interface design: Have we got it wrong?
In Y.Anzai, K.Ogawa and H.Mori , Symbiosis of human and artifact.
Proceedings of the 6th international conference on human computer interaction.
Elsevier Science Publisher, Amsterdam, 1995.
Eye tracking in advanced interface design.
Nielsen, J. Noncommand user interfaces.
Expertise in visual diagnostics: A review of the literature.
Pomplun, M., Ritter, H. and Velichkovsky, B.M.
Disambiguating complex visual information: Towards communication of personal views of a scene.
DFG/SFB360 Situated artificial communicators, Report 95/2, University of Bielefeld, Bielefeld, 1995.
Prieto, F., Avin, C., Zornoza, A. and Peiro, H. Telematic communication support to work group functioning.
In Proceedings of the 7th European conference on work and organizational psychology, Gyor, 19-22d of April, 1995.
Raeithel, A. and Velichkovsky, B.M.
Joint attention and coconstruction of tasks.
Ritter, H. Parametrized self-organizing maps.
Stampe, D. M. and Reingold, E. Eye movement as a response modality in psychological research.
In Proceedings of the 7th European conference on eye movements, Durham, University of Durham, 31st of August-3d of September, 1994.
The levels endeavour in psychology and cognitive science.
Lawrence Erlbaum Associates, Howe UK, 1994.
Communicating attention: Gaze position transfer in cooperative problem solving.
Velichkovsky, B.M., Pomplun, M. and Rieser.
H. Attention and communication: Eye-movement-based research paradigms.
Elsevier Science Publisher, Amsterdam, 1996.
Catching the eye: Management of joint attention states in cooperative work.
Evozierte Cohaerenzen des EEG I: Mathematische Grundlagen und methodische Voraussetzungen .
