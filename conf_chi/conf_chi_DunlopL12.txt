This paper presents a new optimization technique for keyboard layouts based on Pareto front optimization.
We used this multifactorial technique to create two new touchscreen phone keyboard layouts based on three design metrics: minimizing finger travel distance in order to maximize text entry speed, a new metric to maximize the quality of spell correction by reducing tap ambiguity, and maximizing familiarity through a similarity function with the standard Qwerty layout.
The paper describes the optimization process and resulting layouts for a standard trapezoid shaped keyboard and a more rectangular layout.
Fitts' law modelling shows a predicted 11% improvement in entry speed without taking into account the significantly improved error correction potential and the subsequent effect on speed.
In initial user tests typing speed dropped from approx.
21 wpm with Qwerty to 13 wpm  on first use of our layout but recovered to 18 wpm  within four short trial sessions, and was still improving.
NASA TLX forms showed no significant difference on load between Qwerty and our new layout use in the fourth session.
Together we believe this shows the new layouts are faster and can be quickly adopted by users.
The Qwerty layout has been adopted almost universally on laptops and desktops despite the design constraints being far removed from the early physical typewriters that inspired the layout.
Alternatives such as the Dvorak Simplified Keyboard have not been successful for many reasons , but largely because of the high initial learning curve when moving from Qwerty to a faster but alien layout.
The Qwerty keyboard has, thus, dominated on touch screen phones as pick-up-and-use usability issues have prevented the adoption of more optimal keyboards.
Bi, Smith and Zhai  introduced a novel approach to keyboard optimization to attempt to overcome the initial hostility of users to alternative layouts.
They allowed the keys of a Qwerty layout to shuffle by at most one position from their original location to achieve a quasi-optimized Qwerty variant.
This layout had typing speed performance between the original Qwerty layout and a fully-optimized layout while not being alien as keys were roughly where the user would expect them to be.
Touch screens and finger interaction users normally focus on the keyboard area during text entry, thus moving keys slightly is less of a problem than one might expect from desktop/laptop physical keyboard use.
With modern powerful touch screen phones has come increasingly powerful error correction.
Text entry on mobile phones has always been a compromise between the space allocated to text entry and the size of the device.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Here we constrain the optimization process in two ways: * We fix the keyboard layout at the start of the optimization procedure: we restrict ourselves to different letter-to-key assignments and not the more general keyboard layout problem of adjusting the button sizes and positions; * We model single finger text entry: most users of touchscreen phones use the index finger of their dominant hand as the pointer - particularly for small keys .
Given these constraints we can simplify from Fitts' law by only modelling the distance that the user's finger has to move to enter text.
For comparing two keyboards this is a faster and simpler calculation that is as effective at stating if one keyboard is faster than the other, but without giving full predictions of typing speed.
In the optimization process, all keys were modelled as the same size bar the space key which, for simplicity, we modelled as three standard sized keys beside each other on the bottom row - distances were measured to the nearest of the keys .
We built a bigram weighting model of English by using the same national newspaper corpus of English text as in our previous studies  .
Our analysis calculated an occurrence count for each two-letter bigram as used in the corpus1.
To include movement to and from the space key we also included space to give 27*27 possible letter combinations from the 26 letter alphabet.
The most common letter pair was E_  with 981 920 occurrences in our collection.
The probability of any key sequence being E_ is thus 0.033.
As an example, the Qwerty layout has the I and O keys as neighbours, thus in/on, if/of, for/fir, hot/hit etc.
With smaller touch-screen phones this can be a very short physical distance, e.g.
The arrangement of the characters on the keyboard can improve the performance of an error correction algorithm by, for a given language, reducing the likelihood of near-misses resulting in valid words.
While it has been shown that the layout of ambiguous keyboards, for example the traditional phone 12-key pad, can considerably affect entry performance , we believe this paper presents the first work to adjust the layout of an unambiguous keyboard for spell correction.
In the remainder of this paper we present a tripleoptimization process using Pareto front optimization that attempts to optimize for  speed of text entry,  error correction tap interpretation clarity and  familiarity to the traditional Qwerty layout.
Initially we present the three metrics in detail then their combination through Pareto front optimization.
We also present keyboard layouts generated by this process for the traditional key layout and for a slightly squarer layout that increases key sizes .
Finally, we present results from Fitts' law analysis and an initial study into pick-up-and-use usability of our optimized layout.
Throughout the paper we will focus on portrait mode text entry - the normal style of interaction with a touch-screen phone and the larger challenge for text entry.
The time taken to type a letter on the keyboard is dependent on two factors: how long it takes the user to move his/her finger to a position above the key and how long it takes to tap the key.
Fitts' law  has been used extensively to predict the time taken by users to select spatial targets.
For design, Fitts' law implies that the nearer and bigger a target is the quicker it is to tap.
To evenly balance the multiple criteria optimization process used later in this paper, it is helpful if the metrics have roughly equal ranges of values.
We normalized the scores for finger distance to the range of approximately 0...1, where 1 represents the best keyboard found and 0 the worst.
We initially derived a fast keyboard iteratively with several short runs of the optimizer.
The normalised score was given as Mdist = Mcalc /  where 1.1 was used to allow for better solutions in the final run.
For reference the standard Qwerty layout scored 0.395 while Bi, Smith and Zhai's quasi-Qwerty keyboard scored 0.643 - confirming that their quasi-optimization process resulted in considerably less distance for a single finger to move on average.
We discuss the triple-optimized keyboards and the Pareto process in full below.
However, running our Pareto optimization process resulted in over 24 000 keyboards on the final "surface".
Of these, the highest scored keyboard for finger distance metric on a standard iPhoneTM style layout has a distance weight of 0.908 .
Note that the top four most common bigrams  are neighbours with others being near neighbours.
The Pareto optimization process is designed to find best solutions along the Pareto front, as such it is not good at finding bad solutions as poorer ones are discarded in favour of all-round better ones.
However, it is worth contrasting the best solution found with the worst recorded at the end of the search.
The poorest performing keyboard on the front for finger travel distance had a weight of 0.256 .
Tapping out a common phrase with these two keyboards casually confirms that the finger moves considerably less with the best rather than the worst keyboard.
Dictionary disambiguation offers the most common word in the language when a user types a key sequence, e.g.
Overall this works surprising well, with success rates estimated at around 95% .
However, it does not cope with key combinations where two or more words are widely used, e.g.
More complex approaches to disambiguation, e.g.
Alternatively, Gong and Tarasewich  investigated the best layout of miniature keypads to reduce the ambiguity of the keyboard layout itself by separating combinations that lead to multiple popular words.
The best solution, of course, is a combination of both: a powerful contextual engine with an optimized layout to reduce the effort required by the context engine.
For example, typing typung in most desktop word processors and most touch phones will result in the word typing being inserted even though the user tapped the unambiguous u as the fourth key.
Error correction has been shown to be particularly important on touch screens with small keys  and is seen as one of the challenges for intelligent text entry .
This implies that, although automatic error correction has come far there are still considerable problems with error correction on touchscreen mobiles.
In developing our keyboard layout one factor we wished to take into account was interpretation clarity for taps.
We created a table of bad-bigrams, or badgrams for short, of keys that were ambiguous given their neighbours.
This table is similar to the table used above for keyboard distance but is based on the likelihood of a one letter substitution resulting in a valid word, e.g.
We scanned all same-length words in our corpus and assigned a frequency to each badgram found based on the more common of the two words.
The aim of the tap clarity optimizer was to reduce the total ambiguity for keys that were adjacent in the layout, which should maximize the effectiveness of a spell corrector to correctly interpret taps.
Figure 7 compares the interpretation clarity metric for this keyboard with the standard Qwerty and Quasi-Qwerty keyboards.
For Pareto optimization, this score is again normalized to approximately the range 0...1, where 1 represents the best keyboard and 0 the worst.
For reference the standard Qwerty layout scored 0.559 while quasi-Qwerty scored 0.459, showing that this layout sacrificed some spellchecking clarity in making their speed gain.
Again using a standard iPhone-layout, the best found keyboard for neighbour ambiguity had a score of 0.997 .
There is a long history of text entry research into alternative keyboards for touch screens.
While achieving very promising expert user performance predictions, these layouts have had very low adoption rates as users tend to favour the familiar Qwerty layout.
Bi, Smith and Zhai  proposal was a middle ground: they allowed keys to be moved around to optimize a layout but restricted the distance to 1 key away from the home key.
We have followed their general approach but softened this rule by imposed a strong weighting against keys which move far from their Qwerty layout position.
The effect being to allow keys more freedom but punish a keyboard design where many keys move from the Qwerty home location and severely punish keyboards where individual keys have moved far from their home location.
The aim is that when users are typing with a finger on a touch screen, the keys they are aiming for will most often be in the proximity of where they expect it to be given their Qwerty experience but at the same time to give freedom for stronger optimization of other metrics.
Similarity between keyboards can be measured by scoring the distance of all keys to their home keys on a same-sized standard Qwerty keyboard.
With experimentation, squaring the distance gave the best balance between allowing movement and keeping keys near their home locations.
However, as this metric averages the score over all keys, unlike Bi et al.
We calculated the familiarity metric as:      ,    where  is the alphabet in use , ki is the location of the centre of the key on the given keyboard, qi is its location on a same sized standard Qwerty layout keyboard, and distance is the Euclidian distance between these points.
Again the score is finally normalized to the range 0...1 for Pareto optimization, where 1 represents the best keyboard found and 0 the worst.
For reference the standard Qwerty layout scores 1.0 while quasi-Qwerty scores 0.850.
The search algorithm in this work is a variant of local neighbourhood search  adapted for use in finding a Pareto optimal set using the above three metrics: finger travel distance, spelling interpretation clarity and Qwerty familiarity.
The process starts with a randomly generated set of points that are optimized locally for different weightings of the three metrics .
This initial set of keyboards is taken through 2000 iterations of improvement in which local moves are made that may, or may not, improve the solution.
In each iteration each keyboard in the set has a small number of keys swapped ; if the new keyboard is better on any metric then it is added to the set; if it is also at least as good on ALL metrics than an existing solution then it dominates the existing one, which is discarded.
This leads to a Pareto front - a set of dominant solutions on a 3D surface.
The final Pareto front for optimizing the standard Qwerty keyboard is shown in Figure 8.
This shows the trade-off between the different measures with high scores being achievable only at the expense of others.
It also, reassuringly, shows a convex surface showing that compromise solutions are not, overall, poorer than single optimized solutions.
This front is composed of over 24 000 individual keyboards .
In designing artefacts, we often have more than one criterion that we use to evaluate the final product.
For example, a motor vehicle can be judged by its fuel efficiency, its ease of handling, the comfort of the ride and so on.
Often these criteria conflict: a hard suspension may help with handling but be detrimental to passenger comfort.
Multi-objective optimization algorithms  seek to create solutions to such problems by considering the optimization process across these potentially conflicting objectives.
A simple way of addressing such problems is to create a single combined objective function, where each individual objective is a component in a weighted sum.
However, the difficulty of coming up with an appropriate weighting for each part of the sum and the fact that this method only returns a single solution means that this is not generally the method of choice .
Instead, what is needed is a method which can return multiple solutions where each solution has something about it which makes it better than other solutions according to at least one of the criteria.
This leads to a need to explore solutions that are Pareto optimal.
If there are 3 criteria to optimize, as in this study, and we have found a Pareto optimal artefact which has the evaluation , then this means there is no point in the solution set for which all criteria are equal or better.
In other words, if we want to improve the score for one of the criteria along the Pareto front, we have to compromise by lowering the score for at least one of the other metrics.
This was achieved through iterative running of the Pareto optimization process.
A small imbalance at this stage would result in us picking a different near-central solution.
While varying per starter keyboard, most Pareto optimizations didn't change the suggested keyboard for the last 500+ iterations of 2000 optimization iterations, giving further confidence in stability of the solutions discussed below.
The standard Qwerty layout has a trapezoidal shape, if drawn symmetrically, with 10 keys on the top row, 9 in the middle and only 7 on the bottom row .
Full size keyboards pad the lower rows with nonalphabetic and functional keys but there are often fewer such keys on mobiles with additional characters being entered through a secondary mode.
Above we presented our results for optimization using this standard trapezoidal layout and aspect ratio.
MacKenzie states that when measuring Fitts' law distance, the size of a key should be the minimum of height and width .
As such these tall, thin keys have effectively the same Fitts' law functions as if they were just as high as their width but with further distances between the keys vertically.
As discussed above, the small keys also tend to lead to many typing errors as the key centres are very close together - for example keys of the size found on portrait mode iPhones have been shown to be significantly slower and more error prone than larger keys .
As such we attempted to reduce the aspect ratio of keys to make them squarer, while maintaining their height and familiarity with the original Qwerty layout.
We investigated Pareto optimization starting with a more rectangular 9-9-8 profile keyboard that results in a less-tall aspect ratio of approximately 1.5 for the same screen area.
Here we started our optimization process with a Qwerty layout in which the Q and A were shifted one row down to give the starter layout WERTYUIOP QSDFGHJKL AZXCVBNM which has a 9-9-8 profile and a familiarity score of 0.951.
Using this keyboard layout and a 1.5 aspect ratio gave an improvement over the standard 10-9-7 layout with the keyboard shown in figure 10 rating approx.
While a relatively small numerical improvement, the buttons in this layout also have a larger hit area which should improve typing speed and reduce miss-strikes further improving spelling performance.
Using the same area as an iPhone keyboard, this layout increases the key width from 4.6 to 5.2 mm - a considerable improvement of 11% in "target size" used in Fitts' law calculations.
Table 1 summarizes the metric scores for this keyboard compared to the standard Qwerty and the Quasi-Qwerty.
Overall our alternative layout achieves a considerably better finger travel distance than Qwerty and noticeably better than quasi-Qwerty.
It also achieves considerably better interpretation clarity than both, but at a reduction in familiarity.
While the true values of a and b for finger tapping on keys below 5 mm requires to be calculated experimentally, our estimate is, we believe, unlikely to change the ordering of keyboards but will affect predicted speeds as the values of a and b used are based on studies with approximately 10 mm wide keys.
Figure 11 shows the words-per-minute estimates for our two keyboards compared with the traditional Qwerty and quasi-Qwerty  and, for comparison, the fastest single optimized keyboard layout we identified.
This shows a predicted improvement of 10% and 11% respectively for our trapezoidal and rectangular keyboard layouts over standard Qwerty and smaller 3% and 4% predicted improvement over the quasi-Qwerty keyboard.
The finger distance metric used above is suitable for optimization a fixed format keyboard but cannot be used to predict text entry speed.
As such it is worth discussing here as it gives a more concrete comparison to other keyboards through use of words-per-minute estimates.
Equation 2 shows the Fitts' law calculation for weighted average time to press a key.
The time to press a key is logarithmically proportional to the distance to that key while logarithmically inversely proportional to width of the target key .
The constants a and b have to be derived experimentally for a given device, for comparison with work of others we used the figures a=0.083 and b=0.127  in our studies despite their being derived for stylusbased keyboarding.
The same bigram data as used for the finger travel optimizations were used here but these were compared with the table used in  and found to result in very small differences in predicted times.
However, as discussed above this does not fully take into account the increased key size with the rectangular keyboard  nor does it take into account the improvement in error correction likely in practice given the larger keys.
12 shows that the two optimized keyboards presented here also have considerably better tap interpretation clarity that should lead to faster text entry as users will learn that they need to be less accurate on typing and still achieve corrected-error-free entry.
For the standard Qwerty keyboard  we estimated an average key tap time of 0.360 s given an aspect ratio of 1.7 and the constants a and b from above.
This is equivalent to a predicted expert typing speed of 33.3 words-per-minute .
Bi, Smith and Zhai used the same Fitts' constants to estimate 181.2 characters-per-minute, or 36.2 wpm, for a standard Qwerty keyboard - slightly faster than our estimate.
To investigate the initial pick-up-and-use aspects of the new keyboard we created paper prototypes of the new keyboard layout using a slightly earlier version of our optimized rectangular keyboard.
These paper prototypes were correct in size and aspect ratio for an HTC Desire and were trialled with 12 students.
These users were encouragingly positive and stated that they would use the keyboard when available.
The students stated that they generally found keys quickly in practice typing .
One user commented that even for two-thumbed use it felt easier as common keys were more central to the keyboard, an unintentional consequence of finger distance metric and the central space key.
Encouraged by the paper prototype results we developed an Android implementation and ran a four day user trial with 10 regular touchscreen phones users  to measure their performance with rectangular-Sath over the initial learning period.
Sessions lasted under 45 minutes per day in a quiet environment with subjects seated in a comfortable chair without the use of a desk.
Users came at the same time for four days and were asked to enter two initial warm up phrases then 17 phrases selected randomly from MacKenzie and Soukoreff  standard set.
There were 4 task sets , randomly allocated to each participant .
To assess Qwerty performance users entered some phrases using the standard Qwerty layout , all other phrases were entered using rectangular-Sath .
Phrases were presented in the web browser of an HTC Desire S and the users typed answers into a text box on the same web page before hitting "next" to move on to the next phrase.
Timing information was recorded using JavaScript based on the time from first to last key press.
In line with other studies, users were asked to type as quickly as possible but accurately and were allowed to use backspace to correct mistakes they spotted "immediately" but were told not to correct mistakes they noticed later and were prevented from using editing controls except backspace.
The implementation used a basic spell checking algorithm with the standard Android suggestion bar to show suggested words and highlight auto-corrections.
We restricted to same length corrections to target miss-taps and not wider omitted taps, double taps or true spelling errors.
The Qwerty and Sath keyboards used the same underlying code and spell corrector.
Their performance dropped to 13.4wpm  when using Sath for the first time but recovered to 17.7 wpm  by the fourth day of the test .
We also analysed speed as a percentage of the users individual Qwerty performance.
This analysis shows that users dropped to 64% of their individual Qwerty speed for the first block of phrases using Sath but that this recovered to 85% on the fourth day .
For comparison average Quasi-Qwerty performance was approx.
65% of average Qwerty in word-by-word tests, while their freely optimised keyboard achieved only 45% in initial use.
Uncorrected error rates were low throughout the study.
Overall 7.9% of phrases contained a single erroneous word, with none having multiple errors.
With an average phrase length of 5.6 standard words , this equates to an error once per 71 words.
On Qwerty tests, 5.3% of phrases were erroneous with a higher 8.8% of Sath phrases being erroneous .
Errors from key positioning changes should result in same length typing errors.
For Qwerty we found 3%  of phrases were correct-length but erroneous compared with 4%  of Sath phrases.
All Qwerty errors were independently categorised as typos while 4 other errors were recorded with Sath - if these were excluded then Sath would have the same typo error rate as Qwerty in this initial use study .
NASA TLX forms were completed after each session .
However, there were no significant differences between first day Qwerty and fourth day Sath indicating that users had reduced to their Qwerty level of effort .
At the end of the study, users were asked "if it was proven faster and less prone to spelling errors", would they adopt this keyboard.
The Pareto curve provides a 3D surface on which all points are, in some sense, optimal given different bias on the underlying metrics.
As users become familiar with the revised keyboards shown in this paper it may be possible to dynamically move forward along the front towards the origin of familiarity by building on the user's new familiarity with our keyboard.
Longer trials are planned to see if users can handle a keyboard design that changes dynamically over time but in a "familiar way".
We will also investigate how this impacts on their use of the standard Qwerty, for example when using a friend's keyboard or swapping to hard keyboard phone or laptop.
We picked three metrics of speed, interpretation clarity and Qwerty-familiarity as we feel any optimization should take at least these three aspects into account.
Other metrics could be included as Pareto optimization is open to any number of dimensions.
We are also working on optimizing for two thumbs using more detailed timing models .
Several users commented that it would take some time to get up to full speed on the new layout while a couple commented that they had already got used to the new layout.
A couple of comments showed some users understood the design, e.g.
We observed an initial performance of 64% which, after only four short sessions, had recovered to 85% of their own Qwerty performance with users typing at nearly 18 wpm in their fourth session.
While not yet outperforming Qwerty they were typing at a good speed and showed good signs of continual improvement.
Given the growth shown on figures 13/14 we are confident that this study shows  initial use is not too painful and  users would most likely exceed Qwerty speed within a short period of more intensive use.
This paper has introduced a new approach to keyboard optimization.
We use Pareto Front optimization to optimize on three metrics in parallel: finger travel distance , tap interpretation clarity for spell correction  and familiarity with standard Qwerty.
Using our metrics we proposed two new Sath-keyboards that give a considerable improvement in finger travel distance by rearranging the keys on the standard layout keyboard and by also making the key layout more rectangular.
In addition to the predicted improvement in speed we saw a considerable reduction in neighbour ambiguity that should lead to improved tap interpretation and spell correction.
Fitts' law modelling confirmed a conservative improvement of 10-11% in terms of words-per-minute.
When compared with Bi, Smith and Zhai's quasi-optimized keyboard  we show a small improvement in speed with a considerable improvement in the tap interpretation metric .
In user trials, users performed at 64% of their Qwerty speed on first use but this improved to 85% within four short trial sessions and showed strong signs of continued improvement.
Moreover, the combined effect of less distance in typing and higher tap interpretation clarity should, in medium term use, see cumulative gains as users learn they can be less accurate with taps and achieve the same quality input.
User studies are planned to accurately model finger-based entry on touch screens of these sizes and to study the impact of our improved layout and spell correction ability on input speeds over long term studies.
