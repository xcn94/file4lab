Lifelogging technologies can capture both mundane and important experiences in our daily lives, resulting in a rich record of the places we visit and the things we see.
This study moves beyond technology demonstrations, in aiming to better understand how and why different types of Lifelogs aid memory.
Previous work has demonstrated that Lifelogs can aid recall, but that they do many other things too.
They can help us look back at the past in new ways, or to reconstruct what we did in our lives, even if we don't recall exact details.
Here we extend the notion of Lifelogging to include locational information.
We augment streams of Lifelog images with geographic data to examine how different types of data  might affect memory.
Our results show that visual cues promote detailed memories .
In contrast locational information supports inferential processes - allowing participants to reconstruct habits in their behaviour.
Many Lifelogging approaches are passive; systems are designed to automatically record data without the need for user effort or intervention.
This eliminates the burdens of users having to decide whether a particular incident is worth capturing, as well as the need to manually prepare and operate a capture device.
The advantages are obvious - no important moment gets missed, and users aren't taken "out of the moment".
Lifelogging could radically transform mnemonic activities such as writing personal diaries, note-taking or other practices intended to address everyday forgetting, as well as reminiscing activities involving photos.
While there have been many demonstrations of Lifelogging technology, with some exceptions  rather less is known about how it will be used in everyday life.
We also lack theoretical insights into exactly how such tools might support everyday memory processes.
Such insights should allow us to design better tools to access Lifelogs.
The design space here is complex: e.g.
These might have different implications for how and what we remember.
In this study, we specifically wanted to examine the effects on memory of providing locational as well as visual records of everyday activity.
Experimentation, Human Factors INTRODUCTION Now that we can record almost every moment of our everyday lives visually , spatially , or verbally , we can potentially store every second of our lives in a digital archive .
Such extensive capture of everyday events has created a Lifelogging culture and a vision of the future in which a vast store of personal data can provide us all with a kind of "prosthetic" memory.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
There are various ways that psychological theory might inform the design of Lifelogging technologies.
Some theories argue that our memory for everyday events is mediated by visual images .
And studies of domestic photography also observe the evocative power of such images in supporting reminiscence .
These accounts argue for the utility of technologies such as SenseCam , which captures a series of still images of one's everyday life.
Capture is triggered by user activity such as movement, or changes in light.
Indeed, recent work has shown that such images can help people with severe amnesia to consolidate recent memories .
Combining images with location information might also address criticisms of technologies like Sensecam: that they accumulate multiple images of the mundane .
Providing contextual data for visual images could facilitate focusing on the important or unusual .
Finally, different types of Lifelog data might also have different evocative effects.
Prior theory  argues for the evocative power of images, whereas it is not necessarily the case that locational information has the same effect.
Prior work  concerning memory processes argues that memories are often inferential rather than involving mental re-experiencing or recalling of the original event.
True recall means recollecting or mentally reliving an event from the past, including the details of that past.
This is often referred to as "episodic" memory .
Inference, on the other hand, is about deducing that one must have participated in some event even if one can't actually recollect it.
So, for example, I might infer I had attended a meeting because I have my notes about it, even if I don't actually recall being there.
Prior work  suggests that Lifelogging tools can both promote such reconstructive inferences, as well as support genuine recall.
A further question for this study, then, is whether there is a difference between image versus locational Lifelogging data in the extent to which they support true recall versus inference.
Snaps visualization showing sequential images of everyday activity.
It is also well known that human memory is a reconstructive process mediated by cues, and in particular that location cues can be important in triggering everyday recall .
There are now many widely available geotagging tools that provide such information.
Abstract location information might also support different types of memory, offering a high level view of the everyday.
Showing spatial tracks or patterns on a map might allow people to infer their habits .
To investigate these issues, we asked 18 participants to passively capture image and locational information about their daily lives over a two week period.
Their memories of everyday events were then tested using three types of Lifelogs:  Snaps ;  Tracks ; and  SnapTracks .
All of these Lifelogging tools were compared to memory of events when memory is unaided .
The specific research questions were as follows: * How effective are different types of Lifelogs?
Do visual images, locations, or a combination of both promote better recall of past events?
Exactly how are events remembered with Lifelogs?
Are they inferred on the basis of the Lifelog data or do people experience true recollection?
Does this process differ for image versus locational information?
What are the other characteristics of memory that different types of Lifelogs evoke?
In particular, which types of Lifelogs are seen as the most emotionally evocative, and which are preferred?
What do these results imply about how different types of Lifelogs might be used?
How might this affect the design of future Lifelogging systems?
Given the importance of images for everyday memory , we expected the image-centric tools, Snaps and SnapsTracks, to promote greater recall than locational tools  or OM.
With regard to the second research question, we expected that the image-centric tools would provoke more real recall rather than locational tools or OM.
On the other hand, we expected locational tools  to allow people to infer typical patterns in their activities better than purely image-centric  tools or OM.
With regard to questions about other characteristics, and issues of preference, we treated these as exploratory.
Furthermore, psychology research suggests that atypical and emotionally rich memories tend to be more durable .
Locational data could, potentially, be used to highlight the atypicality of individual events.
New methods that aim to identify atypicality from individual locational trails also known as "novelty detection"  have been developed.
On the other hand, studies investigating individual human mobility patterns have revealed that there is a high temporal and spatial regularity in individual's mobility patterns .
This raises the question of whether, even when people have very similar everyday spatial and temporal patterns, the augmentation of locational data with images might add a distinctive layer of information to Lifelogs to further support memory.
Taken together, the literature both from psychology, and from HCI poses many unanswered questions about the nature of memory support for these different kinds of data.
Providing digital cues about past events generally improves recollection .
However such studies do not determine whether these recollections are inferred or actually remembered.
In fact, few studies have examined the ways in which Lifelogging data might cue memory for normal people in the course of their everyday lives.
One exception  showed that automatically captured visual cues can effectively cue recall of the past, but in the longer term  these cues act more to support people's inferences about their past, rather than to support true recollection.
Other work  has shown that Lifelogging tools should be considered more broadly as not just for memory support, but for helping people look back at the past differently and creatively.
Together, these studies show that, while Lifelogging data may sometimes help us recollect the past, equally such cues may cause us to see it, or reconstruct it, quite differently.
At the same time, we know that people remember visual information very well , and a number of Lifelogging tools have focused on using visual information to support memory archiving .
It is evident that visual Lifelog data can be complex, with thousands of often similar images being generated.
There have therefore been attempts to cluster Lifelogs into meaningful events  to help make sense of large streams of visual information.
Other work has investigated the use of a "digital compass" to group captured images into clusters that share a geographic directionality, as a means to provide users with additional visual cues for recognising their events .
New personal Lifelogging services such as Nokia's vine  and ReQall  allow users to continuously record their geographic location.
However, it is not clear what additional benefit locational logging contributes to visual Lifelogging practices, or its ability to effectively act as a cue for organic memory.
Psychology research suggests that people tend to remember places or events better than, for example, temporal event information , making this an interesting topic for research.
A number of sophisticated systems have been developed to help organise geo-visual data .
However, there is little evidence of systematic evaluation investigating geo-visual Lifelogging and its effects on remembering.
SenseCam: SenseCam  is a wearable digital camera which has been widely used in prosthetic memory aid research , visual data segmentation  and as an educational tool .
It has two picture capture modes: temporal and sensor-based.
In temporal mode, SenseCam captures pictures at specified regular time intervals.
In sensor mode, it captures pictures when one of the sensors  is activated, e.g.
In this study, we used SenseCam in sensor mode.
On average this generates about 4000 images per day for each active participant.
GPS: For the GPS Unit, we used the eTrax Legend HCx model  for automatically capturing GPS coordinates.
All devices had the Wide Area Augmentation System  enabled.
This allowed each GPS unit to maximise the satellite accuracy to less than 3 metres .
Each unit also had an additional 2GB micro SD card to ensure that there was enough space for a 2 week continuous log.
Rechargeable batteries with chargers were provided for powering the GPS unit.
Snaps: is a SenseCam picture viewer embedded in a web browser .
Snaps allow people to view their pictures sequentially on a day by day basis.
When the user selects a day they want to remember, their pictures are played in a temporal order from the beginning of that day.
Users can pause or replay their pictures.
Fig 2 illustrates a sequence from one user's morning .
It starts with them leaving their house , popping into the coffee shop , drinking their coffee on the bus to work , stopping to check their bank balance at the next ATM  and finally reaching their work place .
Tracks: Tracks  takes the GPS data and shows user routes on a real-time custom Microsoft Virtual Earth map.
The GPS units were set to sample location every minute.
We used a map visualisation to show users a high level overview of their whereabouts.
Tracks can be filtered by days showing users' daily routes depicting each day in a different colour.
Users can choose to display multiple days on the same map at once.
Furthermore, each waypoint of the GPS route is time stamped.
Timestamps are displayed when users hover over individual waypoints.
SnapTracks: Fig 4 illustrates the SnapTracks interface.
SnapTracks combines GPS co-ordinates and SenseCam data temporally on a map visualisation that displays user routes.
The goal is to use the map as an overview method allowing users to drill down into more detailed personal images.
For instance when a person walks down a street, their position is automatically logged every minute on their GPS unit with an accompanying a time stamp.
At the same time, SenseCam automatically captures pictures and assigns a time stamp.
SnapTracks compares the two timestamps and pairs GPS and SenseCam data based on a +/-25 second range.
Thus if a SenseCam timestamp falls within 50 seconds of a GPS timestamp, that picture and the GPS point will be paired together.
Again data are displayed on the custom Microsoft's live Virtual Earth map as a pin showing that picture as illustrated in Fig 4.
Individual pictures pop up one by one, as the user hovers over the relevant GPS point pins on the map, see Fig 4.
Complete routes and popup pictures from SenseCam can be activated from the map by selecting a day from the right hand side of the SnapTracks interface.
Participants were volunteers from a wide variety of backgrounds: researchers from industrial and academic laboratories, sales people, civil servants, management and administrative staff, as well as other professionals from public and private sectors.
None of the participants had prior experience of wearing SenseCam or using GPS units.
Participants received a 20-pound book voucher on completion of the experiment.
At the capture stage, we asked each participant to wear both lifelogging tools  for two consecutive weeks.
At the recall stage we conducted a controlled within-subject experiment where our participants used each type of Lifelog.
We compared their recall with unaided memory as a control condition.
Participants were tested on their retrieval of information about everyday events that took place during those two weeks of logged activity.
We began the capture session with a general description of the study, handing out the Lifelogging tools and giving hands-on instruction about how to use these tools.
Participants were instructed to wear the SenseCam and the GPS unit every day during the 2 week period.
They were asked to keep both of these devices switched on as long as they could during the day, but obviously there were times when they had to switch them off; confidential meetings and visits to the bathroom are better left un-captured.
Nothing was said in advance about the purpose of the experiment, but participants were informed that their memory would be tested at the end of the study.
Recall took place an average of 5 weeks after the two capture weeks had ended.
Participants were first given a general description of the Recall Methods they would use - i.e.
We also told them about the different types of questions they would be asked.
We then gave them a brief web-based, hands-on tutorial providing detailed descriptions of the different Recall Methods and procedures for the experiment.
We excluded weekends, as we thought these may be highly atypical.
We asked them to answer the following memory question: `What did you do, where did you go and who did you meet on , ?'.
They did this using SnapTracks, Tracks, Snaps or unaided memory , depending on the experimental condition.
They were given as long as they liked to answer.
This recall probe is typical of those used in prior studies of everyday memory .
With the same Recall Method, we then asked the same recall probe for a different period, changing the day, timeof-day and date specified.
Overall, we gave each participant 2 probes for all 4 Recall Methods.
This led to a total of 8 memory questions per participant, covering 8 different periods out of their 2 weeks of logs.
To control for parts of the day/recall method, we counterbalanced the order in which users were asked about specific days and times of the day, and the different Recall Methods they used to answer each memory question.
Participants answered questions on both paper-based forms and verbally.
Paper-based forms contained questions on emotion, typicality, inference and cuing effect for each study question.
The verbal answers were recorded and transcribed by one of the experimenters.
Again following prior research , we classified recall into different events, e.g.
Typicality of the experience promoted  .
Overall preference for one of the recall methods 
We also recorded spontaneous comments made by participants as they recalled their experiences.
In addition we asked open-ended questions about what people perceived to be the main differences between each recall method and why they preferred one type of Lifelog to another.
We present these as quotes below.
To sum up, we collected the following data: * Events: The number of events reported in each condition - e.g.
This was collected through self reports when users where asked to say how they remembered each event, e.g.
This was calculated by combining `know' and `guess' answers and dividing it by the total number of events recalled; Comparative evaluation ratings: for the different Recall Methods and unaided memory, in terms of emotions, typicality and overall preference.
In addition to describing the event, participants were asked, for each event, to state how they were recalling it, and whether they remembered, knew, or guessed .
It was explained to subjects that rather than a scale of wellremembered to badly-remembered, these three options represented qualitatively different types of memory which we defined as follows: Remember - We defined this as when an event can be reexperienced in the `mind's eye', where one can mentally place oneself in the scene described.
Know - This was defined as an event which one infers must have occurred that day.
Guess - We suggested the use of this option to allow subjects to fill in events they were uncertain about .
For each Recall Method, we counted the number of distinct events that each participant described.
These are shown in Fig 5.
Overall recall was low, with a mean of 0.96 events recalled per probe.
However this finding is consistent with similar studies .
We compared different Recall methods using paired t tests, applying the Bonferroni correction.
In each case we compared mean number of recalled events for the two retrieval probes corresponding to each Recall method.
In addition, SnapTracks led to greater recall than Snaps =4.51, p<0.001 again indicating the benefits of providing locational context for SenseCam images.
No other significant differences between pairs of conditions were found.
In addition Snaps  are more likely to be true recollections than Recall methods that provide locational information, i.e.
Also there is no difference between OM and Snaps in the percentage of remembered events =1.72, p>0.05.
Together these two analyses suggest that Lifelogs engender inferencing but that this is more prevalent when locational information is provided.
Consistent with , Snaps led to some inferencing, but events recalled with Snaps were more likely to be true recollective memories than either Tracks or SnapTracks.
But just how was it that these different types of data were operating?
To what extent were these different cues triggering true recall versus simply promoting inferences about what must have happened on the day in question?
Here we can look at the difference between "remembering", "knowing", and "guessing" based on users' judgments about how they remembered each event.
We classified both: `know' or `guess' judgments as reconstructions.
A high reconstruction rating corresponds to a guessing or "inferring" that something happened, rather than true recollection of that event.
We expected that the cues provided by SenseCam data would promote greater inferencing than OM alone.
6 shows the prevalence of inference and the utility of Lifelogs for promoting high levels of reconstruction.
As we expected, there are significant differences in reconstruction ratings for the different Recall Methods.
Again we compared means for the two retrieval probes, across the different Recall conditions using Bonferroni corrected t tests.
We were unable to obtain inference judgments for 8 cases where users had failed to recall any events - these all occurred with OM.
Similarly, if we Figure 6.
Mean Percentage of Events rated as Inferences for different types of Lifelogs and OM.
User comments also bear this out.
One user noted that seeing images tended to promote real recall whereas location promoted inferencing: " usually made me remember.
I must have gone home by taxi."
If images are more powerful as a trigger for true recollection, we would also expect that participants would report more details for those events.
Again we analyzed these data using corrected paired t tests.
We have already seen that OM is heavily reliant on real recall, and visual data seems to sharpen our ability to recall the details of those remembered events.
Visual images also led to more detailed recall than locational data.
This last finding may result from the fact that in the Snaps interface, multiple images are directly visible without user intervention.
This contrasts with SnapTracks - where users are first presented with the map visualization, which they then use to navigate to the images - making access to images less direct.
One user talked about the value of visual images for promoting detailed recall: "I found  pictures really useful for those small micro events that happened over these days...."
Tracks showing different things to Snaps.
Pictures show micro details, but are evocative.
I see Snaps and SenseCam as reminder of a time and SnapTracks and GPS as patterns from that time."
We now turn to the questionnaire data.
Participant judgments for Emotion, Typicality, and Overall Preference for each Recall Method are shown in Fig 8 - 11.
We performed Bonferroni corrected paired t tests to determine perceived differences between Recall methods.
Again we were missing some data, as subjects could not judge the emotions associated with a memory for those probes where they failed to remember anything.
Participants ranked each recalled event on a scale where 0 indicates `no emotion' and 1 `strong emotions'.
The rankings suggest that images were seen as more emotionally evocative .
This is what we might expect if such cues trigger more true recollection as opposed to inference.
And one participant noted the evocativeness of image-centric tools, in particular Snaps compared with OM: " was useless - I could have no emotional attachment to those memories ... but the tools, especially  were very good at reviving accurate memories."
This may have been the result of large variances we observed in user judgments of emotion.
Mean number of details recalled per probe for different types of Lifelogs and OM.
To summarise, these results suggest that images and locational information work quite differently in supporting people's ability to report events from their past.
Images tend to trigger true recollection of the experiences, complete with the details that one might expect if an event is really remembered.
In contrast, locational information supports inference whereby participants are able to deduce what they must have been doing even if they can't actually recall the events in question.
The questionnaire data and user comments also suggest that the different types of Lifelog support looking back at the past in very different ways.
Participants' comments confirmed that the different tools were used in different ways.
Locational information should help with abstraction and inference about the past, in this case about the habits and routines of daily life .
Participants ranked each event for typicality where 0 meant `atypical' and 1 `very typical'.
Again, we found that although user comments were suggestive, there were no statistical differences for these rankings between locational information and OM =1.0, p>0.05 for Snaps versus OM and t=1.0, p>0.05 for SnapTracks versus OM.
We should also add that preference must really be considered in the context of the users' goals.
Although the subjects in this study duly answered this question, ultimately preference must be a function of what a user's goal is .
In this case, it appears that participants recognise that different kinds of cues support different kinds of activities.
They may therefore have been expressing the view that having both kinds of cues available is the best possible situation.
What might we then expect participants to say about which method they preferred and why?
Here it is probably most helpful to first consider participants' comments.
These suggested an overall preference for SnapTracks because this interface allowed people to see rich information but in context/overview format: " got some cues from tracks with  and some cues from pictures with ... was good as a way to browse and find relevant snaps - I remember the day when I nearly had a crash , I used  to browse to the place where it happened and then I could see the actual pictures of the person I nearly crashed into."
Typicality Rating for events recalled with different types of Lifelogs and OM.
We evaluated users' overall preference ratings for different Recall Methods, where a 1 represents a strong positive preference, and a 0 a strong negative preference .
This may be because people wanted to have concrete evocative images presented in their Lifelogs.
Overall user comments showed greater preference for SnapTracks:"I am good at visualising routes I have taken,
This study extends the notion of Lifelogging.
The majority of past studies have tended to view Lifelogs as single sources of data that trigger simple processes of authentic recall.
Instead in this study, we show that there are multiple types of data that we might collect about our pasts, as well as multiple ways of presenting this data.
Different data types and views promote different acts of remembering, including ones which might be more properly called inference rather than memory.
More specifically, the study increases our knowledge of how Lifelogs might support looking back on the past, and the processes by which cueing operates.
Images and locational data clearly function differently: Images promote more genuine, detailed recall, whereas locational information promotes inferencing.
While we lack clear data on this point, there is some suggestion too that images may also be more evocative than locational data - presumably because they are associated with authentic recall.
Interestingly, images also promoted more recall of details than unaided memory.
This was confirmed when examining participants' preferences.
Participants in this study judged as optimal a combination of locational and image data: so that they could rapidly navigate through large amount of data about their past and then zoom in on details of interest.
There are two further contributions of this work.
First, these findings add to theory on everyday memory.
Prior work argues that everyday memory is reconstructive.
Our study showed inferencing was prevalent, in particular with locational cues.
In addition current theories argue for the central role of images in everyday memory .
Our results showing the authenticity and detailed nature of imagemediated recall provide further support for this view when we are talking about true recall.
Second, there are important design implications that follow from this study.
The most obvious is that image data should be the cornerstone of Lifelogs that aim to support true recollection .
But the findings also suggest that while it is important to collect rich recordings about our past, it is also critical to consider how to present this data.
Different views on the data will support different types of remembering.
For example, critics  of Lifelogging argue that such systems simply accumulate huge collections of mundane data.
Our study shows that providing abstractions over that data can potentially address this criticism.
These abstractions work best if they can be directly linked to detailed data.
More specifically, we saw that people recalled more events when they had locational abstraction combined with the ability to drill down into the detailed images if needed.
Future work needs to provide both different methods for abstraction as well as different types of abstraction.
For example, new interfaces might be built to capitalize on machine learning work that infers different patterns in locational data and identifies unusual patterns .
We might use this to provide different styles of SnapTracks or Tracks interfaces, based around different types of locational patterns.
Another approach might be to provide image abstractions.
Other work has used vision processing techniques, e.g.
These might be used for navigation.
In addition, our participants viewed their Lifelogs by date, but there are clearly other types of temporal abstraction that could be explored.
Finally, we might want to combine other user activities with Lifelogging data.
Calendar data about salient personal events could be linked to Lifelogs allowing people to explore detailed aspects of their past, triggered by those calendar events, e.g.
Finally we might explore the benefits of abstraction in medical settings.
These are just some of the technical and design possibilities that are opened up by a deeper understanding of how different kinds of data support looking back at our own personal pasts.
With this in mind, our hope is that future work will continue to more systematically examine the ways in which Lifelogging data interacts with memory and other cognitive, creative and expressive human capacities.
ACKNOWLEDGMENTS We thank our participants for sharing personal everyday Lifelogs.
We also thank James Scott, Alban Rrustemi and Steve Hodges from Microsoft Research for help and advice with SenseCams.
Azuma H., Mukaigawa Y., and Yagi Y., SpatioTemporal Lifelog Using a Wearable Compound Omnidirectional Sensor, The 8th Workshop on Omnidirectional Vision, Camera Networks and Non-classical Cameras - OMNIVIS, Marseille, France, 2008.
Berry E., Kapur N., Williams L., Hodges S., et al, The use of a wearable camera, SenseCam, as a pictorial diary to improve autobiographical memory in a patient with limbic encephalitis, Encephalitis: Assessment and Rehabilitation Across the Lifespan , 17 , pp.
Brewer W., and Sampaio C., Processes leading to confidence and accuracy in sentence recognition: A metamemory approach, Memory, 14 , pp.
Budvytis I., Scott J., and Butler A., CompassBased Automatic Picture Taking using SenseCam, In Adjunct Proceedings of Pervasive 2008, Sydney, Australia, 2008.
Chalfen R., Family photography: One album is worth a 1000 lies, in D. M. Neuwman, ed., Sociology: Exploring the architecture of everyday life Thousand Oaks, CA.
Chalfen R., Snapshot Versions of Life, Bowling Green Ohio, Popular Press .
Cohen G., Memory in the Real World, The Open University, Psychology Press, 1996.
Cohen G., Kiss G., and Le Voi M., Memory: Current Issues , Open University Press, 1993.
Conway M. A., and Pleydell Pearce C. W., The construction of autobiographical memories in the self memory system, Psychological Review , pp.
DeVaul R. W., Pentland S. A. and Corey V. R., The Memory Glasses: Subliminal vs.
Overt Memory Support with Imperfect Information, Proceedings of the 7th IEEE International Symposium on Wearable Computers, IEEE Computer Society, 2003.
Doherty A. R., and Smeaton A. F., Automatically Segmenting LifeLog Data into Events, Image Analysis for Multimedia Interactive Services, 2008.
Doherty R. A., Byrne D., Smeaton F. A. et al Investigating keyframe selection methods in the novel domain of passively captured visual lifelogs.
Fleck R., and Fitzpatrick G., Supporting reflection with passive image capture.
Frohlich D., Kuchinsky A., Pering C., Don A., and Ariss S., Requirements for photoware.
Gonzalez M. C., Hidalgo C. A., and Barabasi A. L., Understanding individual human mobility patterns, Nature , pp.
Harper R., Randall D., et al, The past is a different place: they do things differently there.
Hodges S., Williams L., Berry E., Izadi S., Srinivasan J., Butler A., Smyth G., Kapur N. and Wood K., SenseCam: A Retrospective Memory Aid, UbiComp'06 pp.
Kalnikaite V. and Whittaker S., Software or wetware?
Liao L., Patterson D., Fox D., and Kautz H., Learning and inferring transportation routines, In Proc.
Liao L., Patterson D. J., Fox D. and Kautz H., Learning and Inferring Transportation Routines, Artificial Intelligence, 171 , pp.
Linton M., Transformation of memory in everyday life, in U. E. Neisser, ed., Memory Observed: Remembering in natural context., San Francisco: Freeman, SF, 1982.
Mann S., Fung J., Aimone C., Sehgal A. and Chen D., Designing EyeTap Digital Eyeglasses for Continuous Lifelong Capture and Sharing of Personal Experiences, In Proc.
Ochsner K. N., Are affective events richly recollected or simply familiar?
Journal of Experimental Psychology: General , pp.
Petrelli D., Whittaker S. and Brockmeier J., Autotopography: what can physical mementos tell us about digital memories?
Sellen A. and Whittaker S., Beyond Total Capture: A Constructive Critique of Lifelogging.
To appear in Communications of the ACM, , 2010.
Sellen A., Fogg A., Aitken M., Hodges S., Rother C. and Wood K., Do life-logging technologies support memory for the past?
Stanford University, Wide Area Augmentation System .
Stifelman L., Arons B., and Schmandt C., The audio notebook: paper and pen interaction with structured speech, In Proc.
Tan D., Stefanucci J., Proffitt D., and Pausch R., The Infocockpit: providing location and place to aid human memory, In Proc.
Tulving E., Episodic memory: from mind to brain, Episodic Memory: from Mind to Brain, 53 , pp.
Vemuri S., Schmandt C., Bender W., Tellex S., and Lassey B., An Audio-Based Personal Memory Aid.
Wagenaar W. A., Is Memory Self-serving?, in U. N. & R. Fivush, ed., The Remembering Self: Construction and Accuracy in the Self-Narrative.
Whittaker S., Hyland P., and Wiley M., FILOCHAT: handwritten notes provide access to recorded conversations, In Proc.
