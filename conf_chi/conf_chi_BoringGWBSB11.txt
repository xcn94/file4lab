Current interaction approaches include controlling pointers on the facade's canvas  or pushing content to it through multimedia messages .
The size, visibility, and large audience of media facades offer a great potential for collaborative interaction.
Indirect pointing techniques, however, restrict the number of simultaneous users:  each pointer occludes a  portion of the facade, eventually leading to clutter and large content regions being invisible.
In addition, facades showing pointers need reasonably high resolutions to provide enough pixels per pointer.
One approach to solve these issues is to use an absolute and direct technique such as interaction through live video .
The increasing number of media facades in urban spaces offers great potential for new forms of interaction - especially for collaborative multi-user scenarios.
In this paper, we present a way to directly interact with them through live video on mobile devices.
We extend the Touch Projector interface to accommodate multiple users by showing individual content on the mobile display that would otherwise clutter the facade's canvas or distract other users.
To demonstrate our concept, we built two collaborative multi-user applications:  painting on the facade and  solving a 15-puzzle.
We gathered informal feedback during the ARS Electronica Festival in Linz, Austria and found that our interaction technique is  considered easy-to-learn, but  may leave users unaware of the actions of others.
More and more urban landscapes are equipped with media facades.
The Beijing National Aquatics Center in Beijing, China and the ARS Electronica center in Linz, Austria are two prominent examples out of hundreds of such facades.
However, due to their size and the required viewing distance, interacting with them directly  is normally impossible.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
In this paper, we apply and extend the concept of Touch Projector  to media facades to avoid the limitations of current interaction techniques.
With two applications, we demonstrate how multiple users can interact on a facade simultaneously.
During the ARS Electronica Festival we found that our approach is  considered easy-to-learn, but  may leave users unaware of the actions of others.
The term "media facade" describes the idea of designing or modifying the architecture of buildings with the objective of using their surfaces as giant public screens .
In addition, urban public spaces are emerging more and more as prime locations for media facades that are embedded in the landscape of a city .
Researchers recently explored the social potential of such media facades as they can be seen or even designed by multiple persons simultaneously .
They further studied public participatory crowd experiences when porting popular games to media facades in combination with mobile devices .
Several techniques have been proposed to interact with distant displays.
The most prominent techniques are relative and indirect pointing as well as augmented reality approaches.
Relative and indirect pointing can be used to distant displays by turning a camera-equipped mobile device into a mouse-like device .
However, such input techniques may hinder multi-user scenarios due to the required virtual pointer.
MobiSpray uses a world-in-miniature interface to allow for "spraying" color on various projected surfaces using the mobile device's accelerometers .
Recent advantages in mobile augmented reality allow absolute pointing on displays .
For tracking purposes, their system relies on a marker shown on the remote display.
Touch Projector allows interaction with a distant display shown in the viewfinder using touch in real-time without relying on fiducial markers .
As this system follows a direct input approach, we decided to take it as the basis of our prototype.
According to Dalsgaard et al., applications must consider potential shifts in lighting and weather conditions .
The facade of the ARS Electronica Center is only visible below a certain level of daylight.
The original implementation of Touch Projector did not account for this, as it was built for regular computer screens with strong background lighting in controlled environments.
Especially in the dark, reflections on wet ground are commonly caused by weather.
As described in the IMPLEMENTATION section, we substantially changed the tracking algorithm to allow for outdoor use.
Another challenge is that media facades mostly have unique features .
The ARS Electronica Center can easily be viewed at a distance of 300 meters.
However, the distance influences the facade's apparent size in live video.
To counter this, we used the zoom functionality of Touch Projector.
Ideally, the building would fit exactly into the live video image.
If this is not the case, the mobile device adjusts its zoom level.
This ensures a practically constant controldisplay ratio for users independently of their distance.
Our goal was to implement a system that allows multiple users to interact simultaneously on a media facade.
As discussed in the previous section, relative and/or indirect approaches  may limit the number of users to the number of distinguishable  pointers on the remote canvas.
The low resolution facade of the ARS Electronica Center 1  used for our prototypes lowers this number even more.
Techniques that use a world-inminiature representation  overcome this limitation at the expense of macro attention shifts between both the mobile and target display .
To avoid the necessity of virtual pointers as well as the potential costs of macro attention shifts, we decided to use the concept of Touch Projector on media facades .
Users aim their device at the facade and observe it in live video, allowing them to point through the display.
Touch input occurring on the mobile device is projected onto the facade,
The large size of such facades further allows multiple users to interact simultaneously on them.
The original idea of Touch Projector only transforms input occurring on the mobile device to a facade's canvas.
Thus, interactive controls or temporary feedback are shown on the facade.
This is not always an optimal solution:  tool palettes waste screen real estate decreasing the size of the actual interaction canvas.
On the other hand, the live video on the mobile device shows the facade at all times.
Thus, the facade's content can be augmented locally without introducing macro attention shifts.
To allow for such feedback, the mobile screen superimposes a personal layer on the local live video , leaving the shared view of the facade canvas unaffected.
Our prototype uses a dedicated server to  control the building's lighting through DMX and  communicate with mobile devices .
Similar to Touch Projector, the mobile devices send video frames over wireless LAN to this server, which calculates their spatial relationship to the building.
The server further handles all touch events received from the mobile devices.
To demonstrate the use of  interacting through live video on media facades as well as  the distribution of public and personal content, we built two applications.
These allowed users to paint freely on the facade or solve a 15puzzle in a collaborative way.
Our first application allows users to solve a 15-puzzle on the facade.
Eight pixels  are representing one tile of the puzzle.
Tiles can be shifted by tapping on a tile next to the missing one.
However, the facade's low resolution did not allow for clearly showing division lines that are important to identify tiles .
We decided to allow users to superimpose these lines on the mobile device to allow for tile identification .
As our tiles only have 8 pixels in total, it is hard to identify a tile's correct location.
Users can peek at the solved puzzle by requesting a preview .
We decided to show the preview locally so that others are not distracted.
To identify the facade, we chose to show a white frame around an entire side of the building by permanently lighting the outmost pixels.
This frame can be detected using Touch Projector's image processing methods .
Our system then uses the detected perspective distortion of the building's outline , to calculate the spatial relationship between mobile device and building.
To avoid reflections on wet surfaces being falsely detected, we made two assumptions:  users point their devices at the building instead of the reflection, which causes the reflection to be shown only partly.
In early tests on the facade with real users and reflections caused by wet ground around the building, we found these assumptions to be sufficient.
Aside from determining the spatial relationship of mobile devices, the server stores individual content for each user as image data which  can be transferred to the mobile device.
In some cases , the system also distorts the content for correct alignment with live video.
This is done by using the inverted transformation matrix  calculated during the detection process.
Once the image is sent to the mobile device, it is overlaid on the live video image.
Our second application allows users to paint freely on the facade.
Similar to common drawing applications, users  choose a color and  select a tool from a tool palette.
To do so, users perform a slide gesture next to the live video image.
The mobile device then shows a tool palette .
After closing the palette , users can apply the selected color and tool to the building by touching  on it in live video .
Placing the controls on the mobile device was the only possible solution, as our facade does not offer a resolution high enough to display controls.
All interaction events  are sent to the server regardless whether the user hit a "local" item or not.
As the server knows the exact locations of all elements it can determine and execute the associated action.
Thus, application developers only need to design the interface elements and their actions on the server.
This type of implementation allows for greater flexibility in terms of the heterogeneity found in mobile device platforms.
It limits scalability, however, since computation on the server linearly increases with the number of mobile devices.
During the ARS Electronica Festival in Linz, Austria, we presented our applications to a broad audience.
We handed phones with the application already running to users without any further instructions.
By observing how others used the application, they immediately started to interact with the facade.
Up to three persons were able to interact simultaneously, but we ensured that at least two did at all times.
Downloading the application was not possible as  we used a restricted network and  it was not allowed in the AppStore at that time.
Nevertheless, with three users interacting simultaneously, we were able to observe interesting scenarios including collaboration between them.
Out of the approximately 50 users we asked 15 attendees  for feedback after interacting with the building.
In informal interviews we found that this style of interaction is perceived as  easy-to-learn and 
Overall, the feedback we gained during the interviews was highly positive.
The fact that they could directly change the facade in real time  was mentioned positively.
However, users were sometimes annoyed by the parallel use of our application.
The most important statement was: "It is good to interact in a parallel way if you know the person.
But if you don't know the person, you are kind of fighting over pixels and space to draw.
While this user favored collaboration, another pair of users created a strobelike effect, alternately filling the entire facade with white and black.
Thus, interactions involving either collaboration or competition were supported by the painting application.
This work has been funded by both the "Deutsche Forschungsgemeinschaft"  and the German State of Bavaria.
We thank Antonio Kruger and Michael Rohs for their input in the initial design phase.
We also thank Andreas Prambock, Stefan Mittelbock and Horst Hortner  for their technical support during preparation as well as the festival.
We further thank Dominikus Baur and - especially - Joe McCarthy for their valuable comments and feedback.
In this paper, we presented an extension to the concept of Touch Projector to allow multiple users to interact collaboratively  with media facades shown in live video on their mobile device.
We described the technical realization that can be used under various weather conditions on any digital surface that has or can display a white frame.
We further extended Touch Projector by superimposing individual content  on the live video.
While this was necessary for the low resolution facade in our deployment, it constitutes a very general mechanism when many users interact on larger digital surfaces with their mobile devices: When feedback only affects  a subset of these users, our approach does not distract or disturb others while they interact with the display.
We demonstrated our prototype during the ARS Electronica Festival in Linz, Austria with a large group of users.
The feedback we gained informs future work in the area of multi-user interaction at-a-distance.
In contrast to collocated scenarios in which users are next to or can see one another, larger facades may give rise to greater distances between users, so that they may not be aware of  who is interacting and  where others are.
As this is a common problem of techniques that use interaction at-a-distance, we plan to develop solutions to the awareness problem, by, for example, visualizing the location and direction of others.
Another issue raised by our participants was the heavily parallel nature of interaction using our technique.
The fact that users could simultaneously interact in the same region of the facade was only appreciated if users knew each other.
Otherwise, they rather got frustrated if others interacted  with them in "their" region.
There will always be some tension between permitting desired interactions and preventing undesired ones on a large-scale, multiuser, public media facade.
As this is an intrinsic property of the medium and not solvable in general, we hope to iteratively converge on a more appropriate balance, through partitioning time slots or sub-regions among users on the facade with the ultimate goal of maximizing enjoyment and minimizing frustrations for future users.
