For instance, Tom Malone's early game research  involved the progressive removal of design elements from games and measuring differences in the average amount of time children spent on the different game versions.
They quantified player engagement as the total time spent playing a game and as the number of game levels attempted.
Then, the researchers randomly assigned thousands of game players to a series of A/B tests varying different design elements.
They found, for instance, that music had no significant effect on engagement, celebratory animations had some positive effect, and the presence of "bonus coins"  had a strong negative effect on engagement.
This last finding was surprising, as the longstanding belief was that bonus challenges would be appealing to players .
Their study demonstrates how online experiments can be used to empirically test common hypotheses regarding the effects of design on motivation.
Online games can serve as research instruments to explore the effects of game design elements on motivation and learning.
In our research, we manipulated the design of an online math game to investigate the effect of challenge on player motivation and learning.
To test the "Inverted-U Hypothesis", which predicts that maximum game engagement will occur with moderate challenge, we produced two large-scale , multifactor  online experiments.
We found that, in almost all cases, subjects were more engaged and played longer when the game was easier, which seems to contradict the generality of the Inverted-U Hypothesis.
Troublingly, we also found that the most engaging design conditions produced the slowest rates of learning.
Based on our findings, we describe several design implications that may increase challenge-seeking in games, such as providing feedforward about the anticipated degree of challenge.
In previous periods of educational game development there were few studies regarding the effectiveness of games .
However, contemporary games have the benefit of networked data collection and large online audiences.
As a result, contemporary educational games permit large-scale online experiments investigating the effects of game design factors on both motivation and learning.
Measuring the effects of design elements  on motivation can be relatively straightforward.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
One interesting aspect of games is that their challenge is a motivating force .
In everyday life, people might be expected to minimize challenge--unless, of course, the challenge leads to greater rewards.
While software design portrays "ease of use" as an essential quality, game design is based on the idea that players seek challenge.
How do games promote this challenge-seeking behavior?
And why would anyone seek a challenge?
In many cases, greater challenges lead to greater rewards, both tangible and intangible.
For instance, one may chose a challenging activity if success in that activity leads to a greater status,.
Status is a key motivational element in games and also in educational environments .
Because status and challenge will often correlate, we question whether challenge alone would be motivating.
Several theorists have suggested that completing challenging tasks brings greater internal rewards than completing easy tasks .
For instance, children will smile more after completing longer, more difficult wordscramble puzzles .
This pleasure is believed to arise from one's enhanced sense of self-efficacy or the sense of competence  that comes from the accomplishment.
Under this explanation, it is the successful completion of a challenging task that is more satisfying--not the act of doing something challenging.
Still, a significant body of evidence indicates that, if given a choice, people will choose moderately difficult activities over activities that are very easy or very hard .
Moreover, there is evidence that people enjoy doing activities with moderate levels of challenge, not just completing them or choosing them.
For instance, using Experience Sampling Methods to interrupt individuals' daily activities, Mihaly Csikszentmihalyi  found that people report high levels of enjoyment during challenging tasks; he characterized this enjoyment as a conscious phenomenon called "flow."
The construct of flow and "flow states" have been widely adopted in theories of game enjoyment .
Recently, Abuhamdeh and Csikszentmihalyi sought to experimentally test the idea that optimal enjoyment occurs during moderately challenging activities .
They describe the idea in terms of an inverted-U: "...the notion that we most enjoy optimally challenging activities that are not too easy or too difficult implies a curvilinear, inverted Ushaped relation between difficulty and enjoyment, so that increases in difficulty should lead to increases in enjoyment up to an optimal level , after which further increases in difficulty lead to decreases in enjoyment."
To explore this "Inverted-U Hypothesis", Abuhamdeh and Csikszentmihalyi conducted a large-scale observational study of online chess players .
They quantified the challenge of each game as the numeric difference between the international chess ranking of two players.
Enjoyment was measured through a survey taken by players immediately after each game.
Their results showed that the greatest enjoyment occurred when players faced an opponent with a higher chess rating, but not too much higher.
This provided strong evidence to support the Inverted-U Hypothesis.
Notably, the authors identified another factor governing the enjoyment of individual games: regardless of the difference in chess ranking or who won, players reported feeling greatest enjoyment while playing "close games."
A closer game is one that ends with a smaller difference between the point value of the pieces taken by each player.
Therefore, when the difference in points was minimal, and the outcome was most uncertain, players reported that the game was most enjoyable.
This finding supports previous theory and evidence  about the motivating nature of uncertain outcomes.
The Inverted-U Hypothesis seems appropriate for predicting the effect of challenge on player motivation in videogames.
However, there is little guidance about precisely how difficult a game should be.
In our research, we use large-scale experimentation to test the Inverted-U Hypothesis in an educational game context.
We seek to determine whether there is a particular degree of challenge that optimizes player engagement.
To identify the optimal level of challenge, we randomly assigned players to different design configurations and modeled the effect of the varying challenge on player motivation.
The Inverted-U Hypothesis predicts that engagement will be highest at a moderate level of challenge, neither too hard nor too easy .
In these studies, we operationalized challenge as the probability of success  and motivation as the duration of voluntary game engagement .
Figure 1: The "Inverted-U Hypothesis" suggests that optimal engagement  will occur at a single intermediate level of game challenge .
Factors that increase or decrease challenge from this level should reduce engagement.
To document the relationship between difficulty and engagement, we used Battleship Numberline, an online Flash game where players attempt to explode target ships and submarines by estimating numbers on a number line.
Classroom experiments have shown that the game produces significant improvements in number line estimation accuracy after only 20 minutes of game play .
On the basis of the Inverted-U Hypothesis, we anticipated that a manipulation of the difficulty of the game from very easy to very hard would produce an inverted U-shaped effect on engagement.
To manipulate difficulty in the game, we varied two different design factors: target type and target size.
With the hidden submarine target, players are instead presented with a number indicating the location of the hidden submarine; the player then needs to click on the location of the number line that they believe corresponds to the number provided.
Both the task of locating a given number on a number line and the task of naming a given location on number line are educationally relevant practice activities that may vary in their challenge.
A larger target is easier to hit; estimates can be less accurate and still be successful.
Therefore, the target size can be described in terms of "error tolerance", where a higher error tolerance indicates a larger target .
Take the case of a player estimating the location of a submarine that is "spotted at 20" on a number line from 0100.
If the player clicks on the number line location corresponding to 29, their estimate would have a 9% error--and an accuracy of 91%.
If the target were larger, 20% of the length of the number line , the estimation attempt would be successful.
However, if the target were smaller , the estimation attempt would miss the submarine.
As a result, increasing or decreasing the size of the ship greatly affects the challenge of the game.
To explore the effect of challenge on engagement, we constructed a 2x3 between-subjects experiment involving target size  and target type .
The experiment took place among players who had chosen to estimate whole numbers.
In all conditions the players received the same 20 whole number estimation items  in random order; at the end of this set, the items would be repeated in another random order.
Players had the option of dropping out at any time but the total number of trials was capped at 80 trials.
The time limit for the ship condition was 15 seconds and 10 seconds for the sub condition.
Our operationalized measure of challenge was the estimated success rate of each game configuration, where success rate is measured as the percent of successful estimates divided by the total number of estimates.
Engagement was measured as the average duration of play in each condition, either as the total trials played  or the total time played .
Players are either presented with a visible ship or a number indicating the location of a hidden submarine.
Once the player has typed in their estimate  or clicked on an estimated location , a bomb falls at that location on the number line.
If the bomb hits the target, there is a satisfying explosion and a gold star is released, incrementing the player's star count in the scoreboard.
If the player misses, the bomb splashes in the water and corrective feedback is displayed along with the accuracy of their estimate.
A running tally of the player's average accuracy is displayed in one corner of the screen and a count of the number of stars collected on the other.
There is no final "winning" or "losing" state in the game-- instead, players can continue to play as long as they wish.
Additionally, there are no leaderboards or other mechanisms that allow players to directly compare status.
Battleship Numberline was made available on the GameUp platform on Brainpop.com, which is a popular site for classroom teachers in grades 4-8.
The vast majority of play occurred during school hours, with large drop offs during weekends and holidays.
However, subjects were completely anonymous and were not tracked over time.
As a result, the unit of experimental manipulation was on a game session, rather than a subject.
A game session began when players clicked on one of the game choices  and ended when players exited or made no further actions after a time-out.
Each game session represented a unique experimental assignment and a single player could receive multiple versions of the game by exiting and starting over.
While allowing the same individual to participate in multiple experimental assignments may appear to distort our data, the purpose of the experiment was to measure implicit user preference.
Therefore, choosing to disengage from one condition and start another only enhances our measure of engagement.
Approximately 1,000 game sessions were played per day, ranging from 200 per day over school holidays to 10,000 per day when the game was "featured" by BrainPop.
This scale made it possible to run a broad number of experiments simultaneously from the same subject pool.
Notably, the scale balances the weight of both measures through a correlation with log and log of .95 and .96, respectively.
This measure corroborates that target size has a highly significant effect on engagement, but suggests that there is no significant effect of target type on engagement .
To explicitly test the hypothesis that challenge has an inverted-U shaped relationship with engagement, we need a quantitative measure of challenge.
Therefore, we used the average success rate of each of the six possible design configurations: the lower the observed success rate for a given level design, the greater the challenge it posed.
This is similar to previous research that uses observed probability of success as a measure of challenge .
Figure 3 plots the relationship of challenge to engagement.
In contrast to the Inverted-U hypothesis, our results show a linear relationship between difficulty and engagement .
In short, the easier the game, the longer people played.
The main effects from the design factor target type  are contradictory, depending on how engagement was measured: the submarine target was significantly more engaging based on the number of trials  but the ship target was significantly more engaging based on the amount of time .
As the ship target asks players to type an estimate on the keyboard, each trial takes more time than the click required for the submarine target.
Still, given this contradiction, it is unclear which condition can be said to be more engaging/motivating.
Main Effects of Target Type .
Sub involves clicking a location to estimate a number, while Ship involves typing a number to estimate a location.
The difference in N between subs and ships results from players quitting before completing one trial.
The amount of "time spent" and "challenges attempted" are useful measures of engagement , though they can sometimes contradict one another, as above.
To resolve this contradiction, using a common psychometric practice, we created a combined measure that consists of the log transformation of the number of trials times the number of seconds of play .
In contrast with the Inverted-U Hypothesis, experiment 1 showed that challenge had a linear effect on engagement-- the less challenging, the longer people played.
However, it is possible that the game was not made easy enough, given that the average success rate of the easiest conditions were still <70%; therefore, it is possible that we only measured the left side of the Inverted U.
The pretests were reasonably successful, despite having only four items, achieving a .46 correlation with the hit rate in the experiment and reliability score  of .62.
If a player`s pretest accuracy was above the median, they were labeled "high ability"; else they were labeled as "low ability."
We hypothesized that the very large ship sizes would prove trivially easy to players, resulting in an inverted U-shaped curve.
We maintained the two different types of targets from experiment 1 .
While the time limit in Experiment 1 was consistently 10 seconds , we tested 8 different time limits: 2, 3, 4, 5, 8, 10, 15 and 30 seconds .
We hypothesized that very large time limits would further reduce the challenge of the game and allow us to detect declining engagement with increased success on the right side of the Inverted-U.
This experimental dataset consists of game log data from 69,642 play sessions of Battleship Numberline that were collected from March 25, 2012 to May 4, 2012 from Brainpop's GameUp platform.
These were players who completed the 4-item pretest described above, which occurred prior to the randomization event.
While Experiment 1 gave all players the same set of estimation items, Experiment 2 randomly assigned players to a broad range of item sets.
An item set consists of the specific target numbers that are to be estimated over the course of a level.
The item sets were constructed to vary in difficulty by using data from previous experiments to create bins of items with high and low success rates .
Item sets also varied in the number of items presented and the endpoints of the number line.
Players were randomly assigned to an item set within the estimation domain of their choice.
There were 8 whole number sets, 7 decimal sets and 10 fraction sets for a total of 25 different item sets.
The manipulation of item sequencing showed a significant effect on player success rates, but a minimal effect on player engagement.
Naive0 repeated unsuccessful items immediately after their first presentation, which had the effect of significantly increasing player success relative to random sequencing, for both high and low-ability players .
Despite the improved success rate, Naive0 had a minimal effect on engagement.
Only low-ability players found Naive0 more engaging than random presentation.
This result shows that improving performance may not always increase engagement, particularly when the improved performance results from repetition.
Figure 4: The effect of four design factors and player ability on challenge and engagement.
The dotted lines are players with pretest scores below the median, while solid lines are players with pretest scores above the median.
All four factors influence success rate and, in all cases, greater success is associated with greater engagement.
Error bars show standard error of the mean.
As suggested by the analysis of Item Sequencing, we found that increasing the total number of items presented to a player  had the effect of improving player engagement.
Additionally, we found that increasing the challenge of item sets decreases player engagement.
Item sets are the set of unique estimation items presented to players in a level.
The analysis reported here focuses on a subset of fraction item sets .
Based on previous data collection, we created an "Easy" set of 15 fractions, a "Hard" set of 15 fractions, and an "All Items" set that included easy, medium and hard items .
Finally, this analysis included only high ability students, as low ability students were not as sensitive to the differences between these item sets.
In the first and second columns of Figure 5, we control the number of items but vary the challenge.
This shows that the easier  item set produced greater engagement.
However, the third column seems to contradict this evidence, as the more difficult item set  achieves greater engagement.
This could be evidence to support the Inverted-U hypothesis, as the moderately difficult level achieved more engagement than the easy or difficult levels.
However, our comparison of the third and fourth columns refutes this interpretation.
Here, the difficulty  was controlled while the number of items was varied.
Looking back to columns two and three, this suggests that the greater engagement of "All" results from having a greater number of items in the level.
We hypothesize that increasing the number of items increases engagement by increasing the diversity/novelty of the overall gameplay experience.
This has support from at least one model of game entertainment , which postulates that diversity is one of the major factors accounting for the fun of games.
To address the question of whether players with large targets learned at a different rate than players with small targets, we plotted and compared their learning curves.
To do so, we analyzed a subset of data that tracked each player's entire sequence of estimation attempts.
This subset consisted of 1392 players who were assigned to random sequencing and who played over 30 trials in the decimal domain.
We only analyzed learning in their first 30 trials to prevent player attrition from significantly affecting the measurement of learning curves.
To achieve greater power, we binned the 9 different target sizes into large, medium and small targets.
Our analysis shows that larger targets result in a slower rate of learning, as compared to smaller targets; i.e.. target size has a significant interaction with the rate of learning .
Therefore, while the largest targets were optimal for engagement, they do not appear to be optimal for learning.
Figure 6: Plotting the effects of challenge  on player engagement.
Graph shows quadratic line of fit and a smoothed mean .
This shows that as the predicted success rate increases , players are likely to play for longer.
In contrast to the Inverted-U Hypothesis, low levels of challenge  never appear to negatively affect player engagement.
Success rate was predicted based on a multiple linear regression model, which included main effects of all our design factors  and the 2-way interactions between all the above design factors.
To improve validity, this model was weighted by the number of trials played by each player.
As a player's ability  was expected to impact the predicted success rate of a level, we expanded our model by adding this factor and its interactions with the design factors.
This improved the fit substantially, R2=.46.
This model of challenge , which involved all design factors and player ability, was used to produce the x-axis values in Figure 6.
This graph illustrates the estimated engagement across the range of estimated challenge.
As such, it shows that players are motivated to play for longer as the game gets easier.
While the effect of game challenge is slightly curvilinear, it is not U-shaped - the model does not predict a point where low challenge reduces player motivation.
Taken together, this evidence suggests that we may want to reject the generality of the Inverted-U Hypothesis.
There are several limitations to our approach.
For instance, one could argue that there is a different kind of learning occurring when estimating large and small targets, making this a comparison of apples and oranges.
Secondly, our claims are only meaningful for players who played for >30 trials--and this may represent a particular subset of the population that does not generalize more broadly.
Finally, the high rates of attrition in online experiments make this comparison subject to critique.
In this case, however, the proportion of low-ability students differed across conditions by only 2 percentage points--a difference too small to account for our reported effect.
The above critiques notwithstanding, our preliminary evidence suggests that the easiest targets, which were optimal for engagement, were not optimal for learning.
Measure of Challenge: Their study measured challenge using self-report and the difference of chess rankings between players.
The difference in chess rankings corresponds to a probability of success .
Our study quantified challenge not as the probability of successfully winning a game, but of the probability of hitting individual targets.
Measure of Enjoyment/ Motivation: Their study modeled the effect of challenge on self-reported enjoyment while our study modeled the effect of challenge on engagement .
Engagement may or may not correspond to enjoyment.
Population Characteristics: Their players were older than our players and their players likely had greater expertise in chess than our players had expertise in Battleship Numberline.
In two experiments, we systematically manipulated the design space of an online learning game to determine the optimal level of challenge for supporting maximum engagement.
In contrast to the Inverted-U hypothesis, which predicts that a moderate level of challenge should lead to maximum engagement, we found that the easier the game, the longer people played.
This is a surprising finding, given the substantial amount of theory  and evidence  that suggests that moderate levels of challenge will lead to greater motivation.
It is possible that, despite our efforts, we never made the game easy enough.
The Inverted-U hypothesis could still stand if the theoretically optimal success rate is very high --in that case, we may not have observed the negative effects of decreasing challenge because we lacked sufficient data in this area of very high performance.
In many video games, for instance, the vast majority of user actions are rewarded, with only an occasional setback.
Still, past researchers predicted and observed much lower optimal success rates.
For instance, Atkinson  predicted that motivation would be greatest when the uncertainty of success is highest .
Shapira  predicted that the optimal success rate would be even more difficult, from 25-40% probability success depending upon individual differences.
Furthermore, Csikszentmihalyi's online chess study  found that chess players reported greatest enjoyment when their probability of success was approximately 20% .
Our players were clearly motivated by success--the more successful they were, the more motivation they had to keep playing.
The idea that success will increase motivation is predicted by the Effectance Motivation hypothesis .
A key implication of this hypothesis is that increasing player success rates is likely to increase player motivation.
While one might accomplish this by making the targets even larger, the player might attribute their success to the game, rather than to their own achievement.
Therefore, we predict that increasing success will have a greater effect on engagement if it results from a mechanism that players can attribute to their own competence.
For instance, the game could improve performance by increasing in-game learning .
This improved learning could occur through explicit in-game instruction  or by providing more informative feedback .
If online chess players find a 20% success rate most enjoyable, why might our game produce greatest engagement with far less objective challenge?
There are many differences between the present study and the online chess study that may account for this difference.
Random Assignment: While we randomly assigned players to a particular game configuration, participants in the online chess study freely chose their opponents.
Feedforward: While the chess players were given information about their game's challenge  prior to playing, our players were not given information indicating the amount of difficulty they were encountering.
There is ample evidence that some groups of people demonstrate strong "challenge-seeking" behaviors .
Perhaps challenge-seeking only tends to occur after individuals have acquired some significant level of expertise.
Therefore, perhaps we did not observe the inverted-U because the players of our online game likely had little prior experience.
Models of achievement motivation predict that people will attribute more value to success when the task is more challenging .
However, players did not have any information about the challenge of their particular game configuration .
This is a key difference from the online chess study, where players knew their opponent's international chess ranking.
Therefore, an implication for design is to provide feedforward to players about the challenge of the task they are playing.
This may allow players to more appropriately value their success and failure in the face of challenge.
One limitation of our study was that it was susceptible to self-selection effects: it was relatively common for players to abandon games and start again, where they would be placed in a new experimental condition.
This suggests that players may have deliberately exited a less preferred condition to find a more preferred condition.
Though this self-selection was not intended, since the main goal of our study was to measure how design factors affected player motivation, it seems unlikely to alter our main results.
Still, online game experiments are highly limited by the fact that the data collected are from anonymous and remote subjects.
This means that researchers have a very limited capacity to gain qualitative insight into why subjects are responding the way that they do.
This suggests the importance of triangulating findings between online experiments and laboratory or field studies .
For instance, we may discover that "duration of play" does not, ultimately, sufficiently correlate with player enjoyment.
Our operational definition of challenge is also subject to critique.
We defined the challenge of a particular level configuration as the inverse of its predicted success rate.
Success rate has been used as a measure of challenge in previous research  and it is similar to the notion of a difference in chess ranking in  .
Still, there is evidence that perceived challenge is a greater predictor of enjoyment  than objective challenge.
This may reflect the fact that the objective measure of challenge does not adequately capture the feeling of effortfulness that is associated with the perception of challenge.
Abuhamdeh and Csikszentmihalyi's hypothesis  about "close games" may help explain our results.
They hypothesize that a player's motivation will increase during close games, when there is high uncertainty about winning or losing.
However, this kind of uncertainty does not occur in Battleship Numberline, as the game does not indicate to players whether they have won or lost .
Without winning or losing, there can be no close games.
Additionally, close games only occur when the challenge of the game is closely matched to the player's ability.
In other words, players with greater ability may find challenging games more engaging when the challenge increases their uncertainty about winning or losing.
The Close Game Hypothesis predicts that a clear win/lose state should make challenge motivating when the winning/losing criterion is closely matched to player's ability.
As the performance criterion approaches a player's performance capacity , the player is predicted to experience greatest motivation.
Our research investigated the effects of various game design factors on challenge, motivation and learning.
While we hypothesized that moderate levels of challenge would maximize engagement  we instead observed that the easier the game, the longer people played.
This is a surprising finding that prompts new research questions.
For instance, given that the most engaging conditions were not the most optimal for learning, we can investigate methods for jointly optimizing learning and engagement.
From a design perspective, we can investigate game design patterns that support challengeseeking behavior, as players in more challenging conditions may benefit from a faster pace of learning.
This study contributes one approach to harnessing the crowd to optimize game designs.
Perhaps increasing objective challenge  is simply not desirable to many game players.
Interestingly, challenge is often correlated with increased gameplay diversity; a feature that we found to be a highly engaging.
As increased gameplay diversity can outweigh the negative effects of challenge , it will be important to carefully separate these two variables in future research.
Future work should also address the validity of the operational definitions of challenge and engagement.
The promise of online game research relies on valid metrics obtained in the context of anonymous gameplay.
For instance, is the maximization of motivation/engagement, measured as voluntary time on task, appropriate as a datadriven game design goal?
This question is particularly important for applied research goals, which seek to maximize outcome measures like engagement or learning.
Future applied research may also investigate more efficient experimental designs, to minimize the cost of experimentation to designers and game players.
Very large numbers of voluntary participants gives online game research the potential to significantly expand theories of human learning and motivation.
The implications for design in our discussion  are very standard design patterns that are widely used in games.
However, by framing these game design elements as embodiments of a specific theoretical hypothesis, we can use them to test or extend theories of motivation.
Therefore, it may be fruitful to systematically explore well-known game design patterns in order to generate additional hypotheses.
Game Programming: Nirmal Patel and Nikhil Poonwala.
For conceptual inspiration, much thanks to Prof. Sharon Carver, Prof. Robert Siegler, Prof. Mike Cole, Prof. Mike Levine, "The Shark Game" and the playpower.org community.
For advising the experimental design and analysis, much thanks to Prof. Joel Greenhouse, Prof. Trent Gaugner and Prof. Brian Junker.
Thanks to Dixie Ching, Beau Dabbs, Burr Settles and Turadg Aleahmad for reading preliminary drafts.
Thanks to the members of PIER and SERG for helpful feedback!
Game R&D supported by funding from the National STEM Game Competition Prize, Marvell's Educational Application Grand Challenge, and the Next Generation Learning Challenge .
Graduate funding from IES Program for Interdisciplinary Education Research  and DARPA.
Data analyses were conducted in the highly recommended statistical package JMP 10.
Special thanks to BrainPop.com for supporting educational research!
Hays, R. The effectiveness of instructional games: A literature review and discussion.
Technical report 2005-004, Naval Air Warfare Center Training Systems Division, Orlando, FL.
Harter, S. Pleasure derived from challenge and the effects of receiving grades on children's difficulty level choices.
Harter, S. Effectance Motivation Reconsidered: Towards a developmental model.
Heckhausen, H. Achievement motivation and its constructs: A cognitive model.
Heffernan, N. and Koedinger, K.R.
A developmental model of algebra symbolization: the results of a difficulty factors assessment.
Lomas D., Ching D., Stampfer, E., Sandoval, M., Koedinger, K. Battleship Numberline: A Digital Game for Improving Estimation Accuracy on Fraction Number Lines.
Conference of the American Education Research Association  12.
Malone, T. Toward a theory of intrinsically motivating instruction.
What Makes Things Fun to Learn?
Heuristics for Designing Instructional Computer Games.
The effectiveness of games for educational purposes: a review of recent research.
Ritter, F. and Schooler, L. The Learning Curve.
Developing Conceptual Understanding and Procedural Skill in Mathematics: An Iterative Process.
Task choice and assigned goals as determinants of task motivation and performance.
Behavior & Human Dec. Proc.
The Art of Game Design.
The Rise of the Super Experiment.
Sweetser, P. and Wyeth, P. GameFlow: a model for evaluating player enjoyment in games.
Towards optimizing entertainment in computer games.
