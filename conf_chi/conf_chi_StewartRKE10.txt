Pressure is an integral component of natural interactions with the environment.
Holding, twisting, turning, typing among many more manual interactions all are deeply connected with sensing pressure.
We learn from the sensation how good our grip is, how heavy objects are or how much resistance an object offers when acted upon.
Pressure plays a direct role in many familiar situations, for example in music, pressure leads to expressivity in playing stringed instruments.
In current interfaces pressure often plays a more discrete role.
Sufficient pressure needs to be applied to make keys of a keyboard register, or to perform clicks on a multi-touchpad.
On mobile devices pressure-sensitivity has numerous applications such as in expressive music applications  and in drawing applications  but also promises to enrich traditional input such as typing .
In general, pressure adds another dimension that can be accessed continuously without large hand motions and hence can be used in subtle ways such as pressure-based access control and providing depth to 3D object manipulations.
We conducted a series of experiments to understand fundamental aspects of pressure interaction with one and twosided pressure-sensitive mobile devices.
First we are looking to answer an unsolved question posed in the literature regarding the functional characteristic of pressure input.
It is unclear from the results shown in the current literature, if known deficiencies in pressure input are a result of human performance, sensor behavior, or a mixture of both.
We aim to clarify how linear sensor behavior improves the ability of users to control pressure input.
Furthermore we wanted to address the question of hand pose and interaction type.
That is, is there a difference in performance between pressure input against a solid surface or when an object is handheld, and is there a difference between single-sided  input and two-sided  input.
The results indicate that grasping outperforms single-sided input and is competitive with pressure input against solid surfaces.
This suggests that pressure input in a mobile setting is best delivered through a two-sided interaction paradigm.
Finally, an initial exploration of multimodal feedback to support nonvisual pressure input is presented.
This allows for pressure input on mobile devices with reduced visual presentation capacity and potentially eyes-free operation.
We compare the performance characteristics of visual, auditory, vibrotactile, and combined auditory and vibrotactile feedback.
The paper is structured as follows.
In the following section we discuss related work on pressure input.
We conducted a series of user studies to understand and clarify the fundamental characteristics of pressure in user interfaces for mobile devices.
We seek to provide insight to clarify a longstanding discussion on mapping functions for pressure input.
Previous literature is conflicted about the correct transfer function to optimize user performance.
Our study results suggest that the discrepancy can be explained by different signal conditioning circuitry and with improved signal conditioning the user-performed precision relationship is linear.
We also explore the effects of hand pose when applying pressure to a mobile device from the front, the back, or simultaneously from both sides in a pinching movement.
Our results indicate that grasping type input outperforms single-sided input and is competitive with pressure input against solid surfaces.
Finally we provide an initial exploration of non-visual multimodal feedback, motivated by the desire for eyes-free use of mobile devices.
The findings suggest that non-visual pressure input can be executed without degradation in selection time but suffers from accuracy problems.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Next we investigate various poses for handheld application of pressure and show them to work equally well as pressure applied to a device resting on a table.
Finally, we investigate multimodal feedback and chart the performance characteristics of different modalities.
We conclude with discussing possible applications, open issues and future work.
Pressure-based input with pens and styli has been explored in a substantial body of work.
In terms of controllability it has been shown that people do not keep precise pressure levels well without additional feedback .
They use continuous pressure to control the size of a circular cursor area and the zoom level for small targets.
An advantage of pen-based input is that it is easier to simultaneously apply pressure and move a pen on a screen.
With direct touch, friction between finger and touch surface quickly increases with pressure, making simultaneous movement strenuous.
Zliding is a joint pen-based manipulation of sliding and zooming at the same time using pressure .
Ramos and Balakrishnan  propose pressure marks, which are pen strokes with continuously changing pressure, as input for graphical user interfaces.
However, a number of popular handheld devices are designed for direct finger input and do not use pens.
Direct finger-based pressure input to a handheld device without a pen as a mediator has been explored as well.
The idea of using pressure for embodied interaction with devices has been formulated by Harrison et al.
Gummi  uses bending to control gradual transitions between views, transparency, and zooming.
The iPhone Sandwich  is a research prototype for two-sided multitouch sensing with continuous pressure input.
It consists of two iPhones and a pressure sensing layer between them .
Four forcesensing resistors  are located in the corners of an acrylic glass layer between the iPhones.
Three states are distinguished: A soft press invokes the first, a medium press the second, and a firm press the third character mapped to the key.
For large-scale finger-based multi-touch surfaces Benko et al.
This simulates pressure input but is not as precise as a pressure sensor such as a force-sensitive resistor .
Most pressure-based input techniques rely on continuous visual feedback.
The effectiveness of tactile feedback in mobile devices has been explored in .
EarPod investigated auditory feedback for eyes-free touch-interactions on mobile devices .
Typical applications for pressure input are widget control , menu item selection , expressive typing , conveying the urgency of phone calls , and zooming .
In the literature there are conflicting reports on what transfer functions from sensor values to input values yield best results for pressure input.
For example, Ramos et al.
They suggest choosing an adequate transfer function to counter this effect.
In , Ramos and Balakrishnan use a parabolic-sigmoid transfer function.
These results are in conflict with those reported by Srinivasan and Chen .
They performed a basic experiment on human performance in controlling normal forces of contact with rigid objects.
In contrast to other work they found that when visual feedback is present the error for keeping pressure at a certain target level remained approximately constant for all measured target forces.
However, it needs to be noted that it is difficult to make comparisons due to the wide range of different hardware being used.
In order to investigate controllability of pressure at different levels we conducted an experiment in which users had to keep pressure at a certain level for five seconds.
Users had to move to the target pressure level and then had to keep pressure at that level as precisely as possible.
The experiment used a 2x2x9 within-subjects factorial design.
The factors and levels were: * Pose: front-on-table, grip * Mapping: linear, quadratic * Target pressure: 9 levels  With three repetitions per trial, users had to perform 2x2x9x x3 = 108 trials.
In the "front-on-table" condition the device lay on the table and users operated the pressure sensor with their index finger.
In the "grip" condition users operated the pressure sensor by holding the device with their left hand and applying pressure with thumb and index finger of their right hand.
The order of presentation for mapping was counterbalanced.
Half of the participants started with fronton-table, the other half with grip.
As a pressure input device we used an iPhone Sandwich .
In order to get as precise sensor readings as possible we attached two additional force-sensing resistors  to the top and bottom display surfaces of the iPhone Sandwich.
All measurements in the experiments are based on readings from these two sensors.
We did not use the FSRs in the layer between the devices.
FSRs are not suitable for precision measurements, but the FSRs from Interlink  that we used in our experiments have good hysteretic properties and show sufficiently stable behavior over time such that their limitations do not play a role at the scale of our experiments.
The external FSRs are connected to the analog input pins of an Arduino1 board via a voltage divider or an opamp-based circuit described below.
For the voltage divider the resistor was tuned to provide the best dynamic range and sensitivity for the pressure readings.
The Arduino board provides the digital sensor output via a serial connector to the iPhone Sandwich.
The update rate was set to 30 Hz with a resolution of 8 bits.
Users held the iPhone Sandwich in landscape orientation.
The FSRs were vertically centered and attached about 3 cm from the right edge of the devices to be easily reachable with the thumb and index finger, respectively, of the right hand .
The raw sensor values were slightly filtered using a Savitzky-Golay filter  to reduce noise.
The target pressure was represented as a value ranging from 0.1  to 0.9  where 0 means no pressure and 1 corresponds to maximum pressure.
The maximum pressure was empirically determined in pilot tests to be easily reachable.
The target pressure was visualized as a vertical bar on a horizontal scale displayed on the screen .
The left edge of the screen represented zero pressure; the right edge represented maximum pressure.
The horizontally moving pressure cursor provided continuous visual feedback on the current pressure input.
The target pressure was set in increasing order in steps of 0.1.
The duration of one step was 5s, after which the pressure target advanced to the next step.
We allowed 2s to move to the next level and computed the variation of pressure input around the target during the remaining 3s.
The standard deviation was used as a measure of pressure stability.
Pressure was presented in increasing order to have fixed pressure deltas from one to the next step.
We were not interested in the time to transition to the next level, but in how precisely users could hold up pressure at a particular target level.
Five of the six participants preferred the grip condition to the front-on-table condition, stating, e.g., that grip was more precise for lower pressures and that it allowed them to more easily reach high pressure levels.
One participant had no preference.
Four of six participants mentioned that pressure was more difficult to control for low pressures.
Two participants found it strenuous to hold pressure over several seconds at the higher pressure levels.
The quantitative results are shown in Figure 2.
The graphs show the median variability over the last 3s of each 5s step.
This was computed as the median of the standard deviations for each condition.
These results clearly show that variability increased at lower pressure levels and these results are similar to those reported by .
In order to investigate why variability increased at low pressure levels, we looked at the weight-to-sensor value mapping introduced by our setup.
We placed the FSR on an electronic scale, placed a piece of rubber the size of a fingertip on top of the FSR, and put a range of weights on top .
We then noted the reading of the electronic scale and sampled the sensor output over two seconds.
The resulting curves are shown in Figure 3.
The characteristic of the opamp circuit was measured in the same way as described above.
Figure 5 shows the normalized linear mapping as well as the quadratic mapping.
The blue curve shows the pressure range linearly rescaled from 0 to 1 , the red curve shows the result of the quadratic mapping.
It can clearly be seen that the blue curve is not linear but steeper for lower pressure values, i.e.
The quadratic mapping shows a flatter slope for low pressure values.
For the linear mapping this means that user input variability at a low pressure value will be translated into a larger variability in the sensor output than the same input variability at a higher pressure level.
In order to compensate for this characteristic of the FSR and voltage-divider circuit one would have to use a mapping that is the inverse function of the resulting logarithmic characteristic, which would be an exponential function, in this case x = exp/0.3144.
As we wanted to use the resolution of the sensor to its full capacity we decided to build a new hardware setup in which the hardware already provides linear sensor input.
We used an opamp-based current to voltage converter .
The R transfer function of the voltage divider is Vout = R+R * F SR Vin , hence a voltage divider does not simply create a linear relationship between resistors R or RF SR and the output voltage .
This is also noted in documentation of the force sensing resistor , who propose a current-to-voltage circuit to achieve a linear relation.
The operational amplifier has two defining characteristics.
One is that the impedance between the two inputs is very high and theoretically often treated as infinite.
This has the effect that there is minimal load on any circuit placed left of the opamp.
The second characteristic is that the output impedance is very low which makes the circuit insensitive to load or energy demand at the output.
The operational amplifier will amplify the output as needed to achieve these properties.
This makes this element very versatile for building a range of analog circuits .
To understand the current-to-voltage converter of Figure 4 note that the input impedance is such that practically no current will flow into the input.
Hence all current at the negative input will instead flow across the resistor connecting to the output.
Hence the output voltage simply obeys Ohm's law taking the negative polarity of the input into account.
We repeated the above experiment - holding a particular pressure level for 5s - with 6 participants, this time only using the grip pose.
We compared both hardware setups in this test.
For the voltage divider hardware we used the exponential function derived above to linearize the input before applying the transfer function.
For both hardware conditions we tested a linear and a quadratic transfer function.
The experimental factors thus were hardware  and transfer function .
Otherwise the experimental task was identical to the one described above.
The results of the input variability are shown in Figure 6.
For both the old hardware  and the new hardware  the linear transfer transfer function works better than the quadratic transfer function.
The reason is probably that the quadratic function over compensates the already linearized sensor input.
Moreover, comparing the linear mappings for the old and new hardware, one can observe that there is an advantage of the new hardware.
This is probably due to the better use of the dynamic range of the setup.
Overall these results are in line with Srinivasan and Chen's  findings in that human ability to control pressure seems to be uniform for a wide range of pressure levels.
The test subjects performed significantly better with a linear sensor than with a non-linear sensor.
A linear transfer function works better than a quadratic transfer function if the sensor data is a linear mapping of the input force.
The results reported in the literature may be due to the use of non-linear pressure sensors.
Traditionally, pressure-based input assumes that the device to which pressure is applied is resting on a stable surface.
Examples are pressure-sensitive pen input to tablet PCs or graphics tablets.
Pressure-based input for stationary devices has been explored, for example, in .
Applying pressure to mobile devices when handheld is a challenge and has not been extensively researched.
Moreover, many pressurebased interfaces assumed a pen or stylus to apply pressure .
However, many current mobile devices allow direct finger input.
Device poses tested for handheld pressure input:  index finger on front, device resting on table ;  grip with thumb and index finger;  thumb on front;  index finger on back.
Changing pressure moves the cursor on the horizontal line.
The red rectangle indicates the target pressure and target width.
We therefore investigated direct finger-based pressure input for handheld devices.
The objective was to find out which ways of holding the device when applying pressure, i.e.
As a baseline, we also compared a device resting on a table with a device held in hand.
We were interested in how quickly and accurately users can control pressure they exert with one or more fingers on the device and what pressure range is useful for interaction.
In particular, we investigated user performance of pressure-based input under the following poses : * Index finger on front of device, device resting on table  * Thumb on front and index finger on back of device, device handheld  * Thumb on front of device, device handheld  * Index finger on back of device, device handheld 
As above, the target pressure was represented as a value ranging from 0.1 to 0.9 where 0 means no pressure and 1 corresponds to maximum pressure.
The pressure input was linearized using the hardware described in the previous section.
The pressure was measured using two FSRs, one attached to the front and one to the back display of the iPhone Sandwich.
The device was held in landscape orientation.
The FSRs were vertically centered and attached about 3 cm from the right edge of the devices to be easily reachable with the thumb and index finger, respectively .
The raw sensor values were slightly filtered using a Savitzky-Golay filter  to reduce noise.
The left end of the bar corresponded to zero pressure, the right end to maximum pressure.
Continuous visual feedback was provided on the device display.
As the user increased pressure a vertical line cursor moved along the bar.
The target was shown as a red rectangle on the bar.
The target was selected by keeping the cursor within the target rectangle for the dwell time of 1s.
Selecting the target ended the trial and the target moved to the left end of the bar .
The user had to release pressure and wait for one second after which the next trial would be started at the new target position.
The order of presentation of the four device poses was counterbalanced using a latin square design.
The order of target widths was counterbalanced within the poses.
The distances were presented in three blocks.
Within each block the nine distances  were presented in random order.
This amounts to 4 poses x 2 widths x 3 distance blocks x 9 distances per block = 216 trials per user.
We measured the time required for selecting a target and logged the pressure sensor values over time.
The mean selection times  are: 3.14s for front on table, 2.91s for grip, 3.74s for front, and 3.42s for back .
The selection times are roughly log-normally distributed.
A repeated-measures ANOVA on the log-transformed data shows that these differences are statistically significant .
Bonferroni corrected post-hoc comparisons between all pairs show a difference between front and the other poses, but not among the other poses.
The mean values suggest that handheld pressure application, specifically for the grip posture is not disadvantaged compared to pressure application against a solid surface.
Wide target selection more strongly differentiates the results.
Front hand-held shows up to a factor of 3 degradation in time-to-target compared to grip for low pressure values .
We also asked users which of the poses they preferred.
Six of twelve users preferred grip, 3 index finger front-on-table, 2 index finger on back, and 1 user preferred thumb on front.
The results show that pressure-based selection is possible in reasonable selection times, even with 9 targets equally distributed on the pressure range and with fairly narrow target widths.
Physiologically the sensations of touch and pressure are due to the deformation of mechanoreceptors located in the skin.
While many types of mechanoreceptors exist and are involved in touch sensation, Merkel nerve endings are specifically involved in the sensation of pressure .
Pressure input for interfaces is difficult as humans are not adept at distinguishing absolute pressure values .
When the hand is pressed against an object the just noticeable difference  in contact force is about 7% .
The JND for distinguishing among different weights is about 10% .
The performance for memorizing absolute pressure levels is even lower.
Therefore additional feedback of applied pressure needs to be given to allow users to exert control over pressurebased input.
Currently visual feedback is preferred for pressure-based interfaces as it is the feedback modality that offers the most communication bandwidth between the user and interface.
However the use of visual feedback in mobile scenarios may cause users to be less aware of the visual cues alerting them to dangers in their environment.
EarPod  is an example of a system designed to alleviate the use of visual feedback.
Additionally, eyes-free interaction using pressure input can reduce the amount of screen space that is required for traditional widgets.
While non-visual feedback has been examined for pen-based pressure input , much remains unknown about the design and application of non-visual feedback for pressure input.
Hence we chose to examine a variety of multimodal feedback consisting of audio feedback, audio presented with additional tactile feedback, and tactile feedback by itself.
Continuous visual feedback has been identified as being important for fine control over pressure-based widgets .
However the design of continuous non-visual feedback is difficult as users adapt to stimuli and thus become less sensitive to changes .
Sensor modalities have their particular characteristics.
While it is difficult to control for these differences, we aimed to design feedback across different modalities is such a way that exposure time is normalized.
That is, sensory stimuli should be presented for roughly the same duration in all cases.
The audio feedback condition was expanded by adding small short vibrations from the pager motor of the SK6 Shake device .
When each note was played a small vibration lasting 40 milliseconds was played alongside the audio cue.
This bimodal approach has been used by  to increase user performance when interacting with on screen keyboards.
This observation coincides with annoyance of persistent exposure reported in .
Therefore, we reduced the amount of feedback presented to the user.
Feedback is only given on the transition from one pressure level to the next  rather than continuously with changes in the pressure input.
With this constraint on feedback it was felt that it would be unfair to test the non-visual feedback with a large number of pressure levels.
Previous studies such as PreSenseII  or PressureText  also chose a relatively small set of distinguished pressure levels.
In certain applications this is justifiable.
Mode selection, for example, typically only needs a few distinct states.
Using pager motors to create distinguishable vibration patterns is difficult.
Having only intensity control of the vibrations reduces the design space to make vibrations that are both short in the time it takes to play them and that are easily distinguishable.
After informal testing we decided on the following 3 vibration patterns; one short pulse, a series of pulses with decreasing intensity and two short pulses .
This had the effect of a sharp sensation for the first pressure level, a soft, pulsing sensation for the middle pressure, and two sharp sensations for the final level.
All of them were righthanded.
The task was to reach a certain target pressure level, with the target pressure level presented in the modality being tested.
The subject was tasked with matching the target feedback given with the feedback produced when they moved from one pressure level to the next.
Then the subject would apply the pressure that produced the matching short pulse feedback.
For each modality we tested each pressure level in ten separate occasions.
The target pressure levels were presented in a randomized order.
The subject would select the pressure level by holding the cursor in the same position for 1s.
The pressure sensor was placed underneath the thumb of the subject.
During initial tests subjects found it difficult to recognize the note presented for both the audio and bimodal conditions.
To alleviate this issue the target note was played five times in quick succession in the final experiment.
No other issues about presentation of the target feedback were reported or observed.
We measured both the discrete pressure levels and raw sensor values along with the time taken to select the target for each trail.
A two-factor repeated-measures ANOVA was performed on the accuracy  and selection times  for each condition and for each pressure level.
Accuracy is the rate of correct selection.
A Bonferroni post-hoc multiple comparison revealed a significant difference in accuracy between target pressure levels 2 and 3 .
There was also a borderline significant difference between audio and vibrotactile feedback .
From the study we see that users do not generally slow down in their interactions when using other modalities, however this is to the detriment of accuracy.
Looking at the confusion matrices  we see that the center condition is more prone to errors than the states at the extremities.
In the case of the maximum pressure level this can be explained by being able to lock into the level by exceeding the upper threshold.
So this condition is indeed easier, independent of the feedback modality.
It is noteworthy that we do not see any strong effect when mixing modalities.
The design of the experiment did now allow a learning effect to occur from the outcome of each trial.
Beyond the tactile feedback we did not provide feedback on whether the correct target was selected.
In the experiment learning could only occur from the users' exploration of the pressure range and the feedback that was played on the level transitions.
The accuracy of the results stated above are a lower limit that can be improved by providing feedback on the outcome of the task and by optimizing the distinguishability of the feedback.
One key issue in creating pressure-based interfaces is the tight coupling between pressure applied by the user and the feedback given.
Our results suggest that with an improved sensor, yielding a linear relationship between pressure applied and sensor readings, the issue of non-visual feedback can be properly addressed in relative isolation.
The results show that vibrotacile feedback with a relatively simple pager motor is not sufficient to achieve high accuracy rates.
If the object upon which pressure is exerted slightly changed its shape when pressed, this might serve as additional feedback that helps users to estimate the amount of exerted pressure.
We intend to study various deformable materials and compare their pressure input characteristics with rigid materials.
This work suggests a number of future directions.
For one, pressure adds a further dimension to be represented in graphical user interface elements.
Pressure widgets  already go in this direction but finger-based localized two-sided input suggests further expanding this idea.
We are interested in the development of squeezable widgets, which we call "squidgets," that combine the information provided by pressure widgets with the high degree-of-freedom of local twosided interactions.
Such interactions include local rotations and two-sided sliding.
An advantage of the use of pressure is that it requires very little motion and hence does not lead to dynamic change in occlusion of the display.
For example UI elements can be placed in the periphery of the display and through the pressure dimension still allow continuous input.
We also intend to investigate two-handed pressure input, in which one hand performs the tasks of holding the device and performing "grip" pressure input, while the other hand performs touch input.
This can lead to an interesting division of labor of both hands in two-handed tasks.
While design issues still need to be addressed, the concept of using pressure input is appealing.
One key property of pressure input is the difficulty of observation by onlookers.
This suggests that pressure may be a good input modality for applications in the domain of privacy and safety.
For example one can envision authentication to be executed via pressure gestures, which we call "prestures."
We suggest the use of subtle tactile feedback while the device is in the user's hands will be much harder to observe than the finger motions required to select keys for alpha-numeric password entry on a keyboard or touchscreen.
Mobile devices can be operated on with different hand poses.
Also, the particular touch input paradigm may dictate which of these poses are desirable or ergonomically likely.
We may interact with the device from the front, or the back or from both sides at once.
Comparing these possibilities and also pressure applied to a device laying on a solid surface, we show that two-sided interaction has a slight advantage in selection time and is preferred by the users.
We investigated auditory and tactile feedback to chart the performance for eyes-free use of pressure input.
Non-visual modalities are beneficial in mobile situations, since they allow the user to keep visual attention to cues in the environment.
The study shows no degradation in selection time but a loss of accuracy for these modalities, which we quantify in our study.
Overall, pressure input via force-sensing resistors is linear if properly conditioned.
Two-sided "grip" interactions work best for handheld pressure input and non-visual feedback does have performance degradation against the visual modality.
With these foundations established, we are working to develop higher-level applications and constructs for pressure input.
In particular we are preparing pressure-based gesture vocabularies similar to motion-based gestures.
These can be used in subtle, unobservable ways, suggesting a use in authentication or privacy-sensitive applications.
Furthermore we are interested in expressive use, such as mobile music performance with mobile devices and pressure is an attractive dimension in this setting.
Finally, pressure adds to the dimensionality of input and hence is attractive for applications where many dimensions are manipulated at once, such as 3D editing environments.
In this paper we addressed finger-based pressure input on mobile devices.
Pressure input offers an additional local dimension to touch input and hence offers an array of interaction possibilities.
Because the interaction can be performed without moving the fingers it is a particularly attractive dimension to use when screen real estate is precious or when finger-motion is not desirable.
Pressure sensors can invisibly be embedded below the device casing but can still help to emulate the experience of a physical button.
We conducted a number of experiments to explore several fundamental properties of these finger-based pressure interactions.
The results on transfer functions for pressure input clarify a longstanding discussion in the area.
Literature explored various functions such as linear, quadratic, fisheye, and parabolicsigmoid.
We show that it is important to consider the sensor characteristics first before picking mapping functions and show that with proper sensor use through load-decoupling with an operation amplifier, linear mapping works best in experiments.
