An experiment was conducted to study how credibility judgments about Wikipedia are affected by providing users with an interactive visualization  of article and author editing history.
Overall, users who self-reported higher use of Internet information and higher rates of Wikipedia usage tended to produce lower credibility judgments about Wikipedia articles and authors.
However, use of WikiDashboard significantly increased article and author credibility judgments, with effect sizes larger than any other measured effects of background media usage and attitudes on Wikiepedia credibility.
The results suggest that increased exposure to the editing/authoring histories of Wikipedia increases credibility judgments.
Wikipedia and Encyclopedia Britannia was that the study found little substantial difference in accuracy between the two sources, and this ran counter to the conventional wisdom of what makes for superior quality reference information.
Additional studies  indicate that many Wikipedia articles are judged as credible by experts, yet there remains wide-spread skepticism.
If high credibility information is the aim of Wikipedia , then it is important that users efficiently perceive the credibility of the contributed content.
Most of the more popular Wikipedia articles have a complex history of edits and revisions by many editors.
Some historical data are available through tabs at the top of Wikipedia article pages , which can in turn lead to data about users .
The "standard" wiki interfaces make such historical data available, but many navigation steps are required to gain a general sense of the article history, and the history of its editors.
Users' credibility assessments could be enhanced by better support for making sense of the editing and article histories.
WikiScanner1, WikiRage2, and History Flow3, are all systems that attempt to provide user interfaces that improve on the standard wiki interface and provide greater transparency about the history of Wikipedia articles.
The WikiDashboard tool  is an interactive visualization that is expected to improve the ease with which users can access and make sense of data about articles and editors.
Here we investigate how the use of WikiDashboard affects credibility judgments about Wikipedia articles and authors.
Wikipedia...is the best thing ever.
Anyone in the world can write anything they want about any subject.
So you know you are getting the best possible information.
Although Wikipedia is popular, it has, in its short history, been the target of skepticism  about the quality of its content and contributors.
The conventional stereotype many people have had about great reference works such as encyclopedias was that they were the products of highly reputable experts writing about the things they had devoted their lives to understanding.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
WikiDashboard  was developed to provide users of wikis with improved access to cues about the editing history of Wiki articles and their editors.
WikiDashboard provides visualizations embedded within Wikipedia pages, along with the live content from Wikipedia.
The prototype can be used just as if users are on the Wikipedia site itself.
The prototype provides two types of dashboards:
Article Dashboards , which are embedded within articles and which display aggregate edit activity graphs representing the weekly edit trend of the article, followed by a list of the top active editors for that page.
The active users of the article are ordered by the number of edits they have made.
A weekly edit activity graph for each editor on the right side of the dashboard enables users to investigate when the edits by that editor were made.
User Dashboards , which are embedded within user pages, which display information relating to a user.
In WikiDashboard, each user page has a User Dashboard embedded, displaying the article contribution and editing patterns of that user.
The top summary graph shows the editor's weekly edit activity, which allows users to easily examine the editor's overall edit patterns.
The summary graph is followed by the list of Wikipedia pages on which the editor has made edits.
The list is ordered by the volume of contribution and includes the corresponding articleeditor activity graphs on the right side.
Empirical studies of credibility judgments typically attempt to assess participants' credibility judgments about the information itself , the sources , or the media .
We build upon the work of Chesney  who developed credibility questionnaires as instruments for measuring judgments of article credibility and author credibility.
We also included a battery of questions to assess media usage patterns and attitudes to determine if these preexperimental biases also influence Wikipedia credibility judgments.
That work used two artificial representations designed to convey what the researchers hypothesized would be "high trust" or "low trust" cues .
These two visual representations were contrasted with a norepresentation baseline condition by associating the representations with articles.
As hypothesized, the "high trust" visualization boosted "trust" assessments relative to the baseline no-visualization condition, whereas the "low trust" visualization decreased "trust" assessments.
The current experiment extends that result in several ways.
First, in the current experiment the fully interactive WikiDashboard provided representations of the actual article and editor histories .
Second, WikiDashboard was contrasted with a baseline condition in which users were encouraged to interact with the same editing history data available via the standard wiki interface.
Third, questions culled from prior credibility research were used to assess both article and author credibility, which is a broader construct than just trust assessment.
Finally, the current experiment related the credibility assessments to users' background knowledge and beliefs.
Modern research on credibility dates to the work of Hovland  and can be found in fields including psychology, communication, marketing, management, information science, and human-computer interaction.
With the rise of online media, such credibility research has included the Internet , the Web , and Wikipedia .
Rieh and Danielson  provide a comprehensive review across disciplines.
Historically  two core components of the hypothetical construct of credibility have been  expertise and 
Across two groups, we contrasted the use of the WikiDashboard + Wikipedia against a baseline control condition involving just the Wikipedia interface.
We also tested  two kinds of articles  Skeptical articles that had been independently identified as being of skeptical credibility and  non-Skeptical articles of equivalent lengths were not on the skeptical list.
This results in a 2  x 2  mixed factorial design.
If the Skeptical vs Non-skeptical manipulation produces differences on our credibility judgment tests then we have some confirmation for the test validity.
In addition, the interaction  with the Wikidashboard vs No-Wikidashboard factor allows us to determine if Wikidashboard polarizes further  the differences between Skeptical and Non-skeptical credibility judgments.
Wikipedia history, discussion, and user tabs.
This was done using a Wikipedia article for San Francisco.
Users also practiced answering all of the article and author credibility questions.
During the main phase of the experiment, participants went through six trials.
On each trial they read an article, interacted with WikiDashboard or the standard wiki interface, and then answered the 12 credibility questions.
A total of six articles were presented to each participant.
Three Skeptical articles were chosen from a list on the WikiProject Rational Skepticism page on Wikipedia: universal intelligence, grapefruit seed extract, and extrasensory perception.
Three Non-skeptical articles of similar lengths were selected from the WikiProject Germany page of Wikipedia: Leipzig, Dresden Frauenkirche, and Chancellor of Germany.
The credibility tests both showed high internal consistency: author credibility test Cronbach's  = 0.79 and article credibility test Cronbach's  = 0.77.
For the remainder of our analyses credibility scores were computed as the means of the item scores making up each credibility test.
We employed a technique recommended by Snell  to transform the raw Likert reponses to better fit the assumptions required for our statistical analyses below.
Table 1 presents the mean credibility scores for the two different types of articles .
Article type had no interactions with the No-WikiDashboard vs WikiDashboard factor on article or author credibility.
Given this lack of interaction, the remaining analyses on effects of the WikiDashboard pooled together credibility scores on the different types of articles.
We discuss this lack of interaction further in the conclusion section.
Table 2 presents the credibility scores for the interfaces.
The absolute differences appear small, but the WikiDashboard credibilities are greater, as we shall discuss.
Preliminary exploratory factor and correlation analyses showed relations between media usage patterns and the credibility tests, we performed an analysis of covariance to test the effects of WikiDashboard that included background and media usage responses as covariates.
Tables 3 and 4 present results from analyses of covariance of the mean article and author credibility scores.
The linear models for each type of credibility scores included the interface type  and all of the Media Questionnaire responses .
For brevity, only the marginally significant and statistically significant effects are presented.
The use of WikiDashboard produced statistically significant increases in article credibility and a borderline significant  increase in author credibility.
Interestingly, users who report higher use of the Internet as an information source have statistically lower credibility scores for Wikipedia author and article credibility.
Article and author credibility was assessed with a set of 12 questions derived from prior credibility studies .
An article credibility test was composed of six article credibility questions that asked users to rate the following on a 5-point Likert scale ranging from 1="strongly disagree" to 5="strongly agree:" Each of these questions began.
An author credibility test was composed of six author credibility questions that asked users to rates on a similar 5point Likert scale, "I perceived the writer to ...":  "be credible",  "have high integrity", , "have positive reputation",  "be trustworthy",  "offer information of superior quality", and , "be prestigious."
Media usage patterns were assessed using 5-point Likert scale items.
Usage rates of computer, Internet, email Wikipedia, search, and word processors, was queried using 6-point Likert scale items.
Attitudes towards information sources, including textbooks, Internet, newspapers, television, radio, and magazines, , were assessed using 5-point Likert items.
The boost to credibility incurred by WikiDashboard use is greater than the negative impact of these background biases.
Prevalent skepticism among the public remains about the credibility of Wikipedia articles despite studies  that suggest that much of the information is of high quality and reliability.
WikiDashboard was designed to provide improved access to article and author editing histories and we found that use of WikiDashboard increased credibility judgments about Wikipedia articles and authors.
The market for "lemons": Quality uncertainty and the market mechanism.
Chesney, T. An empirical examination of Wikipedia's credibility.
How do users evaluate the credibility of Web sites?
Giles, J. Internet encyclopaedias go head to head.
Communication and persuasion, New Haven, CT: Yale University Press, 1953.
Kittur, A., Suh, B. and Chi, E.H. Can you ever trust a Wiki/ Impacting perceived trustworthiness in Wikipeda 2008 ACM Conference on Computer Supported Cooperative Work, CSCW 2008, ACM Press, San Diego, CA, 2008.
A scaling procedure for ordered categorical data.
WikiDashboard use equally increased the credibility judgments about articles designated as Skeptical or nonSkeptical.
It seems likely that the lower credibility scores for the Skeptical articles reflect pre-experimental biases about the subject matter  and this baseline credibility was improved by WikiDashboard exposure to the article and author histories.
Wikidashboard did not increase the polarization of judgments about Skeptical and non-Skeptical articles and authors, and one might question whether such as a tool is useful if it is increasing the credibility of an article whether it is a topic that can attract skepticism  or not .
One interpretation might be that Wikidashboard actually decreases critical reading.
However, both groups were motivated to read critically and both groups had training on using the standard edit history information.
The Wikidashboard group had additional UI representations of the crucial information.
We suspect that the increase in credibility judgments is some variation of effects predicted for information asymetry in "lemon markets" in economics : When presented with a highquality good about which they have little information, consumers will tend to initially expect the quality to be lower.
Providing them with more information signals about a high quality good will raise their expectations of quality.
Wikidashboard provides all the information available in the "baseline" case, plus the additional information in the visualization.
Our Media usage and Attitudes questionnaire suggested that people who frequently use the Internet and Wikipedia have a tendency to have lower credibility assessments of Wikipedia articles and authors.
