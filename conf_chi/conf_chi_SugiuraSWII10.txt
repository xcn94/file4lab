We propose a cooking system that operates in an open environment.
The system cooks a meal by pouring various ingredients into a boiling pot on an induction heating cooker and adjusts the heating strength according to the user's instructions.
We then describe how the system incorporates robotic- and human-specific elements in a shared workspace so as to achieve a cooperative rudimentary cooking capability.
First, we use small mobile robots instead of built-in arms to save space, improve flexibility and increase safety.
Second, we use detachable visual markers to allow the user to easily configure the realworld environment.
Third, we provide a graphical user interface to display detailed cooking instructions to the user.
We hope insights obtained in this experiment will be useful for the design of other household systems in the future.
We foresee that next generation electric household appliances  should execute more advanced tasks in an open environment that is shared with users.
For example, it might be nice to have a laundry system that collects clothing in a basket, washes and dries it, and puts it in a closet.
We are developing a cooking system as an initial example of such household systems.
Cooking in a closed environment consumes too much space for typical home kitchens.
We, therefore, designed a system that works in an open environment.
When using the system, the user puts preprocessed cooking ingredients on the table and has small robots execute the cooking tasks using a pot on an induction heating  cooker.
When not using the system, the user can cook on the same table using the same cooker.
Consideration to human factors is critically important for the successful deployment of such open household systems.
They must be safe and able to adapt to dynamic changes of the environment because they share the space with the user.
They also must provide an appropriate user interface for controlling complicated real-world tasks.
We address these issues in the design of our cooking system.
First, we use small robots instead of built-in arms to save space and increase safety.
They are also designed to use common cooking utensils.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
The user can easily add and remove these markers to associate real objects with virtual information in the system.
Third, we provide a graphical user interface for giving cooking instructions to the robot.
The user can control the robots, by instructing them when to add each ingredient to the pot, and the strength of the cooker.
There have been studies on user interfaces for household systems working in an open environment.
Interfaces and interaction systems for giving instructions to home robots have been proposed in the field of human-computer interaction , such as a sketch-based house cleaning instruction interface , non-explicit instructions using a set of special cards , a robot-controlling interface with a laser pointer .
Tangible interfaces are becoming popular in research on controlling robots .
Cooking support systems have been proposed such as a cooking navigation system , cooking training system using virtual reality , and an interactive recipe-creating support system .
Furthermore, a robot that supports the user's cooking by suggesting the next actions to take by voice and gestures have been proposed .
However, most tasks in these systems are limited to relatively simple ones such as robot navigation and object retrieval.
We believe that a graphical user interface is a better method for giving cooking instructions to robots.
A state-of-the-art humanoid robot has demonstrated partial cooking tasks .
However, the user has to write a program for instruction.
We developed our system to cook in a realworld environment, and make "cooking with robots" a reality with a graphical interface.
Cooking starts by selecting a desired recipe in the recipe book .
It comes with a list of necessary ingredients, each of which contains instructions for preprocessing and a visual marker.
The user preprocesses  the ingredients according to the instructions, puts them on a plate, and places the corresponding visual marker on the plate .
These instructions are included with the recipe.
The user also pours water in a pot and places it on the IH cooker.
S/he then presses the start button to start the system cooking.
The system then puts the ingredients into the pot one by one and adjusts the heater strength according to the predefined procedure and notifies the user upon completion.
The user can also define a new recipe.
S/he first preprocesses the necessary ingredients, places them and the appropriate visual markers on the plates.
The system comes with a set of visual markers for common ingredients 
User then defines the cooking procedure, which is, what ingredients to use and how to adjust the heat using a graphical user interface.
The timing for adding ingredients is defined by dragging and dropping corresponding icons on the screen to the first timeline .
The user can put multiple copies of an icon to ask the system to add them by portions into the pot.
Figure 2 shows an overview of our system, called Cooky.
Several small mobile robots on a customized table add ingredients and seasonings to a pot on an IH cooker.
The ingredients are placed on customized plates, and the seasonings are in customized bottles so that a robot can handle them.
The location of the robots, plates, and bottles, are tracked using visual markers attached to them and with a ceiling camera.
The robots, the IH cooker, and the camera are all connected to a controlling PC.
The system comes with a special recipe book and a graphical user interface for observing the progress and giving customized instructions to the system.
Figure 5: Cooking instruction interface.
We created a special table and placed it higher than the pot so that the robots can easily pour ingredients and seasonings.
We also created special plates so that the robots can handle them and the user can place a visual marker on it .
The plate has handles around it for grabbing and a pole at the center for placing markers.
The IH cooker is a modified version of a commercial model , inside which we implanted a micro controller circuit and Bluetooth communication module for controlling the temperature level remotely.
We carefully designed the environment so that the user can also cook without using the system.
The user can use the table as a working space and put ingredients on the same plates.
The user can also use the same bottle for seasonings and the same utensils for stirring the pot.
The IH cooker and pot are of course usable in manual cooking.
We have developed three types of customized small mobile robots, one for transporting the ingredients on plates, one for transporting seasonings in bottles, and one for stirring the pot .
The first robot grabs a plate using a single arm, moves to the pot, and tilts the plate to drop the ingredients into the pot.
The second robot grabs a bottle by using a hand with two fingers, moves to the pot, and shakes the bottle to sprinkle the seasoning into the pot.
The amount of the seasoning is specified on the interface by dragging a seasoning icon multiple times.
The stirring robot stirs the pot at appropriate times.
Before cooking begins, the user needs to select and attach a cooking utensil to the robot.
These robots do not have any sensors and are wirelessly  controlled with the control computer.
Small mobile robots carrying plates and bottles are more appropriate than built-in arms and containers because a user can store them in a cabinet when s/he cooks in the same environment without using the system.
The system uses a vision-based robot control mechanism  in which a central control server both tracks the position of robots and objects on table by using a ceiling mounted camera and simultaneously controls the robots wirelessly.
We chose visual markers instead of marker-less recognition or invisible markers because visual markers work as a good user interface for recognizing and editing associations between physical objects in the real world and virtual information in the computer.
We tested the developed system by recruiting a student from our research lab as a test user.
He has very little cooking experience, but has good computer skills.
We asked the test user to make a traditional Japanese dish, "pork miso soup" by following the recipe.
Before using the system, the test user was asked to preprocess all ingredients as per the recipe; cubes of meat, radish, sliced carrot, burdock, sliced potato, arum root, and miso, a Japanese pasty seasoning.
As for the radish, carrots, burdock and potatoes, which require the same cooking time, they should be placed on the same plate.
The miso paste is mixed with water and poured into a cup because it takes time to dissolve in the pot.
The other ingredients were placed on separate plates, and the related visual markers were attached.
Before starting the test run, 500 ml of water was added to the pot, which was placed on the IH cooker.
As shown in Figure 4, the user set up the cooking instructions according to the given recipe and pressed the start button to start the actual cooking task .
The robots succeeded in adding the ingredients and stirring the pot according to the timeline and finished cooking.
Furthermore, we confirmed that the user was able to terminate the system safely when an unexpected failure occurs or a dangerous situation is detected.
The test user successfully made a meal with Cooky.
The "cooking with robots" concept involves a user preprocessing, such as chopping\slicing ingredients, putting them on plates with visual markers, and dissolving the miso paste.
This may be annoying to some; however, we believe it is a natural and practically feasible interaction for collaborating with robots.
Forlizzi reported that end-users naturally help home robots in the home environment .
We believe that cooking is an ideal situation for humanrobot collaboration, and our prototype system stimulated this natural collaboration.
We believe that the design of individual features and capabilities of our system can scale to and be useful for the design of a wide range of real world systems, particularly where people and robots must work together.
During the test run, we observed the following problems with this system.
An ingredient could not be dropped into the pot because it got stuck on the plate.
Adding a vibration function to the robot arm can eliminate this problem.
The robots were slow because the system used a vision-based object detection system.
It was not possible to specify an exact amount of seasoning due to the limitation of the robot hardware and the user interface.
Current implementation of Cooky only addressed cooking with a pot.
It is easy because the robots just drop ingredients, pour water, and stir the pot.
However, the robots might be able to cook with pans, grills, and ovens if the hardware is available.
The interface for giving cooking instructions can adapt to these situations.
We proposed a cooking system in a shared cooking environment with the user, called Cooky.
The system uses recipes, which include cooking instructions and visual markers; for simple cooking tasks.
The user gives cooking instructions to the system such as timing for the ingredients adding, stirring a pot, and controlling an electric cooker.
Also, we developed small robots for the actual cooking tasks.
The robots perform their tasks according to the user's instructions.
We tested the system and confirmed that it successfully cooked a meal with given instructions.
