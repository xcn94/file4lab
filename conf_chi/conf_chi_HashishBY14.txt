We present an approach to content control where parents and children collaboratively configure restrictions and filters, an approach that focuses on education rather than simple rule setting.
We conducted an initial exploratory qualitative study with results highlighting the importance that parents place on avoiding inappropriate content.
Building on these findings, we designed an initial prototype which allows parents and children to work together to select appropriate applications, providing an opportunity for parents to educate their children on what is appropriate.
A second qualitative study with parents and children in the six to eight year-old age group revealed a favorable response to this approach.
Our results suggest that parents felt that this approach helped facilitate discussions with their children and made the education more enjoyable and approachable, and that children may have also learned from the interaction.
In addition, the approach provided some parents with insights into their children's interests and understanding of their notions of appropriate and inappropriate content.
One modern challenge is that there are an increasing number of devices connected to the internet, providing gateways to unfiltered content that many parents want to control.
There are a number of existing tools designed to help parents limit their children's exposure to inappropriate content, for example, Net Nanny, or CYBERsitter for PC web browsers, or child-friendly filtered versions of tablet software such as Netflix's children's area or Apple's preconfigured adult filter on the iPad.
A common feature of these tools, however, is that they rely on sets of rules created and maintained solely by parents  and are not designed with the intent of involving children in the process; as such, there may not be an opportunity to help the children understand the restrictions placed.
We present an alternative approach to content control which includes the child in the process of setting filters, thereby facilitating a collaborative and discussion-oriented parentchild opportunity for educating about issues surrounding appropriate and inappropriate content.
This provides an opportunity for children to voice their opinion in decisions.
For example, a child may want to point out that a game is popular with their friends' parents, thus inclining the parent to examine it more closely.
This involvement of children in the process builds from pedagogy and psychology research showing how educating young children about rules and morals, and to some extent helping them form their own opinions, may be more effective than simply creating and enforcing rules without explanation .
Involving children also aligns with the Positive Youth Development framework, which suggests that providing structure, positive norms, and opportunities to be involved can support youth in making good decisions .
Finally, this has the added advantage of providing parents with a healthy way to communicate their opinions on media, which has been shown to have a strong impact on how children themselves see media .
Our work specifically targets content filtering on currentgeneration internet-capable smart phones and tablets.
We selected this platform for our exploration as it is modern and usage is rapidly increasing , yet there are currently few content-control mechanisms.
This concern is well grounded, as exposure to such content may impact childhood aggression and education .
Copyrights for components of this work owned by others than the author must be honored.
Abstracting with credit is permitted.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Copyright is held by the owner/author.
Publication rights licensed to ACM.
We present a new approach to content control that aims to include children in the content filtering process, and focuses on child involvement and education rather than control.
We first present an open-ended study that explored children's technology usage patterns and parental opinions, with the results supporting the importance of content control in current-generation devices.
We designed and implemented an initial software platform that serves as a prototype for educational content-control sessions and enabled us to conduct a follow-up qualitative study with parents and their children.
Our findings show that parents consider the collaborative, educational approach to be an effective and engaging way to initiate conversations with their children, and that it provides a novel way to discuss topics which may otherwise be difficult to breach , and that children learn  from these sessions.
Overall, we believe this kid-in-the-loop approach to content control has promise and can serve as an important part of modern internet-capable technologies.
Why families adopt technologies  has been broadly studied, for example, showing how family values and social class can shape attitudes and adoption .
There is also investigation of how new technologies can have an impact on the home and its social structures .
Broadly speaking, such work has indicated that parents have a great deal of concern over their children's exposure to inappropriate content, primarily pornography .
Our exploratory study provides some updated insight into a family's adoption patterns of current-generation technology, but more importantly, our work primarily focuses on actual interactions between parents, children, and technologies in contrast to broad patterns of behavior.
Work on technology usage regulation and content control in families has articulated parental strategies, for example, through discussions with children, co-use, or direct restriction such as passwords .
Co-use and interaction rules  may be preferred over employing hard restrictions such as control software , in part due to a lack of trust in the robustness of the system ; our new approach encourages and scaffolds discussion between parents and their children on what is or not appropriate.
There is some evidence that low uptake of control software - only 33% according to a 2004 study - may be correlated with the age of the child, with more use for families with younger children ; this study also indicated that perceived ease-of-use of such tools may be a barrier.
Further, commercially-available control software generally provides rule-oriented  control methods, for pre-configuration by parents , or machinelearning approaches such as automatically detecting adult images .
Our approach attempts to address all of these concerns: we target younger children and involve them directly, and aim to reduce parental barriers to filtering use by making filtering an interactive parent-child process.
Studying children's interactions with technology has been a common theme in sociology, psychology, and humancomputer interaction; for example, children and television in general , how video games may promote exercise , or how internet use may impact psychological development .
Some explicitly involve children by including their attitudes and points of view as a part of the investigation .
Our work continues this theme by exploring how children use current-generation technologies and parents' attitudes toward them, and more specifically, how children can be involved in the content filtering configuration for current-generation technologies, and how this can impact education of appropriateness.
We conducted an exploratory study to investigate current patterns of how children use technology, what kinds of current-generation technology they use , and the range of thoughts, opinions, and concerns that parents have about such technologies.
In doing so, we provide updated insight into these issues; many prior studies pre-date the current smart phone and tablet trends .
We explicitly did not target content control schemes, as a part of this evaluation was to determine if content control was indeed a strong current parental concern, thus motivating our current work, and so we let it emerge from the data.
As the results below show, overall the idea of control - for appropriate content as well as appropriate use - is a very large concern and consideration for parents, and they have a range of strategies for dealing with this.
We interviewed 12 parents  of children 4-10 years old.
Demographics are listed in Table 1.
We recruited participants through snowball sampling and signs placed throughout our university.
When possible, interviews took place at a participant's home to facilitate note-taking .
Interviews lasted 20-45 minutes, participants received a $10 gift card, and the study was approved by our research ethics board.
Data were collected via audio recordings, which were later transcribed.
We asked participants to describe specific examples of how their children used technology throughout the day.
We used a semi-structured interview technique to investigate: * What kinds of technologies are children interacting with, and, how are they using them?
To me that's a big one.
I just don't want to have them next to each other and doing like a parallel play, I want them interacting with each other and learning how to be brothers.
Parents heavily discussed a wide range of methods they employed to control how their children use technology, mirroring prior research on parental control strategies ; our results below outline how these strategies are manifested with current-generation technologies.
Supervised Use: A common strategy articulated by parents was to only allow children to use technology while under some form of supervision:
We used affinity diagramming for data analysis , where we clustered and axial-coded related statements to uncover themes and commonalities in the parents' discussions.
Parents indicated that their children use a variety of devices ranging from those specifically manufactured for children , to gaming platforms , to multipurpose devices .
Children also used their parents' smart phones.
Overall, while parents were supportive of their children using technology, a major theme of discussion was how parents struggle with setting limits of use, for example, in terms of content types and amount of time.
We elaborate on these concerns below.
A dominant theme in our data was that parents exhibited strong notions of what they consider to be acceptable uses of technology for their children.
In addition, these notions were highly parent and family-specific.
A common acceptable use that parents focused on was education:
In this particular case, the parent attempts to avoid this overhead by choosing devices that require less supervision .
Filtering: Some parents reported that they pre-filter content for appropriateness before giving access to their children, often providing the child with no opportunity for input:
Software-Assisted Control: Parents infrequently described using software-based control solutions , with the exception of using passwords.
Parents indicated that they were aware of such control solutions; however, many commented on the difficulty of use or added overhead for shared devices:
Thus, while a number of software-based solutions exist, they perhaps do not meet parents' needs.
Time Limitations: Many parents employed time limitations for their children; however, enforcing these limits was often challenging and stressful .
For this reason some parents simply avoided purchasing certain devices to circumvent the issue:
We selected this platform as a modern relevant example: mobile devices with a central application repository  are increasing in popularity, and there are currently very few content-control options available.
In addition, the application-repository model provides a clear  cutting point for content: an application can either be marked as appropriate or inappropriate.
We targeted We-Choose primarily at children within the six to eight year-old age group, based on psychology literature that indicates this is when children are capable of reasoning about appropriate and inappropriate material , and are also able to start making generalizations .
However, we do not limit the approach to this age range.
Our We-Choose prototype is designed to facilitate an educational parent-child session about the appropriateness of content.
We provide this in a two-part way: first, in parent-child mode parents and children work together to set content filtering rules and establish what is appropriate, and in game mode, children test their knowledge of what is appropriate.
While game mode is primarily designed for the child, parents can continue to be involved, for example by providing discussion and explanation when the child is unsure about why something was or was not appropriate.
Overall, we highlight that particular design decisions  are not the point of our research; rather, we simply aimed to construct a proof-of-concept of the overarching kid-in-the-loop approach that would enable us to run initial studies in this area.
The parent-child mode follows a simple process: an application is presented on the device, and the parent and child together determine if it is appropriate.
After this, another application is presented, until the parent and child together determine that they have had enough training and switch to game mode.
As Figure 2 illustrates, to help drive this discussion and decision, the application presentation includes: the application logo and name in the center, icons above the logo indicating the kind of content, a text description of the application at the bottom of the screen, and two bins used to classify the game: a green check box  or a red `X' .
The parent and child can then assess the information, discuss why it may or may not be appropriate, and together classify the application.
While the parent can use the application's text description to help explain why it is bad or good, the young children targeted by our system  may not be able to read the application titles and descriptions.
As such, a key element of our prototype is the addition of icons, which  creates a way for the children to develop an opinion on an application they are not familiar with.
Parents in our study generally welcomed technology for their children and discussed the potential for positive impacts.
At the same time, parents expressed concern over some of the dangers of technology use, such as inappropriate content or diminishing of physical and social activities.
They further indicated a range of techniques for mitigating these concerns, and expressed some of the challenges of maintaining control.
The emergence of these themes from our exploratory interviews motivates investigating new filter configuration methods, and combined with our goal of involving children in the decision process, supports our work in developing an approach to content control that facilitates an educational, discussion-oriented "kid-in-the-loop" process.
The longterm vision for our approach is to help children learn rules in an engaging setting, decreasing the ongoing parental management overhead, while at the same time giving parents a control mechanism that meets their needs.
In this section, we describe a proof-of-concept prototype that we use to explore parents' and children's attitudes towards this alternative model of content filtering.
We highlight that this is the first system we are aware of which includes the child in the filtering process, and that emphasizes educational discussion over simple rule setting.
Below we outline how our approach was manifested through the We-Choose prototype.
In our prototype, we have icons indicating appropriate age by relative size of a stick figure, as in Figures 2 and 3, which indicate everyone , and a range from young to high maturity .
Figure 3 illustrates the range of possibilities for this icon.
We also included icons for the application category, which can be one of: action, arcade, puzzle, casual, gambling/casino, educational, sports, racing and adult .
These category and age-rating icons are intended to facilitate conversation about which subject matters or age group applications are considered appropriate for the child.
For example, a parent could explain why an application with a gun  may not be appropriate.
They could also explain why the child is not able to use applications that have a high-maturity age rating.
The same icons are used in the game mode explained below.
Users can also at any time view a summary screen  that contains a list of the applications that the parent and child has already seen and shows how they were categorized.
This enables the users to refer to previous choices to compare and contrast as part of their discussion.
When the parent and child decide that they have had enough training, they can switch to game mode by clicking the "Let's try!"
In game mode, the child works through a number of additional example applications  in a manner similar to the parent-child mode; however, unlike previously, in game mode the child has to try to guess whether or not each application is appropriate for them.
The expectation is that the child will retain some of the rules they learned previously with their parents.
After guessing, feedback is provided as a happy or sad character animation  accompanied by a clapping or crying sound.
Upon completion of all of the examples, the prototype displays all the applications that the child has gone through while playing the game, highlighting any incorrect choices .
This screen can then be used by the parent and child for discussion.
The mode-oriented design of We-Choose enables parents and children to change back and forth between the modes to fit their own particular discussion and education style.
We-Choose is a mockup of an application marketplace with a set of pre-coded  applications based on real Google Marketplace items.
The internal filterlearning system was simply a mock-up for the purposes of enabling interaction within our proof-of-concept prototype.
Through interaction with the parent-child mode, the system internally builds a simple set of binary rules where age ratings and categories are labeled as appropriate or not, based on how applications are rated during parent-child mode.
Following, in game mode if any of the binary flags match the application , it is classified as inappropriate.
The primary purpose of our evaluation was to introduce the concept of kid-in-the-loop content filtering to a group of parents and children, through the use of our We-Choose prototype, and to learn about their impressions of our discussion and education-oriented approach.
We recruited parents and their children and had them use our prototype to configure a content filter for roughly 20 minutes.
We-Choose had 40 items that could be classified, 20 for parent-child mode and 20 for game mode.
We finished with a semi-structured interview with both the parent and child to investigate their impressions of our kidin-the-loop approach to application selection and filter configuration, and to elicit feedback on the We-Choose instantiation.
Each interview started by talking to the child .
One parent and child pair stopped part way through the game mode when the child became tired and irritable; however, the parent still participated in the interview.
Each session lasted approximately 45 minutes.
We begin by describing parents and their children's responses to the approach, followed by a discussion of their interactions with We-Choose.
We recruited 13 sets of parents and children in the six to eight year-old age group via signs posted throughout our university campus and daycare, and in the local community.
In all cases only a single parent participated .
Parents received a $10 gift card and children received a small toy.
The study was approved by our university's research ethics board.
The procedure for each session was as follows.
Participants were given a brief 
After participants completed a short practice session with each mode, we administered the main condition: we clearly explained to participants how they start with parent-child mode and could switch back and forth to game mode as they wished, and should not necessarily aim to try and classify all applications in parent-child mode.
All parents responded very positively to the collaborative content filtering approach, showing interest in using such a system if available.
Below we discuss aspects that parents were particularly enthusiastic about.
Discussion Catalyst: Our We-Choose instantiation was successful in facilitating discussion and giving children an active voice in the content selection process, a point that parents indicated they liked about the system:
It was fun and it was really interesting for me to see her work away at this herself and I guess discovering that we sort of share these feelings about what is appropriate and what is not appropriate.
It is often hard to find time to sort of address the values of the family or the beliefs of the family or moral and ethics.
So if you have a chance to sit down and do something like this together then we can talk about it.
I think it creates a dedicated time and space to do it, whereas everyone is busy all the time.
Everyone is running here and there.
Because he still can't read, he could install something and get frustrated with it even if it is age appropriate  I'd prefer to know... just to give him a bit of a warning first, so even though it would be age appropriate for a range of kids, for him it may not be exactly what he was thinking.
Using video recordings of the sessions, we examined how parents explained and discussed application appropriateness with their children while using our prototype and approach.
Most parents' explanations  depended heavily on the application age ratings , perhaps even more so with children who could not yet read.
To explain the icon meanings to children, some parents spent time working through a reference sheet that we provided containing all icons used in the prototype:
This is a game that everybody should be able to play because all the people are highlighted.
This means it is for little kids.
This one, just by looking at the picture,  for medium maturity or kids that are probably  age  and up.
And then high maturity is really for like adults only because they took out the little ones.
So you can look at that for a clue whether it is good for you.
So if you look at these which ones should you be playing?
All but one set of participants completed the entire parentchild mode before their child started using the game mode .
Most of the parents  actively involved their children while in parent-child mode, explaining the ratings and categories and asking their child to guess whether or not the application would be considered appropriate.
Seven parents used this strategy from the start, while two parents worked through a couple of examples first before asking their child to guess.
Three parents provided explanations as they went through the applications but did not ask their child to venture guesses as to their appropriateness.
One group moved back and forth to game mode before completing all examples in parent-child mode; when asked, this parent indicated she chose this strategy because she wanted to both keep her explanations fresh in her child's mind and keep her child engaged by giving her a chance to actively interact with the prototype:
I thought maybe it will be easier for her when I let her do her task just after it.
I thought that if I talk and don't let her touch anything for a long time she would have said 'I don't want this'  It's a break for her that I give her a chance to touch it.
Is this a good game or not?
Pool break, this is playing pool.
See this one  it is a sports game and this is for everyone it says, anyone can play it.
It looks like someone is looking through a gun.
This looks like blood, and this guy here is running with a gun , so I think no, that is not appropriate.
Anything that helps us think is good.
The children seemed to enjoy playing the game, despite the fairly basic design  and educational focus.
Children enjoyed the rewards for good performance and appeared to take it very seriously.
One child  wanted to change an answer he got wrong, and commented "I'm good at this game!"
C10  happily exclaimed "Mom, we keep getting it right!"
Another child  upon completion turned to his mom and the experimenter and asked: "Can I play again?"
The children performed very well in game mode: average 18.2/20 correct responses  with seven children classifying all applications correctly.
For the children who got wrong answers, interviews revealed that they were also factoring in whether or not they thought they would like the application in addition to the appropriateness.
For one child, who scored 11/20, we noted that the parent's rules about appropriateness were not consistent with our criteria  which appeared to be the source of confusion.
Our results indicate that parents saw value in the discussion opportunity, above and beyond simply creating filters.
This is a primary goal of our kid-in-the-loop approach: it provided context  within which meaningful discussions about rules and values can take place, as well as an excuse, opportunity, and fun way to discuss things which may be less interesting for the child or may be ignored otherwise.
Although we concede that our results do not strongly inform us on how much children were actually in the loop, in terms of how much their opinions impacted the final filter configuration, our approach improves the chances of children learning and following rules by providing a discussion opportunity beyond parent-only filter configuration .
Although our work targets the configuration of content filters, this emerged as a secondary point  in our results.
While some parents highlighted the time and effort saving potential, many indicated that they may not trust a filter that learns from the demonstrations.
We note that despite this, these parents still indicated the value from an educational standpoint.
The We-Choose prototype successfully enabled initial interaction sessions where children and parents work together to configure and discuss content filtering.
No problems arose that hindered interactions, and participant feedback was generally positive.
We do note that families approached the interaction in a variety of ways  and We-Choose supported these differences; future work should likewise consider flexibility.
Overall, we believe that our results lend initial support to the kid-in-the-loop approach to content control and filtering.
Although there remains work in investigating how exactly children enter the decision-making process, the discussion and education approach was well received by parents, who appreciated the facilitation of meaningful discussions with their children, and there was indication of at least shortterm learning on behalf of the children .
There was also some indication that children themselves appreciated having some input into these control type decisions.
As such, we believe our results support this direction as a promising one for future work, not only for configuring control and restrictions for children, but anywhere where parents and children may find themselves using technology together.
As this project was an initial test-bed for kid-in-the-loop education and discussion-oriented content filtering, our positive results leave a rich breadth of future work.
This current work is limited in that it was an in-lab study where children may have been particularly well behaved given the official and public scenario.
Moving forward, it will be important to investigate how such systems would be used during longitudinal deployments to homes.
Further, while pedagogical foundations served as a motivation for this work, we only superficially investigated child learning, and future work should more rigorously explore how being "in the loop" may impact learning about appropriate content.
As part of these questions, we need to investigate how culture and socio-economic status - factors which can impact technology use - would affect interaction.
Further, while we targeted young children in our work, at least some parents saw benefits for older children.
Exploring other age groups - and how this may change the requirements and mechanics - is an important direction for future work.
Part of our prototype design was to rely on visual representations of the content types and appropriateness.
We selected these heuristically and while they appeared to work; future work should take a more structured approach to developing improved representations, for example, that cover additional dimensions such as length of play session, or theme .
Other child-friendly representations such as video, color schemes, and so forth, should also be explored.
Similarly, our use of reward and feedback  may have been somewhat simplistic, and it will be interesting to consider a more fine-grained setup, or how to maintain the reward benefit as the novelty of the animation wears off.
For example, point systems  could be explored.
Finally, we took a minimalist approach to the technical components of content-learning as our research was focused on the kid-in-the-loop discussion aspect and not on the adaptive technologies.
Moving forward, it will be important to consider how content may actually be tagged in real marketplaces, how such tags may be represented through approaches such as ours, and how a system should properly learn based on a small number of examples.
In this paper we presented a novel approach to childoriented content control for internet-capable devices, which keeps the child in the loop and emphasizes education and discussion over simply setting rules.
To test our approach and mitigate some of these issues, we designed and developed an initial kid-in-the-loop prototype based on a tablet PC with a marketplace application paradigm, and conducted a study to investigate how parents and children may react to and use such an approach.
Our study results illustrate how discussion can be facilitated and how children can learn through this approach.
Both parents and children in our study expressed a great deal of enthusiasm about the idea and our instantiation, and many parents provided suggestions of how it may be useful beyond our use case.
