Mobile communication devices, such as mobile phones and networked personal digital assistants , allow users to be constantly connected and communicate anywhere and at any time, often resulting in personal and private communication taking place in public spaces.
This private -- public contrast can be problematic.
As a remedy, we promote intimate interfaces: interfaces that allow subtle and minimal mobile interaction, without disruption of the surrounding environment.
In particular, motionless gestures sensed through the electromyographic  signal have been proposed as a solution to allow subtle input in a mobile context.
In this paper we present an expansion of the work on EMG-based motionless gestures including  a novel study of their usability in a mobile context for controlling a realistic, multimodal interface and  a formal assessment of how noticeable they are to informed observers.
Experimental results confirm that subtle gestures can be profitably used within a multimodal interface and that it is difficult for observers to guess when someone is performing a gesture, confirming the hypothesis of subtlety.
Mobile communication devices, such as mobile phones and networked personal digital assistants , allow and encourage users to be constantly connected and communicate anywhere and at any time.
The nature of this communication is often personal and private, but it takes place in public spaces, where the mobile user is surrounded by other people not involved in his or her communication.
The contrast generated by this private communication in public can be problematic, not only for the confidentiality of the the person who communicates, but -- more importantly -- for whomever is disrupted and forced to listen to a stranger's private conversation .
In fact, mobile phone users generally play an active role: they can decide whether to engage in a phone conversation in public or to wait until they are in a protected, isolated place.
Conversely, bystanders often have a passive role.
The nature of mobile communication is often phatic.
Observations by social scientists  as well as results from ethnographic studies  and critical design explorations  all suggest that personal communication through mobile devices is in large part minimal -- it involves exchanges of little information, and the real function is to provide remote awareness and reassurance to oneself about the possibility to connect to one's own social network.
The design of interfaces and interaction techniques for mobile devices needs to take into account both of these observations.
We propose that mobile interfaces should provide affordance for minimal interaction: in an easy, natural and inconspicuous manner, users should be able to exchange simple signs of presence with a remote partner or friend, for example by sending or receiving one of a few predefined messages.
Generally, mobile interfaces should offer users some simple, low-bandwidth, low-attentional operations that can be performed without disruption or embarrassment even when one is in a public or social context, even in a face-to-face meeting.
Engagement in many simultaneous activities of different attentional demands has been observed in human behaviour long before the diffusion of mobile technology.
In 1963 Goffman  described a main involvement as one that "absorbs the major part of an individual's attention and interest, visibly forming the principal current determinant of his actions" and a side involvement as "an activity that an individual can carry on in an abstracted fashion without threatening or confusing simultaneous maintenance of a main involvement".
In our previous work  we proposed the use of motionless gestures for subtle input as a step towards the definition of intimate interfaces: mobile interfaces that are discrete and unobtrusive.
We presented a wearable controller that takes advantage of the electromyographic  signal to sense isometric muscular activity, voluntary muscle contractions resulting in little or no movement, and reported results from an initial study in which subjects were asked to perform a subtle gesture every time they were prompted through an audio cue.
The results showed that the gestures are easy for people to learn and can be successfully recognised with a simple algorithm.
In this paper we present an expansion of the research on EMG-based subtle motionless gestures by examining  the usability of such gestures in realistic mobile applications and  how noticeable they are to informed observers.
We present an improved wearable armband device, including a gesture sensor and a tactile display, which can be made invisible by wearing it under clothing, as illustrated in Figure 1.
We report a user study in which subjects used this device to control an audio menu.
The emphasis is on the expression of multiple bits of information though subtle gestures, an aspect left open in our previous paper .
We also asked the same subjects to try and guess when someone else was activating the interface.
As a consequence, biosignals can be used in a broader range of applications than before, including novel solutions for human-computer interaction  .
This paper focuses on the use of the electromyographic  signal: an electrical voltage signal generated by muscle activity.
EMG signals can be sensed through surface electrodes, similar to those used for standard electrocardiogram  measurements, generally Ag/AgCl plates covered with conductive solid gel.
The signal acquired through this type of electrode typically ranges from 100 V to about 1 mV and can be modelled to have Gaussian distributed amplitude .
A minimum of three electrodes is required, two of them constitute a differential input pair and the other one is ground.
Active or driven electrodes are sometimes used to create a feedback control loop between the sensor and the body , this method also reduces motion artifacts eliminating the need for conductive gel.
Eletrodes without gel are referred to as dry.
Advances in material technology are producing surface electrodes in forms that can be more comfortable for consumer use, for example, electrodes embedded in flexible grids  or even embedded in fabrics .
They showed a correlation between the mechanical deformation of the limb  and muscle activity, especially fatigue.
Traditional applications of EMG included medical diagnosis  and prosthesis control .
In the context of HCI, a number of studies focused on the use of EMG-based input as an alternative channel for users with physical disabilities: activity on one or more muscles is mapped to mouse movements on a desktop graphical user interface  either in a continuous control fashion or through gesture recognition .
Other examples of EMG application to HCI include robotic control , unvoiced speech recognition , affective and emotional state recognition , interfaces for musical expression , and generic gesture recognition, either to control a music player  a GUI pointer  or a numeric keypad .
The use of EMG signals for subtle interaction with mobile devices has been originally suggested in .
Through electromyography it is possible to sense isometric muscular activity: muscular activity that does not produce movement .
An example of isometric activity is pushing against a wall: muscles are activated, but the wall prevents movement.
Similarly, isometric activity can also be produced by flexing the muscles without load, as when "showing off muscles".
In  we proposed the definition of motionless gestures based on isometric activity.
We developed a wearable system and an algorithm to detect such gestures while users are mobile, and ran a user study to validate the design; in the study subjects were requested to familiarise themselves with the system with minimal feedback  and then to perform the gestures everytime they were prompted through audio stimuli.
However, this initial study did not assess the usability of motionless gestures controlling a realistic interface, nor did it test how visible the gestures were to observers.
Social acceptance of mobile interaction has been raised as an important point by researchers in HCI, and a number of novel interfaces have been proposed to address this factor .
However, no explicit evaluation in terms of visibility or noticeability by others has been reported for any of these interfaces.
McAtamney and Parker  did report a study about the effects of a commercial wearable display on an informal conversation between friends.
The results show that the use of such a display has a negative effect on the conversation.
It must be pointed out, though, that neither the wearable display nor the interaction technique tested were specifically designed for social acceptability.
The Intimate Communication Armband was conceived as a generic input/output peripheral for mobile devices.
It is worn on the upper arm, invisibly under clothes , it senses explicit subtle gestures and provides localised tactile output.
The Intimate Communication Armband connects wirelessly via Bluetooth to a phone or PDA, sitting in the user's pocket or bag.
Being a generic i/o device, it emits signals every time a gesture is recognised and it accepts signals to activate the tactile display.
The mapping strategy from these signals to specific interface actions and events is left open to the application designer.
From a hardware perspective, the system includes two separate circuit boards for the analog and digital subsystems, connected only at one point to reduce interference.
The amplifier design was based on a portable Electrocardiogram  sensor .
The system uses an integrated instrumentation amplifier in the first stage and a right leg driver feedback stage to reduce noise, a well known configuration for biosignal amplifiers .
The right leg driver  feeds common mode signals back to the body through the ground electrode.
After the first stage a 1st order high pass filter at 1.6Hz and a 2nd order Sallen-Key active low-pass Butterworth at 48Hz with a gain factor of 10 are used to eliminate DC components, for further noise reduction and anti-aliasing.
A final stage with unity gain is used to centre the signal with respect to the ADC range.
An integrated voltage converter was used to provide the +5V and -5V supply for the analogue stage from the single cell 3.7V, 130mAH Li-Po battery used to power the entire device.
The circuit schematic is illustrated in Figure 2.
The digital side of the system is based on an Atmel 8-bit AVR microcontroller  running at 4MHz to reduce power consumption.
The microcontroller is used for analog to digital conversion at 160Hz, pattern recognition, and to activate the vibrating motor used for tactile output.
The BlueGiga WT12, a small surface mount Bluetooth module, is used for wireless interfacing to mobile devices and PCs.
A separate integrated circuit voltage regulator is used to convert the battery voltage to the 3.3V required by the Bluetooth module and provide a stable supply for the microcontroller.
The two boards and the battery are housed in a box of about 3cm x 4cm x 2cm, which is inserted into an elastic armband made for a commercial MP3 digital music player, as shown in Figure 3.
The detection algorithm is the same described in : subtle gestures are modelled as short bursts of activity preceded and followed by inactivity in the standard deviation of the EMG signal.
The standard deviation is calculated over a sliding window of duration 0.2s with 75% overlap.
The algorithm was implemented in C on the AVR microcontroller.
Intensive use of first-in-firstout buffers and accumulators, together with careful selection of integer data types to match the data accuracy, were necessary to satisfy the constraints due to the limited amount of memory available.
Two experiments were conducted to validate the design of the EMG motionless gesture sensor.
The first one aimed at assessing the usability of subtle gestures within a multimodal interface , while the second measured how visible the gestures are to others.
The same participants took part in both experiments as described below.
The first experiment examined the usability of the EMG sensor within a realistic interaction scenario in a mobile context.
Subjects selected items from an audio menu through subtle gestures while engaged in a simulated mobile task.
Two conditions were compared: in one case two armband controllers were used at the same time on the two arms, in the other case a single controller was used to select one of multiple options presented over time.
During the experiment, tactile output from the armband device was used to provide feedback about a gesture being recognised.
Compared to audio feedback, the high localisation of tactile output is particularly convenient when two armband devices are used simultaneously.
More formally, the experiment tested the following hypotheses: 1.
EMG-based recognition of subtle gestures can be used for input within multimodal interfaces; 2. the interface bandwidth can be increased by using a single controller to select one of multiple choices presented over time; 3.
EMG controllers can be used concurrently on multiple muscles to increase the interface bandwidth; 4. using multiple muscles is more efficient than using a single muscle, because of the reduced time pressure;
The walking speed of subjects during each task was used as an index for the effectiveness of the interface.
The same measure was later used in other mobile HCI studies .
The subjects' preferred walking speed , i.e.
Each session started with the placement of disposable, soldgel, self adhering, Ag/AgCl 9mm disc surface EMG electrodes.
Differently from what was reported in , the participants skin was not abraded before electrode placement, as the use of driven electrodes  provided increased resilience to signal artifacts.
The electrodes were placed around the upper arm, such that one of the differential pair input electrodes was centred on the biceps brachii, the other differential electrode was on the outside middle of the upper arm, between the biceps and the triceps, and ground was placed on the back of the upper arm, away from the muscle of interest .
The electrodes were all applied at approximately the same distance from the elbow, to test the feasibility of embedding them in an armband.
After the electrodes placement, subjects wore the wireless EMG device with an elastic band between the electrodes and elbow.
Participants were given written instructions that the study was assessing an EMG-based interface and they would control the system using their biceps while walking using a subtle contraction that could be performed with their arm relaxed and at their side.
They were also informed that the contraction recognised has a minimum and maximum dura-
Using the wireless EMG device, participants performed three walking tasks, one without controlling any interface , one while controlling the audio menu with one arm, and one while controlling the audio menu with two arms.
Each of the two menu controlling tasks was preceded by a short familiarisation session.
While walking, participants navigated 8 meter laps around obstacles setup in a regularly trafficked walkway at MIT Media Lab, see Figure 4.
This setup was similar to the one reported by Pirhonen et al.
Subjects were encouraged to try to perform the contractions in a subtle way, without performing much visible movement while activating the controller, however if they had difficulties they were suggested to fold their arm.
During the familiarisation sessions, participants stood and received tactile feedback  when the system recognised a contraction.
The system provided no further feedback as to the amplitude or duration of the contraction.
To speed up the procedure, if participants could not learn to control the system within the first two minutes of familiarisation, the experimenter verbally guided them in performing longer, stronger or shorter gestures.
In all cases, within two minutes of training subjects were able to reliably control the device.
The familiarisation continued at the participant's will lasting up to 10 minutes; during this time participants were asked to attempt to perform the gesture while walking around the obstacles used for the subsequent part of the experiment.
The familiarisation phase was performed first on the arm of the dominant hand, subsequently the same procedure was repeated for the other arm.
On the second arm subjects generally picked up the gesture very quickly.
After the familiarisation phase, subjects were asked to walk for 10 laps without activating the interface, so that their preferred walking speed could be recorded.
Audio Menu The audio menu used for the the experiment simulates what could be employed on a mobile phone.
It contained four items, all related to different ways to handle incoming calls and they were accessed sequentially from item 1 to item 4: 1.
As the menu was navigated, the description of the current item was read, just once, by a computer voice synthesized through the AT&T Natural Voices Text-to-Speech Engine .
When a menu item was selected, the action was confirmed by the same voice.
Two conditions were used to access the menu: * In the first condition, referred to as two-arm, subjects used the arm of the dominant hand to sequentially advance in the menu , and the other arm to select the current item.
The menu "wrapped around" going back to item 1 after item 4.
The interaction always started from the top of the menu: the first time the next action was performed item 1 became the current item.
In this way subjects could operate the interface just with one arm, which was used to select the current item.
Subjects were asked to chose one arm to control the interface, at the beginning of the task.
Similar to the first condition, the menu "wrapped around": after the last item the navigation re-started from the top.
To simulate realistic conditions of use, subjects were prompted with audio stimuli mimicking incoming calls.
At randomised intervals, uniformly distributed between 5 and 25 seconds, a synthetic voice announced an incoming call from one of the following four callers selected at random: "Phone number 617 425 5965", "Prof. Smith", "Mum cell phone", "Alex office".
Subjects were informed of the four potential callers and were instructed to react in a specific way to each caller.
Mnemonic suggestions to remember the association of caller and reaction were also provided.
All subjects participated in all tasks: within-subjects design.
The one-arm and two-arms tasks were performed in a fully counterbalanced order.
A total of 235 stimuli were presented over the entire experiment.
During the two-arms task, 123 stimuly were presented to all subjects, corresponding to an average of 10.25 stimuli per subject .
For the one-arm task, a total of 112 stimuli were presented, corresponding to an average of 9.33 stimuli per subject .
The reaction to each cue was limited to two full menu cycles in the one-arm condition and to 40 seconds in the two-arm conditions, if subjects did not perform a selection by then the cue was counted as missed.
Subjects heard the stimuli and the audio menu item descriptions through wireless headphones.
This ensured that variations in the ambient noise of the laboratory did not have an effect on performance, and reduced the perception of the noise generated by the vibrating motor.
Overall, subjects performed correct selections of items from the audio menu for 226 of the 235 stimuli presented, corresponding to 96.2% of the times.
Incorrect selections were made in 6 cases , in all except one of these an item adjacent to the correct one was selected.
In the two-arms condition subjects performed correct selections for 120 of the 123 stimuli presented, corresponding to 97.6% correct performance; in the same condition 2 erroneous selections  and 1 missed selection  occurred.
In the one-arm condition subjects performed correctly for 106 of the 112 stimuli: 94.6%.
Out of the 12 subjects, 7 performed perfectly in both conditions , while 2 subjects achieved a perfect score on at least one condition.
Only 5 false positives were detected during the entire experiment, but these did not affect the task performance as they happened after a selection was made and before the next stimulus.
Additionally, two times subjects reported that an incorrect selection  was made because of a false positive.
A one-way ANOVA showed no significant differences in the subjects' walking speed when comparing the data corresponding to the control condition, two-arms condition and one-arm condition.
Most of the subjects walked slower when operating the interfaces, however, 4 subjects walked faster in the two-arms than in the control condition, and 3 subjects walked faster in the one-arm condition than in the control condition.
It was observed that 8 of the 12 subjects learnt to control the device very quickly, and that 4 naturally performed the gesture without much movement of the arm.
When asked at the end of the experiment, 7 out of 10 subjects expressed a preference for the two-arms condition, generally because this provided more control and faster operation; only 2 out of 10 subjects preferred the one-arm condition and 1 did not express a preference.
Most of the subjects spontaneously reported that they enjoyed taking part in the experiment and experiencing a novel and unusual way to control a computer interface.
However, the high percentage of correct selections when only one arm was used  suggests that time-multiplexing techniques can produce acceptable results, even more than expected.
In general, these results are in line with those found in our previous work : 96% gesture recognition rate.
The subjects were involved in a walking task while operating the interface and their walking speed was compared to a control condition where the subjects walked without performing any other task.
As discussed above, a reduction in walking speed is generally interpreted as a sign of increased workload and need for attention on the secondary task .
Statistical analysis revealed the lack of significant differences between the two experimental conditions, and between each of the two conditions and the control.
This suggests that controlling an EMG based interface, with one or two arms, does not involve a high workload or amount of attention.
However, further research is required for more conclusive findings.
Users were able to control the audio menu consistently while mobile.
The overall accuracy of 96.2% indicates that EMG can be used successfully in complex and multimodal interfaces, confirming the first hypothesis.
In both conditions subjects performed with high accuracy, confirming that the interface bandwidth can be improved by either using multiple muscles or using time-multiplexing strategies with a single controller .
As discussed in previous sections, the principal motivation for EMG-based interfaces in the context of mobile HCI is subtlety.
People around the user should not notice and should not be disrupted by his or her interaction with a mobile device.
The second experiment was designed to measure how noticeable subtle gestures are, testing the following two hypotheses: 1. subtle gestures detected through EMG are generally not noticeable; 2. the gestures are particularly unnoticeable when the armband device is hidden under clothing.
Subjects were asked to watch a video recording of a trained user activating the armband and to try and guess when the interface was being activated.
The video showed an actor, in front of a neutral background, performing subtle gestures with his upper right arm while talking with someone off screen, and it had no audio.
The video was divided into 3 scenes shown without interruption one after the other.
The first scene showed a medium shot of 135 seconds with the actor wearing long sleeves.
The second scene had the same framing and a duration of 144 seconds with the actor wearing short sleeves.
The last scene showed a close-up of an arm with electrodes and the armband device, and lasts for 41 seconds.
The video was shown on a standard 17" LCD computer display, and the video window measured approximately 8" by 6" at the centre of the screen, under this window 5 buttons allowed subjects to rate noticeability on a Likert scale .
The same subjects who participated in the previous experiment took part in the video rating immediately after completing the two menu navigation tasks.
In this way all viewers were familiar with the EMG-based interface and the idea of subtle contractions.
Subjects were informed of the purpose of the experiment and were given the following instructions: You will see a video  of someone wearing the EMG-detecting armband on his right arm.
The person in the video occasionally activates the EMG interface performing a subtle gesture.
Below the video you will see the following sentence: "The person in the video is activating the EMG interface.." and five buttons labelled: - "definitely" - "very probably" - "probably" - "possibly" - "not sure" Please click on one of the buttons when you think that the person in the video is activating the EMG interface.
No information was provided about the number of times the person in the video actually activated the interface, and subjects were free to try and guess however many times they liked.
The footage used for the experiment is the recording of a user really performing subtle gestures recognised by the device.
The gesture recognition output was then used as ground truth to evaluate the subjects' performance in guessing.
For the short sleeves section, 33.1% of the attempts resulted correct .
The subjects' confidence on correct guesses is reported in Table 1, where the percentages of the correct guesses is reported for each level of confidence, for example 36.84% in the "Long Sleeves" row and the "Definitely" column indicates that 36.84% of the correct guesses in the long sleeves case were with maximum confidence on the Likert scale.
The same data is visualized in Figure 8.
The results show that subjects cannot easily guess when the interface is activated, confirming that the interface is subtle.
In the experiment subjects were told that the person in the video would at some point activate the interface, in reality this information would not be available, making the chance of noticing the interface even smaller.
As expected , when the armband is hidden under clothing it becomes much less noticeable.
Most of the subjects informally reported that they found it difficult to tell when a contraction was performed.
The results can be compared to the probability of a correct uninformed guess, that is the probability of a correct guess assuming that subjects did not look at the video and guessed randomly.
This situation can be modelled with the attempts having a uniform random distribution.
Considering each of the "long sleeves" and "short sleeves" sequences separately, and remembering that an attempt is considered correct if it is within 3 seconds of a contraction, a high enough number of attempts evenly spaced in time would give 100% chance of correct guess.
The minimum number of attempts for 100% chance of guessing is N100% = DS / Da , where DS is the duration of the sequence and Da is the uncertainty interval, in this case 3 seconds.
During the experiment subjects cumulatively attempted to guess 137 times, corresponding to an average of 11.4 attempts per subject, and to a 11.4 / 45 = 25.3% chance of correctly guessing.
Therefore, in the long sleeves condition the subjects guess performance, 13.9%, was much worse than completely random, 25.3%, implying that watching the video did not help guessing, confirming that the contractions are unnoticeable.
In the short sleeves case subjects guessed 8.5 percentage points better than chance, however, overall fairly low.
The results of the close-up condition, where subjects guessed correctly most of the time, confirm that participants understood the task.
This paper presented a formal evaluation of subtle motionless gestures for interaction in a mobile context.
Expanding on our previous research , we presented the implementation and evaluation of a wearable device that recognises subtle motionless gestures based on EMG signals from the upper arm.
Our study demonstrated that such gestures can be profitably used within a multimodal interface in a mobile context and that it is difficult for observers to guess when someone is performing a gesture, confirming the hypothesis of subtlety.
The experimental design used to quantitatively asses how subtle the interaction is probes a space largely unexplored; we hope it is a seed for more discussion on the quantitative assessment of subtlety in interfaces.
Future work should investigate the use of dry electrodes or electrodes embedded in fabric  to improve the device's comfort.
In addition, previous ethnographic studies  suggest that there is potential for the Intimate Communication Armband to provide intimate remote awareness: e.g.
Mobile devices allow and encourage personal and private communication from virtually anywhere and at any time, however, they are often used in a public and social context, where users are surrounded by others not involved in the interaction.
