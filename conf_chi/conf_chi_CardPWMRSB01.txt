The purpose of this paper is to introduce a replicable WWW protocol analysis methodology illustrated by application to data collected in the laboratory.
The methodology uses instrumentation to obtain detailed recordings of user actions with a browser, caches Web pages encountered, and videotapes talk-aloud protocols.
We apply the current form of the method to the analysis of eight Web protocols, visualizing the structure of the interaction and showing the strong effect of information scent in determining the path followed.
To support replicability and reuse, we are developing a bank of ecologically valid WWW tasks and a WWW Protocol Coding Guide, which will be available on the WWW.
As side ventures, we have developed prototypes of tools for instrumenting, coding, and visualizing WWW interactions.
We have framed our coding methodology with an eye towards developing a computational model of information foraging on the WWW that extends our earlier theory .
Here we present some of the assumptions we have made about cognitive representations and processes in WWW interaction.
Most, if not all, of these assumptions have come from information foraging theory.
The development of predictive scientific and engineering models of users' cognition and interaction with the World Wide Web  poses some tough and interesting problems.
Cognitive engineering models, such as GOMS , fit user interaction with application software  when error rates are small, tasks are well-structured, exploration is virtually nonexistent, and content is not a major determinant of behavior.
Typical interactions with the WWW, on the other hand, are very likely to involve many impasses, ill-structured goals and tasks, navigation and exploration, and substantial influences from the content that is encountered.
In this paper we present an approach to the analysis of protocols of WWW use that is aimed at capturing these phenomena and that is aimed towards the development of predictive models that are of use in science and design.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
It is relatively easy to collect usage data at WWW servers, and with small effort one may instrument a browser client to log user and system actions.
Because such server and client logs of user and system behavior are easy to collect, they provide the source for many analyses of WWW interaction.
For instance Catledge and Pitkow , did some early descriptive analysis of WWW surfing, Tauscher and Greenberg  analyzed revisitation patterns based on log file analysis, and Hodkinson, Kiel, and McColl-Kennedy  developed a graphical methods to analyze WWW consumer behavior.
Our own lab has developed user path analysis routines  and user flow models  from log file analysis.
These click-stream analyses are informative because of the sheer volume and breadth of data available.
They do not, however, provide any trace of the moment-bymoment cognition that occurs between user clicks.
If we are interested in developing detailed models of such moment-by-moment cognition--for instance, to better understand how peoples' goals evolve, how people perceive and process the contents of WWW pages, how and why they make surfing decisions, and so on--then progress will be accelerated by having more detailed data traces of that cognition.
Protocol analysis of videos of a day-in-the life study was performed to catalog and provide descriptive statistics for WWW tasks by Byrne, John, Wehrle, and Crow .
The day-in-the-life study required users to turn on a video camera each time they used the WWW in their everyday routine.
To develop the methodology, we have attempted to work with a set of ecologically-derived tasks as described below.
The day-in-the-life study of Byrne et al  illustrates one method for collecting realistic, ecologically valid data.
It is limited, however, in the rate at which one can catalog such tasks.
There are also questions about the representativness of the tasks  and whether or not one can repeatedly study the same task with other users.
We decided to take another tack: To develop banks of WWW tasks that come from users out there in the world, which we can translate into the laboratory.
The Graphics, Visualization, and Usability Center  at Georgia Institute of Technology has conducted ten online surveys assessing Internet demographics and usage patterns.
From October 10 through December 15 of 1998, the following question was posted on the Web and Internet Use subsection of the questionnaire: "Please try to recall a recent instance in which you found important information on the World Wide Web, information that led to a significant action or decision.
Please describe that incident in enough detail so that we can visualize the situation."
There were 2188 usable responses to the survey question along with their accompanying demographics.
Three taxonomic classifications focusing on the Purpose of people's search on the Web, the Method people use to find information, and the Content of the information for which they are searching were developed .
Information foraging theory  is an approach to understanding how user strategies and technologies for information seeking, gathering, and consumption are adapted to the flux of information in the environment.
The framework borrows from biology, and especially from the field of optimal foraging theory .
The task environment of an information forager often has a "patchy" structure.
Information relevant to a person's information needs may reside in piles of documents, file drawers, bookshelves, libraries, or in various on-line collections.
Often the information forager has to navigate from one information patch to another--perhaps from one WWW site to another, or from one search engine result to another.
The person is faced with decisions such as the allocation of time among patch foraging tasks.
Information Scent and Information Diet.
Information foraging often involves navigating through spaces  to find high-yield patches.
For instance, imperfect information at intermediate locations is used by the forager to decide on paths through a library or an on-line text database to target information.
Such intermediate information has been referred to as "residue" by Furnas .
In keeping with foraging terminology, we have called this scent.
Information scent is the  perception of the value, cost, or access path of information sources obtained from proximal cues, such as WWW links.
For example, on a Web page, information scent may be delivered by link descriptors, images, contextual clues, such as preceding headings, or by page arrangement.
Our notion is that the proximal perception of information scent is used to assess the profitability and prevalence of information sources.
These scent-based assessments inform the decisions about which items to pursue so as to maximize the information diet of the forager.
Our protocol analysis methodology is aimed in part at codifying information scent, and we will analyze the effects of information scent on WWW behaviors.
Based on the responses to the survey question discussed above, we identified finding information as one of the three primary reasons for search on the Web.
Six find information tasks were generated using responses to the survey question.
The following is one participant's response to the survey question: "Searched for and found  a comedy troupe web site to copy their photo for a poster to be printed and distributed locally for an upcoming community event."
Our experimental task , based on that response, is as follows:
You know that The Second City tour is coming to your theater in the spring, but you do not know the precise date.
Find the date the comedy troupe is playing on your campus.
Also find a photograph of the group to put on the advertisement.
An example of the WebLogger output database is presented in Figure 1 and caches all the Web pages visited by a user.
A program called Web-EyeMapper, that inputs eyetracker and WebLogger outputs and outputs a database of all the elements of WWW pages visited by eye fixations Video taping of users as they think aloud while performing a task.
The video is focused on the screen.
The current analyses examine the data from four out of 14 participants on two of the six the experimental tasks, the previously-described CITY task and a task named ANTZ .
The following criteria were used to select the two tasks and the four participants:  mean completion time close to the median of mean completion time for all tasks,  variance close to the median of completion time variance for all tasks  nearly intact data for four participants.
The different sources of data were combined into a protocol .
A protocol transcript contains: the URL of the currently displayed Web page, an image of the Web page on the screen, the times for selected events, derived from the WebLogger file, a transcript of the user's verbal utterances, appropriately segmented, and interpretive encoding of the events.
Eye movements and mouse movements are superimposed over the web page using a novel visualization that inserts timing labels every second.
This allows the chronometric relationships between eye and mouse movements to be seen.
In Figure 2, at second 231, the user is looking at a name on the list of posters as she begins to move the mouse to the search box.
Eye and mouse coincide on the search box at second 233, whereupon the user begins typing `antz'.
At second 235 the user looks at the search button.
The mouse arrives there at second 236 and clicks the search button.
Participants were given an introduction explaining the purpose of the study.
The think-aloud procedure was explained and demonstrated, and participants were given several brief practice problems in order to get used to this procedure.
Participants were encouraged to conduct their search as they would typically, except they were instructed not to spawn additional windows, even if they would normally, due to the usage of the WebLogger software.
The first question was then brought up on the screen and participants began their search.
If participants were silent for a period of time, they were reminded to think aloud.
If they were still working on a task after 10 minutes, they were given a hint by the experimenter, but the task was counted as a failure.
The experiment lasted approximately ninety minutes.
The information space of the Web is distributed into patches.
Patches  decompose into other patches, forming a hierarchy, and  vary along many dimensions, and consequently we expect patches to be like other "natural kinds" category structures that are defined by family resemblances.
This is included for completeness.
Goals are often specified in terms of locating information or searching the entire web.
Users often seek out a particular Website , then search within it.
Websites are the large patches in Figure 3.
Some specific subclasses are: Index  sites and Searchengines.
A page  can be thought of as a patch containing link descriptors , contentelements, and other elements.
They may also contain some additional patchy structure, such as sidebars and other groupings, or regions, but we do not distinguish these for the moment.
Because pages are the universal structure for accessing content on the Web, they have the various subclasses: Website entry page, Index page, Search engine page, Hitlist page.
Foraging on a page for link descriptors and contentelements is done by a combination of visual search and scrolling.
It is the content that is the end point of the foraging.
The consumption of content provides the reward for foraging.
In theory, we assume that the smallest elements are equivalent to propositions .
In practice, these are small collections of English words and phrases that could be used by a cognitive operator .
In addition, there are several kinds of elements that serve as specifiers of pages.
Search for content elements can proceed by search through spaces composed of sets of these elements.
Content links lead to pages that contain content, but category links lead to pages containing other links .
In addition to the implicit role that URL's play when users click on link descriptors, users can also manipulate them directly, by typing them into the browser.
List of words and control modifiers of words that can be can be turned into pages by a search engine.
Boolean operators or quotation marks or + to the words to modify the search.
To simplify, we have again represented moves in the space by a single operator S. * States in the Eye-movement space consist of the set of visible objects and the point of regard.
Moves consist of saccades of the eye from position to position in the space to search for information .
Other moves are scrolling the display so as to change which elements are visible.
In this paper, we do not discuss further the complicated task of visual search.
The reader is referred to  for discussions of visual search made with our analysis tools.
In order to keep the analysis simple, we have deliberately used simple operators to define these spaces, even though they are capable of greater articulation.
We have also for the moment avoided the complications of history lists and bookmarks, although these can be readily added to the analysis.
Moves in the problem space consists in typing or editing a new URL into the browser, .
States in the Link problem space are also URLs.
But moves in this problem space consist of clicking on a link descriptor, whether textual  or imaginal  or hitting the Back button .
States in the Keyword problem space are the set of all word lists that can be typed into a search engine and the number of hits associated with each.
This includes expressions of the word made by adding Table 1.
Problem spaces for Web search.
Figure 4 shows the behavior of four users in our study, each performing two tasks.
The behavior is plotted as a Web behavior graph  generated automatically from the WebLogger file so as to visualize the behavior.
A Web behavior graph is a version of a problem behavior graph .
Each box in the diagram represents a state in one of the problem spaces.
Each arrow depicts the execution of an operator, moving the state to a new state.
Double vertical arrows indicate the return to a previous state, augmented by the experience of having explored the consequences of some possible moves.
Thus time in the diagram proceeds left to right and top to bottom.
The WBG is particularly good at showing the structure of the search.
Color surrounding the boxes in the diagram represent different Web sites.
Oval boxes are distinguished so as to show hit lists from a search.
An X following a node indicates that the user exceeded the time limits for the task and that it was therefore a failure.
A loop has been drawn around the problem spaces, showing how the users pass from one problem space into another as the operators in one become less effective.
Web Behavior Graphs for users in the study.
Solid enclosing lines indicate that the states and operators are part of the Link problem space.
Dotted lines enclose the keyword search problem space.
Square dotted lines enclose the direct URL typing problem space.
It can readily be seen from Figure 4 that the ANTZ task is more difficult than the CITY task, since there are fewer successful solutions , more nodes and more backtracking.
The ANTZ problem requires an average of 21.7 unique states vs. 9.8 for the CITY problem  and each ANTZ problem requires more states than the corresponding CITY problem for the same user.
It should be noted that multiple Websites were used by all users on these problems, a geometric mean of 5.6 Websites for the ANTZ problem and 2.8 Websites for the CITY problem.
There were many more transitions within a site than between sites.
The ratio of within to between transitions was 2.1 for ANTZ and 5.2 for CITY.
One of the aims of a methodology should be to capture the signature phenomena of the objects of empirical study, and one of the aims of theory should be to explain those signature phenomena.
Information scent appears to be one of the major controlling variables in Web foraging behavior.
Two of the phenomena it gives rise to are:  the propensity of users to make their link choices based on the information scent of links , and  the propensity of users to switch to another information patch  when the information scent of the current site becomes low .
These phenomena are not only evident in our protocols, but are known to the Web usability analysts .
Scentfollowing has been found to characterize behavior in other systems  and is the basis of Web usability guidelines .
In the protocols, high and low scent seemed to be associated with user's decisions to keep on a trail or to backtrack or change problem space based on spontaneous comments in the protocol.
User remarks such as "that sounds promising" or "That's what I want, `ANTZ' movie posters" seemed to indicate high scent.
Whereas "But there's nothing on Antz" or "I think I'll have more luck with the WebRing" seemed to indicate low scent.
In order to have enough data to make a systematic analysis, however, a side experiment was run in which three judges rated the scent of a page .
The geometric mean of the judges ratings were taken to reduce the effect of outlying ratings.
These ratings are plotted on a scale of white , light gray , medium gray  and dark gray  on the nodes of Figure 4.
Inspection of the figure suggests that as information scent declines, users are more likely to backtrack.
Information scent as a function of distance from the last node before backtracking.
To test this hypothesis in the aggregate, Figure 5 is a plot illustrating the patch scent policy in our data.
From the protocols we identified segments where users sequentially visited three or more pages at a site  and then switched to another site, search engine, or portal.
We found N = 3 sequences of three-page visits at a site and N = 6 sequences of five visits to a site .
Each point in Figure 5 is the geometric mean of scent ratings of the visited pages produced by an independent panel of raters.
Also plotted in Figure 5 is the geometric mean rating of the next page visited after leaving the site, and the geometric mean rating of all pages.
When interpreting Figure 5, it is important to recall that the ratings form an ordinal scale and consequently the graph cannot be interpreted quantitatively .
Figure 5 shows that initially the information scent at a site is high, and when that information scent becomes low, users switch to another site or search engine.
We interpret this by elaborating information forging theory  with the notion of patch potential developed in optimal foraging theory and consistent with other models of Web surfing.
The idea is that a user is assessing the potential rewards of foraging at a site based on information scent.
So long as the potential rewards are above some threshold, then the user continues foraging at the site.
When the potential rewards pass below that threshold, then the user moves on to another site.
This paper has introduced a WWW protocol methodology and used it on the analysis of a study of users searching the WWW for information, a task derived from a task bank of tasks based on a Web survey of 2000 users.
Data are analyzed through coding of integrated protocol displays, through automatically generated visualizations of the behavior such as the Web Behavior Graph, and through analyses of derived databases as a step toward accelerating evaluations of Website usability and the design of novel Internet systems.
Using this methodology and this early study, the following picture for Web search tentatively emerges: 1.
The space does seem to have somewhat of a patchy character.
Many more transitions are within a site than across sites.
This effect seems to be even more pronounced for an easy task than a hard task.
And visual search within a page is less costly than transitioning between pages.
The search patterns of Figure 4 are clearly heuristic search.
Thus, parts of the behavior are not GOMS-like.
If the behavior was GOMS-like the then the search trails in the figure would be more like horizontal lines.
Notice that for the easier task, the pattern is more linear and GOMSlike.
This suggests that building improved systems could concentrate on two rather different operations: improvements to time limiting operators ., that is, improvements assuming GOMS-like behavior.
The second operation to concentrate on is reducing the extent of search , that is, improvements assuming non-GOMS-like behavior.
The heuristic search is not just through a single problem space, but through a combination of perhaps four of them.
The user reacts to an impasse in one problem space by quickly shifting to another.
This suggests thinking if there might be more that might be invented.
In addition to backtracking in heuristic search, users also seem to go back to landmark pages, such as doing hub and spoke searching from a search engine hitlist.
But there is no navigation mechanism built into the standard browsers to do this.
Finally, information scent seemed to play a central role in the searches of Figure 4 as confirmed by Figure 5.
Dwindling information scent caused users to backtrack or switch problem spaces.
These results are preliminary, but they do suggest that with this methodology we may be able to obtain insights into the structure of user behavior on the Web.
