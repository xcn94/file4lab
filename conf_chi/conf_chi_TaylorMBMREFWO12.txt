Viewpoint is a public voting device developed to allow residents in a disadvantaged community to make their voices heard through a simple, lightweight interaction.
This was intended to open a new channel of communication within the community and increase community members' perception of their own efficacy.
Local elected officials and community groups were able to post questions on devices located in public spaces, where residents could vote for one of two responses.
Question authors were subsequently required to post a response indicating any actions to be taken.
Following a two-month trial, we present our experiences and contribute guidelines for the design of public democracy tools and dimensions impacting their effectiveness, including credibility, efficacy and format.
Conversely, digital technologies are beginning to present opportunities to open new lightweight, agile channels of communication and new methods of enabling participation.
For example, on social media platforms, it is now common to express opinions using comments, or by simply `liking' or `disliking' an item.
Likewise, millions of people each week use text messaging to vote on reality television shows.
These actions often cause prompt, visible results that encourage further participation.
We believe there is great potential for these channels to engage communities and improve communication between local residents, their elected representatives and organisations providing services in the community.
The Viewpoint voting device was developed as part of a project exploring the design and development of bespoke technologies with communities, with the view that individual communities have individual requirements.
The project was based in the Callon and Fishwick areas of Preston, in North West England, which have suffered from numerous social problems in the recent past, including crime, unemployment, drugs and racial tensions.
While a considerable effort from residents, the local council and community groups has greatly reduced these problems in recent years, the UK government considers it to be amongst the 10% most disadvantaged communities in the country.
During a two-month trial, Viewpoint allowed local organisations and elected officials to post questions in public spaces in Callon and Fishwick, where residents could vote using either buttons on the devices or free text messages.
The results of the poll were visible to the public, as were responses and promises of action posted by the author.
During the trial period, eight weekly questions were posted, leading to nearly 1,800 votes being placed by the public.
In this paper, we describe use of the device during this period and identify a number of guidelines and factors to consider when developing public democracy technologies, including credibility, efficacy and format.
Communication and participation are important aspects of civic engagement, allowing members of the public to make their views heard, which in turn allows those representing them or providing services to tailor their efforts accordingly.
Despite this, it is claimed that civic engagement and participation within many communities is in decline .
One possible explanation for this apparent withdrawal from engagement in communities is the sense that participation takes too much time and effort, or that grassroots opinions are ignored, undermining people's motivation to become involved in local issues .
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
However, there is currently a lack of research into the use of such technologies in public spaces that we seek to address.
In the Western model of democracy, the public's primary method of participation is electing representatives.
In the UK, voters are able to elect Members of Parliament to the national and European parliaments, and councillors to city and regional councils who control local public services and facilities, from garbage collection to leisure centres and schools.
Callon and Fishwick have two councillors, both of whom work closely with the local community to represent their interests.
Often, e-democracy has concentrated on assisting this voting process by making it easier to place and count votes.
Much has been written about the potential and issues surrounding these applications , but there are other potential roles for technology beyond elections.
After officials are elected, deliberation and mediation play an important role in ensuring that decision-making reflects the will of the population .
This means that decisions are discussed at length and alternative viewpoints are considered before final decisions are made, allowing the public to access information and influence their representatives.
On a local scale, the public's input is typically sought through town hall meetings and direct communication with councillors, although the Internet is becoming an increasingly valuable tool for this purpose.
This ongoing involvement in the democratic process is considered to be a key aspect of civic engagement , or what has been described as participatory citizenship: "the act of citizens actively engaging in and contributing to the provision of public services in order to improve these services for themselves and other citizens" .
However, our willingness to exert effort is influenced by our past experiences .
Likewise, the willingness of individuals and communities to engage in this process is strongly related to their sense of collective efficacy--their belief that they are able to effect a change through their actions, without which there is little motivation to participate .
In addition to members of the public, other organisations may become involved in this discourse, either as providers of services or as representatives of particular interest groups.
For example, in Callon and Fishwick, a large number of homes are rented from two non-profit housing associations who offer housing to those with low incomes.
The housing associations work closely with both the council and the community to meet their residents' needs and improve the areas in which they operate.
Technology can--and already does--play a role in deliberation and mediation .
In the UK, for example, most MPs and councillors have public email addresses to allow direct communication with their constituents.
Community networks , such as the PEN project in Santa Monica , have allowed members of the public to interact both with each other and with members of the local government.
Recent studies in the UK have likewise shown that interaction online can support communication and civic engagement .
However, to be a credible democratic tool, technologies should be as inclusive as possible.
Web-based technologies can often exclude those who do not have access to computers and the Internet, such as the elderly or financially disadvantaged, widening the information gap between those with access and those without.
Furthermore, there is a considerable experiential difference between voting and participating online and doing so in person.
For this reason, we consider whether information appliances  in public spaces with simple, customised interfaces can allow a wider cross-section of the public to make their voices heard and effect change, increasing their perception of their collective efficacy and potentially leading to further participation.
In existing research, public displays and terminals have often been used to reach a wider proportion of the population.
PEN, for example, provided free public terminals in libraries so that all citizens could participate regardless of their ability to access technology.
More recently, VoiceYourView  has gathered feedback from members of the public in-situ using a familiar telephonelike device, hiding more technical aspects of the system.
A number of research projects have made use of voting mechanisms and large displays to assist deliberation in meetings , while other projects have used polls in social contexts such as public spaces , bars  and classrooms .
In these small groups, the effect of polls is readily visible; for example, if a jukebox system plays music that people in the room have selected, this provides an immediate, strong sense of efficacy and an incentive to use the system to exercise control of the environment.
However, few of these technologies have been evaluated in the wild over prolonged periods or with larger groups.
A further advantage of an information appliance is the potential for simple, lightweight interaction.
They suggest that technology could offer simpler means of making one's voice heard and engaging with other community members.
In light of this, we position Viewpoint as a means of simple, lightweight participation.
The journalists interviewed local residents and community workers to produce materials in a variety of mediums, including video documentaries and written articles, which were used by designers to generate design concepts.
From these materials, an emergent theme was communication: groups providing services within the area struggled to promote themselves and engage residents, while many residents were uncomfortable making their opinions heard, not wanting to be perceived as interfering by other residents.
Many even refused to allow their voices to be recorded so they could not be identified.
This did not mean that residents held no opinions--on the contrary, they often had strong views on local issues that were expressed off-record, leading us to consider methods of contributing these opinions anonymously.
In response to this, Viewpoint was initially conceived as a device that would allow community groups or local councillors to pose simple questions to the area's residents, who would be able to vote anonymously by text message.
This would open a new channel of communication between residents and groups within the community, which would make the result of the poll highly visible while keeping individual opinions private.
It was intended that question authors would submit responses after each poll closed, acknowledging the result and stating what action they intended to take or had been taken, thereby providing an indicator of efficacy.
Our concept favoured a minimalist design, such as simple a binary question, which we intended would lower barriers to participation.
Before development progressed, we sought feedback on this initial design concept both from residents and from organisations who might post questions, including councillors, two housing associations and the local church.
Feedback explored both existing attitudes towards participation and civic engagement, plus a number of issues surrounding the design itself, including locations for the devices, and whether residents should be restricted to a single vote .
Opinions on traditional forms of consultation and participation proved to be generally negative.
Although some residents reported voting regularly, others displayed disillusion with the political process and a low sense of selfefficacy: residents generally felt that their input had no effect and their voices were ignored.
As a disadvantaged area, residents were regularly consulted on many local issues but rarely saw any action taken as a result of their input, causing "consultation fatigue".
The councillors and housing associations identified the importance of gathering feedback from members of the public and felt that the device could potentially help with this.
However, the responses to these attempts were often lacklustre and representatives commented on the difficulty of generating good quality feedback.
In general, responses to the design concept itself were very positive.
Residents particularly liked the idea of a simple voting interface that was easy to understand, and suggested public locations such as community centres and shops as appropriate deployment locations.
Several residents dismissed the prospect of being able to vote multiple times as unproblematic, and even suggested that voting multiple times was a valid way of indicating how strongly individuals felt about an issue.
However, one representative from a housing association made clear that they would prefer only one response per person, and warned that we should not expect a large quantity of feedback from any new consultation method.
Residents also stressed that they wanted to know what would happen as a result of the polls, arguing that there was "no point" in voting if the results were not used.
This issue was also raised by potential question authors, who agreed that questions should not be asked if action could not be taken.
One housing association representative stated: "we would have to be confident enough to be able to respond  it's a bit silly to put a question on and then think `what do we do with that now?'
You've got to be able to act upon it."
Another respondent suggested that the area was already suffering from consultation fatigue, having been consulted extensively with little effect, underscoring the need to have a discernible impact.
Potential question authors typically had difficulty formulating questions that were both simple and actionable during the meetings, but felt confident that they could think of suitable questions given time.
Regardless, there were several promising suggestions: one housing association representative, for example, suggested using the device to decide where funding should be spent.
To gather further feedback on the Viewpoint concept, a low-fidelity prototype was developed for demonstration at a community event that brought a number of local groups together to network.
This prototype took the form of an application running on a large monitor, hidden behind a foamcore screen .
The screen had a printed design themed around a barometer to measure the `climate' of opinion, with cut-out sections where results on the monitor were visible.
Behind it, the monitor displayed the current question, current results and voting instructions, as well as a previous question, its results and information about actions taken as a result of the poll.
Each poll had two options, which were voted for by sending a text message to a specified phone number containing a short keyword .
When this was received, the animated results dial updated accordingly.
Throughout the event, attendees were invited to use the device, given an explanation of what it was intended to achieve and asked for their opinions on both the concept and the prototype.
General feedback on the design concept was positive: attendees recognised the importance of making their views heard, and felt that Viewpoint could help to achieve this.
One attendee noted that it was an "interesting and novel way of getting people involved and because it's using technology, it'll be attractive to young people as well".
Both residents and community organisations were readily able to identify areas, if not specific questions, where the device could prove useful.
Feedback on the prototype itself was more critical, and much of this criticism related to the method of interaction.
Although most residents owned a mobile phone, many older residents were not able to send text messages and some users needed to be coached to send their votes to the device.
Furthermore, even those who were comfortable with text messaging felt that it was more suitable for remote interaction and that using text messages to communicate with a collocated device was unusual.
Consequently, it seemed that the inconvenience of needing to send a text message would discourage the type of simple in-situ interaction that we had hoped to encourage with the design.
Several users also suggested that the prototype was too complicated and featured an excessive amount of text.
From our own observations, it seemed that people were unsure how to approach the device or how to interact with it.
Most required an explanation of the device and interaction--although the presence of researchers around the device may have discouraged them from examining it independently.
Based on the feedback from our initial trial and consultation, we revised our first design for deployment into the community for a two-month period.
During this time, 1,783 votes were cast in eight different polls, six of which were sourced from local councillors and housing associations.
This section describes the final deployed device, usage of the device, and feedback gathered from stakeholders in the community.
The Viewpoint device was a self-contained unit, which could be mounted on a wall or flat surface for security .
In response to feedback that the trial device was too complicated, the interface was simplified to show only two information windows: a question box with very simple voting instructions and a results dial that showed the current result, total number of votes and the poll's end date.
Rather than showing both the current and previous poll at once, a rotating dial was provided that allowed users to scroll through all previous polls to see the final results and any response provided.
Question Q1 Would you miss the Bespoke Newspaper if it was gone?
Do you think CCTV is a good or bad thing for the area?
Would you be willing to spend 1 hour per month helping to improve local parks and open spaces?
Would you like to see a new community centre for Callon?
Is local dog fouling a problem that deserves priority attention?
Do you think that skips  should be provided again, on the Callon estate, later on in the year?
Would you be interested in working with  and other local residents to ensure that the services we deliver in your area meet your standards?
Do you believe easy access to alcohol is a strong contributor to anti social behaviour in Fishwick?
As buttons provided no easy way of identifying voters, a brief timeout--initially set to 30 seconds, but later increased to one minute--prevented multiple votes being cast by a single individual in a short period of time.
Mobile phone voting was still available for convenience and secrecy, but only required the user to text `POLL1' or `POLL2' to a five-digit freetext number.
A similar device was designed that omitted the buttons, simply showing the current poll and texting instructions, so that it could be placed in locations where the user would not have direct access, such as inside a window.
Each device connected to the Internet to coordinate votes across multiple units, so a vote entered on one Viewpoint would register on all devices.
The Viewpoint devices were deployed in three locations in the community.
Devices with buttons were installed in a busy convenience store used by many residents and in the foyer of a community centre that various local groups used as a meeting and activity space.
A third device without buttons was deployed in the window of a local housing organisation.
Each of these locations played an important role in the community and saw considerable traffic during a typical day.
Throughout the two-month trial period, a total of eight polls were posted by four different local organisations , each lasting for one week.
Due to a lack of suitable questions at the time of deployment, the first two questions were posted by the research team.
Subsequent questions were sourced directly from community groups.
These questions took a number of different forms.
Two questions from councillors sought to identify how strongly residents felt about particular issues on the estate .
Other questions, from a councillor and a housing association, were aimed less at gathering opinions and more towards identifying numbers of potential volunteers for possible future initiatives .
The final category of questions was intended to determine the level of interest or support for potential new facilities or services .
Question authors were emailed the results when the poll ended and invited to submit a response: of the six questions not posted by the project team, four had a response provided.
In the case of the two polls that primarily sought to identify levels of interest , the response took the form of contact details for residents who wished to participate.
We did not receive responses for the questions relating to the community centre or alcohol problems .
The quantity of votes cast using the devices was considerably higher than had been anticipated, particularly given the lack of engagement we were warned of during early fieldwork.
A total of 1,783 votes were cast, peaking at 328 in the second week of deployment, with an average of 223 votes per poll.
Conversely, no votes were received via text message during the entire duration of the deployment.
The CCTV question , which was a contentious issue in the area, showed the highest number of votes.
The penultimate poll showed the lowest number of votes, although this was preceded by a week without content and was also disrupted by connectivity issues at the shop.
Of the two interactive devices, more votes were cast at the community centre, which accounted for 1,086  of the votes, with the remaining 697 cast in the shop.
This was somewhat surprising: from our own observations, the shop saw considerably more traffic.
However, we did receive reports that children would congregate in the community centre entrance, often voting multiple times, and the shop did suffer from occasional outages.
The share of votes also differed considerably by location, reflecting the different segments of the community who utilised the two spaces.
When considered separately, half of the results differed significantly between locations.
The most striking difference occurred in Q4, where users of the existing community centre voted strongly against a new facility proposed by a different organisation , while voters in the shop voted for .
In addition to recording votes, the two interactive devices also logged use of the dial to view previous poll results.
Throughout the entire trial period, we logged 10,975 turns of the dial, split into 785 distinct sessions of interaction .
While this indicates a high level of usage, it is difficult to distinguish how much time was spent actually reading results and responses.
The nature of the third device, which did not have any points of direct interaction, means no usage logs exist.
The fact that users could only interact with this device by text message and no such messages were received suggests that interest in the device was low.
It should also be noted that its physical location in the housing association's window, which was intended to make it visible to passersby, was not as visible as we had hoped, possibly contributing to the lack of text votes.
To evaluate Viewpoint's reception in the community, we solicited feedback from three groups of stakeholders: the councillors and organisations who posted questions; the three venues that acted as hosts for devices; and members of the public who encountered the devices and placed votes.
Like the initial fieldwork, these interviews were largely conducted by local people taking part in the journalism programme, but other interviews were conducted by a member of the project team and some stakeholders contacted us directly with their thoughts.
One councillor and a housing association representative were interviewed about their experience posting questions to Viewpoint, which were largely positive.
The housing association stated: "the response was absolutely overwhelming.
I was just gobsmacked by the number of people who responded to that question."
Although the second poll posted by this organisation saw the lowest number of votes, she still characterised the response as "unbelievable" and went on to explain that previous consultations had faced difficulty in engaging residents.
The councillor likewise described the response as "overwhelming", and saw Viewpoint as a means of gathering a broader and more balanced view on local issues: "we only get complaints from people who are really bothered about , so it was a chance to really gauge the feeling about it locally".
The device was also seen as an additional method of increasing awareness of the council's activities.
He suggested that results from Viewpoint were one of many resources the council could use to make informed decisions about utilisation of resources.
He also downplayed issues around multiple votes, suggesting that the subject matter of the questions was not emotive enough to justify the effort required to meaningfully impact the result.
Both expressed a desire for a greater ability to communicate with voters through the devices, as they had posted questions seeking volunteers for various initiatives, but were then concerned about their inability to contact those responding positively.
To alleviate this, they suggested allowing voters to enter their personal details through the device, or displaying contact details for the relevant councillor or housing association.
In both cases, this information was later provided in the question response, but was consequently unavailable until after the poll had closed and only visible when scrolling through past polls.
The hosts of each device were a valuable source of day-today observations of interaction, and also served as a point of contact for curious residents.
One staff member in the shop stated: "It gives the little man, gives him the impression, even if it's not true, that what he thinks actually matters.
Like other members of the community, they stressed that the value of the device was dependant on the ability of question authors to act on the result.
Staff at both the shop and community centre initially reported that children had been pressing buttons as they passed by the device and voting multiple times without reading the question, which they saw as a problem.
This was particularly prevalent at the community centre, where children would gather outside the entrance, close to the foyer where Viewpoint was situated.
As a result of this, the delay between votes was increased from 30 seconds to one minute.
One host later commented that this was occurring less as the novelty value of the device decreased.
Early during the deployment, shop staff reported that customers were reading questions and asking about the device, but during later interviews they reported that interest had declined and many customers were blindly pressing buttons as they passed by.
Although the shop owners responded positively to the device, they also felt it took up too much space in the shop and did not want to keep it beyond the trial period.
This device also had connectivity issues through the deployment, and less technically confident staff members expressed irritation when asked to reset the device.
A number of these comments clearly indicate that members of the public doubted the ability of the device to have an impact on the community.
There is some evidence to suggest that residents took note of the results.
At an unrelated event, one of the authors was recognised as a member of the project team by a local resident, who mentioned the negative response to our first poll regarding the project newsletter and asked: "what are you going to do about it?"
In this example, the public nature of the poll results empowered a resident to demand action.
This illustrates for potential for Viewpoint, given time, to empower the wider community in a similar way.
Over a two-month trial period, Viewpoint demonstrated that it was capable of engaging residents in dialogue with local organisations, allowing them to gather an unprecedented quantity of feedback on a range of local issues.
These included existing problems and potential new facilities, as well as raising awareness of their activities and measuring levels of interest in volunteering.
Although no single intervention can address the complex issues surrounding democracy and participation in communities, deploying Viewpoint in the wild has highlighted a number of issues surrounding the design and use of voting devices to support participation in communities.
Based on these experiences, we have identified a number of factors impacting the design of public voting technologies that we present as guidelines for future research in this domain.
Perhaps the most important goal of Viewpoint was to improve the community's sense of collective efficacy.
By making the community's `voice' heard and making the effect of their input more visible, this would hopefully encourage further participation.
In an attempt to achieve this, a key aspect of the design was the notion of `actionability'--that the results of questions posted on the display could be used to inform decisions and lead to genuine improvements in the community.
The devices aimed to achieve this by inviting responses to each question from the original author.
Whether the goal of improving efficacy was achieved is difficult to assess.
Although actions were promised for a number of polls, a sense of efficacy is something that can realistically only be developed over extended periods of time.
It is unreasonable to expect any single intervention to reverse a deep-seated lack of faith in the system of governance, which had been created by many years of a perceived lack of change.
However, our experiences have highlighted two areas that could be targeted to increase efficacy.
Opinions on Viewpoint were solicited from members of the public as they passed the devices.
Many of these opinions were very positive, reflecting on the ability of Viewpoint to make the community's voice heard: "It's good for the community.
Communities know they can get together and people can share their opinions."
This is the main place in the daytime where you get the highest volume of people coming through that actually live round here and the issues affect directly."
Feedback from the general public was far more mixed than from community organisations.
Many residents appeared unaware and uninterested in the device, and several had not previously noticed the installations: "I'm not really interested in it.
I don't think these things do any good and I haven't used it.
What's the point of asking questions when nothing ever happens?"
What's the point of gathering people's opinions about what's going on if you're not going to do anything about it?"
From our observations, members of the public typically expect a rapid response to their input, while councils and other organisations operate within defined processes that constrain their ability to take action, which the public are not necessarily aware of.
For the question authors, any single method of feedback collection is likely to be just one of a number of input sources that inform any decision, which might take considerable time to reach.
This is particularly true of individual councillors or representatives, who may not have the authority to make direct changes themselves.
Consequently, this can be perceived as a lack of efficacy or unwillingness to respond.
Our view is that this problem is largely caused by a lack of transparency: members of the public are not made aware of how the input they provide will be used or how long changes might take.
Although Viewpoint attempted to make the end result visible, the process between the vote and the result was still opaque.
Future technologies aiming to address this design space should consider how the process of reaching these results can be made more transparent.
A second factor is the actual ability of organisations themselves to effect change.
It was intended that questions would only be posted when decisions needed to be made that could genuinely be based upon input from residents, but despite initial enthusiasm shown by local organisations, it was simply not realistic to provide actionable questions with such regularity.
As a result, many of the questions aimed to gauge the mood of the community rather than make decisions.
While this is certainly an important part of the democratic process, it risks contributing towards the consultation fatigue felt by many residents.
This leads us to consider that it might be infeasible to have a constant stream of questions if such a device were deployed permanently.
For this reason, it may be beneficial to consider short-term deployments at times when consultation is required and organisations can commit in advance to taking action based on the results, perhaps in locations relevant to the issue at hand.
Such deployments could help to retain the device's novelty in the eyes of both the public and organisations, while being carried out at times when issues were most relevant.
In this scenario, organisations asking questions could state in advance what actions they are capable of taking, increasing the visibility of this promise.
However, this would have the disadvantage of preventing voting from becoming a regular, habitual occurrence, which could be a benefit of fixed deployments.
Firstly, the simple design meant that it was relatively easy for a single voter to register multiple votes over the course of a week.
Evidence also suggested that many votes were placed flippantly, often by children who would vote multiple times despite the delay or without reading the question.
Almost a fifth of votes followed the preceding vote by less than two minutes, casting doubt on their credibility.
None of the results were significantly impacted by removing these votes, however.
Multiple voting itself was not necessarily seen as an issue by all members of the community.
Our early fieldwork indicated that some residents saw this as a legitimate means for those who felt passionate to make themselves heard, reflecting existing processes where the most vocal members of the community are best represented.
Conversely, some question authors required that only one vote be cast per person.
However, any method of uniquely identifying users would greatly increase the complexity of the interface and discourage interaction.
This highlights a difficult unsolved design issue for noncritical voting devices: how can we discourage flippant votes, but make voting easy enough that it encourages legitimate participation?
Solutions to this problem may lie with both novel user interfaces and simple human intervention; for example, the shop owner monitored use of the device and reported asking children to leave if they were voting multiple times.
Above all, we recommend that lightweight democracy technologies should not automatically assume that high levels of security are required for non-critical domains and that this should be tailored to individual deployment contexts.
In an election, the result is typically secret until after the polls have closed, to avoid influencing subsequent votes.
For other methods of judging options, such as a show of hands in a town hall meeting, the result may be visible to everybody.
Indeed, for deliberation and mediation to take place, it is necessary for different opinions to be aired in public.
Viewpoint displayed results in real-time, allowing residents to see the current result before they voted, see the impact of their vote on the result, and track the progress of polls through the week.
This was primarily to demonstrate that the device was working and create a positive user experience, reinforced by mechanical sound effects to indicate that an operation was taking place.
Like issues around misuse, we should not assume that all voting technologies need to conform to the standards of critical elections and referenda.
However, further exploration is certainly required to determine to what extent this visibility affects the way people cast their votes.
For example, voters may feel persuaded to vote with the majority, might feel that voting is futile if their choice is in the minority, or might feel more inclined to vote if they disagree with the current result.
Like the other factors discussed above, there is a careful balance to be achieved between the need for simplicity and needs of organisations to collect adequate data.
Finally, the physical location of each Viewpoint device was naturally a contributing factor towards its usage.
Viewpoint was very much a situated technology, and as each device was deployed in a different location, behaviours surrounding the two displays differed.
The locations selected were ideal not just because they saw considerable traffic, meaning a large number of residents passed the devices regularly as they went about their day-to-day business, but because they were locations where members of the community met and where discussion about local issues already took place--where community happens.
These are valuable locations for any technology hoping to engage the community.
The location of the devices also impacted on the results themselves, as different locations reached different audiences, due to both the geographic location within the community and the roles of the deployment venues.
This was most marked in the question relating to the community centre, where the proportions of votes cast at each location were inverted.
This was not reflected in the reported results, which simply aggregated votes from all locations.
A more detailed report of results might better reflect how different segments of the community felt on certain issues, allowing service providers to target their efforts accordingly.
Viewpoint has demonstrated that simple voting interfaces in public spaces can provide an easy method of encouraging participation in communities where traditional methods have been unsuccessful.
This presents potential benefits to residents, councillors and other community organisations.
However, although data collected through the device led to at least one firm promise of action, residents remained sceptical about action being taken based on the results.
Even with the best of intentions, real-world constraints on organisations meant actions were limited in scope and, like other forms of consultation, it can take considerable time for changes to come into effect.
Further research is required to address the challenges of making these constraints more transparent and balancing simplicity against credibility.
Through this trial, we were also able to identify key design factors impacting the design of public voting technologies.
These related to the efficacy of the system and its ability to produce change; the credibility of the results and voting process; and the practical issues surrounding the design and location of the voting device itself.
Future research can utilise this guidance when exploring the potential role of public voting technologies in community participation and civic engagement.
Given the quantity of feedback received, the device was successful in encouraging participation from a far greater proportion of the community than had been managed by existing methods.
This was achieved by lowering barriers to participation through the device's interaction design, question format and location.
In terms of the device's interaction design, it is clear that the extremely simple method of placing votes was a key factor in generating the high number of votes.
By only requiring a simple button press to participate, the design of the device lowered barriers to participation and encouraged interaction.
The very tactile buttons and immediate feedback also made this quite a satisfying user experience.
Only a small degree of extra complexity was required to discourage interaction, as demonstrated by the unfavourable response to voting by mobile phone.
This suggests that our approach of making the device as simple as possible was an appropriate choice.
Clearly there is a trade-off here between the need for simplicity and other requirements, such as efficacy and credibility discussed above.
For example, when interviewed, several question authors expressed a desire for higher fidelity feedback that was not possible with this design.
Consequently, while such a simple user interface might not be suitable for all similar technologies, to encourage participation they should remain as simple as possible, while also attempting to create an engaging user experience.
In addition to the physical design of the device, the format of the questions themselves appeared to influence the degree to which residents engaged with the device.
For example, the question that received the least votes was also the longest.
Furthermore, questions seeking to determine levels of interest in services or volunteering secured fewer total votes.
Conversely, the most successful questions were concisely worded and implied realistically achievable results.
This agrees with our earlier observations regarding barriers to participation, and also relates closely to efficacy: if there is no perception that a positive outcome is likely, there is little motivation to participate.
This indicates is a clear need to work closely with organisations to formulate engaging and actionable questions.
Although councillors and local organisations are accustomed to generating content for public consumption,
