One hallmark difficulty of children with Autism Spectrum Disorder  centers on communication and speech.
Research into computer visualizations of voice has been shown to influence conversational patterns and allow users to reflect upon their speech.
In this paper, we present the Spoken Impact Project , an effort to examine the effect of audio and visual feedback on vocalizations in lowfunctioning children with ASD by providing them with additional means of understanding and exploring their voice.
This research spans over 12 months, including the creation of multiple software packages and detailed analysis of more than 20 hours of experimental video.
SIP demonstrates the potential of computer generated audio and visual feedback to encourage vocalizations of children with ASD.
150 children , highlight the need for effective methods to facilitate the development of communication, including speech.
This paper presents SIP, the Spoken Impact Project, which aims to explore a new area of HCI: using real-time audio/ visual feedback to facilitate speech-like vocalizations in low-functioning children with ASD.
This work is grounded in HCI and behavioral science literature.
We believe computer-generated feedback, based upon a child's vocalizations, can influence the vocalizations of children with ASD for communicative purposes by providing them with additional means of accessing information regarding parameters of their voice .
We first outline the foundations of SIP's design.
We then describe the four areas of our research: Software Design, Within-Subject Experimentation, Data Gathering, and Data Analysis.
Beyond the results of the experiment, the main contributions of this work are the demonstration of a new approach to ASD research  and an initial understanding of how the SIP model could be further explored by the HCI community.
As a child develops, acquisition of speech and language typically progresses with little or no explicit effort from parents, family, or doctors.
Developmental disorders, such as Autism Spectrum Disorder , can significantly disrupt the natural development of social behaviors, such as spoken communication.
Since language is "a unique characteristic of human behavior...  contributes in a major way to human thought and reasoning" , the communication deficits of children with ASD are likely to have detrimental effects on multiple aspects of their lives.
Kanner's 1943 description  of 11 children with ASD documented this disorder in the scientific community.
In the past 60 years, scientists and therapists have strived to better understand ASD and provide treatments to mitigate its many communicative and social difficulties.
The ASD population is not a homogenous group.
Many of the characteristic difficulties and developmental delays revolve around communication, empathy, social functioning, and expression.
The Autism Society of America describes ASD as "insistence on sameness... preference to being alone... spinning objects  obsessive attachments to objects".
While some children have limited impairment, those who encounter greater challenges with social and communicative skills are considered low functioning.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
In the 1960s, Ivar Lovaas' adopted the pioneering approach of "applied behavior analysis" to help teach communication and social skills to children with ASD.
The treatment focuses on extrinsic rewards  for encouraging targeted behavior .
Over time, rewards are slowly faded/removed resulting in more naturalistic behavior.
CHI 2009 ~ Learning Challenges have been used to help develop social and communicative skills in children with ASD.
While the merits of this treatment have been documented for 40 years, this form of intervention is financially expensive and labor-intensive.
Furthermore, frequent sessions requiring sustained attention and intense human-to-human contact can be anxiety producing .
This anxiety, that characterizes many children with ASD, along with their human detachment  causes difficulty for practitioners and children.
Generalization of social communication skills is another programming challenge.
Given the documented impact of these forms of treatment, technology has the potential to augment and/or increase this impact while reducing the burden on families and children.
Our research begins with the basic question: can real-time visual/audio feedback positively impact sound production in low-functioning children with ASD?
While there is controversy about whether high-functioning children with ASD should be pressured to communicate vocally, this concern is not applicable to this vein of research.
These children do not possess a linguistic system .
Teaching functional communication is essential, although the method should vary according to individual preference and capabilities.
Since the 1990s, the HCI community has examined how computers can aid in the diagnosis of ASD .
In addition, HCI has studied audio perception  and teaching human-to-human interaction to high-functioning children with ASD .
Elements of play have also been studied demonstrating that technology/computers can reduce the apprehension associated with human-to-human interaction .
Other HCI research  and technology-based behavioral science research , with individuals other than those with ASD, have illustrated the use of computer solutions in the context of speech and communication therapy.
With this work, we explore methods and technology that can facilitate speech and vocalization processes of children with communication skill deficits.
Specifically, we employed contingent visual and auditory feedback  to motivate and reward vocalization and  to provide information about the acoustic properties of vocalizations.
Due to the current limitations of speech recognition software , forms of speech detection are limited, especially for individuals with poor diction.
Hence, our technological solutions must be designed to aid and supplement practitioners and researchers rather than replace them.
We posed the following research questions about the effects of contingent audio and/or visual feedback on low functioning children with ASD.
R1: Will at least one form of real time computer-generated feedback positively impact the rate of spontaneous speech-like vocalizations?
R1 is the primary question of SIP: testing the impact of computer-generated feedback.
R1 builds upon the success of traditional alternatives  and other related work.
The remaining research questions examine modes of feedback, and their implications on rate of spontaneous speech-like vocalization.
R2-R5 are derived from research into the profiles of children with ASD  that concluded that these individuals prefer visual feedback .
The responses to R2-R5 will directly impact future systems and the extent to which individualization is needed.
R2: Will all forms of feedback positively impact the rate of spontaneous speech-like vocalizations?
R3: Will subjects increase the rate of their spontaneous speech-like vocalizations during conditions with visual-only feedback, audio-only feedback and/or mixed feedback?
R3a: If there is a modality that demonstrates significance , or p < 0.1, which specific form of feedback in that modality significantly and positively impacts the rate of spontaneous speech-like vocalizations?
The quantitatively driven investigation of R3 may hide the impact of a specific form of feedback; if one form of feedback in a modality is significant, but fails to adjust the results in R3, it will not be analyzed in R3a.
Therefore R4; R4: By testing feedback conditions that were qualitatively favored by subjects , will we uncover forms of feedback that positively impact the rate of spontaneous speech-like vocalizations?
R5: Is there a modality of feedback whose variations indicate  the child's rate of spontaneous speech-like vocalization are positively impacted.
SIP explores a new area of HCI research focusing on the use of contingent audio and/or visual feedback to encourage sound production in low-functioning children with ASD.
Without the development of techniques to encourage speech/vocalization, a diagnosis of ASD can have far reaching negative implications for a child's social, developmental and educational life.
Building on prior work, our focus on computer visualization in this population is unique.
Most HCI visualizations research has focused on neurologically typical individuals .
ASD treatment research in HCI has targeted higher functioning children with ASD , failing to address the needs of non-verbal/low-functioning children with ASD.
These higher-functioning individuals tend to be more capable of articulating their needs and opinions during evaluation as well as understanding tasks they may be asked to complete.
April 6th, 2009 ~ Boston, MA, USA * Reward: computer sound was produced upon completion of subject's sound.
Duration of reward sound was related to duration of sound produced .
Sound could be music or found-audio .
There were five forms of audio feedback available that could be mixed with any visual feedback permutation.
During three months , the researchers designed the Spoken Impact Project Software  package in Java using the Processing Library .
SIPS generates audio and visual feedback directly related to the amount of external noise detected by the system.
For example, a circle on the screen could change in diameter, as sound, particularly voice, grows louder.
An "echo", like that heard in a stairwell, is an example of audio feedback.
Distortions could be applied to change the perception of the sound returned to the subject.
SIPS visual feedback  consists of one of three possible types of graphical objects: circular/spherical, lines, or found images .
These objects can be presented in one of four types of motion metaphors:  Falling-objects move from one portion of the screen downward, as if drawn by gravity.
This includes particle effects like water from a shower head or fireworks ;  Spinning-objects move in a circular or spiral pattern ;  Flashing-objects appear and disappear quickly ;  Stationary-objects stay in a fixed location .
The falling and spinning metaphors were selected to leverage stimuli that garner interest from children with ASD .
Flashing feedback was investigated due to its high energy which often appeals to neurologically typical children.
Stationary objects were explored to focus on change in an object 
Among the four categories, approximately 12 unique motion/pattern combinations were created; most can function with any type of object .
SIPS provided two categories of audio feedback based on the sound produced.
There was a slight delay between the source sound and feedback, but both input and output occured simultaneously.
Our subjects demonstrated limited response to requests or instructions to perform tasks due to the severity of their ASD.
Therefore, engaging subjects in the same activity across trials and sessions was not a viable option.
We relied on the visual/auditory feedback to be sufficiently engaging to promote spontaneous speech-like vocalizations.
The feedback presented and tested was varied across children to enable an exploration of R3 and R3a.
As a result, each child's performance served as his or her own baseline/ control for comparison across conditions.
Given the number of subjects participating and the questions generated, a within-subject design was selected.
The analyses were conducted using a baseline created by each child and comparing that baseline to each of the computerized feedback conditions: visual, auditory or visual/auditory combined.
The within-subject experimental design , an adaptation of an alternating treatments design , consisted of five non-verbal children  diagnosed with "lowfunctioning" ASD.
Each child enrolled in the study first participated in one to three 30-minute "orientation sessions" which acclimated the child to the study room, researchers, and computer feedback.
No data were recorded during these sessions, though initial preferences for feedback type/style were noted.
Room configuration was selected based on child preference and is described/labeled in Figure 2.
Each child attended 6 data sessions after completing the orientation period.
A data session lasted for approximately 40 minutes and consisted of approximately 8 two-minute trials.
Each trial began with an antecedent demonstration by the researcher .
Subjects then could engage the system in whatever manner they chose.
Feedback permutations were selected based on researcher's subjective calculation of vocalization rate.
Order of presentation was randomized across sessions to accommodate for order effects.
However, the first trial of each session was a baseline trial with no audio or visual feedback.
Although this baseline trial provided a means of comparison for assessing changes in spontaneous speech-like vocalizations due to visual/auditory feedback, we provided no control for order effects related to the presentation of the baseline condition.
Baseline was always the first trial.
This is critical when assessing children with special needs .
Spontaneous Speech-Like Vocalizations - sounds produced by the subject that can be phonetically transcribed  and are not being imitated.
Unlike imitated vocalizations , SSLVs are more indicative of vocalizations that may be used for meaningful speech because they rely on longer-term storage and retrieval of linguistic information .
Examination of existing digital tools for digital video annotation found interfaces to be overly complicated and lacking in reliability measurement functionality.
Therefore, we designed/built a suite of applications called VCode and VData.
A full description of the tools, features, justification and reaction of users is presented in .
VCode is a tool used by coders to view and annotate digital video.
In order to support SIP, VCode provides two types of annotations: ranged  and momentary .
VData is a tool designed to perform agreement calculations and link annotations by two coders back to the original video.
VData utilizes point-by-point agreement to assess reliability.
Point-by-point agreement is calculated by assigning one coder as a primary coder and the other as secondary.
Any mark made by the primary coders is considered an opportunity for agreement.
Marks made by the secondary coder that are the same as the primary coder are considered agreements.
The percent agreement is calculated by dividing agreements over opportunities.
Through VCode and VData, the data collection and agreement calculation process was simplified.
Over a six-month period, 1200 minutes of video were annotated .
Inter-rater agreement  across all 18 variables was 88%.
Our within-subject experiment analyzed the dependent variable Spontaneous Speech-Like Vocalization .
The independent variables were the various permutations of visual and auditory feedback.
These analyses permitted comparisons between the mode of feedback  as well as the different types of feedback within modes .
A set of dependent variables was developed to quantitatively assess the impact of SIPS.
This guide, A3  or Annotation for ASD Analysis, was based on existing literature in HCI and behavioral sciences.
A full description of A3, the 18 variables, developmental process, justifications, coder's guide, reliability data, and reactions from coders is presented in .
We focused our analysis on Spontaneous Speech-Like Vocalizations , one of the dependent variables from A3.
There is a clear and important distinction between those vocalizations that are spontaneous and those that are imita-
Each subject was analyzed independently.
Due to the varying lengths of each trial, a comparison of the number of occurrences of SSLV would be weighted towards longer sessions.
To mitigate this effect, we analyzed a normalized rate of SSLV  to arrive at a rate.
Wilcoxon rank-sum and Kruskal-Wallis tests were used to compare SSLV rates in response to different types of feedback.
The Wilcoxon rank-sum test is a non-parametric alternative to the paired T-test.
The KruskalWallis test is a non-parametric alternative to a one-way analysis of variance .
These tests were well suited for these data where distributions were not normal and where numbers were small because they do not make any distributional assumptions.
All tests used a two-tailed alpha with a p<0.05 denoting statistical significance.
R3 addresses whether all forms of feedback in a specific modality positively impact SSLV.
An examination of R3 for each subject is conducted by performing a Wilcoxon ranksum test comparing rate of SSLV at baseline with rate of SSLV in groups audio only, video only, and mixed feedback.
Results from R3 can be Video , Audio , Mixed  or some permutation of the three.
If none has a significant p value, R3 is considered Neither, indicating that no modality increased the rate of SSLV .
To protect the privacy of our subjects, we have changed their names; gender status was maintained.
All five of the subjects' spoken language developmental benchmarks  were in the first phase , equating closely to the development of a neurologically typical 6-12 month old.
R3a examines if there is a specific type of feedback that increased the rate of SSLV in a modality that approached significance.
Using the result from R3, we parsed specific forms/combinations of feedback within those statistically significant modalities .
Trials within the specific modality are divided into subcategories based on specific forms of feedback and tested against baseline using the Wilcoxon rank-sum test.
R3a required that p values for R3 either approach or reach statistical significance.
Initial analysis of Oliver's data  demonstrated borderline significance comparing baseline to all feedback trials .
Further, the audio only and mixed feedback conditions  approached significance.
Due to a trend towards significance in the two conditions involving audio, we compared the rates of SSLVs at baseline with any condition containing audio feedback .
There was a statistically significant difference between conditions containing any audio feedback and those containing no audio .
We used qualitative observations gleaned from researchers and video to guide this analysis.
Here we could employ overlooked forms of feedback that appeared to increase the rate of SSLV.
Using the Wilcoxon rank-sum test, we compared baseline with conditions that were qualitatively observed to increase SSLV rates.
Since audio appeared to increase the rate of Oliver's SSLV, we explored the impact of different types of audio feedback in combination with visual feedback.
Table 1 suggests that echo feedback encouraged SSLV, while visual feedback did not appear to have significant impact on SSLV rate .
We qualitatively observed that Oliver reacted positively to audio from a popular cartoon show.
From this analysis, we conclude that audio feedback was associated with higher rates of SSLV for Oliver.
Specifically, SSLV rates increased in conditions with echoing audio feedback .
From this analysis, we concluded that Frank had higher rates of SSLV in conditions with audio feedback and with audio and visual feedback combined .
Specifically, he appeared to produce higher rates of SSLV in response to audio and visuals from a specific cartoon.
Interestingly, his mother stated that Frank did not watch this cartoon show.
Initial analysis of Frank's data  showed a significant difference between baseline SSLV rates and rates produced by all feedback conditions .
We found a statistically significant difference in rates of SSLV with audio only and mixed feedback .
Due to significance in both conditions with audio, we compared rate of baseline SSLV with any condition with audio feedback.
Given the robust effect of audio feedback, we compared Frank's responsiveness to audio feedback with and without visual feedback .
Audio feedback was categorized as "found audio" and "echo".
Based on our qualitative observations, we isolated and analyzed trials where audio feedback from a specific child's cartoon was present.
Frank demonstrated the most significant increase in rate of SSLV over baseline when audio from the cartoon was present .
For Frank, visual feedback had a positive impact on the SSLV rates when audio was also present.
Finally, we examined all conditions with audio feedback into those with specific types of visual feedback to assess the impact of specific visual feedback types on the rate of SSLV production.
Based on qualitative observations, we analyzed trials where a visual image from a specific cartoon was present.
Frank demonstrated increased rate of SSLV over baseline for all visual feedback in addition to audio except for Spinning Spiral of Dots and Random Dots , with the clearest effect in Firework-Like .
Initial examination of Larry's data  failed to reach statistical significance for the R2 and R3 analyses.
While statistical tests did not reach statistical significance, qualitative observations from researchers and study video, in conjunction with graphical representation of the data , led us to believe that feedback did have an impact on rate of SSLV, specifically conditions with echoing audio feedback.
Qualitatively, researchers observed a higher degree of attention and SSLV, during conditions with echo/ reverb feedback.
Comparing conditions with echoing feedback with baseline produced a lower p-value than other analysis , yet it did not reach p<0.05.
We performed a Wilcoxon rank-sum test to compare conditions using echoing feedback with visual feedback to conditions with only echoing feedback and no visual feedback.
Given p=0.970, we concluded that there was no significant difference in SSLV between echoing conditions with and without visual feedback.
To compare the impact of echoing feedback on SSLV rates with varying types of feedback, we used the Kruskal-Wallis test.
First, we categorized all of Larry's trials into one of the following 5 conditions;  baseline,  any condition with echoing feedback,  audio feedback only ,  visual feedback only ,  audio + visual feedback .
The KruskalWallis test resulted in p=0.060.
To increase statistical power, we combined visual only feedback with the mixed condition since groups had visual presentations2 .
Analysis of these groups found a statistically significant difference .
A post hoc pair-wise comparison of each condition, using Wilcoxon rank-sum test  was performed.
Statistically significant differences were found between the echo condition and audio only  .
From this analysis, we concluded that Larry showed preference for echoing audio feedback .
However, we believe that with more statistical power, we could make a more conclusive statement.
Initial analysis of SSLV duration  was significant for visual only conditions .
Audio only feedback  was not tested, due to lack of interest observed in initial orientation sessions.
To examine impact of visual feedback, we divided the types of visual only feedback and compared the average duration of SSLV's with those produced in the baseline condition .
The last row in Table 5 is an amalgam of different forms of visual feedback in which abstract colored dots were replaced with one or more found image.
These data support our qualitative observations that Diana responded only to conditions where images shown were from cartoon shows, and that audio feedback reduced her SSLV duration .
Three statistically significant forms of feedback were Spinning Image , Multiple Circles  and any feedback with Found Images  .
From this analysis, we concluded that Diana produced more SSLV's  with visual feedback compared to baseline and mixed .
Specifically, she appeared to show increased engagement with forms of visual feedback that contained a cartoon character .
Diana's mother reported that she watched movies/TV-shows with these characters.
Initial data analysis for Diana, revealed much higher p values  than expected when comparing them to qualitative notes made by the researchers.
Confused by these findings, we examined annotations made by video coders and noticed that large strings of Diana's SSLV's were grouped together.
A3 guidelines stated that utterances must be separated by a pause of 2-seconds to be considered independent.
However, Diana's pauses ranged from 1-to-1.5 seconds in duration.
As a result, phrases of multiple utterances were captured as a single occurrence.
To accommodate her shorter pauses, we re-analyzed her data using mean duration of SSLVs rather than rate.
For this subject, we used average duration as a proxy for rate.
Brian was the most difficult subject for us to qualitatively discern a particular pattern or "taste" for feedback.
This was supported by extremely high p-values for all coarse tests conducted .
During three sessions, we inadvertently failed to run a baseline, reducing the number of comparison points to three instead of six.
While Wilcoxon rank-sum statistics approached significance for one particular form of visualization in which a cartoon character spun in a circle centered on screen, it failed to reach significance.
In 4 of the 5 subjects, we found that at least one type of feedback produced an increased rate of SSLV.
We were unable to show that any form or modality of feedback, when compared to baseline, significantly increased the rate of SSLV's for Larry and Brian.
This may be, in part, due to the small number of data points collected and high degree of ASD.
We were, however, able to demonstrate that echoing audio feedback produced a significant difference in rate of SSLV's when compared with all other forms of feedback for Larry.
Overall, we concluded that particular modes/ types of feedback may encourage SSLV in children with ASD.
Parents responded with high praise for our technique, and asked for similar procedures to be implemented in their own homes.
One mother stated, My child's reaction is one of excitement and looking forward to see what was next to come.
You may be onto something here.
Another mother stated her child's reaction, Since my son is fairly severely affected by autism, he stays in his "own little world" quite a bit.
So the fact that he showed interest in and seemed to enjoy some of the visuals and sounds is quite a positive thing.
It is commonly believed that individuals with ASD are more responsive to visual feedback than auditory .
However, we had two subjects who responded primarily to auditory feedback .
One preferred a mixed condition .
One responded to visual only .
And one subject  did not show any significant response to any form of feedback.
When viewed from a global level, 3 of 5 subjects responded to audio feedback, and 2 of 5 responded to visual feedback .
This suggests that further exploration of feedback in both the visual and audio modalities is essential.
This finding is of particular note in that it is in contrast to other work.
Researchers qualitatively noted that Frank's response was exceptional, both in terms of his reaction to the computer feedback and his eagerness to participate.
Noting this, researchers constructed a Wizard-of-Oz system, based on SIP, geared towards teaching specific skills.
The model followed a common form of behavioral therapy : Prompt a word - wait for a response - reward if correct or repeat if incorrect.
We replaced the computer voice recognition with a researcher to test the concept.
This system aurally prompted subjects with a word in the form of the phrase "Say ."
Once the prompt was completed, the computer provided visual feedback  and audio feedback .
Immediate feedback provided the subject with an instantaneous reaction to their sounds, for both visual and auditory reinterpretation.
If Frank did not repeat the sound, or the repeated sound was not "close enough," the researcher directed the system to re-prompt.
If Frank's response was "close enough," the researcher directed the system to provide an auditory and visual reward.
With parental permission, we conducted 2 sessions using this system.
The first consisted of 10 words, which had been previously used by Frank .
Initially, Frank played with the system .
After 15 minutes, he began repeating words upon the request of the system.
At the end of the 30-minute period, Frank imitated every prompted word.
During the second session, we used 6 words his mother stated that he had not spoken before, in addition to 4 words from the previous session.
Although some subjects had a larger range of forms of feedback that resulted in increased rate of SSLV than others, 4 of 5 subjects did have one particular condition that out-performed the others.
The specific results, in conjunction with varied modes of feedback that resulted from R3 analysis, indicate that visualizations, and any potential therapeutic application, will likely need to be tailored to individual subjects.
The degree of customization is unknown due to small sample size.
We can proceed, however, knowing that individual interests/preferences must be taken into consideration.
This work illustrates the varied types of audio/visual feedback that garnered the increase in SSLV.
CHI 2009 ~ Learning Challenges used to date.
Frank readily played the Prompt-Repeat game and attempted to imitate the new words.
Although articulation was often unclear, he made a concerted effort to repeat all 10 words, including the 6 new ones.
Of particular note, Frank had been highly resistant in the past to this form of vocal imitation language therapy.
While this follow-up study consisted of a sample of n=1, and was conducted using Wizard-of-Oz, it does suggest the possible implications of using a SIP-like system to encourage and teach specific vocal skill imitation or possibly acquisition.
April 6th, 2009 ~ Boston, MA, USA Given the results from the SIP study, we believe that audio and/or visual feedback can be used to encourage spontaneous speech-like vocalizations in low-functioning children with ASD.
In addition, SIP demonstrated that both visual and auditory feedback can impact spontaneous speech-like vocalization.
This suggests that further exploration of feedback in both modalities is essential.
This finding is of particular note in that it is in contrast to other existing work.
SIP also suggests that low-functioning children with ASD may have distinct and varied preferences for types/styles of feedback.
As a result, individual customization may be necessary in future efforts.
Although the range of variation necessary is unknown, the final solution might include a suite or menu of feedback styles that may be selected by the parent, clinician, or child.
Given the promising results of our data, the encouraging messages of parents, and the potential impact demonstrated in the Wizard-of-Oz study, we believe that SIP-styled therapy is an exciting and viable method for encouraging speech and vocalization in low-functioning children with ASD.
This research presents initial steps towards exploring the application of audio and visual feedback to encourage speech in low functioning children with autism.
Given our encouraging results, there are many exciting areas of future work.
One of the most immediate directions might be adaptive feedback selection.
Previously, researchers subjectively assessed which visualizations and forms of audio feedback were engaging to subjects.
Future work might examine if a system could adaptively change forms of feedback in concert with the subject's response via machine learning.
This would not only ease the job of clinicians and researchers, but as preferences change and subjects satiate, such a system would accommodate and adapt to these changing preferences.
We see the potential to test our approach with other populations or other target behaviors.
One unanswered question is how to identify a method for teaching specific vocal skills, such as words in context, syllables, etc.
Another opportunity would be to explore the delivery of a SIP appliance.
The investigation of a toy-like device could provide therapeutic play at home, as well as at the practitioner's office.
REFERENCES  Adler-Block, M., Bernhardt, B. M., Gick, B. and PBacsfalvi, P. The Use of Ultrasound in Remediation of North American English /r/ in 2 Adolescents.
The effect of live interactive video on the communicative behavior in children with autism.
University of North Carolina at Chapel Hill, Chapel Hill, 1996.
In Proceedings of the INTERACT .
The children participating were diagnosed with autism and had significant intellectual disabilities.
Their attention to tasks was limited.
Sometimes the subjects would appear highly engaged with a type of feedback, while other types proved completely unengaging.
This often resulted in trial sessions of extremely short duration, as subjects would get up and move away from the computer.
Duration of the trials had high variance, and reduction in observation time may have reduced statistical power of this study and the capacity for statistical tests to reach significance.
We may not have fully appreciated the positive effects of SIPS in this small study.
However, we were able to observe numerous types of feedback that garnered significant changes in SSLV rates.
With the small scale of this first study, we cannot conclude that audio/visual feedback will increase SSLV for every child with ASD.
However, based on our 5 within subject analyses, we believe our results are promising.
We also wish to highlight that there is a leap between producing SSLV and real-world communication.
Our current study focused specifically on encouraging a behavior that is a precursor for functional communication.
This work, in conjunction with the findings from the Follow Up study, lay the ground work for future exploration of this area of research.
2007  Grandin, T. Thinking in Pictures: And Other Reports from My Life with Autism.
Teaching Language in the Natural Environment: An Analysis of Spontaneity.
A., Truong, K. N., White, D. R., Abowd, G. D. and Pering, T. Designing Capture Applications to Support the Education of Children with Autism In Proceedings of Ubicomp 2004 , 2004.
1997  Kanner, L. Autistic Disturbances of Affective Contact.
A., Arriaga, R. I., Chetty, M., Hayes, G. R., Richardson, J., Patel, S. N. and Abowd, G. D. Grow and know: understanding record-keeping needs for tracking the development of young children.
A., Hayes, G. R., Abowd, G. D. and Grinter, R. E. From the war room to the living room: decision support for home-based therapy teams.
Proceedings of ASSETS `98 .
Children with Specific Language Impairment.
Marshalla Speech and Language, Kirkland, WA, 2001.
Journal of the International Neuropsychological Society, 3.
National Autistic Society, London, 2000.
Division of Behavioral and Social Sciences and Education, Washington, DC: National Academy Press, 2001.
Promotion of creative activity in children with severe autism through visuals in an interactive multisensory environment.
In Proceedings of 2005 conference on Interaction design and children .
Journal of Speech, Language, and Hearing Research, 50.
The eyes have it: a task by data type taxonomy for informationvisualization.
In Proceedings of the IEEE Symposium on Visual Languages , 1996.
Playing with Virtual Peers: Bootstrapping Contingent Discourse in Children with Autism.
In Proceedings of the Proceedings of International Conference of the Learning Sciences .
