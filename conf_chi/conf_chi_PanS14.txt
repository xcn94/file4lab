Gaze, attention, and eye contact are important aspects of face to face communication, but some subtleties can be lost in videoconferencing because participants look at a single planar image of the remote user.
We propose a low-cost cylindrical videoconferencing system that preserves gaze direction by providing perspective-correct images for multiple viewpoints around a conference table.
We accomplish this by using an array of cameras to capture a remote person, and an array of projectors to present the camera images onto a cylindrical screen.
The cylindrical screen reflects each image to a narrow viewing zone.
The use of such a situated display allows participants to see the remote person from multiple viewing directions.
We compare our system to three alternative display configurations.
We demonstrate the effectiveness of our system by showing it allows multiple participants to simultaneously tell where the remote person is placing their gaze.
We evaluate the effectiveness of our system by measuring the ability of observers to accurately judge which target the remote person is gazing at.
We run an experiment to demonstrate that our system can convey gaze relatively accurately, especially for observers viewing from off-center angles.
This demonstration and results thus motivate the further study of novel display configurations and the supporting camera and networking infrastructure for them.
When a group of people communicate face to face, numerous cues of attention, eye contact, and gaze direction provide important additional channels of information, such as attention targets, conversational turn-taking indicators .
However, those non-verbal cues can be lost in traditional teleconferencing systems .
A variety of systems have been developed to support gaze awareness in group video conferencing, though the majority use a 2D planar display .
We propose to use a cylindrical display which provides the same angle of view from all directions.
We further propose to use a camera array to surround the remote person horizontally, capturing unique and perspective-correct videos for each potential observer's viewing direction  to Figure 1.
Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Many systems have achieved accurate reproduction of gaze direction in group video conferencing, including MAJIC , Hydra , GAZE-2 , Animatronic shader lamps avatars  and 3-d live .
These systems support correct gaze direction when used with one participant per site.
Several current multiview display systems use a single display and a filter method or a lenticular separation method to produce different views.
These methods divide the resolution of a display among multiple views so that each view has only N/K pixels, where N is the pixels of the full display and K is the number of views.
MultiView  supports K fullresolution views.
However, those planar displays are visible from the front only.
Experiment setup: In the remote room, a camera array is used to capture unique and correct perspectives of the remote person gazing at the target 5.
In the local room, a cylindrical multiview display is used to allow each observer to view their respective perspectives simultaneously.
One of observers seating in viewpoint 1, only sees the video captured by camera 1.
The screen's main function is to reflect the image produced by a projector only to an observer in a very specific viewing zone.
The idea of creating multiview screen for video conferencing is proposed by Nguyen et al.
Our screen consists of a retroreflective layer around the cylinder, with a one-dimensional diffuser layer 6mm above.
Experimentation was conducted with different retroreflective materials, leading to the decision to use "white number plate reflective" from ORALITE R , because it has a strong retroreflective characteristic, minimal reflective properties and good diffusive properties to reduce glare effects.
A 1D lenslets-based lenticular sheet is used as the onedimensional diffuser.
The lines of the lenticular sheet placed horizontally to provide vertical diffusion.
A 6mm or more physical spacing between retroreflective layer and lenticular sheet allows the light to mix vertically.
The smooth side of the lenticular sheet is facing the observes and projectors.
The 40 lenticules per inch  sheet with 49 viewing angle from Pacur R  is chosen for two reasons: the thin thickness  of this sheet allows it easily to wrap around the cylinder; we only require a modest amount of vertical diffusion.
More diffusion would hurt the brightness of the image.
The goal of our system is to allow multiple observers to perceive the gaze of a remote person accurately.
That is observers can each see a unique and perspective-correct image from their viewing directions simultaneously.
Each camera is linked to the corresponding projector to stream real-time video using TCP.
The cylindrical screen ensures that each projected image will only be seen by an observer who is in the viewing zone for that projector.
Also, using available offthe-shelf components allows our system to be built at a low cost.
The cost for a three person multiview display would be approximately $1000, for a nine person multiview display would be approximately $2920.
In the remote room, nine PlayStation R Eye USB digital cameras are vertically mounted on an angled table at radius of 600mm every 15 , as illustrated in Figure 2 and Figure 2.
We manually adjust the cameras to look at the point above the center of the angled table.
We then use Camera Calibration Toolbox for Matlab R to locate the cameras' positions and orientations accurately.
The accurate positions and orientations of the cameras are used in the arrangement of projectors, so that accurate projecting of video can be done.
The cameras are set to the 56 field of view setting.
The cameras capture at 30 Hz at 640x480 pixel resolution.
We arrange each camera vertically in order to make full use of the pixel resolution to represent the remote person's head.
In the local room, the cylindrical screen is located at the center of an angled table which is the same size as the one in the remote room.
We designed a cylindrical screen 32 cm in diameter and 70cm in height.
The size is small enough to situate almost anywhere in a room.
This display is visible from all directions, whereas flat displays are only visible from the front.
The radius of curvature of the screen is similar to a real convex face to avoid the TV-screen-turn effect .
Nine projectors and observer viewpoints were set around the half annular table with a radius of 1500mm at every 15 which exactly line up with each camera in the remote room as depicted in Figure 2 and Figure 2.
We vertically mounted each projector at a height of 1800mm, allowing an observer to sit under a projector.
We use Projector-Camera Calibration Toolbox R to align the projectors' positions and orientations accurately.
Each projector projecting a unique image on the part of the cylinder at the same horizontal level, but there are some overlap between images that projected by different projectors.
The cylindrical multiview screen controls diffusion and produces relatively narrow viewing zones above, below, and slightly to the sides of a light source.
Therefore, a observer sitting under the bottom of a projector sees only the image from that projector.
We used NEC R NP110 projectors with resolutions of 800x600 pixels.
The purpose of the experiment was to demonstrate that our cylinder multiview system can better represent the remote person's gaze for multiple observers.
We measured the effectiveness of the displays by measuring the ability of multiple observers to accurately judge which target the remote person was gazing at.
We compared four display conditions.
Cylinder multiview multi-video condition was our system discussed above, which could support correct viewing for multiple viewpoints around a conference table .
Cylinder multiview single-video condition was identical to the cylinder multiview multi-video condition, except that only the center camera was used for capturing the remote person .
All projectors project this video, instead of projecting unique perspective-correct videos.
Thus, observers would perceive the gaze direction as if they were standing straight in front.
This condition should show the benefit of using camera array.
Cylinder diffuse single-video condition used a curved diffuse white projection screen.
Only the center camera and projector were used .
This condition mimicked TeleHuman , which developed for a single user; other users can view the display but will see a distorted view.
Flat diffuse single-video condition used a conventional 2D flat screen, instead of 3D cylinder surface.
This condition mimicked the commonly found Mona Lisa gaze effect, which occurs when 3D objects are rendered in 2D, causing the gaze perception of all in a room to be the same .
Image quality remained the same in all conditions.
We expect that viewers in cylinder multiview single-video condition and flat diffuse single-video condition will see much more incorrect targets compared to those in cylinder multiview multi-video condition.
We further expect the cylinder diffuse single condition to lie between these two in performance, as the 3D cylindrical surface eliminates Mona Lisa gaze effect but viewers only could see part of head in some extreme viewpoints.
We included viewpoint 5 where the observer at the center position as a benchmark; viewpoint 1 and 9 where observers sat at two extreme viewing angles; and viewpoint 4 where the observe sat right next to observer 5.
In the cylinder multiview multi-video condition, we expect a similar level of error for observer perceiving targets at all viewpoints.
For the other three display conditions, we expect the level of error will increase symmetrically as the viewpoint diverges horizontally from the central position.
12 groups of four were used for testing, and each group experienced one of four different display conditions with each observer sat at one of the four viewpoints .
Each observer was given a sheet of paper with an empty grid of 15 squares.
The video of the remote person reoriented to a new target card every 10 seconds.
At the same time an audio prompt to the observers instructed them that this was a new target.
Then, observers would then judge which target  the remote person was gazing at and then write this in the relevant grid square.
The experiment took about 5 minutes.
Participants received chocolates as compensation.
The primary measurement in our results was the level of error in perceiving targets.
We defined target error  to be the absolute value of difference between the observer's perceived target number  and the actual target number : i = |toi - tai |.
Figure 4 shows the target error at the four viewpoints in four display conditions.
The line of the cylinder multiview multi-video condition shows that it achieved the lowest mean target error.
The means were very similar across the four viewpoints, indicating that the viewpoint had little impact in this display conditions.
At the extreme viewpoints , the means were significantly below that of the other three display conditions.
This is expected as when the observer did not sit in viewpoint 5, those display conditions still used the video from camera 5.
A 4 display conditions x 4 viewpoints x 15 target positions mixed design ANOVA was conducted on the target error, with display condition and viewpoints as two between-subjects factors and target positions as a within-subjects factor.
Tukey post-hoc tests revealed significant mean differences between each of the display conditions.
This supports the primary hypothesis.
The mean target error at viewpoint 1 did not significantly differ from viewpoint 9, p > .05, which is also expected as the viewing angles of viewpoint 1 and 9 are equal only opposite in direction.
The display conditions x viewpoints interaction was significant, F  = 7.277, p < .001, indicating that mean target error due to viewpoints were different in four display conditions.
We further investigated whether there was leftward bias or rightward bias in perceiving targets in different display conditions.
Figure 4 shows the target bias at four viewpoints in four display conditions.
Positive values indicated leftward biases whereas negative values indicated rightward bias.
For the cylinder multiview multivideo condition, the mean target bias did not change substantially across different viewpoints.
This further supports the hypothesis.
By contrast, for the other three display conditions, the biases depended on the observers' viewpoints.
For the flat diffuse single-video condition, the biases of four viewpoint in this study nicely fit in the previous work  that is the mean target bias varies linearly according to seat position.
The graph also shows that the bias of cylinder diffuse singlevideo condition is less than flat diffuse single-video condition.
This parallels the previous finding  that biases occur differently while observing convex, flat and concave surfaces.
We presented a novel display system for video conferencing.
The highlights of this system are as follows.
Firstly, the cylindrical display offers a 360 view whereas flat displays are only visible from the front.
Secondly by using a camera array, a projector array and a multiview screen, we are able to transmit the remote person to multiple observers gathered around the cylindrical display, maintaining accurate cues of gaze direction.
A similar cylindrical multiview display could also use a very dense projector array covering 360 , thus supporting a large number of viewpoints from any directions without introducing crosstalk and reducing resolution.
Our current system is used for asymmetric conversations, such as a teaching scenario.
Systems using similar principles could be configured to support symmetric conversations, by arranging camera arrays that are denser but further from the users.
As cameras and projectors are now becoming very cheap, the low cost and ease of setup make this an interesting platform for next generation video conferencing.
