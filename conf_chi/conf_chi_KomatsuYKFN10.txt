We describe artificial subtle expressions  as intuitive notification methodology for artifacts' internal states for users.
We prepared two types of audio ASEs; one was a flat artificial sound , and the other was a sound that decreased in pitch .
These two ASEs were played after a robot made a suggestion to the users.
Specifically, we expected that the decreasing ASE would inform users of the robot's lower level of confidence about the suggestions.
We then conducted a simple experiment to observe whether the participants accepted or rejected the robot's suggestion in terms of the ASEs.
The results showed that they accepted the robot's suggestion when the flat ASE was used, whereas they rejected it when the decreasing ASE was used.
Therefore, we found that the ASEs succeeded in conveying the robot's internal state to the users accurately and intuitively.
This is because it is said that one's internal state is deeply reflected in her/his expressed paralinguistic and nonverbal information; that is, other people can intuitively and easily understand a person's internal state from such information when it is expressed.
Recently, some researchers have reported that very small changes in the expression of such information  significantly influence human communications, especially in the conveyance of one's internal states to others .
It is therefore believed that such subtle expressions can be utilized to help humans easily understand an artifact's internal state because humans can intuitively understand such subtle expressions.
For example, Sugiyama et al.
However, since these researchers tried to implement subtle expressions on artifacts , their implementations were considerably expensive.
In contrast to the above approaches, Komatsu & Yamada  reported that simple beeping sounds from a robot with decreasing/increasing frequency enabled humans to interpret the robot's negative/positive states.
Funakoshi et al  also reported that the robot's blinking LED could convey to users a robot's internal state  for the sake of reducing the occurrence of speech collisions during their verbal conversations.
It then seemed that such simple expressions  from artifacts could play a similar role to the subtle expressions of humans, so we named these expressions from artifacts "Artificial Subtle Expressions ," referring to artifacts' simple and low-cost expressions that enable humans to estimate the artifacts' internal states accurately and intuitively.
We stipulate that the ASEs should meet two requirements for designing and two requirements for functioning simultaneously.
Specifically, the two requirements for designing are as follows:
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Simple: ASEs should be implemented on a single modality.
It is then expected that the implementation cost would also be lower.
Complementary: ASEs should only have a complementary role in communication and should not interfere with communication's main protocol.
This means that the ASEs themselves do not have any meaning without a communication context.
Intuitive: ASEs should be understandable by humans who do not know about the ASEs beforehand.
Accurate: ASEs should convey the designer's intended meanings accurately.
Specifically, ASEs should convey the internal states of the artifact just as subtle expressions do in nonverbal information by humans.
The participants in this experiment were informed that 1 point was equivalent to 50 Japanese yen  and that after the experiment, they could use their points to purchase some stationery supplies  of equivalent value.
The position of the coin in the three hills was randomly assigned.
In each trial, an artifact placed next to the participants told them in which position it expected the coin to be placed.
The artifact placed next to the participants was the MindStorms robot .
The robot told the expected position of the coin using their speech sounds.
The participants could freely accept or reject the robots' suggestions.
In each trial, even though the participants selected one hill among three, they did not know whether the selected hill had the coin or not .
The participants were informed of their total game points only after the experiment.
In this study, we focused on audio ASEs.
Related studies with audio ASEs include those that proposed simple and effective information to convey specific meaning to users, e.g., "earcon " or "auditory icon " These earcon and auditory icons play an effective role in informing users of specific meanings as communication's main protocol, while ASEs play a complementary role for the main protocol.
This point is the significant difference between ASEs and earcon or auditory icons.
In this paper, we investigated whether the ASEs could convey the artifacts' internal state to the users accurately and intuitively; specifically, we created audio ASEs that were intended to meet the two requirements for designing them, and we investigated whether these ASEs met the two requirements for functioning by conducting a simple psychological experiment.
We used a "treasure hunting" video game as an experimental environment to observe the participants' behavior .
In this game, a game image scrolls forward on a straight road, with small hills appearing along the way.
A coin is inside one of three hills, while the other two hills have nothing.
The game ends after the player encounters 20 sets of hills, and the approximate duration of this video game is about three minutes.
The purpose is to get as many coins as possible.
We implemented the audio ASEs in the robot's speech sounds.
These artificial speech sounds were created by the text-to-speech  function of "Document Talker ."
Just 0.2 second after these speech sounds, one of the two simple artificial sounds was played as the ASE .
These ASE sounds were created by "Cool Edit 2000 ."
Komatsu & Yamada  reported that the decreasing artificial sounds expressed from the robot were interpreted as negative feelings by humans; therefore, we intended that the decreasing ASE would inform users of the robot's lower confidence in the suggestions as the robot's internal state.
Here, the main protocol of the robot was to tell the expected position of the coin, while the ASE protocol was to indicate the robot's confidence level in a complementary manner.
The two ASE sounds were created quite easily by simply editing the consumer software.
Thus, the ASEs met the two design requirements, that is, simple and complementary.
Therefore, to confirm whether the ASEs were able to convey the robot's internal states to the users accurately and intuitively, we needed to investigate whether the utilized ASE met the two requirements for functioning, that is, being intuitive and accurate.
Thus, this experimental setting, where the participants were not notified of whether the selected hill was correct or not, was intended to reduce such associations and to clarify the effect of the ASEs on the participants' behavior.
The purpose of this experiment was to observe the participants' behavior as to whether they accepted or rejected the robot's suggestions in terms of the types of ASEs used.
We assumed that the participants would accept the robot's suggestion when the flat ASE was added to the speech sounds while they would reject the suggestion when the decreasing ASE was used.
If we could observe these phenomena, we could recognize that the utilized ASE had succeeded in conveying the robot's internal states to the participants accurately and intuitively; that is, the ASE had successfully met all four requirements.
In addition, after the experiment, we conducted interviews to determine whether or not the participants had noticed the ASEs and, if so, how they had interpreted them.
Nineteen Japanese university students  participated.
The treasure hunting video game was projected on a 46-inch LCD in front of the participants, and the robot was placed in front of and to the right of the participants, with the distance between them being approximately 50 cm.
The sound pressure of the robot's speech sounds at the participants' head level was set at about 50 dB .
The robot's speech sounds with the ASEs were remotely controlled by the experimenter in the next room using the Wizard of Oz  method.
Before the experiment started, the experimenter told the participant the setting and purpose of the game.
However, the experimenter never mentioned or explained the ASEs.
Therefore, the participants had no opportunity to acquire prior knowledge about the ASEs.
Among the 20 trials, the robots expressed the flat ASE 10 times and the decreasing ASE 10 times.
The order of expression for these two types of ASEs was counterbalanced across participants.
Actually, the robot told the exact position of the coin in all 20 trials, but the participants did not know whether or not the robot was telling the right position because the participants were not able to find out whether the selected hill had the coin or not.
To investigate the effect of the ASEs on the participants' behavior, we calculated the rejection rate, indicating how many of the robot's suggestions the participants rejected for 10 flat ASEs and 10 decreasing ASEs.
These rejection rates for the 10 flat ASEs and 10 decreasing ASEs were analyzed using a one-way analysis of variance  .
The result of the ANOVA showed a significant difference between the two groups =13.38, p<.01, ; that is, the robot's suggestions with the decreasing ASE showed a significantly higher rejection rate compared to the one with the flat ASE.
Therefore, the ASEs affected the participants' behaviors significantly, and we found evidence supporting our assumption mentioned previously.
The most interesting point was that the ASEs affected the behavior of the participants without their being informed of the meaning or even existence of the ASEs.
In the interview sessions, 5 out of the 19 participants said that they immediately realized the meanings of the ASEs after the robot's speech sounds and that they utilized these ASEs when it came to accepting or rejecting the robot's suggestions, e.g., "I felt that the decreasing artificial sounds meant that the robot had less confidence in its answer."
However, the remaining 14 participants said that they did not notice the existence of the ASEs.
Here, if there were significant differences between flat and decreasing ASEs in their rejection rate, the ASEs were interpreted by these 14 participants unconsciously.
In this case, we strongly argue that the ASEs were able to convey the robot's internal state to the participants accurately and intuitively.
These rejection rates were analyzed using a one-way ANOVA .
The result of the ANOVA showed a significant difference between them =4.98, p<.05, ; that is, the robot's suggestions with the decreasing ASE had a significantly higher rejection rate compared to the one with a flat ASE, even though these participants did not notice the existence of the ASEs.
To sum up, the results of this experiment clearly show that the utilized ASEs succeeded in conveying the robot's internal states to the participants accurately and intuitively; that is, the ASEs succeeded in meeting all four requirements.
Thus, we confirmed that simple and low-cost expression ASEs could be utilized as intuitive notification methodology for artifacts to convey their internal states to users like paralinguistic or nonverbal information.
However, in this paper we have reported just the initial evidence of ASEs.
Therefore, as a follow-up study, we are planning to implement the ASEs in various kinds of spoken dialogue systems such as ATMs and automatic telephone reservation systems.
Specifically, we are now focusing on car navigation systems' speech sounds; the reason for this is that current car navigation systems still sometimes give poor driving routes to users.
However, if this navigation system's confidence level regarding the route instruction is not very high, the instructions of speech sounds with ASEs could implicitly convey a lower confidence level.
If the ASEs are still effective in such situations, they could be utilized in various situations in which artifacts have to convey their internal states to users.
In this paper, we investigated whether the ASEs could convey the artifacts' internal state to the users accurately and intuitively; specifically, we created audio ASEs that were intended to meet the two requirements for designing them, and we investigated whether these ASEs met the two requirements for functioning by conducting a simple psychological experiment.
As a result of this experiment, the robot's suggestions with the decreasing ASEs showed a significantly higher rejection rate compared to the ones with flat ASEs.
Moreover, these ASEs were interpreted by the participants even though they were not instructed of the meaning or even the existence of the ASEs.
