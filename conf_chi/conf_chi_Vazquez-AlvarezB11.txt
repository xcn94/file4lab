As mobile devices increase in functionality, users perform more tasks when on the move.
Spatial audio interfaces offer a solution for eyes-free interaction.
We present a comparative study of spatial audio techniques evaluated in a divided- and selective-attention task.
A podcast was used for high cognitive load  and classical music for low cognitive load , while interacting with an audio menu.
Results showed that spatial audio techniques were preferred when cognitive load was kept low, while a baseline technique using an interruptible single audio stream was significantly less preferred.
Conversely, when cognitive load was increased the preferences reversed.
Thus, given an appropriate task structure, spatial techniques offer a means of designing effective audio interfaces to support eyes-free mobile multitasking.
He finds out he has to reschedule a meeting with his boss.
He then decides to pause his music and starts interacting with his calendar using an audio menu as he keeps on walking.
As he starts browsing through his appointments to find a free slot, Stephen calls him back.
While taking to Stephen, David browses his calendar and finds a suitable time later on the day for their meeting.
The call ends and David continues listening to his music while making his way to the office.
An audio interface like the one illustrated in our example makes eyes-free interactions possible while on the go when visual attention is compromised or the mobile device is out of reach, and enables the user to interact with his mobile devices purely through sound.
The extent to which such an audio-only interface is desirable depends on how we deal with cognitive load and multiple streams of information.
In our example, we have differing levels of both.
From a notification of a voice mail, which might be delivered at the same time David listens to music, to a multitasking extreme of listening to music during a phone call while rearranging a meeting and walking the streets of New York.
All of this without getting run over by a yellow cab.
How should an audio interface be designed to deal with these competing requirements?
In this paper, we consider basic strategies for the presentation of multiple audio streams and examine their usability under varying cognitive load.
How much multitasking are mobile users exposed to in their daily lives?
Imagine a typical morning for David as he commutes to work: David is travelling on the New York City subway system on his way to work and listening to music on his phone, as he always does.
While David is in transit, his boss Stephen tries to call him but, as there is no underground cell phone coverage, he leaves a voice mail.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
When multiple tasks are supported purely by audio, users must be able to direct their attention selectively to each individual audio stream representing a task.
Spatial audio has been used in previous research  as a successful technique to segregate multiple audio streams by placing each audio stream at a different location around the user's head, mirroring how humans perceive sounds in real life .
What is not yet clear is what spatial audio design might be the most effective for supporting multiple audio streams and how much, if at all, the spatialization of the streams might contribute to an increase or decrease of the user's cognitive load when engaged in a number of simultaneous tasks.
Thus, an important issue is how to design audio inter-
This paper presents an evaluation of different spatial and non-spatial audio techniques in such a multitasking scenario.
Different attention demands impose different amounts of cognitive load on the user.
When David is listening to the voicemail left by Stephen, he is focusing attention on the voicemail audio stream while monitoring his music .
However, when David is talking to Stephen while interacting with his calendar using an audio menu to find a suitable time for their meeting, David is dividing his attention between both audio streams .
The first task results in less cognitive load, and the second in higher cognitive load.
Cognitive load has been described as the amount of mental re-sources needed to perform a given task .
As tasks add up, the mental resources needed increase and cognitive load rises.
Previous research by Marentakis and Brewster  investigating pointing efficiency in deictic spatial audio displays, showed that increased cognitive load resulted in reduced pointing efficiency.
Shinn-Cunningham  and Best  have also investigated how perceived spatial separation of sources and consistency in source locations influences performance on selective- and divided-attention tasks.
They found that performance was better when sources were perceived at different locations instead of the same location.
However, she adds that "further experiments are necessary to determine whether spatial attention influences performance differently when competing sources differ from one another in more natural ways".
When designing audio interfaces it is critical to consider the attention demands expected from the user.
This affects the attention required to monitor the information being relayed by the stream and also the attention required to monitor the spatial location of the stream.
Spatial audio offers the ability to foreground and background audio streams, for example, moving an audio stream to the side , while a second stream is played from the front.
Spatial minimization could help users alter focus between streams.
Thus, when designing mobile audio interfaces to support multitasking, how would different auditory techniques, spatial or non-spatial, perform under different user attention demands?
In this paper we quantify the effect of cognitive load on a number of spatial and nonspatial audio techniques during selective- and dividedattention tasks involving user interaction.
Our research question was: Are spatial audio techniques able to efficiently support both divided- and selective-attention tasks?
Participants listened to two different streams: one continuous and the other user activated.
In the selective-attention group, the continuous stream was a piece of classical music taken from Mozart's Sonata for two pianos K448 in D Major.
This specific music piece has been frequently used in spatial-temporal reasoning research.
The sonata was divided into different fragments: one for the training session and four others were used in the four different conditions.
These fragments were all mono, 16-bit and sampled at 16kHz, and approximately 1.5 minutes long.
The participants were told they would have to answer a question on the audio menu tasks to ensure selective attention.
In the divided-attention group, the continuous stream was a podcast selected from the BBC Radio 4 programme `From our own correspondent'.
Five different podcasts with a similar journalistic format were chosen.
One podcast was used for training the participants and the rest were used in four different test conditions.
They were all mono, 16-bit and sampled at 16 kHz, and narrated by a male speaker.
In order to ensure divided attention participants were asked to monitor the podcast and told they would have to answer questions on content as well as a question on the audio menu tasks.
In order to retain coherence, and to allow enough audio material to pose content questions before, during and after the audio menu tasks, the podcasts were longer than the classical musical streams .
Our aim was to generate a low cognitive load for the selective-attention group by using classical music, and a high cognitive load in the divided-attention group by using speech.
The user-activated audio stream was a hierarchical audio menu with synthesized audio items.
It consisted of a threeitem top level: music, appointments and current time.
The 'current time' item only had one sub-level with time information, .
All the audio items were mono, 16-bit, sampled at 16 kHz, and were spoken by a female RP voice.
All the audio menu items were different for the different conditions.
Both the continuous and user-activated streams were normalized to 70% of the audio dynamic range, which equals to a normal conversation typically 60-70dB.
The audio menu was always presented at 0 azimuth  and always 1m away in the frontal horizontal plane.
All four conditions were tested in the same randomized order in both the divided- and selective-attention groups.
Participants were tested in a static lab environment seated on a chair holding the mobile phone in an upright position wearing a pair of headphones.
The study was run on a Nokia N95 8GB using the built-in HRTFs and the JAVA JSR-234 Advanced Multimedia Supplements API to position the audio sources.
The audio was played over a pair of DT770 PRO - 250 OHM Beyerdynamic headphones.
Participants completed two training sessions before the test conditions.
First, a training session was devoted to familiarizing the participants with the audio menu structure in their own time.
The second training session used the concurrent condition to familiarize the participants with listening to a continuous audio stream while interacting with the audio menu.
For each test condition, participants listened to a continuous audio stream and after approximately 1 minute, the user was prompted with a 25-ms sine wave beep at 1500 Hz to start interacting with the menu and complete the three tasks described previously in any order.
To initiate this interaction, the participant pressed the central navigation key on the phone.
The arrow keys on the phone were used to browse the menu items.
Once the tasks were completed and the audio menu was exited by pressing the central navigation key again, the user continued listening to the continuous audio stream until it was over.
A NASA-TLX subjective workload assessment was completed, and, once all four conditions were completed, participants were instructed to rank them in order of preference: `1' being most preferred and `4' the least.
The experiment took 30-45 minutes in total.
Participants were allowed to rest between conditions.
Box plots present ranked preferences per condition and attention group: divided-attention  and selectiveattention .
The boxes contain the middle 50% of the data, the horizontal bold black lines show the median and the points outside are suspected outliers.
The grey shaded conditions showed no significance.
Figure 2 shows a stacked count for the order of preference for the four conditions compared in the divided- and the selective-attention groups.
A non-parametric KruskalWallis for different conditions per attention group showed there was a significant difference in the medians =61.810, p<0.001.
Mann-Whitney tests with Bonferroni correction showed a significant difference between the interrupted conditions by group, and also between the user-activated spatial minimization conditions by group.
Users' preference for interrupting the continuous stream significantly decreased  and preference for spatially minimizing the continuous stream significantly increased  when the streamed source was classical music.
Raw overall workload was calculated from the NASA-TLX questionnaires completed after each condition.
As expected, perceived overall workload was significantly higher in the divided-attention group  than in the selectiveattention group .
Post hoc Pairwise Comparisons with Bonferroni correction for condition type showed that perceived overall workload during the interrupted condition was significantly lower  than in the rest of conditions for the divided-attention group.
No significant differences were found between conditions for the selective-attention group .
Task completion times were significantly higher  for the divided-attention group than for the selective-attention group .
Post hoc Pairwise Comparisons with Bonferroni correction for condition type showed that task completion times for the interrupted condition were significantly lower .
These results suggest a mixed design of audio techniques would be required within our initial usage example.
Concurrent streams should be used to play the voicemail notification with spatial audio being used to help separate the information streams.
Also, when David decides to access his calendar eyes-free, he could continue listening to the music spatially minimized, as this will not disrupt his task efficiency.
It would be nonetheless important to allow him to interrupt his menu interaction at anytime while navigating the streets of New York on foot.
As we might expect, users do not like being put under cognitive load.
Participants in this study reported higher workload and took longer to carry out tasks in the dividedattention group.
Furthermore, listening to concurrent audio increased the effect of load.
The use of spatial techniques had a neglible impact on reducing this effect .
In the selective-attention group however, preference results were significantly reversed for interrupted and minimization conditions.
This shows that users disliked having the continuous stream interrupted when not under load, and using spatial techniques to separate the continuous stream from the user-activated menu was preferred.
Addressing our research question, we can say that the spatial minimization technique presented in this paper offers an effective means of presenting and interacting with multiple audio streams simultaneously in a selective-attention scenario.
However, spatialization techniques were not as effective in the divided-attention task, in which the interaction benefited significantly from the interruption of the continuous stream.
