Image Based Rendering  allows interactive scene exploration from images alone.
However, despite considerable development in the area, one of the main obstacles to better quality and more realistic visualizations is the occurrence of visually disagreeable artifacts.
In this paper we present a methodology to map out the perception of IBR-typical artifacts.
This work presents an alternative to traditional image and video quality evaluation methods by using an EEG device to determine the implicit visual processes in the human brain.
Our work demonstrates the distinct differences in the perception of different types of visual artifacts and the implications of these differences.
The advantage of perceptual based graphics has been apparent for a long time, and while a considerable amount of work has been done in measuring conscious, cognitive processing , much less has been done in Computer Graphics to take advantage of covert measurements and visual processing.
In this paper we present a new approach that uses an electroencephalograph  to interface with the human brain and measure the output of implicit  visual processing in the brain in response to artifacts in image sequences.
The way videos are perceived by people is becoming increasingly important in visual media.
Image and video based rendering techniques allow for the creation of complicated 3D scenes and videos from a few images.
The ubiquitous use of 3D cinema, affordable display technology, and the merging of real world scenes with computer graphics allows for the creation and pervasive use of realistically rendered images and videos for movies such as Avatar.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
However, one of the main areas that still require a lot of research is the assessment and perception of the rendered output.
Rendering systems can now closely approximate a real scene but physical or statistical accuracy does not necessarily amount to visual accuracy.
During rendering visually objectionable artifacts can arise which limit the application of most rendering algorithms.
The most common artifacts that occur in rendered images are ghosting, blurring and popping .
In this paper we perform an experiment to analyze the perception of these artifacts.
Traditionally the quality of a video has been judged by either user-studies or the use of quality assessment algorithms.
Apart from requiring a large number of participants, user-studies can at best only measure the explicit output of the visual cognitive process .Quality ratings obtained by user studies are always filtered by some decision process which, in turn, may be influenced by the task and/or rating scale the participants are given .
The subjective judgment of a viewer is often biased by external factors such as mood, expectation or past experience.While current work in computer vision and graphics focuses on the explicit output of the human visual system we propose to use the implicit processing of the HVS  to determine the perception and quality of a video.
There is extensive literature dealing with implicit and explicit processing in the human brain .
Koch and Tsuchiya  discuss the evidence showing that visual processing can occur without conscious perception or attention and that conscious awareness of a stimulus is preceded by complex visual decision making processes.
We propose to use this covert processing in the human brain to assess the quality of a video with artifacts.
In our study we also specifically chose to look at motion in rendered sequences as motion plays an important role in perception owing to effects such as speed and direction of motion, visual tracking of moving objects and motion saliency.
Given the complexity of the HVS in perceiving motion, traditional systems based on it have not been able to effectively model temporal aspects of human vision .
There are several advantages to developing methodologies that merge covert human visual processing with traditional computer graphics and vision techniques.
First the analysis of visual information processing that occurs in the absence of conscious attention will allow boosting of traditional masking and rendering algorithms and introduce the robustness and flexibility associated with human vision.
Secondly, such an analysis of the covert visual processes reveals aspects of how these artifacts are viewed by the HVS that have not yet been accurately modeled by computer vision algorithms.
Given that it is more important for rendered images and videos to be perceptually accurate as opposed to physically accurate, rendering times can be shortened by eliminating computations that calculate image features that are not apparent to the human eye .
Computer graphics algorithms can take advantage of the limitations of the human eye to compute just enough detail in an image or video to convince the observer without a perceived deterioration in quality.
Specifically, our main contribution is a methodology for the analysis of artifacts in videos using an EEG to interface with the human brain and mine the covert visual processing.
In this paper we present the design and results from our experiments with video stimuli containing five different types of artifacts.
We present an analysis and comparison of the covert visual decision making about the video quality obtained from the EEG with the conscious video quality judgment obtained via direct user feedback which serve as initial proof of concept for our ideas.
All participants had average experience with digital footage and no involvement in professional image/video rendering or editing.
The basic stimulus for the experiment was a 5.6 second video  of a person walking along a park trail from left to right.
The occurrence of the artifact was delayed by 4 frames  to avoid locking the participants attention to a fixed time.
Five different kinds of artifacts were incorporated into the scene.
These artifacts included both temporal and spatial aspects.
The following 6 test cases were shown : 1.
Popping on Person: a small rectangular area  containing the walking person freezes for one frame 2.
Popping: A static rectangular area of the image  freezes for one frame.
Blurring on person: a small rectangular area containing the walking person is blurred with a Gaussian kernel with a size of 15 pixels in 10 successive frames.
The blurring area moves along with the motion of the person 4.
Blurring: A static rectangular area  in the center of the scene is blurred with a Gaussian kernel with a size of 15 pixels in 10 successive frames.
Ghosting on Person: A partly transparent silhouette of the person stays behind for 10 frames, fading to invisibility in the last 5 frames .
One trial consisted of a ready screen followed by the video with artifacts which was instantly followed by the quality assessment screen.
Participants were instructed to follow the moving person with their gaze and rate the quality of every test case on an integer 1 to 5 mean opinion score  scale .
The participants were not informed about the presence of artifacts in the videos.
They were instructed orally and received a training in which every one of the 6 videos was shown 3 times.
This prepared for the procedure and showed the whole range of available video qualities.
During the main experiment all videos were shown 30 times resulting in 180 trials per participant.
The videos were played in a block-wise randomized order and the same video was not shown twice in a row.
An EEG was recorded with 32 electrodes attached according to the international 10-20 system.
Additionally a 4 channel EOG and mastoids were recorded which were used as a reference to remove data with accidental eye movements.
The recorded data were referenced to the mastoids and filtered with a high-pass filter with a cutoff frequency of 0.1 Hz to remove DC-offset and drifts.
Trials of a length of 1.2 seconds time locked to the appearance of the artifact occurrence were extracted from the continuous data.
All trials with blinks, severe eye movements and too many alpha waves were manually removed.
There has been recent interest in studying visual processing for image rendering and analysis techniques .
However very little work has been done in using implicit visual decision making processes for video assessment.
They use brain processes to show that users can implicitly categorize pictures based on content.
Their work however required users to memorize the images and to be attentive to the content viewed.
Our work looks to analyze the implicit visual processing behind viewing videos with motion and not static images.
They looked at the user feedback from rendered sequences that moved over facades of buildings.
This work focused on the output of conscious visual cognitive processes.
They reported that when shown different images of decreasing quality the participants EEG results showed corresponding detected changes in image quality.
Their work showed that the brain response varied with the image compression value.
Figures 2, and 3 show the different ERPs averaged over all participants over all trials and over electrodes PO4, PO3 and Oz and as compared with the no artifact ERP with time 0 corresponding to the appearance of the artifact.
Firstly, all artifacts were detected by the brain, albeit with varying strength.
The artifact which evoked the greatest response was popping on the moving person which has a latency of 264ms and reaches a maximum amplitude of 5.758V.
This is followed closely by blurring on the moving person.
Static popping and blurring evoke a smaller response.
Popping is a more obviously perceived artifact and evokes a quicker response.
Ghosting however requires the brain to process the perceived distortion before a response occurs.
This latency due to processing of the perceived stimuli is also seen with blurring, which is also a less obvious artifact.
Table 1 shows the detailed latency and maximum potential responses for all artifacts.
From both the ERP figures and Table 1 the second result that becomes clear is the difference in the perception of artifacts related to motion and those independent of motion.
Both popping and blurring linked with the motion of the person produce a much larger response potential than popping and blurring not linked with the motion of the person.
Figure 4 shows an average of the participant responses for all trials for each video.
As can be seen participants rated the quality of the video with the ghosting artifact as the best after ground truth.
This is in contradiction with what the ERPs showed where although the latency of both blurring and ghosting was the same the ghosting artifact evoked a response with a maximum potential of 3.082V as opposed to 2.681V for blurring.
The most obvious difference between the explicit quality rating and the implicit brain reaction can be seen with the Popping on Person and Popping artifact.
Participants rated the two with almost the same rating  whereas the ERPs show a marked difference in the response of the brain to either artifact.
This same difference is also observed in the two blurring artifacts.
The participants rated them both equally whereas the ERPs show a marked difference between the two  with the same latency.
We also ran a standard two-tailed t-test to confirm the validity of the curves as shown in Figures 2 and 3.
For all artifact cases the two tailed t-test was run for the stimuli time peArtifacts Popping on pers.
In all cases the null hypothesis was rejected.
Given the rejection of the null hypothesis in all cases and the fact that the probabilities are all less than 0.05 there is sufficient evidence for the statistical significance of the results.
We also ran the two-tailed t-test between popping and popping on person and blurring against blurring on person.
Given these values we can safely assume a statistically significant difference between the responses over all artifacts.
To determine the deviation of individual participants from the average we also ran a two-tailed t-test of one randomly selected participant against the averaged results of all the other participants.
Given these p-values and the acceptance of the null hypothesis it is clear that any one participants response is close to the average.
There are no statistically significant differences.
The analysis of the ERPs from this experiment also indicate a potential emotional reaction to the artifacts.
Previous data from EEG studies and emotion has provided evidence of lateralization of emotion in the frontal cortex .
This theory predicts right hemisphere dominance for negative emotions.
The results from our experiment show an increased output in the right frontal cortex for test cases with more severe artifacts where the maximum output was for popping on the moving person.
This can theoretically be explained by the negative emotions elicited by bad video quality.
We showed that the covert  and overt  output of the human visual processing does differ and in some cases the difference is striking.
We also showed that the brain responds very differently to not only different types of artifacts but also to artifacts specifically linked with motion.
Artifacts linked with motion evoke a much larger response in the brain.
We also showed that it is possible to categorize artifacts based on how they are perceived.
This provides information on the perception of videos which has previously not been modeled.
This also creates the possibility of shortening rendering times by eliminating computations that calculate image features which do not evoke a strong reaction in the brain as opposed to those which do.
The brains response to artifacts is also essential for the modeling of masking algorithms for rendered image sequences.
While the current experimental setup provides new and relevant information it has some limitations.
The main issue we see is the absence of eye movement information.
Eye tracking would allow us to incorporate information regarding the exact viewing pattern of the participants during stimuli presentation.
A more complete picture of participants eye gaze pattern during stimuli presentation is essential for advances in realistic image and video synthesis.
