A duet of interaction between a handheld and a wrist worn device : the watch is used as a tool palette when annotating text on the phone ; a simultaneous pinch-to-close swipe gesture on both devices mute their notifications ; the watch's orientation indicates which hand part causes a touch, thus enabling a seamless transition between modes: for example, writing with the pad of the finger , scrolling with side of the finger , and text selection with the knuckle .
The emergence of smart devices  is redefining mobile interaction from the solo performance of a smart phone, to a symphony of multiple devices.
In this paper, we present Duet - an interactive system that explores a design space of interactions between a smart phone and a smart watch.
Based on the devices' spatial configurations, Duet coordinates their motion and touch input, and extends their visual and tactile output to one another.
This transforms the watch into an active element that enhances a wide range of phone-based interactive tasks, and enables a new class of multi-device gestures and sensing techniques.
A technical evaluation shows the accuracy of these gestures and sensing techniques, and a subjective study on Duet provides insights, observations, and guidance for future work.
Interactive computing technology is becoming increasingly ubiquitous.
Commercialization is rapidly catching up with the research community's vision of mobile and ubiquitous form factors: smart phones, smart watches, and smart eyewear are all available for purchase.
Soon, many of us may carry not one smart device, but two, three, or even more on a daily basis.
For interaction designers, this introduces a new opportunity to leverage the availability of these devices to create new interactions beyond the usage of a single device alone.
At present, the space of interaction techniques making use of this opportunity is underexplored, primarily focusing on using a secondary mobile device such as a smart watch as a viewport and remote control of the smart phone .
To the best of our knowledge, we are unaware of any existing work that takes a different approach in designing a class of joint interactions on two smart mobile devices.
To address this limit, our research envisions a symphony of interaction between multiple smart mobile devices.
To approximate this vision, we start by considering a scenario of two smart mobile devices as a joint interactive platform.
Specifically, our goal is to explore various ways wherein these two devices can perform their individual input and output techniques to create new interaction possibilities for the users.
Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Inspired by research on conversational linguistics , and prior HCI work on `foreground-background' interactions , we explore a design space of interaction between the phone and the watch.
Based on their spatial configurations, Duet coordinates the two devices' motion and touch input, and extends their visual and tactile output to one another, thus enabling the watch to enhance a wide range of phone-based interactive tasks.
For example, we can divide an interface between the phone and the watch, such as reserving the phone for a canvas while hosting a tool palette on the watch .
We can create novel gestures, such as a crossdevice pinch-to-close gesture to simultaneously mute both devices .
We can also use a watch's sensors to augment touch, such as using its orientation to infer which finger part  is touching the phone's screen .
In the following sections, we first review techniques of handheld, wrist-worn and device-to-device interaction.
Next we present our design space that encompasses the interaction between the phone and the watch based on their `foreground-background' interactional relationships.
We then introduce a suite of gestures and sensing techniques enabled by this joint interactive platform - and a technical evaluation of their recognition accuracy.
We then demonstrate Duet's various application scenarios enabled by these gestures and techniques, and report users' reactions and feedback to inform future work.
We first review prior work that explores individual interaction techniques developed for handheld and wristworn devices.
We further summarize various device-todevice interactions that demonstrate examples of using multiple devices to create new interaction possibilities.
Touch is more difficult on wrist-worn devices, which typically have small screens, exacerbating the fat finger problem .
Zoomboard used iterative zooming to ease target acquisition .
Facet utilized a multi-segment wristworn device, which allows touch to span multiple connected screens, yielding a richer input vocabulary .
Given the limitation of direct-touch on wrist-worn devices, the exploration of alternate techniques becomes more important.
Motion and spatial awareness creates a variety of wrist-based interaction.
GestureWrist and GesturePad use wrist-mounted accelerometer and capacitive sensors to recognize hand grips and pointing directions .
Past research also focuses on wrist rotation and tilting , most of which was implemented using a mobile phone held in the hand.
In contrast to handhelds, a wrist-worn device is a potentially better solution: its wearability untethers the users' hands from any sensing devices, allows the sensing to be always available with one's day-to-day activities, and provides high-fidelity data by closely coupling the device to one' hand, wrist and arm movement.
A watch can also enable freehand gestures beyond its surface.
A disappearing mobile device  can be mounted on the wrist and interacted with by `scanning' fingers on top of it.
Abracadabra enables spatial input with a small wrist-worn device by using the magnetometer to sense finger-mounted magnets .
Gesture Watch  and AirTouch  use multiple infrared sensors mounted on the back of the wrist to detect freehand gestures, such as hand swiping along the forearm.
Instead of using the other hand to perform gestural input, earlier work also explores using wrist-mounted contact microphones to detect fingertip gestures .
Similarly, Digits reconstruct real-time 3D hand models by instrumenting sensors on the inner side of the wrist and facing the camera towards the palm .
Our review shows a plethora of interaction techniques developed for both handheld and wrist-worn devices individually.
Yet few have considered marrying their techniques to design for scenarios where a user is carrying and using both devices.
To better understand this issue, we review prior work on device-to-device interaction.
Device-to-device interaction associates multiple individual devices to create new interaction possibilities.
We summarize three association principles from the literature: synchrony, proxemic interactions, and distributed gestures.
Synchrony associates devices by the synchronization of their inputs.
Pick-and-drop synchronizes pen input across multiple computers to enable direct content manipulation between them .
Smart-Its Friends senses a handshake as a natural way to establish connections between smart artifacts .
Synchronous gestures detect the bumping between two tablets, thus allowing interactions such as spanning and sharing a photo across two screens .
Touch is perhaps the most common input method for modern handheld devices.
Motion and spatial awareness, enabled by a device's on-board sensors, can also be leveraged to enhance touch-based interaction .
Past research has demonstrated interaction by orienting , positioning , tilting , or whacking  a device.
To go beyond the device's physical boundaries, others also explored interacting with the device using freehand gesture .
All these techniques, under Buxton's framework, fall into the `foreground interaction' category .
Meanwhile, for `background interaction', context-awareness, such as location, has long been proven useful in various mobile interaction scenarios .
Altogether, this work collects a toolbox of possible techniques for handheld devices.
The above interaction techniques for handhelds can also be found on wrist-worn devices.
However, wrist worn devices have an even smaller form factor and are worn on our bodies, which demands a reconsideration of the techniques as well as explorations into new interaction possibilities.
Similar techniques were also used in Lucero et al's work where a pinching gesture between mobile devices spans a shared canvas across them .
Siftables proposes synchronized interactions with multiple networked tangible interfaces, such as bumping all devices at once to swap in a new set of data associations .
Proxemic Interaction associates devices by their spatial relationship  between one another.
The Relate system built customized sensors into USB dongles, thus allowing peer-to-peer computation of devices' spatial relationship, and a set of spatial widgets to incorporate such relationship into the user interface .
A spatial proximity region around mobile devices can be used to mediate content access and sharing among a group of users .
Gradual engagement applies a similar idea to facilitate different levels of information exchange as a function of device-to-device proximity .
Distributed Interactions divides the tasks, features, or functions of an interface between multiple devices.
Roomware envisions a room of inter-connected smart artifacts that augment people's individual or collaborative tasks .
ARC-Pad divides cursor positioning task into absolute pointing on a mobile device and relative adjustment on a large display .
A cross-device interaction style  designs interaction between a mobile device and a large interactive surface, such as selecting from a list of tools on the mobile and applying that tool in an application on the surface.
While this work shows the potential of certain device-todevice interactions, we are unaware of any existing research that has explored the opportunities of using the phone and the watch together.
We see an immense potential to explore this opportunity of combining a smart phone and a smart watch to enhance our everyday mobile interactions.
The fundamental idea of our design space is to allow the phone and the watch, in various ways, to perform their individual input and output techniques, and together to create new interaction possibilities for the users.
We construct a design space  based on Falk's research on conversational linguistics , and Buxton's  and Hinckley et al.
In constructing this design space, our goal is for the two devices to carry out interactive tasks for the user as a single unified platform.
This is similar to what Falk observed and described in her paper `The conversational duet': "In conversations between three or more persons, two of them may undertake jointly to carry out the communicative task to a third in such a way that a written version of their resultant in-sequence text would be indistinguishable from that of a single speaker."
Buxton defines foreground interaction as "activities which are in the fore of human consciousness - intentional activities" .
In the past, these frameworks have been focusing on the context of a single device.
Our design space extends this framework to a scenario when two mobile devices are present, guiding the design of interactions between them.
As shown in Table 1, the combination of foreground and background interactions, when two devices are present, creates a 2x2 design space encompassing a variety of interactions that leverage the availability of both devices.
Current commercial designs have been focusing on the lower-left quadrant, where the watch is used as a temporal replacement for the phone, such as using the watch to check new emails or read text messages when the phone is not ready to hand .
The lower-right quadrant characterizes work that uses both devices for context and activity sensing .
Less work has been done in the two upper quadrants where the phone remains in the foreground as an active input and output platform, and the watch transitions between foreground interaction  and background sensing.
Duet is a new system that focuses on and explores these two areas of the design space.
To explore these areas of the design space, we built an interactive platform on a smart phone and a smart watch.
We used a Samsung Galaxy S4 smart phone and a Sony SmartWatch.
The phone has a 1080x1920 capacitive multitouch screen, quad-core 1.6 GHz processor, and a 3-axis accelerometer.
The watch has a 128x128 pixels capacitivetouch color display, and is connected to and run by the phone via Bluetooth.
The API of the watch provides limited touch input of seven pre-defined gestures: press, long press, release, and four swiping directions.
Its accelerometer has a maximum rate of 10Hz.
Multi-device gestures: We adapted the stitching technique  and the pinching gestures for interaction between the phone and the watch, to support four novel multi-device gestures .
The first two involve the finger swiping from the phone to the watch  or from the watch to the phone .
The second two gestures are performed by two fingers swiping simultaneously, where the fingers move towards each other  or away from each other  .
To fully explore the design space, we consider two possible ways in which the devices can be worn or carried in relation to one another.
Figure 2 shows these two spatial configurations: with the face of the watch worn on the dorsal side , or on the ventral side of the wrist .
These two spatial configurations afford different ways in which the watch can augment phone-based interactions.
In particular, wearing the watch on the ventral side provides additional visibility and quicker access to the watch while holding and using the phone.
The current spatial configuration can be detected by constantly monitoring the two devices' relative orientation, or by using a motionbased gesture to explicitly register that information .
While not necessary, we found the use of an expansion watchband can enable easy switching between these two configurations .
In the background of interaction, the watch can be used as an auxiliary sensor for the phone.
Flip and tap: To perform this gesture, a user flips her hand  immediately before tapping on the phone's screen .
Hold and flip: Inspired by DoubleFlip , this gesture consists of flipping the phone while holding the finger down on the screen.
By detecting the synchronized motion of both devices, we also distinguish if the user is flipping the phone with the hand wearing the watch .
Finger posture recognition: By sensing the watch's orientation when touching the phone, we can tell which finger part  causes that touch .
The availability of a smart phone and a smart watch gives rise to a suite of new gestures and sensing techniques .
Below, we describe the gestures and sensing techniques we explored, in the context of our design space .
Specifically, we developed two categories of techniques, where the watch is either in the foreground and background of interaction.
This section provides a brief overview of these gestures and sensing techniques and a description of our gesture recognition methods.
Later we describe the Duet system to demonstrate interactive scenarios and applications that utilize such techniques.
In the foreground of interaction, the watch can be used as an additional input device to complement the phone's motion and touch input.
We implemented two gestures that utilize this additional input channel: Double bump: Bumping the phone on the watch creates a synchronous gesture  that provides distinct input properties compared to bumping on other surfaces.
To reduce the chance of false positives, we implemented a double bump gesture, where the phone bumps against the watch twice in succession .
In total, the evaluation produced 12 participants x 15 conditions  x 4 blocks x 10 trials per block = 7200 data points.
All techniques except for Multi-device gestures used machine learning based recognition.
The results for Multidevice gestures will be discussed after our analysis on the first five techniques.
We used machine learning techniques for implementing our recognition system.
For motion-related input, our general approach is to segment a chunk of accelerometer data  pertinent to a particular gesture.
We then flatten the data into a table of features - each axis value at a given time point is considered a feature.
Using these features we can train a machine learning model  to recognize the gesture.
These recognizers are used only if the watch-wearing hand is detected during the onset of a touch ; otherwise a default interaction is applied.
To understand the feasibility of our designs, we tested the recognition accuracy of the six described techniques .
In the evaluation, participants wore the watch on the dorsal side of their left wrist  except for the Multi-device gestures, which require the watch to be moved to the ventral side .
The accuracy of each technique was tested independently.
Each technique recognizes several conditions, corresponding to the number of classes in the machine learning model .
Some techniques  included a baseline condition  to test false positives.
The conditions for each technique were as follows, with the number of conditions in parentheses: Double bump : Users either performed a hold and double bump, or a hold without the double bump.
Multi-device gestures : Users performed the four multidevice gestures: pinch-open, pinch-close, phone-to-watch swipe, and watch-to-phone swipe.
Flip and tap : Users either performed a flip and tap, or performed a standard tap without first flipping the hand.
Hold and flip : Users either performed a hold and flip, or a hold without the flip.
Finger posture recognition : Users tapped the phone with either the pad of the finger, side of the finger, or knuckle.
Handedness recognition : Users tapped the phone with either the left  hand or the right  hand.
Participants first learned to perform each technique condition by watching a demonstration by the experimenter.
In the trials, participants were presented with visual cues instructing them to perform each condition.
Twelve participants  completed our study.
Each participant performed five blocks of the six techniques, with the order of techniques counter-balanced using a Latin-square design.
In each block, participants repeated 10 trials for each condition of a given technique.
We conducted a conventional ten-fold cross validation using all the data from each technique.
As shown in Table 2, all techniques achieved an accuracy of over 97% except for Double bump .
This result gives us a basic assessment where the interaction data from a group of users is known a priori, and a model can be trained and finetuned to a particular group of users.
To challenge our techniques in more realistic scenarios, we conducted two further evaluations and analyses.
It is important to know how the features perform at a per user level .
For each technique, we separated the data between the participants, and ran a ten-fold cross validation within the data of each participant.
As shown in Table 2, the features are indicative for each technique for specific users .
However, the results also show some users were inconsistent in performing the techniques, especially Double bump  and Hold and flip .
These two techniques, by nature, are more complicated than the others, and demand clearer instructions and perhaps a larger set of training data.
For each technique, we repeated this process 12 times .
We then calculated the average and the standard deviations of the accuracy.
As shown in Table 2, the results indicate that for most techniques, there was some inconsistency between participants .
As a result, their performance dropped compared to the previous two analyses.
A solution to mitigate this problem is using some online learning mechanisms that dynamically incorporate a new user's data into the existing model.
The multi-device gestures were recognized using hard coded heuristics, based on the gesture length, duration, and timing.
The results of our evaluation  show a fairly high accuracy of our implementation.
We now introduce the Duet system, which demonstrates how the novel gestures and sensing techniques we have described could be utilized to enhance a wide range of interactive tasks across various applications.
Duet is an interactive system that explores the joint interactions between a smart phone and smart watch.
The system can be thought of a smart phone shell that is enhanced by the watch.
The shell consists of a home screen and four common mobile apps.
The interactions we present are meant to explore the areas of interest within our design space .
In particular, we demonstrate how the watch can perform foreground interactions as an input device or extended display, or serve in the background as an auxiliary sensor.
Meanwhile, the phone remains in the foreground, whose interaction is enhanced by these three different roles of the watch .
The Home Screen provides techniques for managing the device and its applications .
To unlock the device from an inactive mode, a user performs the hold and flip gesture .
This gesture requires a synchronized motion of both the phone and the watch, thus reducing recognizer false positives.
Optionally, one can use it as an additional security layer that requires the ownership of both devices in order to gain access.
Four app icons are displayed on the home screen.
The user can touch an icon to open an app, or use a knuckle-touch to move the icons .
Contrary to existing designs, this requires no extra steps to distinguish between opening and navigating the apps, and repositioning their icons.
A person can also use the watch to quickly switch between apps.
Pressing and holding the watch brings up an app selection screen on the watch, which displays the app icons in a 2x2 grid .
Additional app icons would be organized on pages that a user would swipe between.
Tapping on an app loads it on the phone, and pressing and holding on the app selection screen dismisses it.
Tapping an email opens it; while a knuckle-touch can be used to select and apply actions to multiple emails, such as `archive', `mark as read' or `delete'.
This technique requires no extra widgets  for selection, thus saving more screen space for the other interactions.
In social occasions like meetings and movies, a person can use the multi-device gestures to manage which device email notifications are received on.
A pinch-to-close mutes both devices simultaneously .
A pinch-to-open resumes their notifications .
A stitching gesture from the phone to the watch directs all the notifications to the watch .
The opposite direction pushes all the notifications to be shown on the phone .
We also use tactile feedback to inform a gesture's direction, e.g., when swiping from the phone to the watch, a user can feel two vibrations - first on the phone, then on the watch, as if a single vibration was `transferred' across the devices.
This technique provides a way to customize notifications on multiple devices without resorting to extra physical buttons or UI elements.
The Map app enhances a user's search and navigation task.
Existing map apps only partially support one-handed use - a common scenario that happens when, for instance, the user is holding a coffee.
While zooming in can sometimes be accomplished with a double tap, it is difficult to zoom out with a single hand.
With Duet, we use the double bump as a gestural shortcut for zooming out .
A normal tap on the page brings up the menu with basic and frequently used options .
Alternatively, with the watch as a sensor, one can use the flip and tap gesture to display an advanced menu that contains additional commands .
We use the finger postures recognition to implicitly select tools in the reader app.
For example, after selecting a pen tool from the menu, the finger pad is used to annotate the text , the side of the finger to scroll the page , and the knuckle to start text selection .
This allows for a seamless transition between three frequent operations without having to explicitly specify any modes.
Another difficult task on a map app is selecting tiny and cluttered location markers .
Inspired by Shift , we design a mechanism for using the watch to facilitate small target acquisition on the phone.
To start, the user thumbs down an area of interest , which is then zoomed in on the watch .
The user can select an enlarged target on the watch , or swipe to pan and adjust the zoomed-in area .
Releasing the thumb brings the user back to the map navigation on the phone.
The watch assists users in selecting multiple small targets without invoking widgets that take up screen space.
In addition to the phone's default copy and paste functions, the watch can also be used as a clipboard that holds multiple pieces of text.
Upon selecting the text , the text will be displayed on the watch.
Users can then add it to the clipboard by swiping right on the watch .
One can also retrieve an earlier selection by swiping down the clipboard .
First, users liked how adding the watch can create lightweight interaction, which might otherwise be cumbersome on the phone alone.
For example, swipe to switch map views was considered as a "handy" feature , "better compared to  traditional way of doing it" , and "reduce interaction steps" .
Second, people liked using the watch as an extended display.
For example, P3 liked how using the knuckle to select emails dispenses with UI widgets and "increases screen space", P2 commented that flip and tap to bring up the advanced menu "saves screen real-estate", and P8 liked how a tool palette on the watch "saves screen space" for the text in a reader.
The call app shows an exemplar interaction using the watch to retrieve information while holding the phone for a call.
In this situation, back-of-device touch  might be a useful input solution.
To enable a quick exploration of this idea, we flipped the phone and turned its front screen into a back-of-device touch area .
This proof-ofconcept prototype allows a person in a phone call to retrieve information that can be displayed on the watch.
Users can navigate between a list of frequently used apps, by swiping up and down.
Once the desired app is located , details can be retrieved.
For example, swiping left/right on the Email app goes through the inbox where the watch shows one email  at a time .
Tapping on an email opens it; and the user can read the email by scrolling through its text; another tap closes the email.
This technique works for cases where the caller needs to quickly access information on the phone, such as recent emails, missed calls, or calendar events.
Third, users enjoyed having a set of novel gestures enabled by using the watch as an auxiliary sensor.
For example, most participants liked the possibility of using the watch to sense the pad, side and knuckle of the fingers.
P2 and P5 further recommended designs that allow users to customize what each hand part does in the applications.
Last, users found it most compelling when the phone and the watch complemented one another and created interaction that went beyond their capabilities as individuals.
For example, P2 considered accessing apps on the watch while on a phone call a feature he "can't think of any other  way to do it".
The watch in this scenario fit in a `niche' wherein phone-based interaction fell short.
Some participants commented that a tool pallet on the watch resonated with their experience of using a physical toolbox , pencil box , and color pallet : the combination of both devices did not just enable a certain function, but also created a unique and pleasant experience when using that function.
On the other hand, participants also pointed out issues and concerns with Duet.
Foremost, participants often felt less enthusiastic when a Duet technique did not show significant improvement from what existing single-device designs could already achieve.
For example, P7 thought hold and flip is good for some "niche applications" , but would be "overkill" if using it to replace the existing locking/unlocking mechanisms.
We recruited 10 participants, five male, five female, ages 21 to 27.
All participants were smart phone users.
Six participants were students from three different local universities and the others were young professionals.
We demonstrated all the Duet interactions to the participants, and asked them to comment on their easiness  and usefulness .
The participants could also try out Duet by themselves and think aloud while exploring.
The entire study took approximately 60 minutes.
People also gave mixed reviews for some of the watchenhanced gestures.
For example, both P8 and P9 pointed out that knuckle-touch could create screen occlusion and felt hard when dragging for precise positioning ; however, they liked using it for email selection, as this interaction required less precision and felt easier when performed with the knuckle.
Finally, many participants noted the small display and touch area of the watch.
We also received valuable suggestions for additional features from the participants.
Users suggested different mappings between techniques and applications, e.g., using multi-device gestures to copy text from the phone to the watch , or as another way to authenticate the ownership of both devices .
A number of participants suggested including a `fall back' option for situations where the user misplaces either device .
This further suggests a design challenge: how can we allow the users to transition to a multi-device paradigm and interface with them as if they were a unified interactive platform?
We can rethink how we can phrase the interaction between and by multiple devices into a fluid stream of action.
Our multidevice target selection technique  has set foot in this exploration.
As shown in Figure 14, this technique starts from the phone with a `touch and hold on the map'.
This leads to a `showing touched area' on the watch, and leaves room for `touch to adjust or select targets'.
A touch release on the phone brings an end to this technique, dismissing map display on the watch, and leaving selected targets, if there is any, highlighted on the phone.
All these `components' of the techniques are phrased together, `glued' by the muscle tension of thumb that holds down on the map .
By thinking in terms of phrasing in musical communication, we can explore more ways of designing interaction that spans multiple smart devices.
We discuss issues and questions to inform future work.
Despite the promising accuracy levels shown in the technical evaluation, it should be noted that the study was performed in a controlled lab environment.
As such, there will likely be conditions where recognition rates may not perform as well.
For example, our handedness detection  is based on the assumption that, when wearing a watch, a touch down event will cause synchronized movement between the watch and the phone.
However, a touch might only incur subtle finger motion, without detectable movement of the watch or the phone ; a bare hand's touch might also coincide with the devices' movement, thus resembling a touch caused by a watch-wearing hand .
Our future work will explore software and hardware solution for mitigating this problem.
Some of the Duet techniques require wearing the watch on the ventral side of the wrist to keep it readily visible and accessible .
Although an elastic watchband greatly eases the switching between the two configurations , a user still needs to perform the switch.
Our future work will explore alternate input/output modalities on the form factor of a watch, e.g., extending the design solution of Facet .
Exploring the `phrasing' of Duet.
Musical communication research found that musicians use phrasing to structure their duet performance .
In particular, phrasing allows musicians to communicate with one another by delimiting their duet performance into temporal frames through which musicians anticipate each other's musical actions while finding room for their own musical expression.
Similar to how Buxton articulates this concept in gesture design ,
Our paper focuses on a duet of interaction between a smart phone and a smart watch.
In the future, it would be interesting to consider how our design space and the interactions could be extended to not just a duet of devices, but perhaps a trio, a quartet, and eventually towards a symphony of devices and interaction .
Soon mobile interaction will no longer be the solo performance of the smart phone, but will rather be a symphony of a growing family of smart devices.
Our Duet system reveals a design space of joint interaction between two smart devices and illustrates underexplored areas where the phone remains in the foreground of interaction, and the watch is used to enhance a wide range of phone-based interactive tasks.
Our technical evaluation demonstrates the accuracy of the new gestures and sensing techniques used by Duet, and a subjective study on the Duet system provides insights, observations, and guidance for future work towards a symphony of interaction.
Amento, B., Hill, W., and Terveen, L. The sound of one hand.
Baudisch, P. and Chu, G. Back-of-device interaction allows creating very small touch devices.
Buxton, W. Integrating the periphery and context: A new taxonomy of telematics.
