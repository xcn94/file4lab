ABSTRACT Photographs play a central role in many types of informal storytelling.
This paper describes an easy-to-use device that enables digital photos to be used in a manner similar to print photos for sharing personal stories.
A portable form factor Combined with a novel interface supports local sharing like a conventional photo album as well as recording of stories that can be sent to distant friends and relatives.
User tests validate the design and reveal that people alternate between "photo-driven" and "storydriven" strategies when telling stories about their photos.
Keywords Digital storytelling, multimedia photography, browsing.
For example, all of us have had the experience of handing around a photo album while the photographer tells us the story behind the pictures, or receiving a couple of photographs in the mail with a short note from a friend or family member.
In developing our prototype "StoryTrack" device, we imagined two specific scenarios which guided the design and embody both the imposed constraints and assumptions about user needs and priorities.
Fred fetches his box of pictures and pulls out the most recent batch of photos.
He flips through the pictures one by one, and relates interesting anecdotes associated with some of the photos.
Occasionally Ben points at an image and asks about it.
At one point Fred gets sidetracked and launches into a story about last year's trip to Canada.
He looks back through his other photos to find a picture that illustrates the point.
Fred's children Amy and Johnny want to send some pictures to Grandma.
They pick out some pictures of themselves playing from the recent photos.
While doing so they come across a funny picture of Dad in Alaska and add that in as well.
In addition to creating a brief message to go along with their photos, they spend a lot of time recalling  about what happened in each picture.
INTRODUCTION One of the most common and enjoyable uses for photographs is to share stories about experiences, travels, friends and family .
Almost everyone has experience with this form of storytelling, which ranges from the exchange of personal reminiscences to family and cultural histories.
The World-Wide Web can facilitate the sharing of such stories in digital form, and has inspired a movement towards "digital storytelling."
For instance, Bubbe's Back Porch  is a collection of family stories expressed as Web pages containing text and photographs, captured during a series of workshops--a grandmother's conversation as she makes soup, a grandfather's tale of how he met his wife.
On a grander scale, national institutions such as the US Library of Congress store oral histories from, for instance, migrant farm workers in 1940s California .
The goal of our project is to support the sharing of digital photographs and associated stories.
The design objectives were motivated by both formal research  and informal observations and interviews regarding photo usage.
To copy other~vise,to republish, to post on serversor to redistribute to lists, requires prior specificpermissionand/or a fee.
Existing tools do not naturally support these activities.
As explained below, current form factors and user interfaces present barriers to sharing digital photographs.
To overcome these limitations, we set out to build a prototype device that is easy to hold and pass around like a regular photo album, with an interface that requires no training to select, display and comment on a sequence of photos.
The authored stories then correspond to folders of bookmarks that a user creates, representing interests that change over time.
The remainder of .this paper discusses the application of the story metaphor to digital photos.
The following section describes our prototype device and explains how it attempts to meet the stated requirements.
Next, the results of informal usability tests are presented, demonstrating the differences between anticipated and actual use of the device.
The conclusion offers several suggestions for developers of digital photo albums and story sharing devices.
However, digital photographs are generally viewed on personal computers that do not facilitate shared interactions.
People can only create digital stories with special-purpose software requiring computer skills.
Hypermedia composition tools such as Isis  or MediaDesc  also support story creation, but require the user to focus on structures such as temporal constraints and hyperlinks rather than just telling a story.
In contrast, our design does not distinguish between authoring and viewing modes thereby allowing people to view existing stories while simultaneously creating a new one.
Our work also differs in some respects from research on image retrieval and organization .
Digital photos have an advantage over print photos in that users can search for and retrieve them both by their content  and by their metadata .
Much previous work has focused on such searching as a key aspect of working with digital photos.
For example, the FotoFile system  provides a unified interface for annotation and search, using categories such as people, places and events that are commonly used for labeling photographs.
With prints, however, people are generally limited to very simple search strategies--scanning through chronologically ordered images in an album or batch of photos.
Our prototype derives great simplicity by operating on very similar principles without any sophisticated retrieval mechanisms.
Sharing photos in a natural setting requires a portable device that can be used in different locations throughout one's home.
The device should also be large enough to show photos at a size similar to regular prints, viewable by more than one person.
Initial investigation with mocked-up interfaces led to a design for two-handed usage that allows the device to be held easily, rested on one's lap or a table, or shared with another person.
Figure 1 shows our current prototype being shared by two people.
Note that a typical personal computer cannot easily be shared.
One user typically controls both the mouse and keyboard and has the best view of the monitor.
In contrast, sharing photos requires that control pass easily from one user to another.
Stories form an intriguing organizational metaphor; blending aspects of chronological orderings and usercreated groupings such as folders or directories in a file system.
There are two kinds of stories represented in the StoryTrack: 1.
Imported stories are the "rolls of film" with which a user starts.
In the case of scanned prints, they might correspond to literal rolls of film.
However, in the case of digital photos, they correspond to a set of photos downloaded from the camera in one session.
Within an imported story, photos are ordered by time of creation.
Authored stories are selections of photos that have been grouped and ordered by the user.
The sets of imported and authored stories can themselves be ordered according to the time of creation of the stories.
At any time, the story under construction has special status.
When complete, it joins the set of authored stories.
A photo appears exactly once in the set of imported stories, and can appear in zero or more authored stories.
Objects from other domains could equally be organized in this way.
Furthermore, people point at pictures when talking about them.
Using the same gestures to control the device might be confusing and produce unexpected behavior.
Instead, all input controls are mounted on the edges Of the device.
As seen in Figure 1, this enables control to pass more fluidly between two users.
The middle track shows the authored stories: photos that have been grouped into stories by the user.
Each story appears as a sequence of thumbnails.
Stories are ordered according to their time of creation; the display again visually distinguishes separate stories using colored backgrounds.
The bottom track represents a story in progress: the "working set" of photos selected during the current session.
A photo will appear in the bottom track if it has been added to the working set by pressing either of the +  or record buttons, as detailed below.
The imagined usage scenarios presented quite a design challenge.
At any point, a user may switch from recording an anecdote to viewing another set of images, may hand the device off to somebody else, or may simply browse through the latest photos.
To accommodate such usage, we developed a novel interface based on the story metaphor.
Figure 2 shows the layout of the display.
It is divided into three main regions.
The large c e n t r a l a r e a of the screen displays the currently highlighted thumbnail.
The a u d i o a r e a shows available audio narrations for the highlighted photo.
The n a v i g a t i o n a r e a at the top of the screen is a graphical representation for browsing and navigating through photos.
Each of the three horizontal tracks of photo thumbnails serves a distinct purpose: 1.
The top track shows the imported stories: all existing photos currently stored in the device, ordered chronologically ~.
Photos from digital cameras are ordered according to when they were taken, while images scanned from print photos are ordered by scanning time.
Alternating background colors distinguish separate stories .
The permanent display of all three tracks enables an essentially modeless interface where a user can simultaneously view stories, see their original unedited set of photos, and see the story they are creating.
The display also provides helpful context for viewing the current photo.
In a typical interaction, a user comes across a photo that is interesting and adds it to the working set, possibly also recording a related voice annotation.
At the end of the session, the bottom track is grouped into a single story that is then appended to the middle track.
We now explain the interaction in detail.
Figure 3 labels the control buttons.
The top two buttons on each side, easily accessible to the thumbs, scroll the current track either to the left or the right.
A bright yellow vertical line  indicates the current track and the center thumbnail of this track.
This selected photo is always also displayed in the large central area.
When one of the scroll buttons is pressed, the current track shifts to the left or right.
As a different thumbnail moves under the indicator, the corresponding photo is displayed.
Variable-speed scrolling allows the user to quickly traverse the photos on a track.
At slow speeds, the display appears as shown in Figure 2.
An earlier prototype used a center-weighted dial to control scrolling speed.
The left and right buttons are better suited to the way the device is held, but cannot control scrolling as easily.
At present, a single "click" of a scroll button moves the track by exactly one thumbnail.
Holding down a scroll button for a longer time causes scrolling at increasing speed.
There are two remaining navigation buttons.
The track selection button moves the indicator between the three different tracks.
As illustrated in Figure 4, the expand/collapse button controls which of two different views of a track is shown: * * The expanded view, shown by default, where every photo is shown in thumbnail form.
The collapsed view, where each story is represented by a single image, allowing faster navigation.
The thumbnail of the first photo in a story is used to represent the story.
Pressing the +  button appends a copy of the currently selected thumbnail onto the working set .
The -  button, conversely, removes the selected thumbnail from the working set.
Pressing the record button begins recording of an audio clip associated with the currently selected photo in the working set.
If the photo is not already in the working set, it is appended before recording begins .
If the selected photo is already on the working track, the new recording overwrites any previous recording associated with it in the story under construction.
The recording can be stopped with the stop button.
If the user scrolls to a new photo while recording, the recording for the first photo terminates and a new audio clip is started that is associated with the new photo.
Our aim is to make recording a story as similar as possible to viewing a story.
However, to prevent accidental erasures, scrolling backwards automatically halts the recording.
We hypothesized that some users would compose a story by first selecting a working set of photos using the +/buttons and then annotating each photo in order, a "select then narrate" strategy.
We believed other users users would continuously record annotations while navigating and selecting photos.
This "select while narrating" strategy is also supported: when recording is active, each new photo that a user views for longer than a short time interval is automatically added to the working set along with any narration.
The cluster of buttons at the bottom left controls the creation and playback of stories.
The play button starts playback from the currently selected thumbnail.
If an audio narration exists, it is played through the built-in loudspeaker.
Subsequently, or after a short pause if there is no audio narration, the currently selected track automatically scrolls forward to the next photo  and continues playing until the stop button is pushed or the end of story is reached.
If the user navigates to a different photo while playing, playback will continue from that point.
The length of the wavy lines is proportional to the duration of the audio.
The narration associated with the currently selected story is listed first and is played by default when the play button is pressed.
Pressing the play button multiple times in quick succession selects one of the alternate audio clips and playback "jumps" to the corresponding story, providing a kind of automatic hyperlinking between stories.
For sound recording, a microphone is attached to the external body of the tablet, while the builtin speakers are used for playback.
Stories and metadata about photos are stored on the tablet's hard drive in Extensible Markup Language  2.
This allows for easy translation to Hypertext Markup Language  or Synchronized Multimedia Integration Language  so stories can be shared with others who do not have a StoryTrack.
The SMIL format is especially appropriate as it allows the synchronization of audio with a series of images, exactly matching the structure of our stories.
Digital photos can be loaded onto the device from digital cameras by inserting a flash memory card, or may be downloaded through a wireless network connection.
The final group of buttons, at the bottom right of Figure 3, controls story operations.
The save button "saves" the current working story  by moving it to the end of the middle track.
Note that the current state of the device is also saved to disk at that time, matching users' expectations about "save" and persistent storage.
The user would also have the option of electronically sending a completed story to another user for viewing on a similar device or on a regular PC via a media player application or standard Web browser.
However, the implementation of this feature was not part of the user testing reported here.
This interaction design achieves our primary goals for modeless sharing of digital photos and stories.
A user can seamlessly switch between browsing, viewing, authoring, and showing.
In addition, by removing the complexities of dragging, menu selection and other artifacts of windowsbased interfaces, we arrived at something that we hoped would be intuitive and simple to use in conjunction with our hardware controls.
To evaluate the efficacy of this design for sharing digital photos, we conducted an informal usage test .
Subjects were presented with the device in a natural setting and encouraged to think aloud while using it.
Observation of the user interaction helped identify features of the interface that did or did not work well.
Moreover, it provided valuable insight into the ways that people use photos to tell stories.
The prototype described here is based on a portable tablet computer  augmented with several specially built control buttons.
Although fairly heavy at 3.91bs , we expect future prototypes to be lighter as hardware technology advances.
The screen viewing angle permits up to two users seated side by side, and the machine provides sufficient battery life and computational resources for testing our design.
The software is implemented using Java 2 on Windows 98, with additional native libraries for audio I/O.
The control buttons are simple pushbutton switches connected to the tablet's serial port via a BASIC Stamp 2 microcontroller.
We observed nine sessions of subjects.
In seven of these sessions, we observed pairs of subjects consisting of one primary  and one secondary user .
The remaining two sessions involved a single primary user.
For each session, the StoryTrack was preloaded with 2-3 recent sets of photos provided by P. We intended that P treat the device as its owner.
Eight subjects provided prints that we scanned, one subject provided photos taken with a digital camera.
The total number of photos provided by each subject ranged from 45 to 234, with half of the subjects falling in the 45-50 range .
Note that on initial introduction to the device the first track included all of P's photos; the second and third tracks were blank.
Each session was divided into three stages: initial exploration, sharing, and feedback.
Physical Interaction and Form Factor The primary complaints about the physical nature of the device referred to its weight and bulkiness.
Our prediction during the design of StoryTrack was that subjects would show photos to a local audience by holding the tablet in both hands while pressing the buttons.
However, the weight of the tablet and size of the BASIC Stamp assembly  made it difficult for subjects to lift and maneuver the device comfortably during usage.
All of the primary subjects dealt with these problems by resting the tablet on their laps and rotating it as needed to show the other subject the photos.
P then played with the device for 10--15 minutes without any further input from the experimenters.
At the conclusion of this stage, a written instruction sheet was provided detailing the functions of each of the control buttons as well as an overview of the interface.
At this point subjects were welcome to ask any questions regarding the basic functionality of the device, but were not provided answers regarding usage strategies.
For example, we would explain that the + button added an image to the current working track, but would not explain how to use the + button along with the recording capabilities to create audio-annotated stories.
Once P felt comfortable with the device, S was brought into the room and seated adjacently.
If desired, the device was reset, erasing any stories created during the first stage.
First, to share photos locally with S. Second, to create a story that could be sent electronically to any specified recipient .
In the two single-subject sessions, the local sharing task was skipped.
The third stage consisted of a series of follow-up questions directed at both subjects, broken down into three discussion topics.
First, comments on the interface .
Second, comparisons of the StoryTrack experience with the users' current handling of print or digital photos .
Finally, feedback regarding the storytelling aspects of StoryTrack.
By holding the tablet in this position, the subjects maintained easy access to the button controls.
Many subjects mentioned that the buttons were conveniently placed so that it was easy to simultaneously hold and control the device.
In several of the multiple-subject sessions, one manipulated the controls along the right edge of the device while the other manipulated the controls along the left edge.
Occasionally, the device was handed over to the other subject.
Subjects frequently used one hand to point to images on the screen.
This is similar to a way of browsing through print photo albums--one person holds one side of the album, another person holds the other side and both of them can point to photos.
Subjects had no difficulty operating the control buttons although very few subjects discovered and used the fast scroll capability.
Rather than hold down the scroll button, subjects would press it multiple times quickly to advance through a track.
Since many subjects asked for a fast method of advancing through the tracks  we suspect that an alternative input device, such as a thumb wheel or pressure-sensitive pad, may be more effective at facilitating variable-speed scrolling.
The buttons used in this study give a satisfying tactile click when pressed, and so create the expectation of a discrete rather than a continuous action.
Software Interaction As already explained, subjects had few difficulties with basic navigation and the saving of stories.
The experimenters did explain the save function to one subject and the operation of the recording function to two subjects.
All other subjects learned to operate the basic functions of the device during the exploratory phase without experimenter help.
The expand/collapse feature  occasionally caused confusion, due in part to the alternating background colors.
Upon first use, some subjects thought most of their photos had disappeared.
Overall we were pleased to find that subjects could operate the prototype with little or no instruction.
Eight of the nine primary users were able to create sequences of phqtos and "save" them onto the second track during the initial exploratory stage.
At the end of the first stage subjects asked few questions and spent very little time, less than 30 seconds on average, reviewing the instruction sheet.
Primary users had no difficulty demonstrating the device to the secondary users without experimenter help.
Everyone intuitively understood the use of the three tracks although they did not necessarily label the groupings as "stories."
Subjects saved 2-8 stories each.
Some of these were unintentional, occurring during the exploration stage, and some did not include audio recording.
Most of the stories ranged in length from 3-7 photos.
The record function also caused confusion for several subjects.
A number were surprised to hear their own voices while experimenting with the play button after having inadvertently recorded some narration.
Subjects uniformly favored the "select then narrate" strategy, preferring to add photos using the + button and explicitly start and stop audio recording.
In general, few subjects used audio recording except when creating a story to be sent.
Several subjects requested additional functions for editing stories.
Users wanted to insert photos into the middle of stories, and to bring saved stories back down to the bottom track for editing.
During the two-person tests many stories about photos were told.
As observed in , it is socially inappropriate to be silent while showing your photos to someone.
There appeared to be two different styles of storytelling: 1.
Photo-driven--the subject explains every photo in turn, the story prompted by the existing sequence of pictures.
Narration often comprises a sequence of sentences of the form "This is my wife," "This is my parents at home," etc.
This corresponds to the welldocumented use of picture-taking to preserve memory and aid recall .
Story-driven--the subject has a particular story in mind , then gathers the appropriate photos and recounts the story.
Table 1: Observed interaction types of photo-driven and story-driven browsing, then recorded an accompanying audio narration.
These observations shed some light on the relative merits of browsing and search.
If subjects cannot think of a story to tell  until prompted by another photo, then browsing has to precede search.
Furthermore, since subjects often move between photo-driven and storydriven styles, it is important to support both without context switching in the interface.
Whether these styles were the preferred strategies or due to characteristics of the prototype remains to be determined.
However, subjects seemed to enjoy using the device and did not ask for or mention the lack of search or other retrieval tools.
Audio clearly plays a big role in sharing photos.
All subjects talked a great deal while showing photos to their partners in the study.
Subjects did not record these conversations, nor did they record audio annotations for their own use.
However, they did record narrations for sequences of photos to be sent to a friend or family member .
It seems quite likely that the use of audio may change with experience as users become accustomed to multimodal albums.
Indeed, our youngest tester  had a very different way of composing a story.
Favorite pictures were added multiple times, and the voice annotation consisted of sound effects such as "Splash!"
Rather than sticking to one or another of these styles, subjects would segue from one to the other.
A familiar photo would remind them of a particular story , or in the midst of telling a story an unexpected photo would come up .
For example, one subject was creating a story about a camping trip until she came across a Thanksgiving photo.
This photo received a brief cOmmentary before she moved on to creating a new story about a musical performance.
Table 1 summarizes the characteristics of each strategy.
All subjects started with a photo-driven style when showing photos to a local audience and were more likely to use story-driven strategies when assembling photos to send to a remote audience.
Note that there was often not a clear distinction between photo driven and story driven usage.
People normally expect photos to be in chronological order and often explain the sequence of events as they go through each photo.
At least one subject created a story for local sharing that was simply a re-ordering of the photos in correct chronological order.
Modeless interfaces that simultaneously support these activities should be preferred.
The "shoebox:" A disorganized container for all sets of photos, possibly in approximate chronological order.
Apart from actual shoeboxes, closets and desk drawers were commonly cited containers.
The album: A carefully selected and ordered set of photos, presented in an album.
The Web site: Subjects with digital cameras or scanners select a small number of photos at regular intervals to post on a personal Web site, in order to share them with friends and relatives.
Approximately one third of the subjects use the shoebox exclusively, one third use a combination of the shoebox and the album, and one third use a combination of the album for print photos and the Web site for digital photos.
In many cases, the albums and Web sites include short text annotations describing the photos.
This is the conventional way to record stories with personal photos.
It may also help explain why subjects showed a preference for "select then narrate" over "select while narrating," since the process of annotating a print album or Web site typically occurs after the photos have been selected.
Different advantages were cited for the StoryTrack depending on the subject's current organizational methods: * * * "Shoebox" subjects liked the idea that all of their photos would be easily browsable and all in one place; Album creators liked the fact that a photo could be in more than one story; Subjects with digital photos and Web sites liked the fact that now they could share these pictures without having to sit around the computer screen, which was not seen as a sociable activity.
Chalfen, R. Snapshot versions of life.
Bowling Green State University Press, Bowling Green OH, 1987.
Gomoll, K. Some techniques for observing users.
Idris, F. and Panchanatban, S. Review of image and video indexing techniques.
Creative multimedia for children: Isis story builder, in Proceedings of CHI 95 , ACM Press, 37-38.
Kuchinsky, A., Pering, C., Creech, M.L., Freeze, D., Serra, B. and Gwizdka, J. FotoFile: A consumer multimedia organization and retrieval system, in Proceedings of CHI 99 , ACM Press, 496-503 Nielsen, J. Guerilla HCI: Using discount usability engineering to penetrate the intimid~ition barrier.
The StoryTrack device demonstrates that digital photos can be used to support some of the same kinds of story sharing that people enjoy with print photos.
It also provides a convenient way of recording stories and sending them to family and friends, much more easily than is possible with conventional albums or tools.
The novel "three track" interface enables a very clean design that was easy to use for all of our test subjects .
In less than 15 minutes of using the device, people very naturally mixed browsing, composition, and annotation of photos while seamlessly switching between "photo driven" and "story driven" strategies.
It remains to be seen whether these simple navigational tools and story metaphors will suffice for very large collections of photos.
Looking ahead, we are curious whether access to this kind of device would alter the quantity or types of photos people take.
