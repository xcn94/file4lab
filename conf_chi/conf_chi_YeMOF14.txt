With the increasing popularity of mainstream wearable devices, it is critical to assess the accessibility implications of such technologies.
For people with visual impairments, who do not always need the visual display of a mobile phone, alternative means of eyes-free wearable interaction are particularly appealing.
To explore the potential impacts of such technology, we conducted two studies.
The first was an online survey that included 114 participants with visual impairments and 101 sighted participants; we compare the two groups in terms of current device use.
The second was an interview and design probe study with 10 participants with visual impairments.
Our findings expand on past work to characterize a range of trends in smartphone use and accessibility issues therein.
Participants with visual impairments also responded positively to two eyes-free wearable device scenarios: a wristband or ring and a glasses-based device.
Discussions on projected use of these devices suggest that small, easily accessible, and discreet wearable input could positively impact the ability of people with visual impairments to access information on the go and to participate in certain social interactions.
In this paper, we explore the potential impacts of wearable interaction for people with visual impairments.
Key questions include: How are users with visual impairments currently using mobile phones and wearable devices compared to sighted users, and what challenges exist?
What are considered to be the benefits and drawbacks of wearable input as an alternative to mobile touchscreen interaction for people with visual impairments?
How might an alternative wearable interface to a smartphone impact use, including behavior in social settings, sense of privacy, personal safety, and ability to use the phone on the go?
To address these questions, we first built a wristband that wirelessly controls the VoiceOver screenreading software on Apple iOS devices .
We then conducted two studies: an online survey of 215 people  and an interview study with 10 people with visual impairments.
The survey included questions on current mobile use and two proposed eyes-free wearable device scenarios: a wristband or ring, and a glasses-style device.
The interview study covered similar topics, but also employed the wristband as a design probe, expanding on the potential impacts of such a device .
With the popularity of personal tracking devices like the Fitbit Flex and Nike Fuel Band, and the introduction of Google Glass, wearable devices are entering the mainstream.
Once only the purview of academic research labs and niche products, this emerging technological era makes it critical to consider how wearable interaction can be designed to meet the needs of a broad range of users.
For people with visual impairments, in particular, wearable devices offer the potential to provide efficient mobile information access.
Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
The contributions of this paper are:  confirming and extending previous findings on smartphone and wearable device used by people with visual impairments;  a proofof-concept wristband input device designed for eyes-free use;  characterization of the potential benefits of wearable input for people with visual impairments in terms of social context and public use.
Our findings highlight not only the essential role of mobile devices in the daily lives of people with visual impairments, but also persistent limitations of these devices.
In terms of projected wearable input use, our visually impaired participants were consistently positive, both in the survey and interviews.
Finally, interview participants touched on potential impacts of the wristband device, such as inclusion in social interactions and the ability to access information on the go .
Beyond navigation aids, however, little work has examined wearable computing for people with visual impairments.
Braillebased or talking watches are used for telling time using tactile and audio output.
In terms of research prototypes, Finger-Braille  employs vibration motors on the fingers to output braille characters for deaf-blind users.
Touchscreen accessibility is an active area of exploration.
Commercial screenreading solutions for smartphones, such as Apple's VoiceOver and Android's TalkBack, have achieved widespread adoption in the US .
Researchers have also tackled touchscreen mobile accessibility, both through software solutions that provide interaction with the screen and audio output , and through hardware solutions such as tactile overlays  and haptic output .
Many eyes-free multitouch text input solutions have been proposed , although efficient accessible text input remains a challenge .
In terms of the social context of mobile device use, Kane et al.
Shinohara and Wobbrock  also examined how stigma and misperceptions of assistive technology affect people with disabilities.
Our study differs from this previous work both in our focus on projected wearable use and because smartphone adoption rates are much higher today .
Although not focused on accessibility, many touch-based wristband and smart watch solutions have been proposed, including examples like IBM's wristwatch computer  and Lyons et al.
Such solutions tend to rely heavily on the visual display for interaction.
More applicable for users with visual impairments is Perrault et al.
Another eyes-free example comes from Pasquero et al.
Other hand or wrist-based input solutions have been proposed, such as detecting hand gestures with various sensing mechanisms , using touch or gesture-sensitive rings , or fingertip-based cameras .
While potentially interesting for people with visual impairments, this lattermost solution, called Magic Finger , would interfere with tactile sensing because it covers the fingertip.
Interaction with limited visual attention is often touted as a design goal for wearable input , and the potential benefits for blind users are sometimes discussed.
However, these benefits are largely hypothetical with the limited exceptions of EyeRing   and Gustafson et al.
Finally, also related to our study is research on the social acceptability of general-purpose wearable technology-- smart watches or Google Glass as opposed to, for example, hearing aids or standard glasses.
One study, from Bodine and Gemperle , showed that perceived comfort of a device is related to perceived functionality.
More recently, Profita et al.
Our choice of the wristband form factor for our design probe is partly inspired by this finding.
The vast majority of work on wearable computing for people with visual impairments has focused on navigation tools to aid in travel and/or communicate points of interest; see surveys by Velazquez , Dakopoulos and Bourbakis , and Ross .
To characterize current mobile device use and to assess reactions to two eyes-free wearable computing scenarios, we conducted an online survey with 114 participants with visual impairments.
We also collected data from 101 sighted participants and report on the comparison between the two groups in terms of mobile device use.
We recruited mobile phone users through email lists, organizations working with people with visual impairments, Twitter, and Facebook.
The survey was hosted on SurveyGizmo and was designed to take 20-25 minutes for screenreader users on a desktop computer.
Participants could opt into a draw for a $100 Amazon gift certificate.
Finally, after removing remaining problematic codes, the average kappa score across all codes was 0.80 .
The worst performing code  was Other/general concern for privacy.
SPSS 21 was used for inferential statistical analyses.
The survey consisted of 26 questions, both open-form and close-form.
The questions covered: general background , current mobile technology use , attitudes about public mobile phone use , headphone use and speech dictation, and two eyes-free wearable computing scenarios designed for people with visual impairments.
The scenarios were: Scenario 1.
Imagine a small, wearable device, like a wristband, watch, or ring that allows you to interact with your mobile phone while the phone remains in your pocket or bag.
For example, you could swipe or tap on the wristband to navigate through apps or emails, which would then be read aloud to you through a headset using the screenreader software on the phone .
New wearable technologies are coming out that include cameras and computer vision, for example on glasses .
Imagine a small, wearable device of this type that can analyze the visual environment and communicate this information to you through audio or vibration.
Of the 215 participants, 114 reported having visual impairments that could not be corrected with glasses or contact lenses ; 101 reported no visual impairments .
For VI participants, reported levels of vision were: 50 totally blind, 38 light perception, 15 low vision, and 11 other .
The median age of VI participants was 35-44, whereas for sighted participants it was 25-34.
Only one participant aged 65+ was present in each group.
While VI participants were evenly split between male and female , there were more female participants in the sighted group .
As a result of online recruitment methods and the requirement that participants own a mobile phone, the sample is likely biased toward technology savvy participants who can afford Internet and mobile access.
Indeed, 85% of sighted participants and 84% of VI participants owned a smartphone, substantially higher than the 56% of American adults who do according to a June 2013 Pew Research report .
While the data will thus not be representative of the entire population, it offers a picture of one end of the technology use spectrum, and likely represents future technology adoption trends.
A total of 247 surveys were completed worldwide.
An additional 61 were only partially completed, resulting in a dropout rate of 20%.
Because of cultural and regional differences in attitudes toward privacy, personal safety, social norms, and even wearable device acceptance , we analyze here only responses from participants in the United States and Canada: 215 total .
Median completion time was 21 minutes for visually impaired participants and 9 minutes for sighted participants.
For open-form responses--privacy, safety, use on the go, speech input, headphone use, and the wearable scenarios-- we followed an iterative coding process .
Two researchers independently developed codebooks for each question, which were subsequently refined and merged.
For each of the first five questions, the two researchers then coded a randomly selected subset of 20-30 responses and Cohen's kappa was computed to assess interrater reliability for each code; two to three iterations of refinement and comparison were completed per question.
As mentioned, 85% of sighted participants and 84% of VI participants owned smartphones; the remaining owned other phone models.
Confirming previous studies , iPhones were more popular with VI participants compared to sighted participants, at 91% and 55% of the smartphone share in each group, respectively.
Android was the next most popular, at 9% and 36% for VI and sighted participants, respectively.
Interestingly, perhaps reflecting the benefits of smartphones for people with visual impairments, more VI than sighted participants used a mobile device to complete the survey itself .
Participants reported using their mobile phone frequently, with 89% in each group using it at least every few hours.
The phones were also used for a wide range of tasks, with the majority of participants  reporting use for the following: entertainment; text messages; phone calls; email or social networking; navigation; shopping, banking or government services.
Question  I am concerned about safety when using my phone in public  I am concerned about privacy when using my phone in public  It's easy to use my phone while I'm on the go 
Sighted and VI participants both reported using a range of technologies with their mobile devices .
For VI participants, the most popular was a screenreader followed by wired headphones.
Substantially more VI participants used Bluetooth keyboards and headsets than did sighted participants.
Just under half  of the 98 screenreader users reported using headphones often or always with the screenreader, compared with 17% who reported rarely or never.
Seventy-five participants provided detail on situations in which screenreader users choose not to use headphones; the most common reasons were when privacy is not a concern , specific tasks , and convenience .
VI participants were also much more likely to use speech input than sighted participants, confirming recent findings by Azenkot and Lee .
Two thirds  of VI participants used speech at least sometimes, compared to only 27% of sighted participants.
Building on Azenkot and Lee's  findings, however, we also coded open-form data from 145 participants about situations in which people prefer not to use speech input.
The most common situations were similar across both groups: noisy environments , privacy concerns , quiet but public environments .
And, although not overly concerned about privacy as a group, 32 VI participants  listed technologies that help preserve privacy, such as iOS's Screen Curtain feature to blank the screen .
For example, R22 wrote: "No more risk than anyone else.
Can use VoiceOver's screen curtain and read in braille , how many people can read braille?
Participants may thus not have expressed concern about safety because they were already taking steps to mitigate risk.
Finally, for use on the go, the most commonly cited concern from VI participants was the difficulty of hearing the phone in a noisy environment , whereas sighted participants most commonly mentioned the need to concentrate on the task at hand, such as walking or driving --common situational impairments .
The survey included Likert scale questions for privacy, safety, and use on the go, as shown in Table 2.
Although we had expected to see differences between the two groups, and possibly due to age and gender, responses were surprisingly similar across these factors.
Mann Whitney U tests comparing sighted and VI responses for each question found no statistically significant differences.
We also conducted exploratory analyses with impairment, age, and gender as independent variables , but no statistically significant differences emerged.
As one example of the similarity of responses, males and females in the sighted group both rated safety concern on average 3.1 .
The open-ended responses on privacy, safety, and use on the go provided more context.
Because the eyes-free wearable device scenarios were aimed at people with visual impairments, we focus on results from only VI respondents here.
Both wearable scenarios--a wristband/ring and a glasses device with a camera and auditory/haptic output--were popular with VI participants.
For the wristband, 70% of VI participants answered "yes" to wanting to use such a device, while only 5% reported "no" .
Similarly, for the glasses scenario 68% of VI participants reported that they would want to use such a device, while 9% reported that they would not.
To examine whether gender, age, and impairment type  impacted these responses, we employed ordinal logistic regression with response  as the dependent variable.
This analysis does not include the 11 VI participants who reported an impairment type of "other".
Sixty-eight VI participants who stated "yes" to using the wristband/ring, expanded on potential advantages and disadvantages.
R269 , wrote: "more privacy; don't have to keep my phone in my hand or worry about the screen curtain being on or not."
Too few VI participants said "no" to report aggregate data.
Sixty-seven VI participants elaborated on their choice of "yes" with ideas for applications and output modalities.
The two most popular applications ideas were navigation/walking support  and reading text .
Facial recognition, object identification, general scene information, and points of interest were all also requested by at least 10% of these VI participants.
The most popular output modalities by VI participants were speech , haptic , braille , and non-speech audio --often for different tasks.
For example, several participants wanted haptic output for navigation or object detection and speech for other information.
Six VI participants who did not want to try the glasses elaborated on their responses.
Beyond not seeing utility in the device, issues included not wanting so much information, privacy/security concerns, and distraction.
Participants used their mobile devices frequently and for a wide range of tasks.
VI participants were more likely to use optional tools like Bluetooth keyboards, speech input, and  refreshable braille displays.
VI participants also reacted positively to the wearable scenarios--both the wristband/ring device and the glasses.
To strengthen the survey findings and to capture a richer understanding of potential impacts of wearable interaction for people with visual impairments, we built a prototype wristband that controls the VoiceOver software on iOS devices.
Using the wristband as a design probe, we then conducted an interview study with 10 visually impaired participants.
45"20 mm capacitive buttons made of conductive fabric.
The Navigation button was a pressure-based touch panel that used a 50mm touch potentiometer.
The controls are connected to an Arduino Uno board, which converts the signal to key press and release events and sends these via a BlueSMiRF HID Bluetooth modem to a paired iPad.
The custom software was written in Arduino, and makes use of the SoftwareSerial and CapSense libraries.
The wristband provides the following tactile features to support eyes-free use:  embroidered guide ridges along the edge to demarcate buttons;  raised bases for the buttons themselves allowing them to be easily distinguished from the main band;  a strip of tape on the Navigation button to distinguish back and forward; users can lightly run their finger along the button before pressing a side.
The current wristband arose from an iterative design process and informal evaluation with early versions of the prototype.
The wristband, shown in Figures 1, 2 and 3, provides three buttons: Home, Select, and Navigate.
The buttons produce keyboard events that are sent wirelessly via a Bluetooth modem to a paired iOS device, allowing the user to control VoiceOver and receive audio feedback.
Although there are few controls, they are versatile:  pressing the left/right sides of the Navigate button moves forward/back through items ;  tapping Select opens an item ;  a short tap on Home returns to the home screen, and a long tap activates voice dictation  as it would on an iOS device.
We intentionally designed the wristband as an e-textile fabric device, in contrast to the bulky form factor of many smart watches.
The main band was made of felt, and fastened with Velcro.
The procedure was designed to fit in a single 60-minute session.
It began with a background questionnaire, followed by a semi-structured interview on current device use .
The interview covered the same themes as the survey but also included current wearable device use.
We then transitioned to the wristband usage phase, which took on average 10-15 minutes.
First, for participants unfamiliar with VoiceOver, we provided a short  overview of its primary features on an iPad.
We then hid the iPad from view for sighted participants and had participants wear the wristband on their left arm.
Following a short introduction and guided practice with each button, we asked participants to complete a series of basic tasks , including: navigating to, opening and closing apps; navigating through content within an app ; using Siri for voice commands .
Finally, the session concluded with a semistructured interview  on the design of the wristband, and the predicted impacts of using such a device in terms of themes like privacy, safety, and so on.
Two participants mentioned that the screenreader could draw unwanted attention and curiosity from strangers about how blind people use phones , for example: "...when you feel someone is just looking at you and I know it is probably because they are trying to figure out how does the blind person do this or whatever, or does she need help kind of thing.
So it would be nice if the phone could convey more information through vibrations than auditory."
The majority of participants discussed situations when they feel self-conscious about using their phone around others.
One reason was the desire to project competence, which could be undermined by struggling with the phone or having the screenreader speak certain information aloud.
For example, VI1 mentioned: "I don't do a lot of work-related tasks with speech yet.
So if I'm doing it, it's not work related and I'm embarrassed to have people listening to me doing stuff that's not related to work."
The theme of social etiquette arose frequently.
Seven participants commented on the need to be polite toward others by not intruding with noise, primarily from the screenreader.
Confirming the survey findings, almost all of the screenreader users  either used earphones or turned the volume down in consideration of others, for example: "So on the train I'll just try to sit in a place like next to the window where I can put the phone here low next to my ear and kind of minimize disturbance to other people" .
As with the survey responses, participants were not overly concerned about personal safety when using their phone in public.
Only one participant expressed concern that people might target someone with vision loss.
Interviews were audio recorded and transcribed for analysis.
Use of the wristband was video recorded.
One researcher analyzed the transcripts using an iterative coding process with open and axial coding to identify emergent themes in the data .
The use of semi-structured interviews allowed us to pursue themes that we had not identified in advance; thus, not all topics were necessarily discussed with all participants and specific counts of participants should be considered a conservative estimate.
Mobile phone adoption patterns  were similar to the survey, yet additional themes arose in the interviews.
The screenreader can make it difficult to interact with the mobile device in a discreet, socially acceptable manner.
VI2, for example, commented on the ability to use his phone during meetings where he's expected to actively participate:
Whereas VI survey participants most commonly cited noise as a barrier to using the phone on the go, interview participants focused more on the impacts of walking.
Both are common examples of situational impairments .
Two primary concerns with walking were:  at least one hand is busy because they are holding a cane or dog, and  screenreader audio can interfere with the ability to use hearing for navigation and spatial orientation .
For example, VI7 captures the difficulty of simple tasks while on the go on a smartphone compared to her old flip phone: "It's not very easy for me, because I always have one hand with my cane, so, because I can't do stuff onehanded with my phone, that's very hard.
I can't just take it out and flip it and hold it up to my ear.
I have to take it out and double tap a few fingers and, you know, then put it up to my ear.
So I have to stop and use two hands."
Previous work has shown that talking devices and speakerphone mode can cause privacy concerns for blind users , a problem that may be magnified with today's multimodal smartphone interaction.
Indeed, for both speech input and screenreader use, a majority of participants were concerned about privacy.
For speech dictation, for example, VI7 expressed that she sometimes types instead of using speech, based on privacy concerns.
As with the survey, many participants also reported using headphones with the screenreader to preserve privacy.
For some people, headphones are critical--VI2 mentioned that if headphones are not easily available, he may delay using his phone.
And, as with the survey, a few participants mentioned using iOS's Screen Curtain, although two of three participants used it primarily to save battery power .
Speech input and text entry.
Accessible text entry remains a challenge on mobile devices, with one participant expressing a desire for, "anything that can be done to make it easier to input text into the iPhone" .
Perhaps reflecting this challenge, participants were likely to use speech input and/or Bluetooth keyboards--confirming the survey findings and past work on speech .
Of the four participants who mentioned using a Bluetooth keyboard, two used it for entering passwords .
Another participant  used it at home for email and social media, commenting that with the Bluetooth keyboard: "If you email on the phone then it is just the same as if you were writing the email on a laptop" .
For a sighted person, the small size of a smartphone screen would be restrictive, but this comment highlights how the size of the device itself can be irrelevant for a blind person with audio and an effective input device.
Misplacing the phone was also frustrating for some participants because of the difficulty of finding it by touch.
For example, VI9 said: "Because I am not trying to spot it visually, I have to find it tactilely, so either it always has to be in the same spot for me to find it or it is just a pain in the butt and it is like eh!
Especially if I am answering the phone or whatever."
While we focused primarily on mobile phone use in the interview, we also asked about wearable devices.
No participants owned a wearable device .
Three participants expressed no interest in wearables, while four others had thought about getting a talking pedometer or Fitbit--VI8, in particular, was interested in the Fitbit because she already uses Zombies, Run!
Only VI1 had previous extended experience with a wearable device: a custom-built paging device to allow people to direct him through loud beeps when doing open water swimming.
Overall, these findings show the essential role of mobile devices in the daily lives of people with visual impairments, but also important limitations such as sometimes negative impacts on social interactions and inefficient text input.
Participants found the wristband generally easy to use and required only brief training on how to use it.
As a targeting strategy, participants often anchored their right hand in some way  and relied on spatial memory to point to buttons.
To reorient the hand, we observed participants feeling along the far side of the wrist to find the top edge of the Select button or along the near side to find the bottom edge of the Home button.
In contrast, the embroidered guide was not often used.
Some issues also arose: three participants accidentally triggered the fabric buttons, and the Navigation touchpad was not always instantaneously responsive.
Participants were positive about adopting the wristband for future use, which confirms the survey's wearable scenario findings.
Participants rated the device on Likert scales from `1' to `5' where `1' is the most positive.
When prompted, participants provided a range of design suggestions for improving the wristband.
These included increased tactile cues, such as different textures for each button.
Another common request was to receive haptic feedback when a button is pressed, and, related, that the capacitive fabric buttons were too sensitive.
A locking mechanism would be useful for preventing accidental activation.
Finally, some participants suggested making the device smaller; VI5  commented that,
Other less frequent design suggestions included changing the button layout to horizontal, providing more functionality, and directly mapping buttons to functions for quick access.
Of course, as with the phone itself, using audio while walking can be a safety concern for people with visual impairments .
Beyond discreet use in social situations, there were no clear trends in terms of how the wristband would impact privacy.
For example, VI7 felt that it would offer the same level of privacy as using the Screen Curtain with the phone itself: "It wouldn't be like people would be able to see what you're actually doing anyways."
Physical ability to use the phone.
Four participants expressed that the wearable would make it easier to access information while on the go compared to a mobile phone.
One reason was that it requires only one hand, for example: "You could also use your cane while you were doing this because just momentarily you might do something but you wouldn't be holding something in your hand.
You could walk with a bag or something in your hand and use the other.
With a touchscreen you can't do that while you are moving."
Aesthetics was raised by many participants as an important consideration.
Two participants  mentioned the desire for the wearable to look like a mainstream device, reflecting previous studies with mobile accessibility .
For example: "I'm wondering if other people would be having the same... Would this be a mainstream product that everybody else would have too?
I don't want to be the only one using .
The reasons behind these choices included ease of access, social awkwardness/comfort, and discreet use.
VI8, for example, preferred an "unobtrusive" ring or a necklace: "That way, like, if I'm wearing a business suit or something nice or having this electronic thing with buttons hanging out... wouldn't necessarily interfere with that."
Following use of the wristband, a number of themes arose with respect to its potential impact.
Five participants felt the wearable would facilitate use in social situations, because it is discreet or because it could impact social interaction in other ways.
In addition to not needing to pull the phone out, two participants commented that the physical movements required to use the wristband were more discreet than VoiceOver gestures .
At the same time, however, three participants felt that the wearable would not impact their mobile use in social settings because it would be just as impolite to use the wearable as it is to use a phone.
In terms of broader impacts on social interaction, VI1 felt that the ease of accessing the wristband would allow him to contribute to conversations in a new way : "I mean people do that now, you're talking to them and they're looking stuff up on the internet, and if there's a question that comes up they look it up on the internet, I'm getting used to that, so I might be able to do that, which I don't do that now.
But I might be able to do that."
VI9 discussed how the wearable could impact sharing photos with her friends: "Usually if I hand over my phone to someone I am turning VoiceOver off, because my friends who are sighted don't know the gestures for the phone.
But somehow if I could still keep the gestures and have the wristband and still control the phone, going to the next one  or whatever it is, then that would be nice.
Maybe I could feel like I could control the phone and know what is happening instead of ... handing my phone over."
Participants expressed a tension between the primary safety advantages of the wristband--hard to grab and no need to pull the phone out -- and the potential for the device itself to draw unwanted attention because it is unusual .
The wristband also offers the potential to make quick calls faster than the phone, which could impact safety, for example: "If I did need to call 911, for example, the person might not know until it was too late ...  pull the phone out of my pocket and say, `Siri, call 911,' or dial it myself, which would take even longer."
Our findings highlight the important role that smartphones in particular are playing in the everyday lives of people with visual impairments, confirming and extending previous work on mobile device use .
At the same time, access on the go and socially acceptable discreet use, among other issues, remain problematic.
The wearable device scenarios appeared to address some of these issues for people with visual impairments.
In terms of current mobile phone use, participants with visual impairments were more likely than sighted participants to use optional software and hardware .
This highlights the contrasting interaction experiences of both groups, particularly the difficulty of accessible touchscreen text input.
Azenkot and Lee  also recently showed that visually impaired users are more likely to use speech input than sighted users; however, we extend and further contextualize these findings, highlighting privacy and social considerations that arose in the survey and interviews.
Since the aesthetics of the device were important for visually impaired participants , we recommend that such wearable devices be small, with an easily customizable aesthetic.
Our findings also offer design insights for camera-based wearable devices.
In the glasses scenario, visually impaired participants requested a range of output modalities: speech, haptic, braille, and non-speech audio.
This variety of preferences suggests that designing a device like Google Glass to provide effective interaction in multiple modalities will benefit not only accessibility goals but also broader use.
Since blind users do not always need the visual display of a smartphone, the typically sleek form factor of the phone can simply become a large and cumbersome input device.
That said, providing appropriate alternative input can be transformative.
Take one of our interview participants, who described her iPhone with a Bluetooth keyboard as being equivalent to her laptop--an analog that few sighted people would likely make.
We have also informally observed use of keyboards and refreshable braille displays while the phone remains stowed away.
While external keyboards used in this way can come one step closer to meeting the needs of someone with a visual impairment, even a small keyboard can sometimes be burdensome--it does not necessarily facilitate discreet use, can be misplaced, and would need to be stored when not in use.
Miniaturization of the input device  may be worth exploring.
We explicitly designed the wristband with fabric buttons to provide a slimmer aesthetic than today's primarily bulky smartwatches .
Capacitive fabric, however, does not provide mechanical feedback, which was requested by several participants.
Future wearable devices such as our wristband should explore haptic and a greater variety of tactile feedback in addition to smaller form factors.
One possibility to maintain the fabricbased approach would be to embed mechanical buttons beneath the fabric surface.
The primary limitations of this work are that the data is almost all self-report and that the projections of future wearable device impact by are just that--projections--and not necessarily indicative of what will actually occur.
As such, it will be important for future work to conduct field studies of devices like the wristband and, more broadly, to observe and study what happens over time as these technologies become more widely adopted.
Regarding the survey data, the visually impaired and sighted groups had different age and gender distributions, and we likely had a bias toward technology savvy users.
The upside of this latter bias is that the findings likely represent future technology trends.
As previous work has demonstrated that gender plays a role in wearable technology acceptance , we attempted to control for possible age and gender biases in the survey analysis.
Our regression models revealed no significant impacts of these variables on reception to the wearable scenarios; however, it will be useful to confirm these findings in future studies.
Our findings show that smartphones are playing an important role in the daily lives of people with visual impairments, although accessibility-related issues remain.
The positive response by people with visual impairments to our wearable scenarios highlights the potential impact of well-designed, accessible, wearable interaction.
As our studies show, emerging wearable technologies offer immense potential to improve daily information access and even social interactions of people with disabilities.
As the next generation of wearable interaction makes its way into the mainstream marketplace, it is thus critical to ensure that they are designed with such inclusivity in mind.
We thank Kotaro Hara, Jon Froehlich, Michael Gubbels, Matt Mauriello, and Leyla Norooz for their technical support and guidance.
We also thank the Maryland State Library for the Blind and Physically Handicapped, and the many people and organizations who emailed or tweeted about the survey.
Hanlu Ye was funded through a CRA-W DREU internship.
