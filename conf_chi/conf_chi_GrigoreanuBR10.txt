End-user programmers code is notoriously buggy.
This problem is amplified by the increasing complexity of end users programs.
To help end users catch errors early and reliably, we employ a novel approach for the design of enduser debugging tools: a focus on supporting end users e ffective debugging strategies.
This paper makes two contributions.
We first demonstrate the potential of a strategycentric approach to tool design by presenting StratCel, an add-in for Excel.
Second, we show the benefits of this design approach: participants using StratCel found twice as many bugs as participants using standard Excel, they fixed four times as many bugs, and all this in only a small fraction of the time.
Other contributions included: a boost in novices debugging performance near experienced participants improved levels, validated design guidelines, a discussion of the generalizability of this approach, and several opportunities for future research.
One recent example that received media attention came following Lehman Brothers collapse.
Barclays Capital agreed to purchase some of Lehmans assets but, due to a spreadsheet error resulting from hidden dependencies, the company purchased assets for millions of dollars more than they had intended .
A few weeks later, Barclays filed a motion in court asking for relief due to the mistake.
The impact of end-user programming errors like the example above is amplified by quickly increasing complexity of end-user programs and by the large number of end-user programmers.
The complexity of corporations spreadsheets doubles in size and formula content every three years .
In addition, there are tens of millions more end-user programmers than professional programmers .
In response to this problem, end-user software engineering research has begun to emerge in many areas.
Of particular relevance are research spreadsheet debugging tools.
The hidden structure of spreadsheets is an end-user debugging pain point  and tools such as Davis overlaid arrows , Shiozawa et al.s dependencies in 3D , and Igarashi et al.s animated dataflow visualizations  have sought to address it.
Tools which visualize broken areas  also aim to highlight the spreadsheet structure.
Some debugging tools improve the automatic detection of errors .
Others empower users to systematically test their spreadsheets .
However, a critical stone has been left unturned in the design of spreadsheet debugging tools: how tools can directly support end-user programmers existing debugging strategies .
Building upon a recent comprehensive overview of Excel users debugging strategies , this approach led to the following contributions:
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Participants expressed positive comments about StratCels usability and applicability to their personal projects.
A positive impact on end-user debugging success:  twice as many bugs found by participants using StratCel compared to Excel alone,  four times as many bugs fixed,  in a fraction of the time,  including two bugs which both the researchers and Control group had overlooked, and  a closing gap in success based on individual differences.
Design guidelines, resulting from our validated empirically-based implications for design.
Lastly, we argue for the generalizability of this approach and list several opportunities for future research.
The sample users were real participants in a previous spreadsheet study .
For example, the most successful female was in her twenties and had worked as an auditor for the past two years, building large and complex spreadsheets to check clients paperwork .
As a Business major, she also used spreadsheets in her classes and her personal life, and had programmed in VB.NET for one class.
Continuing with an iterative approach, we cycled dozens of times through design, implementation, testing, integration, maintenance, and usability evaluation.
To guide our iterations, we continued with the earlier methods and also added walkthroughs with a paper prototype, walkthroughs of the tool itself, and sandbox pilot sessions.
In this section, we address the question of whether a strategy-centric approach in the design of end-user debugging tools is practical and, if so, how it can be achieved.
We then report our experience building StratCel: an add-in for Microsoft Excel.
In the first subsection, we provide a quick overview of the iterative approach and methods we employed in StratCels design.
In the latter subsections, we then list several candidate design guidelines from a study of Excel users debu gging strategies .
We also detail how we employed these candidate guidelines in our design of StratCel to see which would prove effective: we later evaluate these.
In this section, all candidate design implications come from that earlier study, and are formatted as follows: Candidate 0: This is an example implication from .
The earlier study revealed that different levels of strategy  lead to different types of implications for design .
The upcoming subsections reflect the following three levels of implications for design:  a strategy is the users approach for the entire task.
Implications for design based on strategies are therefore high-level and may act as a check.
Stratagems are the happy medium and are therefore a great level for sparking innovation: lowlevel enough to be concrete, yet high-level enough to design a new feature.
Stratagems are in turn made up of  clusters of tactics, or low-level moves  with a purpose.
Examining moves and tactics reveals low-level implications for design: iterative improvements to the usability of existing features.
Implications for design based on the overall strategies can help us frame the functionality of the debugging tool as a whole, because strategies are followed by the user throughout the entire task.
Candidate 1: Supporting both comprehensive  and selective  debugging strategies by: - Helping comprehensive users keep track of cells they want to return to later on.
In other words, support for the to-do listing stratagem  may help reduce the cognitive load of both comprehensive and selective users by helping them keep track of items they need to look at in the future.
Table 1 summarizes empirical findings from seven studies encouraging support for to-do listing.
Note that, since both of these strategies needed to be supported, StratCel does not impose an order in which to proceed through to-do items or their related information.
Candidate 2: Provide explicit support for to-do listing.
Candidate 3: Automatically generate list of items to check.
To address these implications for design, the core functionality of StratCel involves automatically generating a list of to-do items and providing actions related to managing a task list, such as setting the items status and priority .
Each item in the list is a range of consistent formulas automatically consolidated into one item.
Using the tool, the user can change the status of each to-do item.
Item status can be:  unchecked, meaning that the user has not yet made a decision about whether that item was completed,  checked, meaning that the user has verified that item and decided s/he does not need to return to it, and  to-do, meaning that the user would like to return to that item later.
Evidence Used breakpoints, open-close files, paper  and "...checks and X's to show me what I'd already checked" .
Males and females using Forms/3 , PowerShell , and even integrated development environments want to-do listing support .
Misuse of the features can lead to incorrect feedback from tools , a loss of formatting information, or simply be ineffective.
Perhaps why no participants from  employed it in Excel.
Often used in conjunction with code inspection, a female success stratagem .
May remind comprehensive Participant SF about cells she found suspicious and selective Participant SM about cells he had skipped over .
This explicit support for to-do listing helps guard against users having to use costly workarounds to change the spreadsheets existing formatting.
While the "automatic generation" implication seems to suggest that users would have less flexibility in creating their own to-do lists, storyboards and expert walkthroughs with the prototype backed the need for this implication.
Candidate 4: Provide relevant information in the context of each to-do item.
StratCel also automatically reports information about each item to help the user identify it, including: the worksheet name, an automatically generated name , a description pulled from cell comments, the items priority, and the items spreadsheet address.
Following walkthroughs and sandbox pilots, we decided that the priority could be encoded in a color instead of having its own field in the list .
One important implication followed by other end-user debugging tools has been to directly overlay or tie hidden information about the structure of the spreadsheet to the spreadsheet itself .
Therefore, in StratCel, we synchronized cell selection and to-do item selection: selecting an item in the list also highlights the cells to which that item refers, and vice-versa.
Candidate 5: Providing information about the nine remaining stratagems in the context of each to-do item.
While strategies cover the entire task from start to finish, the debugging tool has multiple smaller components that further help make sure the task is accomplished accurately and quickly.
For example, let us say that the first to-do item is about cell A1.
Subtasks for checking off that particular item may include: examining the formula to make sure it matches the specification, testing different conditions and making sure the output is right for them, getting help when stuck, etc.
Other basic to-do list management capabilities include adding a comment,  filtering on a status, and  assigning priorities to items .
Control flow is the only stratagem that StratCel does not support.
Even though Excels language is declarative, it would still benefit from better support for implementing repetition.
How StratCel can better support this remains to be determined.
In the previous section, we addressed how to-do listing can facilitate the use of the comprehensive and selective debugging strategies.
The remaining eight stratagems are all supported in the context of each to-do item: each provides additional information about the item.
For example, selecting an item in the to-do list also selects it in the spreadsheet.
This displays a representative formula in the formula bar  and highlights its value in the spreadsheet .
Also related to formulas is the following: Candidate 6: An easy way of accessing formulas related to the current code may help users fix more bugs through reuse.
To access more information related to the content of a formula, StratCel provides a "Help on Formula" feature to search several databases for information related to it .
Figure 2 shows the search result when looking up a formula containing both the IF and HLOOKUP functions in the Excel documentation .
Another type of search that could be added to this list in the future is a search of Excel documents in a user-defined directory.
This helps the user access the collective prior experience.
Keeping track of done versus to-do items might help organize prior experience, while Excels recently used formulas feature may highlight relevant formulas.
Candidate 7: Perfect viewing spatial and dataflow relationships to help users organize collected data.
Four stratagems remain to be addressed: dataflow, error checking, spatial, and specification checking.
A directed graph shows the dataflow dependencies between task items .
The graph can also be used to navigate the items; hovering over the items in the graph selects the related item in the task list as well as the related cell in the spreadsheet.
Since consistent formulas are highlighted as the graph is navigated, this also reveals the dataflow dependencies between spatial areas of consistent formulas.
Spatial relationships can also be deduced from status borders: users can bring up borders around to-do items by clicking on a button in the ribbon.
Areas of unchecked formulas are blue.
And items marked as "checked" have a green border.
This way, inconsistent cells brought to the users attention by the feedback following support , and also from the cells that get highlighted when a task item is selected.
For example, if the formula looks like this: , then selecting Excel looks up "IF LOOKUP" in Excel's documentation.
The same thing would happen with the other search engines.
Finally, item specifications are automatically generated from comments in the spreadsheet and can also be modified by the user.
They are displayed in the white box at the bottom of the task pane  and also in tooltips when hovering over items in the list  or in the navigation graph .
Finally, implications for design based on observed tactics and moves are the lowest-level observations.
As such, they are most applicable to fine-tuning the features implemented based on the stratagem implications.
For example, we mentioned a dataflow graph for navigating the spreadsheet.
The tactic of navigating dependencies in Excel led to the following implication: Candidate 8: Include inter-worksheet relationships.
Due to this implication for design, StratCels dependency graph feature displays both inter-worksheet relationships between to-do items as well as intra-worksheet relationships.
Hovering over the nodes in the different worksheets allows the user to navigate between those worksheets.
Candidate 9: Allow users to easily identify areas of the spreadsheet on which to focus their attention .
To address this implication in StratCel, users can superimpose the to-do status of task items onto the spreadsheet.
While we originally used a shaded circle in each cell to display the to-do status of that cell, walkthroughs revealed that this was overwhelming when the status of many cells was displayed.
We therefore switched to only coloring the outside borders of spreadsheet areas with a particular status.
For example, Figure 4 depicts an area of the spreadsheet with many unchecked formulas  and two cells with to-do status .
Candidate 10: Too much feedback about where possible errors may lie is overwhelming, so only the most likely cells to contain errors should be highlighted by default.
StratCel currently automatically highlights inconsistent formulas by setting them as to-do items , since those have a high likelihood of being incorrect.
However, other Excel error checking warnings are ignored to reduce the false-positive rate of bugs found; sometimes, too much feedback is as bad as none at all.
This lends support to the feedback following stratagem .
While we originally thought the spreadsheet had ten nested bugs harvested from real users, as was reported in  and also based on our own experience, there were in fact 12 bugs in the spreadsheet .
These bugs were unintentionally introduced by the professor and by spreadsheet users from  when they attempted to add new features to this spreadsheet.
There were: six inconsistency bugs , three propagated logic errors , and three  logic bugs on individual cells .
The participants had a total of 45 minutes to find and fix these bugs.
Unlike in , where participants were provided a handout description of what areas of the spreadsheet were meant to do, we incorporated the descriptions directly into StratCels white "specification" field .
To gauge the success of employing a strategy-centric approach in the design of debugging tools, we conducted a preliminary evaluation of StratCel.
In so doing, we wondered whether a strategy-centric approach to the design of debugging tools would lead to an increase in debugging success, whether StratCel was intuitive to use, and what design guidelines we could pass on to designers.
We employed the same procedure as .
Participants first received a short  tutorial about Microsoft Excels auditing tools and StratCels functionality on a practice task.
The StratCel functionality presented included selecting to-do items from the list, viewing information related to the item, marking the item as "done", "to -do", or "unchecked", and adding user-defined to-do items.
The task was also the same as in : "Make sure the grade-book spreadsheet is correct and if you find any bugs fix them."
The grade-book spreadsheet contains 1718 cells, 288 of which were formula cells, and two worksheets: one for the students individual grades and one for summary statistics for the class.
The spreadsheet is also highly formatted, containing one blue column, one yellow column, four gray columns, 30 rows with alternating colors, three different font colors, 46 cells with bold fonts, five underlined fonts, many different font faces, and all borders delimiting spreadsheet regions.
This grade-book spreadsheet is real-world.
It was selected from the EUSES Spreadsheet Corpus of real-world spread-
In this pilot study of StratCel, we used five participants of varied backgrounds and spreadsheet experience.
One male and one female were self-described novices, one male was a self-described intermediate, and two females were selfdescribed experts.
Our participants were members of two Seattle area clubs: the females came from a knitting circle and the males from an archery club.
None of them had seen the new tool before the study.
This was the group who had the StratCel Excel add-in available to them, and we will call them the "Treatment participants".
We compared their success to the eight participants from .
There, three males and three females were selfdescribed spreadsheet experts and one male and one female described themselves as intermediates .
We will call these participants the "Control participants".
We chose to compare StratCel with Excel rather than a research environment to keep the experimental setup as "real world" as possible for external validity.
Therefore, the task was a real spreadsheet, the bugs were real end-user programmers bugs, and Excel is a real world environment with which all of our participants were familiar.
This allowed us to test StratCels main goal, namely supporting all debugging strategems from a central debugging tool.
There was no significant difference in any background variable between the Control and Treatment groups: age , major , and computer science experience .
All thirteen participants had at one point edited spreadsheet formulas for work, school, or personal reasons.
Two of the Treatment participants  did have less spreadsheet experience than was accepted in the Control group; they were self-described novices.
We brought these two participants in for two reasons.
First, we wanted to see how they would do in comparison to the experts from the other group.
Second, we wanted to see how they would do against the experts in their own group.
Control group found nine bugs, whereas all of the Treatment participants found at least nine bugs.
Qualitative observations of how participants used StratCel revealed several reasons for this sharp increase in bug finding success.
The first was Candidate 10: Too much feedback about where errors may lurk is as bad as no feedback at all.
Since StratCel set inconsistent formulas as to-do items by default, all five participants found those six bugs.
For example, to do this, the intermediate male participant immediately filtered the task list to only show items automatically set as to-do: inconsistent formulas.
Figure 1b shows his list right after filtering.
The novice Treatment male and an experienced Treatment female employed our response to Candidate 9 to find the inconsistent formulas: Easily find areas of the spreadsheet on which to focus their attention.
He brought the status borders up immediately to view the items that were automatically given to-do status .
The remaining two female participants  used a different method: they both walked through the list one item at a time, starting at the top, and only took on inconsistency items once they reached them in the to-do list.
One mentioned she was able to tell where inconsistencies laid based on the address of each to-do item being shown.
For example, if an item covered the range from "A1:A3, A5" that is what showed up in the "address column" of that to do item.
This allowed her to quickly notice A4 was missing, which therefore must have been an inconsistent formula: "This was really helpful because it has a way to say these are all your formulas...
These are the ones you need to go look at.
And I like this part  which shows me where I can find all of the formulas, so I can see them.
For example, on this one, I could see there was a gap for E16 and I could go back and look specifically at that cell, because I expect it to be the same, and see what's going on."
Since our data were not normally distributed, we employed the Wilcoxon rank-sum test with continuity correction in analyzing our quantitative data.
This is non-parametric alternative to the t-test.
We also report qualitative observations about the participants actions and verbalizations.
These analyses helped both triangulate our quantitative findings and further explain the reasons behind the statistical differences.
The Treatment participants performed better by every success measure: the number of bugs found, the number of bugs fixed, the time to each bug find and bug fix, the reduced impact of individual differences, and participants verbalized satisfaction with StratCel.
To further help designers build better end-user debugging tools, we also highlight those empirically-based guideline candidates that had the biggest impact on our participants  success by listing them as design guidelines in this subsection.
In general, participants who had StratCel available to them were better at finding bugs.
A "bug find" was an explicit statement by the participant that a  formula was incorrect.
They found more bugs, including two previously unnoticed bugs, faster, and with less variability resulting from individual differences.
Specifically, Treatment group participants found significantly more bugs  than Control group participants.
Our Treatment participants, however, found inconsistencies in the spreadsheet much more easily  and in a variety of ways.
Thus, we would like to reiterate three of the empirically-based candidate guidelines mentioned earlier but now as validated design guidelines for end-user debugging tools: Design Guideline 1: With automatic error detection tools, it is critical to value quality  over quantity .
Only cells containing likely errors should be highlighted by default.
Design Guideline 2: As most tools currently already do, important information about cells  should be overlaid onto the spreadsheet to give the user a quick overview of the to-do status of both individual cells and of the overall spreadsheet.
Design Guideline 3: Some users prefer to get a comprehensive understanding of the spreadsheet before fixing bugs , whereas others will start by trying to fix apparent bugs right away .
Since both approaches have advantages and disadvantages, both should be supported.
All participants found at least nine bugs.
Other than the six inconsistency bugs, there were four other bugs inserted by the researchers  and two more that were not noticed by either the researchers or the Control participants, but which were found and fixed by the users in this study!
These unnoticed bugs, while fairly easy to fix once spotted, were well-hidden: one individual cell was in the upper-right corner of the spreadsheet, and the second was hidden in the middle of the second worksheet.
These two previously evasive bugs were the crowning glory of the usefulness of StratCel in bug finding: some hidden bugs can evade the eyes of many experts and novices alike.
However, the to-do list enabled participants to give an equal amount of attention to each item: even items in the top-left corner of the first worksheet and cells in the middle of the second worksheet.
Design Guideline 4: Strategy-based tools should provide explicit support for to-do listing.
Design Guideline 5: To improve debugging of end-user programs, it helps to automatically generate a list of items to check so that all areas of the code are given equal attention.
What caused the striking difference in the number of bugs fixed?
A major contributor was that Treatment participants had found more bugs, therefore also having the opportunity to fix more.
Furthermore, the six inconsistency bugs were trivial fixes once the users had found them.
Had the Treatment group participants only fixed the inconsistencies, they would have already fixed three times more bugs than the Control participants on average.
The two to five additional bug fixes varied by participant, but the methods by which they were fixed always involved the additional information given in the context of an item.
For example, the intermediate male used Excels "Recently Used" function library to find a formula used in a different spreadsheet , which could have been used to fix one of the most complicated bugs in the spreadsheet.
All of the participants employed the descriptions provided for each item.
These helped them fix two bugs consistently: two bugs on individual cells that were easy to overlook without StratCel pointing them out, but straightforward to fix once there : none of the Control participants found or fixed either of those bugs, and the researchers only knew about one of the two.
Each of the features available in StratCel was used by at least one participant, backing the importance of showing related information in the context of each to-do item.
Design Guideline 6: Information about the remaining stratagems should be provided in the context of each todo item to provide more information on which to base a bug fix.
Design Guideline 7: Viewing formulas related to an item  might be particularly useful for improving debugging success.
Just as with the number of bugs found, Treatment participants also fixed significantly more bugs  than the Control group participants.
This is like a really good way of helping me keep track of what I've done and not get lost."
In terms of gender, comparing the median number of bugs found  and fixed  by females and males in the Control and Treatment groups, we noticed that there were few gender differences between them.
Even so, Treatment participants were a little closer to each other than Control participants in terms of success: meaning that StratCel helped both males and females.
Spreadsheet debugging is often a time-sensitive activity, whether a trained accountant does it  or a young clerk as was the case in the Lehman-Barclays mix-up.
Thus, another important measure of debugging success in addition to the number of bugs found and fixed is how long it took participants to find and fix those bugs.
On average, Treatment participants found and fixed each bug consistently faster than the Control participants.
The Wilcoxon rank-sum test allows us to measure statistical difference in bugs found and fixed based on order, without worrying about missing data such as those of participants who never found or fixed a bug.
The advantage of Treatment participants was clear from the very beginning of the task.
Treatment participants also found and fixed all of the remaining bugs significantly faster than Control participants .
Thus, when time is short, StratCel users should be able to more quickly pinpoint errors and their solutions from the very start and keep that advantage throughout the task.
It also appears that the more complex the spreadsheet is, the more useful StratCel will become, though this remains to be tested in future studies.
While we did not ask our participants for feedback beyond their verbalizations during the task, the participants were nevertheless anxious to give it.
Several comments revealed possible iterative improvements to the tool.
For example, participants had a feature available to add to-do items to the automatically generated list.
The most successful Treatment female used it as a way to add two comments for the next person who will look at the spreadsheet: one about how little she trusts the spreadsheet and a second about a change she would have liked to have made to one of the formulas in the future.
The most successful male also added a custom to-do item, but he did so by mistake.
Their feature request was to add the functionality of removing items from the to-do list.
Another improvement requested by the two experienced females was the capability to sort the to-do list by clicking on the field headers.
One of the potentially most critical problems with the to-do functionality is that it is too easy to check off items as done, to never be returned to again.
One of the experienced females put it this way: "The only thing that I was thinking about is that it's really easy to say 'Oh, I've looked at this.'
And I don't know if there could be a way to make sure that that's what they meant.
But I think that's just... A user has to be smart enough to know not to do that.
There's only just so much that you can help a user avoid."
One possibility for making sure that the user really meant to check something off would be to list each of the "stratagem tool components"  as individual subtasks.
This way, users would have to check off several subtasks in order to achieve an overall "check" for the item.
Further research is needed to determine the best method.
Overall, however, the participants unrequested comments were very positive, and most immediately thought of ways to apply StratCel to their own day-to-day tasks.
Here are selected few of the quotes:  "So, can I use your tool?
You should sell this and make a million dollars!"
Another surprising discovery was that the Treatment participants performed very similar to one another, despite their individual differences.
In previous studies on end-user debugging, both gender  and experience  have impacted end-user debugging success.
Also, recall that even the novices from the Treatment group performed at least as well as the most experienced and successful Control participants.
When comparing Treatment novices to Treatment experts, there was little variation between the Treatment particiants, despite their very different backgrounds: the SD was twice as great for the Control group than the Treatment group.
Treatment novices did not do much worse than Treatment intermediates and experts.
In particular, for the Control group, bugs found ranged from 1-9 and bugs fixed from 0-6.
In the Treatment group, bugs found ranged from 9-11 and bugs fixed from 811.
Since there is a much less pronounced difference between the less experienced and the more experienced participants in the Treatment group, it appears that StratCel helps everyone, and especially less experienced users.
The following quote comes from the novice Treatment female: "I feel like it would be extra useful for someone like me who, well, I can use Excel and I can figure it out, but, like, I'm definitely not an expert at Excel.
If you would like to share the tool, I would love to try it on those."
I have a pattern and I have steps I have to go through.
And I need a way to track them."
When you look at it, you know what it is.
There are lots of tools, where you can tell that people said, 'well... there's just a workaround and you can just do it this way'.
But this one, it just seemed very straightforward and it builds on everything from Excel."
Even for an environment as mature as Excel, the addition of a strategy-based tool did improve end-user programmers debugging success using many measures:  Participants who had StratCel available to them found twice as many bugs, fixed four times as many bugs, and in only a fraction of the time.
While StratCel helped everyone, it was particularly helpful to less experienced users.
StratCel also helped males and females equally.
Participants found StratCel intuitive to use and immediately thought of ways in which the tool applied to their day-to-day work.
This approach to end-user debugging tool building has raised many questions, opening the door to opportunities for future research.
The current instantiation of StratCel centers on the to-do listing stratagem, supporting the other stratagems within the context of each to-do item.
A future goal might be to create a new tool that centers around one of the other stratagems  and that supports all other nine stratagems within the context of either a formula or of an output value, in those two cases respectively.
Would the addition of another strategycentered tool improve users success even further?
Even within its current instantiation of the implications for design, each of StratCels components can be improved with further research.
For example, StratCel currently only highlights inconsistency errors, but both Excel and other tools provide many other automatically generated warnings.
An ordered list of the available automatic spreadsheet error detection algorithms and their falsepositive rates would be required to further improve the error checking component, in order to know which algorithms to turn on by default.
In general, our approach does not compete with related tools: a better testing algorithm or a better error checking algorithm can be plugged into StratCels support for that particular stratagem.
Finally, related empirical work has drawn parallels across programming populations and environments: from spreadsheets, to scripting environments, and integrated development environments .
Can StratCels core functionality be transferred to one of these other environments?
If so, will it also lead to increased debugging success there?
Do these concepts change when users are not able to manipulate the code directly and have to work at a higher level of abstraction ?
In summary, we have shown that a strategy-based approach to building debugging tools is both achievable and beneficial.
Powerful but disconnected features may be the ap-
In this paper, we have shown that a strategy-based approach alone can be effectively applied in the design of debugging and troubleshooting tools to improve the correctness of end-user programmers code.
As a part of this effort, we instantiated our approach in StratCel: a strategy-based add-in for one of the most widely used end-user programming environments, Excel.
StratCel addresses implications for design at three levels: low-level moves and tactics, mid-level stratagems, and high-level strategies.
As with any experiment, our setup had both advantages and disadvantages.
The small treatment groups gave us the opportunity to deeply examine our participants rich qualitative and quantitative data, allowing us to see how and why StratCels users were more successful.
This ultimatel y helped us promote several design candidates to design guidelines.
To address the potential sampling bias, we validated our results through triangulation and provided descriptive explanations through chains of logic .
Follow-up studies could further increase the internal  and external  validity of this work.
Our results showed that tools can be built to support a comprehensive understanding of strategies directly.
We employed implications derived from higher strategy levels  to frame the functionality of the tool as a whole, while implications based on lower levels of strategy  helped us fine-tune individual features.
For example, support for the to-do listing stratagem provided a way to reduce end-user programmers co gnitive load, by helping comprehensive participants better keep track of to-do items to revisit and by helping selective participants see which formulas they had skipped.
The remaining nine stratagems defined the core activities which needed to be supported within the context of each to-do list item 
Finally, the implications from the lower strategy levels  helped us finetune the features supporting each stratagem: for example, making sure that the dataflow dependencies showed inter-
