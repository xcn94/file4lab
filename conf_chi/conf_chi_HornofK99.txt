This research presents cognitive models of a person selecting an item from a familiar, ordered, pull-down menu.
Two different models provide a good fit with human data and thus two different possible explanations for the lowlevel cognitive processes involved in the task.
Both models assert that people make an initial eye and hand movement to an anticipated target location without waiting for the menu to appear.
The first model asserts that a person knows the exact location of the target item before the menu appears, but the model uses nonstandard Fitts' law coefficients to predict mouse pointing time.
The second model asserts that a person would only know the approximate location of the target item, and the model uses Fitts' law coefficients better supported by the literature.
This research demonstrates that people can develop considerable knowledge of locations in a visual task environment, and that more work regarding Fitts' law is needed.
People can select a target from an alphabetically or numerically ordered menu significantly faster than from a randomly ordered menu.
This has been demonstrated by Perlman  and Somberg .
A simple explanation of this phenomenon is that if a menu always contains the same items in the same places, people can learn and remember the exact location of each item.
But Somberg's and Perlman's observations only partially support this theory.
Both researchers found that, even after practice and even when menu items are selected with a keystroke instead of a mouse, people can select the top items in an ordered menu faster than lower items.
This suggests that people cannot learn the location of all menu items equally well.
Both researchers left as an open question a more detailed explanation for this phenomenon.
The research presented here attempts to fill this void by offering an empirically validated model of the low-level perceptual, cognitive, and motor processing that people use when they select a known item from a numerically ordered pull-down menu.
Menu selection is a very common human-computer interaction technique, and has been studied at length , but models of the low-level cognitive processes and strategies that people use when they select an item from a menu have only been emerging in the last few years.
To give human-computer interaction  practitioners better advice for building better menu systems, more work needs to be done to figure out how people use menus.
In a previous CHI paper , we presented empirically validated models of the low-level perceptual, cognitive, and motor processing that people use when they select a known target item from a randomly ordered pulldown menu.
In this paper, we present similarly detailed models for numerically ordered pull-down menus.
The EPIC  cognitive architecture  provides a general framework for simulating humans interacting with their environment to accomplish a task, and is well-suited to model a menu selection task.
EPIC resembles the Model Human Processor , but differs in that EPIC is a precise computational model, has a programmable production-rule cognitive processor, and incorporates more specific constraints synthesized from human performance literature.
EPIC consists of a production-rule cognitive processor and perceptual-motor peripherals.
To model human performance aspects of accomplishing a task, a cognitive strategy and perceptual-motor processing parameters must be specified.
A cognitive strategy is represented as a set of production rules, much the same way that CCT , ACT-R , and SOAR  represent procedural knowledge.
The simulation is driven by a description of the task environment that specifies aspects of the environment that would be directly observable to a human, such as what objects appear at what times, and how the environment changes in response to EPIC's motor movements.
EPIC computational models are generative in that the production rules only represent general procedural knowledge of the task, and when EPIC interacts with the task environment,
To act upon the environment, a production-rule strategy sends motor commands to the various motor processors.
These motor commands specify a movement in terms of its style, as well as other characteristics such as direction and extent.
Predefined manual movement styles allow EPIC to point with a mouse , press a mouse button , point with a mouse while holding down the mouse button , and release a mouse button .
Compound movement styles combine multiple movements into a single command.
For example, the PUNCH compound movement style executes a PRESS and RELEASE with a single command.
A PUNCH of a mouse button is more commonly referred to as "clicking" the mouse button.
A motor movement must be prepared and then executed.
Movement preparation time will be reduced if the previously executed movement had any identical features.
The standard 200 msec to prepare a POINT, for example, will be reduced to zero if the previous manual motor command was an identical POINT.
Execution time represents the time required for mechanical muscular movements in the physical world, and is thus determined in part by features such as the distance that an effector must travel.
Motor movement styles and their associated timing functions and parameters are based on what is available in the human performance literature .
Subset of EPIC architecture, showing flow of information and control.
The processors run independently and in parallel.
Not shown: Auditory and vocal motor processors, task environment.
EPIC takes as its input: * The cognitive strategy for accomplishing a task.
EPIC generates as output: * The time required to execute the task.
As shown in Figure 1, information flows from sense organs, through perceptual processors, to a cognitive processor , and finally to motor processors that control effector organs.
All processors run independently and in parallel.
The appearance of a visual object in the EPIC task environment produces multiple object-feature outputs from the visual perceptual processor.
These object-feature pairs are deposited in visual working memory using a standard delay for each feature.
For example, if the visual object "4" appears in the task environment, the location feature of this new object will arrive in visual working memory before its text feature.
Location information can also be made available to the cognitive processor by defining named locations for a particular task environment.
Named locations represent knowledge of fixed locations in visual space.
For a POINT movement, the coefficient K is set to 100, as given in .
For a POINT-PRESSING movement, the coefficient K is set to 140; this value is derived from data presented in .
This provides a cursory overview of the EPIC cognitive architecture.
A more thorough description of EPIC is presented in .
The task modeled in this paper will be presented next.
The menu selection task modeled in this paper was designed by Nilsen, who presented the task to human participants in an experiment .
Nilsen used menus of three, six, and nine menu items.
Menu items were the numerical digits from 1 to n, where n was the length of the menu.
Menu items were either randomly re-ordered for each trial or presented in numerical order.
Trials were blocked by menu length and ordering.
Menus always appeared at the exact same location on a computer screen.
As shown in Figure 2, each trial consisted of the following steps: Using a mouse, move the cursor to the GO box, which causes the precue of the target item to appear above the GO box.
Commit the precue to memory.
Click on the GO box.
As quickly as possible, click on the target item in the menu.
Two different menu styles were used: Walking and clickopen.
With walking menus, participants moved the cursor to the GO box, pressed and held down the mouse button, moved the cursor to the target while keeping the mouse button depressed, and then released the mouse button.
With click-open menus, participants moved the cursor to the GO box, clicked the mouse button, moved the cursor to the target, and then clicked the mouse button.
Within a block, all menus were of the same style.
Every serial position takes the same amount of time regardless of the menu length.
Nilsen's task with a numerically ordered menu and six items in the menu.
Eight experienced mouse users participated in the experiment, and were financially motivated to perform each trial as quickly as possible.
Nilsen presented each participant with eighteen trials for every possible combination of target position, menu length, menu ordering, and menu style .
The final fifteen asymptotic trials are reported in the data.
Nilsen's observed data for randomly and numerically ordered menus.
Mean selection times as a function of serial position of target item, for menus with three, six, or nine items.
Also: Time required to move the mouse to each target position as predicted by Fitts' law with a coefficient of 120.
These features in the data will direct the model-building endeavor that follows.
All of the models that follow will compare how well the models' predictions match Nilsen's observed data.
But the comparisons will use a more detailed view of the same data presented in Figure 3.
Since the observed data points for the different menu lengths are the same, but the menu styles produced different times, the graphs that follow will collapse the observed data and the predictions by menu length, but expand them by menu style .
Figure 3 shows Nilsen's observed data for randomly and numerically ordered menus, averaged across participants, blocks, and menu style .
Also shown is a Fitts' law movement time prediction, with a coefficient of 120 .
The important features in the numerically ordered menu data include: * Participants select an item from a numerically ordered menu substantially faster than from a randomly ordered menu.
As a result, the visual search strategies presented in the previous CHI paper  to explain the randomly ordered menu data will not also explain the numerically ordered menu data.
Evidently, extensive visual search is not needed for the numerically ordered menus.
This section presents two classes of models, the immediate look, point, and click models and the immediate look, point, check and correct models.
Preliminary modeling not discussed here for lack of space demonstrates that waiting for the menu to appear will produce excessive delays.
As a result, all of the models discussed in this paper represent the belief that people will use anticipated location knowledge to prepare and execute eye and hand movements to the target without waiting for the menu to actually appear.
EPIC that correspond to the actual menu item locations and are available before the actual menu items have appeared.
The difference between the two classes of models is that the immediate look, point, and click models assume that the location information will always be correct, so a second eye and hand movement will never be necessary.
The immediate look, point, check and correct models, on the other hand, allow for imperfect location knowledge; they check to see that the first eye and hand movement landed on the target and make a corrective eye and hand movement if necessary.
The discussion of each model includes a flowchart that summarizes the production rules written in EPIC to represent that model.
Production rules were written to maximize performance within the constraints imposed by EPIC, and to be as parsimonious as possible.
The production rules send the correct motor commands to interact with the current menu style , but for the sake of brevity, the flowcharts will summarize both sets of motor movements as just click, point, and click.
Selection times observed by Nilsen and predicted by the immediate look, point, and click strategy run with standard Fitts' coefficients of 100 and 140.
For positions 2 through 9, the model could be underpredicting for a number of reasons, including  participants could not anticipate the exact location of the target, which would imply that  this is not the strategy participants really used, or  participants took longer to point than is predicted by Fitts' law with the standard coefficients.
The next model investigates the third of these possibilities.
The immediate look, point, and click models represent a belief that people anticipate a target location before opening a menu, execute an eye movement and a mouse movement to that location immediately upon opening a menu, and then click on that location without confirming that the cursor is actually on the target.
This strategy assumes that anticipated target locations are correct.
The EPIC production rules to represent this strategy are summarized in Figure 4.
The immediate look, point, and click strategy run with nonstandard Fitts' coefficients represents the belief that participants could anticipate the exact location of a target item before the menu appears and always execute a correct eye and hand movement to the target, but that mouse points took longer than is predicted by standard Fitts' coefficients.
The results from running the immediate look, point, and click strategy with exactly known location information and with nonstandard Fitts' coefficients of 175 and 220 are shown in Figure 6.
The values of 175 for POINT and 220 for POINT-PRESSING were chosen iteratively to provide a good fit.
The implications of these increased values are discussed later.
With the increased Fitts' coefficients, this model now does a very good job of predicting selection times for positions 2 through 9.
The difference between the predicted and observed values for the two menu styles is the same, and both the predicted and the observed values follow the same negatively accelerated trend.
The overall plausibility of this model and the implications of the nonstandard Fitts' coefficients will be discussed after providing a plausible explanation for position 1.
The results from running the immediate look, point, and click strategy are shown in Figure 5.
Each predicted selection time is averaged from one trial run for every menu length and serial position combination.
For these trials, the Fitts' law coefficients in EPIC were set to the standard 100 for a POINT and 140 for a POINT-PRESSING.
The results in Figure 5 demonstrate that the model is wrong.
The predicted values are negatively accelerated, as are the observed data, and the difference between the two menu styles is predicted to be the same as the observed data.
But the predictions for most positions are much too fast,
Instead, in this model, a twitch is assumed to occur with the first click when the target is "1".
EPIC's predictions when running the immediate look, point, and click strategy with special case for position 1 and nonstandard Fitts' coefficients are shown in Figure 8.
An explanation as to how participants selected targets in position 1 so quickly requires a detailed analysis of the task.
Recall that upon clicking on the GO box, the cursor is automatically positioned exactly one pixel above the first menu item.
When the participant knows the target item will be in position 1, all that he or she must do is click on the GO box, make a tiny downward movement with the mouse, confirm that the target has actually appeared, and click again.
Additional production rules were added to the immediate look, point, and click strategy to create a special case for position 1 branch, rules that will only be executed if the precue is a "1".
A flowchart summarizing the production rules appears in Figure 7.
In the special case production rules, there is no separate POINT movement, but rather the click on the GO box is assumed to produce as a side effect a tiny downward twitch that is prepared in advance along with the click.
Selection times observed by Nilsen and predicted by the immediate look, point, and click strategy with special case for position 1 run with nonstandard Fitts' coefficients of 175 and 220.
Though this model explains the data well and offers a reasonable explanation for how people accomplish the task, there are two aspects of this model that make it questionable.
First, it is hard to accept Fitts' coefficients so much higher than the standard values.
Second, the model asserts people know exactly where to look and point before the menu even appears.
The first problem, of the increased Fitts' coefficients, actually points to a shortcoming in the HCI literature.
Though Fitts' law is often cited as a useful tool for prediction and design in HCI , the exact form and coefficients of Fitts' law are not settled.
Several studies in fact provide evidence for a Welford Fitts' coefficient of about 175 for a mouse point .
In addition, the Fitts' equation appears in several forms , which makes some coefficients incomparable.
Thus, it may or may not be reasonable to use such large Fitts' coefficients.
Much more work needs to be done to determine the correct Fitts' coefficients for various tasks and environments.
It should be pointed out that re-running the randomly ordered menu models presented in  with the increased Fitts' coefficients of 175 and 220 does not seriously reduce the good fit of the randomly ordered menu models since, as argued in , the pointing time effects are very minor compared to the effects due to visual search.
The second problem is that all of the immediate look, point, and click models assume that a person has exact location knowledge for all menu items before the menu even appears.
This assertion seems to contradict Perlman's  and Somberg's  findings that, even with numerically and alphabetically ordered menus and a constant time to select an item once it is found, the top menu items can be selected faster than lower menu items.
Perlman's and Somberg's findings suggest that some items do take longer to locate even in a known, ordered menu.
So, the immediate look, point, and click models provide a good fit and a reasonable explanation for how people select an item from an ordered menu.
But the models discussed next provide an equally good fit and perhaps an even more plausible explanation.
Running the immediate look, point, check and correct strategy in EPIC with exactly known location information reveals the baseline prediction of the strategy, before adding any error to the initial eye and hand movement location.
The results from running this model are shown in Figure 10.
Each predicted selection time is averaged from one trial run for every menu length and serial position combination.
The immediate look, point, check and correct models represent a belief that people anticipate a target location before opening a menu, execute an eye movement and a mouse movement to that location immediately upon opening a menu, check to see if the cursor actually landed on the target, make a corrective eye movement and mouse movement if necessary, and then click on the target.
These models allow us to explore the possibility that people cannot predict the exact location of the target before it appears, but only an approximate location.
The flowchart in Figure 9 summarizes the production rules written in EPIC to explore the plausibility of this strategy.
Note that the strategy carries forward the special case for position 1 discussed in the previous section.
Selection times observed by Nilsen and predicted by the immediate look, point, check and correct strategy run with exact location knowledge.
As can be seen in Figure 10, the model does not account for the data.
But the results are informative nonetheless.
The model's predictions for the first three serial positions are very close to the observed, and with roughly the same negatively accelerated slope as the data.
The model underpredicts for serial positions 4 and above, which might be remedied by adding some error to the model that would sometimes make necessary a second, corrective eye and hand movement.
The immediate look, point, check and correct model run with approximately known location information represents the belief that people can anticipate the position of a target in a menu before the menu actually appears, but that people can anticipate the location of items higher in the menu more accurately than items lower in the menu.
Approximately known locations are introduced to the model by perturbing the vertical coordinate of the named location for the target item at the start of a trial.
To represent the relation between the accuracy of location knowledge and distance, these initially anticipated target locations vary from trial to trial, and are normally distributed around , the true distance from the GO box to the correct target location, with a standard deviation  that is defined as =e* where e is a constant error coefficient.
Thus, the further away the target, the less likely that the first eye movement and mouse point will land within the target region.
The immediate look, point, check and correct strategy.
For simplicity, the model asserts that a third eye and mouse movement will never be necessary.
For the small amount of error introduced in these models, the first movement will rarely fall more than one menu item away from the target, in which case the correct location information will be readily available for the second eye and hand movement.
A value of e = 0.04 provides a very good fit with the data presented in Abrams et al.
Seeing as how in Nilsen's task there are multiple target locations from trial to trial and the target is not visible at the start of the trial, a higher error coefficient e seems plausible for predicting the error in the initial eye and mouse movement locations when modeling Nilsen's data.
The results from running the immediate look, point, check and correct strategy with an initial location error coefficient e = 0.1 are shown in Figure 11.
The value of 0.1 was chosen iteratively to provide a similar slope as that of the data.
Three hundred trial runs were executed for every unique combination of menu length, serial position, and menu style.
The predictions in Figure 11 average those results.
To see if such a style would help the model, a modification to the existing POINT movement is introduced in these models.
A more complete representation would be to introduce a new movement style to the EPIC motor processor, but these modifications are tentative.
The specific modifications are as follows:  The existing POINT movement style is modified to allow a POINT to begin during the release of a mouse button rather than waiting for its completion.
The results from running the immediate look, point, check and correct strategy with an initial location error coefficient e = 0.1 and a click-and-point compound movement style are shown in Figure 12.
The predictions in Figure 12 average the results from three hundred trial runs executed for every unique combination of menu length, serial position, and menu style.
Selection times observed by Nilsen and predicted by the immediate look, point, check and correct strategy run with approximate location knowledge .
As can be seen in Figure 11, the model comes very close to explaining the observed data.
The predicted values have almost exactly the same negatively accelerated slope as the observed data, and are very close to the observed data, but the model's predictions are a little too slow for how quickly people accomplished this task.
Perhaps the overall high speed of the observed data is due to extensive overlapping of the motor processing involved.
For example, perhaps people can prepare and execute a compound click-and-point movement, a movement style not currently implemented in EPIC.
This tentative new compound movement style is introduced in the next model.
Selection times observed by Nilsen and predicted by the immediate look, point, check and correct strategy run with approximate location knowledge  and with a click-and-point compound movement style.
As can be seen in Figure 12, this model predicts the observed data very well, with an average absolute error of 3.92%.
This model demonstrates that two problems with the immediate look, point, and click models - increasing the Fitts' coefficients and asserting perfect location knowledge - can be overcome by a more subtle analysis of the task and a more detailed representation of the perceptualmotor activity required to accomplish the task.
The models also suggest that people can anticipate the position of items that appear higher in an ordered pulldown menu more accurately than items lower in the menu.
The models presented here also demonstrate that more work needs to be done in the study of human performance to predict simple pointing time with a mouse.
A more systematic effort is needed to catalog Fitts' coefficients for specific pointing tasks and mouse environments.
And to be truly valuable, aimed movement studies need to report observations in at least as much detail as can be found in Walker et al.
Perhaps an altogether new model is needed for predicting aimed movement times, such as Meyer's Law , which relates movement time to width, distance, and the number of submovements required.
Hillsdale, NJ: Lawrence Erlbaum Associates.
A comparison of four input devices for the Macintosh interface.
Proceedings of the Human Factors Society 34th Annual Meeting, Santa Monica, CA: Human Factors Society, 267-271.
Cognitive modeling reveals menu search is both random and systematic.
Proceedings of ACM CHI 97: Conference on Human Factors in Computing Systems, New York: ACM, 107-114.
An overview of the EPIC architecture for cognition and performance with application to human-computer interaction.
Extending Fitts' law to two-dimensional tasks.
Successfully modeling Nilsen's data for both numerically and randomly ordered menus provides evidence that a more general visual search task can similarly be modeled.
Future work includes collecting data for a more two-dimensional visual search task, such as icon search, and then carrying forward the strategies developed in the menu selection tasks in an effort to explain the low level cognitive processes involved in more general search tasks.
Many thanks to Erik Nilsen for providing additional details on his experiment and generously sharing a copy of the menu software used in his experiment.
This work was supported by the Advanced Research Projects Agency under order number B328, monitored by NCCOSC under contract number N66001-94-C-6036 awarded to David Kieras.
Ann Arbor, Michigan: The Cognitive Science and Machine Intelligence Laboratory, The University of Michigan.
Also: Ph.D. dissertation in Psychology, The University of Michigan, 1991.
Making the right choices with menus.
A comparison of rule-based and positionally constant arrangements of computer menu items.
Spatial and temporal characteristics of rapid cursorpositioning movements with electromechanical mice in human-computer interaction.
Speed and accuracy of saccadic eye movements: Characteristics of impulse variability in the oculomotor system.
