This paper examinesthe use of the systemto communicate complex diagramsand gives someexamplesof user output.
Performance is not as good as expectedand it is postulated that context will play an important part in the perceptionof diagramscommunicatedusing music.
A set of experiments are reported which indicate that context does indeed seem to play an important role in assisting meaningful understanding of the diagrams communicated.
The implications for using music in auditory interfacedesignare discussed.
Screen Readers are based on a speech representation of the content of the screen.
Becauseof the intensely serial nature of speech,graphic-intensivescreens canbe difficult to describeusing this medium.
We have been interestedin exploring the use of auditory interfacesfor some time, both for visually impaired users and for those with normal visual abilities.
Indeed, we are particularly interested in creating what we have termed "equal opportunity interfaces"- that is, interfaceswhich do not make prior judgments about the media capabilities of the user population but offer a variety of communication media,from which the usercan selectan appropriatemix to match their capabilities and limitations.
Such interfaces would not only be capableof adaptationto matchuserswith significant hearing or visual difficulties, they would also allow trade-offsto be made betweenvision and audio for commonapplications.The work in this paper explores an extremumof this spectrum in contrast to most interface work which is located at the other extremum .
In comparison with visual media, which have been extensively explored, non-speech use of the auditory medium has been largely ignored.
The use of audio in humancomputerinterfaceswasfirst reportedby Bly.
Gaver hasproposedthe idea of Auditory Icons  and usedthem in the SonicFinder to assistvisually impaired userswith editing.
Such auditory icons are short bursts of familiar sounds.Edwardshas developedthe Soundtracksystem to assistblind usersin editing.
Blattner an co-workers has proposedthe use of musical phrasescalled Earcons  short musical melodies which shared a common structure suchas rhythm.
However,apart from suggestingthe idea of sharing a common rhythm, no other musical techniques were suggested.
Blattner has also used someproperties of musical structuresto communicatethe flow in a turbulent liquid.
During the last few years, some researchworkers have attempted to use music in interfaces.
Graphical user interfaces  have now become the dominant techniqueusedfor interaction betweenusersand computer applications.
Such interfacesare said to offer a user-friendly approach with a high utility.
One important reasonwhy it is thought that they have been successfulis their use of Direct Manipulation techniques,a term first coined by Shneiderman to describe the emphasison continuousrepresentation of objects,physical actionsrather than complex syntax, and rapid incremental reversible actions with instant feedback.There is no doubt that such interfaceshave had a beneficial effect to users in general, but they represent a serious step backwardsfor blind or visually impairedusers.
Recently some progress has been made in assisting program debugging using music, for example, the work of Bock  , and Vickers andAlty  There are very few recorded experiments which systematicallyevaluatethe use of music in humancomputer interaction.
Mynatt has investigated the 1133 mapping of visual icons into auditory Earcons.
She commentson the importanceof metaphorical qualities of everyday soundsand how thesecan be usedin designing good Earcons.
This paper reports continuation of our previously published work on exploring the usefulness of auditory media  in interface design.
Someof our work has concentratedon the audiolisation of algorithms   , and program debugging .
The work reported here is a continuation of our investigation into the use of music to communicatediagrams to blind users  1151.This work has already shown that the highly structured nature of music can be used successfully to convey graphical information iu dia-m to visually challenged users.
The only other related work of which we are aware is the AUDIOGIUF system of Kennel .
This system use touch to concentrateupon particular areasof the diagram.
Output is by speechor a set of individual notes.
Figure 1 The AUDIOGRAPH System description of the system will be given here.
The AUDIOGIUPH systemhas both a visual interface and a completely auditory interface for blind users.All musical output is produced by MIDI output from Visual Basic, communicated to a stereosound systemusing a Creative Labs Soundblaster 16-bit card.
The actual sounds are created using a Roland MT32 Multi-timbre output device.
All output information and input feedback are communicated using music alone.
The main objective behind the set of experimentsreported in this paper is to seeif music alone can be usedto transfer meaningful information to users on the computerinterface.
We decided to use an extreme case- to determineif blind users could, by the use of music alone, appreciate the spatial layout of objects in a graphical area using musical feedbackalone.
Becauseof this emphasison music, and the fact that there has been little previous work on the use and evaluation of musical representations, music alone wasused both to communicateall information aboutthe interface and for all input control commands.
We appreciatethat in a real interface, such as a commercial computer application, it would be sensible to use speech in addition to music , but we felt that the inclusion of other auditory modes of interaction would risk confusion in the interpretation of the experimentalresults.
Figure 2 `Rec&uition of Co-ordinate from a Musical Sequence average musical ability.
No special musical ability or training was expected for any of the experiments performed.
A musical questionnaire was given to all participants, prior to experimentation, to check their musical experienceandknowledge.
The interface  is shown in figure 1.
There are two major areas - the grid on which diagrams are drawn and perceived, and the control area,
Input interaction with the systemis exclusively via the arrow keys on the keyboard .Theseare usedfor moving the cursor round the graphics area  and to select control actions.
Other keys  are usedto confirm actions.The spacebar is used to toggle between the graphics area and the control area.
The main control actions include shape selection , shape expansion and contraction, dragging, and file loading and saving.
There are also a selection of scanning controls which communicate the currentcontentsof the graphicalareain different ways.
Graphicalshapes were describedmusically by tracing out the shapein soundusing this metaphor.
Examplesare given in Figure 3.
Even before training most usersrecognizedthe Circle and the two lines.
The overall position of graphical objects using various scanningtechniques All theseuseda similar metaphorfor implementation- a coordinate point is described by using a musical mapping from distanceto pitch , and X and Y co-ordinatesare distinguished by timbre .
For interest we reproduce the results for pitch interval recognition in figure 2.
Subjectswere played the sequence of notes from the samelower note  to the note representingthe co-ordinate value, and askedto determine that value.
For example,EXPAND usedthe following sequence: t t I I 9 I 1 1 I t I I I I I ,mJr* I Irl Idm and CONTRACT was representedby the inverse of this pattern.
Users found these completely intuitive and no training was required.
The UNDO command was representedby the playing of a tune with a "fault" in it followed by the "correct" tune.
At first hearing userswere baffled by this, but on hearing the explanation they understood it immediately and had no further trouble recognizing it.
This is an example of the importance of context which will be examinedshortly.
File nameswere represented assimple tunes.
Three different scanning techniques were provided to enable users to obtain an overall appreciation of the graphical spaceand to enable them to build up a mental model of the space.
Another three subjects using a differen stimuhrsand the samethreescans grid on it.
This in itself causeddrawing problems as when the pencil crossed over a grid, the drawing necessarily became more uneven, and errors in the diagram are a combination of perception errors and drawing errors.
It is impossible to devise a scoring mechanismfor the output, but the success achieved by subjects can be appreciatedby examining some actual output.
These are shown in Figures 5 and 6 for one subject from each group.
It can be seenthat subjectshave obtaineda broad picture of the diagrams, the first subject performing qualitatively rather better than the other.
Whilst the diagrams generally have captured correct number of objects in the space and the distributions are broadly in agreement, the perception of size is disappointing.
For example, in figure 5, Ascending Scan, the subject has realized that one circle is bigger than the other but both have been drawn incorrectly.
Our previous experimentsin perception and size led us to expect better performance.
The difference between our earlier experiments on individual objects and the experimentson arbitrary sets is the complexity of the latter stimuli.
Figure 7 Meaningful Stimuli and Hints organisingprinciple to assistthem in coping with the more complex diagrams.
In reality, users rarely have to comprehend meaningless sets of shapes, and their perception is guided by their expectation of what is presented.
We therefore decided to carry out a set of experiments with meaningful sets of objects to see if context had a significant effect on comprehension.
In most cases, for either group, subjectswere able to identify the individual components even if they did not get the overall meaning.It is possiblethat the "Car" wasthe mostrepresentative object in the vehicle set and might well have been guessed,in contrastto `8" and "3" which are not special items of their sets.
Five blind subjects werepresented with four diagramsas shownin figure 8 below.
Figure 8 The four dia,oram variants presented these.The first group  listened to four different diagramsand were not given any guidanceas to the nature of the diagrams.
The second group  listenedto the samediagramsand were given a hint or semanticguidanceas to their nature.Thus, they might be told that the diagramwas "a type of vehicle", "a number", "a letter of the alphabet",or "a methodof data representation".
The diagramswerepresented aurally using AUDIOGRAPH in a different order to each subject in each group.
All subjectsused the Centre-Scanning techniqueto explore the graphicalspace.
In those groups given no semantic guidance, no subjects assigned any meaning to the first hvo diagrams.
Two subjects interpretedthe third fi,me as a "three" and three subjects  interpreted the fourth figure as the letter "E'.
Table 2 Performance of Subjects with SemanticGuidance The results indicate that the communicated graphical information using the musicalmappingof the graphicalarea is interpreted by subjects as a random combination of objectsin the absence of a perceptualcontext.
However, in the presenceof an expectation, the graphical information communicatedis interpreted as a meaningful shape.This implies that the perceptual context has a direct and contributing role in the interpretation of the music used to communicate the graphical objects.
This level allows users to assign meaning to musical messages without further training or instruction.
The very act of mental activity at this level also is likely to increase memorability of the interface.
Theseideascan be illustrated with examplestaken from the AUDIOGRAPH.
The DetectableMusical Mapping is used to identify the important characteristics of the domain which MUST be distinguishable.
In the case of the AUDIOGRAPH system, the listener certainly needs to distinguish the following 1. the size of a coordinate 2. an X coordinatefrom a Y coordinate 3. the different graphical shapes 4. the different control actions There may be other domain events which need to be communicated dependingupon user task, but the above list is certainly the minimum required for basic understanding.
The size of a coordinate is mapped into pitch in the Chromatic Scale .
Additionally, the notes are grouped into 10s and the longer the sequence,the higher the coordinate value.
Thus we provide three basic handles for determininga coordinatevalue.
The X and Y coordinatesare distinguished by Timbre  and in Time .
Additionally, we provide a distinctive drum note to prepare the listener for the start of the coordinate sequence.
The shapesare derived from geometrical traces of the objects which are shown by experiment to be distinguishable.
Control Actions are short distinct Ear-cons The required domain differences under these mapping are detectable.We have already shown in  that users with averagemusical ability can distinguish betweeninstruments in the different classes of the orchestra and map pitch to numeric difference.
The Perceptual Context is created by use of a common mapping for coordinates, shapes, and cursor movement.
The audio versionsof the shapesare directly related to their geometriccounterpart,in a similar mannerto the coordinate description of the space.Thus they are not only detectable, but also can be understoodin termsof the metaphorrelating pitch to length.
The control action Earcons, likewise, are underpinned using a metaphoric interpretation.
The EXPAND Earcon is detectable but also does "expand' numerically and is the opposite to CONTRACT.
UNDO can be heard to correct a tune and is not just a unique Earcon.
Furthermore, the absence of a meaningful context will often result in a lack of a meanin,oful interpretation even though the individual elementsare perceived.This finding, which hasparallels in the use of other perceptual channels  has important implications for auditory interfacedesign.
The use of music in an auditory interface to communicate graphical shapeshas shown promising results.
Users were able to identify shapesand their approximate size, use the tool to move them around the area, and adjust their size.
They were able to use the musical controls to expand and contract shapes, file and retrieve them and drag them Although an actual tool would have used speechoutput in certain operationsin preferenceto music, the insistenceof a full music interface has tested the idea quite thoroughly.
We believe, for example,that much more use of musical abstraction could be used to reducethe length of messages.
However, it is in the experiments on the role of context where we see someinteresting lessonsbeing drawn.
Firstly, there is much more to auditory interface designthan simply producing unique and identifiable mappings.
This is a necessary,but not sufficient, condition for a successful design.
The target here is to produce a recognizable and distinguishable musical message,to the listener which can be understoodin the presenceof other musical structuresin the application.
This level provides a detectable mapping.
There are clearly many possible detectablemappingsfor any problem domain.
At this level, given a detectablemapping, the CONT... designermust create the perceptual context or expectation in the listener because interpretation of the music will dependon the expectation of the listener.
At this level, the individual structures are interpreted by the listener in domain terms .
Listeners can now assign meaning to individual messages but cannotnecessarilyreasonabout the global interaction.
Our results also lead us to suggestthe existenceof a third level THE REASONINGAND SEMANTICLEVEL.
Finally we have observedusers employing the third level once they become familiar with the auditory mappings.
When one begins to communicatediagramswhich have an underlying structure, users are rapidly able to exploit this.
For example, if users knows that the graphical sceneis a row of houses,and they find windows in the first house, they immediatelyassume that windows are likely to exist in the others.
This aspectis not explicitly presentedin the detectablemappingnor in the perceptualsupportlevel.
Later shewas able to represent more abstractactions utilizing the metaphoricalqualities of everyday sounds.
She then began using soundsfor which she did not want the user to identify the original sourceof the sound.In this respect,this is moving closer to our work in music, wherethe sourceof the sound is not related to the use of the sound in the representationschemefor the domain.
She then critically examinesclaims about users preferring musical to natural sounds in interface design and points out that this is not becausethe music somehowsounded"better" but because the musical soundshad beencarefully constructedto reflect metaphorically what they were representing .
For example, her musical sequencefor representingtermination of a phone call endedabruptly and soundedas if the phone was being replacedon the hook.
Other musical mappings  used in a number of recent studies have relied to some extent on perceptualsupport.
For exampleBrewster and Crease report the use of auditory Earcons in an experiment investigating user errors when employing menus.
Relationships in the menus are reflected in the auditory design .
However other mappings were not so perceptually obvious.
Also rhythm was used to signal selection and slips.
Although such eventswill be readily detectable,they are not related perceptually to the actions being described.
Perhaps a glissando might have been better to describe a slip, for example.We are not suggestingthat Brewster and Crease would necessarily have obtained improved results using these mappings, but are simply using the example to illustrate how the perceptuallevel might be applied.
We have been impressedwith the capabilities offered by music in interface design particularly for those who are blind or who are visually impaired.
At the detection level we need to know more about the capabilities of human beings with an average musical capability.
There certainly is a basic musical capability in mostpeople .
We needto know better how to exploit it, by finding out what people can and cannot perceive musically.
Secondly,we needto explore how to support this basic detectability with perceptual support.
It is possible that we could learn much here from thosewho write jingles for commercialtelevision or composersof film music.
We also needto know more about possible cultural differences in the waysin which humanbeingsinterpret music.
We openedthis paper with a plea for the developmentof "equal opportunity " interfaces, interfaces in which users could decidefor themselves, the distribution of information presentedbetweenthe visual and audio channels and this paper has investigated the audio extremum.
A full understandingof this idea will require an appreciation not only of the perceptual support which can be offered in visual andauralinterfacesbut also how the two interact.
