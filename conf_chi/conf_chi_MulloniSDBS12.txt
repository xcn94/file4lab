Alessandro Mulloni1, Hartmut Seichter1, Andreas Dunser2, Patrick Baudisch3, Dieter Schmalstieg1 1 3 Graz University of Technology 2 HITLab NZ, Univ.
We investigate 360 panoramas as overviews to support users in the task of locating objects in the surrounding environment.
Panoramas are typically visualized as rectangular photographs, but this does not provide clear cues for physical directions in the environment.
In this paper, we conduct a series of studies with three different shapes: Frontal, TopDown and Bird's Eye; the last two shapes are chosen because they provide a clearer representation of the spatial mapping between panorama and environment.
Our results show that good readability of the panorama is most important and that a clear representation of the spatial mapping plays a secondary role.
This paper is the first to provide understanding on how users exploit 360 panoramic overviews to locate objects in the surrounding environment and how different design factors can affect user performance.
Further, since it is a first-person overview, users do not need to switch to other representations such as maps.
Panoramas can be rendered in any geometrical shape, but rectangles are typically used, similar to any other photograph.
If we use the term readability qualitatively, as the ease of reading panorama elements, rectangles offer good readability of the panorama but do not clearly represent the fact that the environment surrounds the user: i.e., leftmost and rightmost points in the rectangle depict a part of the environment that is located behind the user.
This paper is the first to investigate 360 panoramic overviews for users co-located with the panorama, rather than remote.
In our scenario, users try to understand where points on the panorama are physically located in the environment.
The spatial mapping between panorama and environment must be therefore clear.
In this paper we consider - in addition to Frontal - two shapes that provide a clearer representation of the spatial mapping: Top-Down and Bird's Eye .
We conduct a sequence of user studies, asking participants to use panoramic overviews for locating points in the environment.
Our results highlight that good readability of the panorama is the most important factor when a panorama is available, while a clear representation of the spatial mapping is advantageous when no panorama is available.
We contribute to understanding how 360 panoramic overviews support users locating objects in their surroundings and how different design factors affect user performance.
In this paper, we target users of location-based services  who are looking for objects within their visibility range.
A typical scenario might require highlighting a building entrance.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Zheng  presents route panoramas, a technique to join a sequence of images of a path into a single panoramic image.
These works focus on the exploration of remote environments and do not aim at communicating the spatial mapping between visualization and environment.
First-person imagery can be advantageous in location-based services.
Chittaro and Burigat  show that photos allow faster navigational decisions at road intersections, as compared to a map.
Similarly, Google Maps for mobile3 supports navigation with Street View images.
Users successfully identify buildings in the environment from the panoramas, even if there is an offset between the users' location and the position in which the panorama was captured.
In these works the panorama only provides a limited field of view, while our goal is to provide omnidirectional overview.
They dynamically enlarge the field of view to fit the whole panorama, to help users capturing a gapless panorama.
In a previous paper , we present a similar approach for augmented reality.
We propose zooming between live video and an online-captured 360 panorama, showing that the overview is beneficial for complex tasks of spatial search in augmented reality.
Similarly to this paper, both works provide omnidirectional overview for magic lenses.
However, they visualize the panorama as a rectangle and give no clear indication of whether users understand the spatial mapping between panorama and environment from the rectangle.
We conducted a pilot study to gain first understanding on how users exploit panoramic overviews to locate points in the environment.
We tested four conditions, defined by the variables Shape  and Image .
We recruited 4 participants from our university.
We showed them a sequence of panoramas, marked one point with a green crosshair, and asked them to point to the corresponding location in the environment.
All participants used all conditions.
We counterbalanced the order of conditions with a balanced Latin square and randomized the crosshair position.
To isolate and accurately measure comparative performance with the visualizations, we chose a controlled lab setup.
Participants pointed with a wand and then clicked a button on the wand .
We used a wand to acquire accurate motion and timing data via an infrared tracker5.
Afterwards, we interviewed participants and asked them to describe the strategy they used, for each shape.
From the interviews, we isolated two types of strategy: using grid and wind rose to determine body-aligned directions , and visual matching of objects in the panorama with corresponding objects in the environment.
We decided to conduct three experiments to isolate the effects of the two strategies: the first study with no panorama , the following two studies with a panorama .
During the three experiments, we collected questionnaire data on expertise with panoramas , maps and games .
Expertise was balanced within the participants.
The choice of a shape for a panoramic overview is guided by two design factors: good readability of the panorama, and clear representation of the spatial mapping between panorama and environment.
For our experiments, we considered three shapes .
We also add further cues to each shape, visualizing an avatar, a wind rose and a grid.
A rectangular shape provides good readability of the panorama, but no clear mapping to the environment.
A cylindrical shape maps panorama and environment in a direct way, but sacrifices readability.
Due to the 3D view, the panorama is warped and occluded on the sides .
A circular shape provides good readability of the panorama and direct mapping of the yaw.
However, since the pitch is mapped to the distance from the center of the circle, the panorama is distorted for high pitch, and upside-down in the area of the panorama, which is behind the user.
In the first study, we evaluate how different shapes impact on the performance of the pointing task, assuming that no panorama is available .
Shape: Frontal, Top-Down, Bird's Eye.
We expected a difference in time: Top-Down < Frontal and Bird's Eye < Frontal, because Top-Down and Bird's Eye, in contrast to Frontal, provide a direct representation of the mapping between panorama and environment.
The crosshair was assigned a random yaw angle within one of the intervals, and a constant pitch angle of 0.
Participants performed 5 repetitions of 3  x 12  trials, for a total of 180 measurements.
We used balanced Latin squares to counterbalance the order of shape and angle intervals.
First, we introduced participants to the three experimental conditions.
We clearly indicated to all participants the front, left, right and back lines in the visualization.
Participants were allowed 6 practice trials for each shape.
We instructed all participants to be as fast and accurate as possible but to give higher importance to accuracy.
Finally, we conducted a short interview asking participants to describe the strategy they used to complete the task with each shape.
We used the same setup as in the pilot study.
All participants used their dominant hand.
For each of the 180 repetitions, we recorded task completion time  and unsigned error in yaw  between the target and the selection.
For each shape x angle condition and participant, we calculated median time and error of the 5 repetitions.
A Friedman test did not show any effect of shape on error.
In the following, we analyze time measurements under the assumption of comparable accuracy.
Since the data violates normality and sphericity , we conducted a nonparametric Friedman test, which revealed a significant effect of shape on time  = 16.67, p < .001.
Post-hoc Wilcoxon Signed Ranks tests with Bonferroni correction showed that all pair-wise differences are significant: Top-Down was significantly faster than Bird's Eye  and Frontal , and Bird's Eye was significantly faster than Frontal .
Bird's Eye was on average 3.5% slower than Top-Down; Frontal was on average 16.3% slower than Top-
In Figure 3 , we can see that Frontal was generally slower than Top-Down and Bird's Eye, besides for target locations around 0.
A Friedman test shows no effect of repetition on time, highlighting no significant learning effect.
In the interviews, participants reported orientating to bodyaligned directions  using grid and wind rose, and then refining the pointing direction.
Participants reported imagining themselves "in the middle of the visualization" for Top-Down and Bird's Eye.
For Frontal, more "thinking" with respect to body-alignment was required.
Our results support our initial hypothesis, and highlight a further significant difference between TopDown and Bird's Eye.
In general, we see that, if no panorama is available, users rely on body-aligned reference lines to orient themselves and refine the orientation of annotations between these lines.
Shapes which correctly represent the spatial mapping of the panorama to the environment result in significantly shorter task completion times.
In the second study we evaluate how user strategies and performance change when a panorama is available.
We used the same setup and design as in study 1.
However, in this study we used a panorama of the room in which the study took place .
The panorama was up-to-date with the room's appearance during the study.
The panorama covers 360 in yaw, and  in pitch .
We expected a difference in time: Top-Down < Bird's Eye and Frontal < Bird's Eye, because we expected good readability to be advantageous for completing the task and more advantageous than the strategy used in study 1.
None of the participants had taken part in the previous study.
In this experiment, we calculated error as the greatcircle distance  in degrees between the target and the selection.
A Friedman test showed no significant effect of shape on error.
Post-hoc Wilcoxon Signed Ranks tests with Bonferroni correction showed that Bird's Eye was significantly slower than Top-Down  and Frontal .
Bird's Eye was on average 21.9% slower than Top-Down, and 19.8% slower than Frontal.
Friedman tests showed an effect of repetition on time, for all shapes .
However, Wilcoxon Signed Ranks tests only highlighted a significant learning effect between the first repetition and the others.
This is not a problem for our analysis, since we perform it using the median values of the five repetitions.
In the interviews, participants reported looking for objects in the panorama and corresponding objects in the room .
For this strategy, most participants reported that Bird's Eye is inconvenient, as the sides are either not visible or warped and hard to see.
One participant also reported issues with the backside of Bird's Eye, where the panorama appears mirrored.
Figure 3  illustrates this: we can see that Bird's Eye was slower than Top-Down and Frontal mostly around +/- 90, in the warped or occluded regions.
The results show that users adopt a strategy predominantly based on visual matching when a panorama is available, independently of the shape.
As hypothesized, TopDown and Frontal were significantly faster than Bird's Eye.
Bird's Eye was on average 16.1% slower than Top-Down, and 17.1% slower than Frontal.
A Friedman test showed no effect of repetition on time.
In the interviews, reported strategies and issues with Bird's Eye were in line with study 2.
Figure 3  illustrates that Bird's Eye was again slower than Top-Down and Frontal mostly in the warped areas.
Participants reported that Frontal was the easiest to find the pitch of points, whereas finding the yaw was considered harder.
With Top-Down, participants had issues with the outermost third of the visualization , due to the strong distortion effect.
The results of this study replicate the results of the previous study for the case of varying pitch angle.
Our results show that, in the presence of a panorama, users mainly perform visual matching of objects in the panorama with correspondences in the environment.
Consequently, good readability of the panorama has primary importance in the design of a panoramic overview.
As a secondary strategy - and the main one when no panorama is available - users look for body-aligned directions within the visualization.
A panoramic overview designed to represent the mapping between panorama and environment provides therefore a fallback, whenever a panorama is not available.
We are looking forward to apply this work to locationbased services in outdoor scenarios.
Here the environment is mutable and visual matching is not always feasible.
In those scenarios, we will investigate how user strategies intertwine.
Our results inform us on how design choices will affect support for visual matching and communicating body-aligned directions.
In the third study, we aimed at corroborating the results from study 2 in the case of varying pitch angle.
Same as in study 2.
In this study, the crosshair was assigned random pitch within .
Same as in study 2: we expected a significant difference in task completion time: Top-Down < Bird's Eye and Frontal < Bird's Eye.
This is because we expected visual matching to work also for non-zero pitch angles.
None of the participants had taken part in the previous studies.
Post-hoc tests showed a significant difference between Frontal and Bird's Eye.
