Content on computer screens is often inaccessible to users because it is hidden, e.g., occluded by other windows, outside the viewport, or overlooked.
In search tasks, the efficient retrieval of sought content is important.
Current software, however, only provides limited support to visualize hidden occurrences and rarely supports search synchronization crossing application boundaries.
To remedy this situation, we introduce two novel visualization methods to guide users to hidden content.
Our first method generates awareness for occluded or out-ofviewport content using see-through visualization.
For content that is either outside the screen's viewport or for data sources not opened at all, our second method shows off-screen indicators and an on-demand smart preview.
To reduce the chances of overlooking content, we use visual links, i.e., visible edges, to connect the visible content or the visible representations of the hidden content.
We show the validity of our methods in a user study, which demonstrates that our technique enables a faster localization of hidden content compared to traditional search functionality and thereby assists users in information retrieval tasks.
Second, it is common that many  occluding application windows are open, potentially covering relevant information.
A third cause of content being hidden are minimized windows.
To manage limited screen-space, users regularly minimize windows, which may contain important information.
Finally, relevant information may be contained in unopened or not accessed documents.
Common strategies to identify relevant information include searching and brushing.
Users can search for specific keywords and explore the context of individual occurrences.
While zooming and scrolling can be used to manually search through content, most applications also provide a built-in search function that highlights occurrences of a search term.
Often, users can advance the viewport of the application to the next matching term.
Brushing is similar to searching, but instead of an explicit query, the query is implicitly given by selecting an existing item.
Further occurrences of the selected item may be highlighted and/or linked.
Brushing is common in visualization tools and text-editors.
By going through all open application windows and searching or brushing in each application in turn, users are able to eventually access all relevant information.
As search functions are also available for searching through online documents and files stored on disk, all types of initially hidden content could possibly be explored.
For certain tasks this kind of workflow is sensible.
It is, for example, sufficient for looking up words in a dictionary, where each term has one entry.
There are, however, other tasks where seeing a global structure between individual pieces of information is highly relevant.
Consider a user investigating the causes of a crisis in a company.
The investigator needs to tie together information from multiple sources.
These may involve dozens of reports with hundreds of pages each, multiple spreadsheets documenting money flow, web exposes of other companies involved, travel routes of employees, etc.
If the investigator finds an interesting fact, she will typically want to cross-reference other occurrences of the fact.
For many documents this is inefficient using the sequential search approach.
In this paper, we introduce techniques that instead let users see an overview of all occurrences, no matter in which document they are contained or if they are visible or hidden, and jump directly to the most interesting occurrence.
When analyzing multiple data sources and documents simultaneously, not all information can be kept in plain sight.
There are several causes for information being hidden from a user.
First, many documents contain more content than can sensibly be displayed at a time, making it necessary to show only a small fraction of the information contained.
Copyrights for third-party components of this work must be honored.
For all other uses, contact the Owner/Author.
Copyright is held by the owner/author.
Directly accessing all content, both visible and hidden, poses a number of challenges.
To address these challenges, we elicited six requirements that a technique for visualizing hidden content needs to address.
This list evolved out of an initial set of requirements which we based on our experience with designing visualization interfaces for application domains such as systems biology and our own needs when working on search tasks.
We then created multiple prototypes, which we informally evaluated with users, leading us to the following final set of requirements: R I: Mental map.
Users should be aided in building a mental map of the explored documents.
Ideally, this overview should make use of the investigator's spatial memory by pointing out occurrences at their actual position on the desktop , or at least preserve relative arrangement of occurrences .
For such a mapping, it is necessary to communicate the information's location or at least the direction in which information can be found.
R II: Indicate occurrences & relevance.
Sources or sections mentioning a search term multiple times tend to be more relevant compared to documents or parts that only contain a few mentions of a term.
Thus, users may want to prioritize densely populated documents or sections in their search.
To support this requirement, visual cues should indicate the amount of information available at a specific location or in a certain direction.
To enable users to quickly judge whether looking at a specific region in a document in detail could be interesting, getting fast previews of hidden content should be possible.
Fast navigation between all available chunks of information is essential for an efficient exploration.
Once a user has chosen to closely investigate a piece of hidden information, it should be possible to quickly navigate there with minimal interaction.
The integration of information from different sources is essential to capture all types of hidden content.
The technique should connect information from open application windows, minimized windows, and documents which are only present as a file on a disk or available on the Internet.
All sources should be handled in a unified manner to allow for all types of hidden content.
The technique must be able to accommodate arbitrary changes to the content presented on the desktop.
In particular, the arrangement of windows on the desktop can change at any time: Windows can be moved, resized, minimized, or closed.
Moreover, the content and viewport of windows may change at any time, possibly removing existing information, adding new information, or changing location and visibility of information.
In addition to content being hidden, visible content can also be overlooked .
While traditional highlighting techniques such as color work reasonably well on a uniform background, a cluttered environment, e.g., due to many windows, or other factors such as large display sizes can increase the chances of relevant content being overlooked .
Our contribution are two novel visualization techniques for hidden content and their combination with visual links into one sophisticated information exploration system that integrates multiple applications and data sources.
First, we present smart links, a see-through visualization to extend visual links to occluded content.
Second, for out-of-screen content, we present a combination of visual links and smart previews, aiding the user in quickly estimating the amount of relevant information and allowing accelerated navigation to the information.
Additionally, we show how minimized windows and information from files on disk can be integrated into the visualization.
Using these two techniques, we provide guidance to all aforementioned types of hidden content.
We conducted an exploratory user study evaluating the performance of our hidden content visualization methods relative to standard search functionality.
The results of this study indicate that visualization of hidden content is superior to traditional methods in both quantitative and qualitative measures.
As mentioned previously, the two main reasons for available content not being considered is that it is hidden, i.e., not visible to the user, or that it is overlooked even though it is technically visible .
We first discuss techniques to show and access hidden content, followed by techniques that help avoid overlooking content.
For hidden content, we distinguish between techniques that reveal occluded or out-of-viewport content that could be shown within the given display space and techniques that visualize off-screen content.
A common strategy to reveal occluded content are seethrough interfaces that cull away the foreground to reveal the background.
A prominent example are magic lenses , which in their general form can not only remove foreground but also alter the representation in arbitrary ways.
Magic lenses are typically invoked manually and locally , a characteristic that is not suitable for search tasks.
While completely transparent windows  and user interface elements  have been evaluated in the past, in practice they are rarely used when reading and interacting with content in window managers.
An approach that uses transparency for `unimportant' window regions is described by Ishak and Feiner , while Baudisch and Gutwin introduce 'multiblending' , as a smarter alternative to alpha blending that considers multiple image features and makes the blending results more readable.
A more sophisticated approach is taken by Waldner et al.
They use a measure of salience to reveal salient occluded content in regions where the occluding elements are not salient.
None of these approaches use a semantic measure of relevance, i.e., consider what is currently relevant to a user.
Search tasks, however, inherently require revealing specific semantic elements.
Figure 1: Visualization of occluded, out-of-viewport, and off-screen content.
Multiple browser windows and files stored on the computer contain occurrences of the search term "France".
Most occurrences are either outside one of the browser's viewports, which is indicated by arrows and links to the out-of-viewport locations, or are occluded by another window, which is indicated by semi-transparent red window labels.
The arrows pointing to applications in the taskbar indicate off-screen content in a minimized window  containing 12 occurrences of the search term and 16 files found by the desktop search engine.
Hovering over an arrow, reveals a smart preview showing the regions of the documents containing occurrences.
A common strategy to visualize off-screen content are marks rendered within the visible area that point to off-screen content.
Baudisch and Rosenholz introduce halos , circles with the center at the  point of interest and a radius chosen so that a segment of the circle intersects with the display.
Similar in spirit are wedges , a technique that uses triangle instead of circles.
Users can infer the location of the point from the size and position of the circle or triangle segment.
A problem of halos and, to a lesser extend of wedges, is scalability and clutter if many targets should be indicated.
To remedy this, Waldner et al.
Highly abstracted document previews are another technique to visualize off-screen content.
Eick and Ball use such abstract representations for visualizing software .
Hearst combines them with a visualization of the search term density in specific regions of text .
This technique has been extended by Dieberger and Russel  to consider multiple search terms and enable fast navigation and preview.
The occurrences of search terms can also be superimposed on the scroll bar , a technique that is nowadays, for example, employed in web browsers and in software development tools.
However, all of these tools and techniques use very abstract representations.
We believe that using a representation that preserves the appearance of the document under inspection will provide additional benefit to users.
In our work we combine both, marks to indicate the presence of off-screen context and on-demand smart previews to minimize clutter and enable efficient discovery of and navigation to off-screen content.
Such methods are also used for generally `interesting' content .
A different approach is to employ connectedness , i.e., visual links , as a method to highlight occurrences of a search term, which are beneficial especially in a cluttered environment such as in an information visualization system  or on large screens where not all content is in a user's field of view .
We believe that visual links are the most powerful method to point to content distributed over the screen, especially in a highly heterogeneous environment spanning multiple windows and various types of documents, and consequently have chosen to combine them with methods to visualize hidden content in this paper.
For visualizing hidden content we take two steps: indicating that relevant content is hidden in the first place, and revealing the hidden content on demand.
We introduce novel techniques to visualize occluded content, i.e., content that is occluded by other windows, out-of-viewport content, i.e., content that is outside of the application window but within the limits of the display, and off-screen content, i.e., content that is outside of the available display space or that is in closed, minimized,
Figure 2:  Smart links pointing to out-of-viewport occurrences of a search term.
All of these techniques are integrated with visual links to create a strong visual connection between all related pieces of information--hidden as well as visible--resulting in an information exploration interface that makes hidden content easily accessible and reduces the risk of overlooking content .
Relevant content is often hidden due to the limited viewport size.
Large portions of content can be situated in virtual space outside of a window's viewport.
We distinguish two cases of out-of-viewport content:  The target region is outside the current viewport, but would be visible on the screen if the application's viewport was extended, and  the target region is outside the screen.
We consider the latter case as off-screen content, which is treated in a later section.
For the former case we use smart links: semi-transparent outlines--one for each target region--that indicate the location of invisible target regions  and are connected to other visible or hidden occurrences with visual links.
Smart links clearly indicate the occurrence and relevance of hidden content  and support a user's mental map .
If the user hovers over a target region outside the application's viewport, as shown in Figure 2, all of the application's content that fits on the desktop is rendered in order to provide context to the otherwise `disembodied' target region, thus providing fast previews of the hidden content .
When the user selects such a target region, the application's viewport is automatically centered around the region, allowing the user to immediately continue working with the application at the chosen position, thus facilitating fast navigation .
If a target region is located either outside the screen, within a minimized windows, or in unopened files, it is not possible to draw a link to a specific target region.
Instead, we visualize off-screen content by drawing an arrow pointing into the direction of the target, or at the icons representing the minimized windows and unopened files.
To avoid clutter in cases where multiple target regions are off-screen, we only draw a single arrow for each icon or window edge.
For the latter case we adjust the arrow to point towards the center of gravity of all outside regions.
Additionally, we draw a text label next to the arrow to show the number of hidden target regions in the given direction .
These encodings indicate occurrences and relevance .
To get an overview of the whole document  and to enable fast navigation , we provide a smart preview of the complete document, which appears when hovering over the arrow.
For search tasks, it is reasonable to assume that users are only interested in those parts of the document that contain relevant information.
We use this consideration to present the user with a more compact preview where regions containing no relevant information are clipped, freeing up space for increasing the size of interesting areas .
In this way, all hidden regions of the document are presented at once.
To decide which areas should be removed, we first calculate bounding boxes of all highlighted regions, then loop through all bounding boxes and mark regions with a certain margin above and below as important and finally hide all unmarked and therefore unimportant regions .
These smart previews can be zoomed and panned to explore all target regions in detail .
To facilitate orientation , the current viewport of the application is highlighted using a rectangle in the preview.
To direct the user's attention to windows containing occluded content, we use markers, connected to visual links, as shown in Figure 3 that contain the title of the windows where relevant content was found.
We chose this approach over showing direct links to occluded content , since user-feedback indicated that direct links produce too much clutter.
When hovering over such a marker, we overlay the hidden window semi-transparently and highlight and connect the relevant content , as shown in Figure 3.
To avoid interference with the background window, the overlay can optionally be shown completely opaque.
The necessary scaling makes it hard to recognize information.
Overlapping bounding boxes are merged.
Figure 5: Links to unopened documents.
The number shown inside the icon indicates the number of documents containing the current search term.
When using the smart preview for minimized windows, we draw an arrow next to the application's icon in the task bar to indicate that it contains target regions.
Upon hovering over the arrow, the smart preview is revealed .
When the user selects a target region, the minimized window is restored and the viewport is centered on the selected target.
Information may also only be available in unopened documents.
To integrate unopened documents, we query a desktop search engine to find occurrences of search terms.
Similar to our approach for minimized applications, we draw an arrow next to the desktop search engine's icon in the task bar and show the number of documents found within the icon, as shown in Figure 5.
When opening the search engine, we highlight the search term in the search engine's previews and provide smart previews to reveal the details, as shown in Figure 5.
After the server has received a user-triggered search string, it forwards the request to every connected client application, enabling each application to add its regions.
Upon receiving a request, each client searches its content for instances of the requested identifier and reports back the bounding boxes of all found occurrences.
For simple selection types, like individual words, bounding boxes already provide an accurate approximation of the relevant region.
To highlight and link more complex shapes, such as objects in a map or graph, a client is free to use arbitrary polygons for representing its regions.
Visual links are drawn between all highlighted regions.
The naive approach that connects all highlighted regions to a common center results in a cluttered visualization.
To remedy this, we bundle links using force-directed edge bundling , an algorithm based on an iteratively refined system of control points, attracting each other.
The system is initialized by calculating the center of gravity of all occurrences.
Then, the highlight region closest to the center of gravity is determined, and all other regions are connected to it.
Moving the center of gravity avoids an artificial branching point.
Next, all links are subdivided into segments of approximately equal length and finally, force-directed edge bundling is applied.
Due to potentially large differences in the length of individual links, the forces affecting a single link can change rapidly, leading to sharp corners in the link routes.
To address this issue, we apply a geometric smoothing on the points forming the link routes after executing the bundling algorithm.
All rendering output is directed to an off-screen buffer first.
This buffer is twice the size of the screen and copied into the fullscreen window.
Using hardware accelerated texture filtering, the visualization is automatically smoothed while being downscaled.
The use of alpha-transparency allows blending with the desktop content.
To fully integrate heterogeneous data sources , we implemented a central service written in C++, which runs in the background as a standalone application and accepts connects from other applications taking part in the visualization.
These other applications are integrated using a minimally invasive approach through the use of a plug-in API or minor modifications of the application source code, if no API is provided .
The data exchange between the server and the clients is handled using WebSockets.
To add the described user interface components on top of the existing screen content, we create a transparent Qt window which we render using OpenGL.
In this way, the user can interact with all content that is not covered by our visualization.
For rendering see-through visualizations and smart previews, the client application is required to send an image of its content to the server.
We use a hierarchical tile map, where each level consists of a single or multiple tiles, which add up to a full preview image of the client application's content at a specific zoom level.
Using different resolution images for the individual zoom levels, we create tiles in a resolution that is sufficient for a single level of zoom.
As the user zooms into the preview or moves the viewport, missing tiles are asynchronously requested from the corresponding client application.
While working in a desktop environment, the arrangement of opened windows can change at any time .
As this possibly affects the position and occlusion of regions, we need to react to such changes.
Current operating systems usually do not allow receiving notifications for changes in windows of other applications.
As a workaround, we use a window monitoring component, which periodically requests a list of all opened windows, including their geometry and stacking order, and compares this information with the previous state.
If any changes are detected, the server triggers the recreation of the visualization for all active identifiers.
As a proof of concept, we have integrated several widely used applications into our system.
A browser add-on allows searching for words or phrases matching a given search identifier.
The bounding boxes of all found occurrences, both within and out of the current viewport, are sent back to the server for further processing.
As a non-textual example, we have used the Google Maps JavaScript API1 to create a mash-up which supports the search for geographic locations by name and the retrieval of corresponding screen coordinates on the map.
Retrieving the name of a location on a map and querying by this name is also supported.
For connecting minimized windows and the desktop search engine, the location of the associated icons needs to be known.
Therefore, we query the list of windows in the task bar and calculate the exact location of each icon using the known icon sizes.
To retrieve the data for the smart preview for unopened files, they are opened in the background in their respective applications while visual feedback is suppressed.
For a basic integration with our system  applications need to implement a simple WebSockets protocol, which all modern browsers support.
For a full integration, applications need to provide imagery of hidden areas for the preview, which is typically supported in either the GUI library or the graphics API.
Our implementation is open source and can be downloaded at http://hidden-content.caleydo.org.
Due to the use of cross-platform libraries, our implementation runs on Linux, Microsoft Windows, and Apple OS X.
Our technique can be used interactively on all operating systems and is usually able to update all visualizations within half a second.
Due to the delay of an application notifying our system of viewport changes like scrolling and window resize operation a short delay until the graphics elements update is unavoidable.
During our study no user raised any concerns regarding the performance of our implementation.
We conducted an exploratory user study to evaluate our hidden content visualization technique for three desktop scenarios of varying difficulty.
The scenarios involved up to twelve web browser windows.
To gather meaningful feedback, a major part of the study focused on an informal post test interview about the used hidden content visualization techniques.
We recruited 18 participants from a local university  with a background in computer graphics and visualization.
10 participants indicated that they have experience with visual data analysis.
As baseline condition we used the standard searching and highlighting technique of the web browser , synchronized across all browser windows, to isolate the effect of our visualization.
Participants could mark  words in the web browser and press a keyboard shortcut  to search the document for the marked word.
The found terms use the default colored box to highlight all occurrences.
Pressing the Enter button repeatedly advanced to the next occurrence of the word within the same application.
As an alternative method, participants could also type the search term into a text field.
To search for the same term in a different application window, participants only had to switch the window and continue with the inspection of the highlighted occurrences.
A new search term replaced the previous one.
Switching windows was possible through standard operating system features.
We tested the baseline condition against our fully functional, real-time hidden content visualization implementation, as described before.
The ability to interact with all types of links was provided, which either brought covered windows to the front or scrolled the regions outside the viewport into sight.
The procedure to trigger a search was identical to the one used in the baseline condition.
Participants were asked to perform three information analysis tasks, with thirteen desktop windows opened concurrently.
The desktop was presented to the participants on a 22" monitor with 1920 x 1080 pixels.
Participants were seated approximately at the same distance from the monitor.
No restrictions where enforced during the test, i.e., users were allowed to move or to rearrange windows.
All tasks dealt with properties of aircrafts and airports.
To generate two setups with equivalent complexity, we have altered two original data sets taken from Wikipedia to include the exact same number of hidden and visible regions for different properties.
The default window setup is shown in Figure 6.
Out of the six documents describing an aircraft, three contained the requested number of engines.
For the remaining aircrafts, participants where asked which of them have two more features installed, resulting first in two and finally one matching aircraft.
Twelve additional windows were randomly distributed across the whole screen, each approximately one third the size of the screen.
The synchronized highlighting and guidance functionality was provided among all thirteen windows.
Due to the large number of windows, participants were confronted with numerous overlapping windows and covered regions.
Also, the shown documents were about six to ten times larger than the viewports they were displayed in.
We consciously avoided tabbed browsing, i.e., nested window management, in the study, since it would have made the design more complex and we were primarily interested in testing the performance of our techniques with larger numbers of  overlapping windows.
We designed the following tasks with increasing complexity: Task 1 was designed as a simple information retrieval task testing the effectiveness of finding information.
Participants had to find a single keyword in a subset of the open windows.
They were additionally asked to take information from the context area of the search results into account.
Participants should tell whether each of the six aircrafts described within the documents is controlled using a yoke or a side-stick.
For two aircrafts the information was unavailable and no answer was required.
Task 2 was designed as a more complex search task testing the efficiency of locating documents containing relevant information.
Participants were asked to tell the experimenter which of two given keywords were contained within every of the twelve browser windows.
The windows contained none, one, or both keywords.
Task 3 was designed as a research task testing the effectiveness of finding information.
It required long content interaction, using three search terms, scanning through entire paragraphs, and reasoning.
Participants were asked to find all aircrafts equipped with a certain number of engines.
The number of engines was indicated by a specific phrase.
The study was conducted as a within-subjects experiment over the described two conditions and the three tasks for each condition.
For each task, we measured task completion time and correctness.
To start a trial, participants clicked on a button located in the master window on screen.
The same window included check boxes for answering the questions and completing the trial.
We automatically measured the time between the initiation and competition of a trial.
Prior to each task, participants were given a warm-up period, which allowed them to become familiar with the technique and the content of the application windows.
After each condition, participants were required to assess their subjective satisfaction with the technique on a questionnaire containing six questions.
After the hidden content visualization condition, we presented them with an additional questionnaire, comparing the individual approaches we employ for the different kinds of hidden content.
Upon completion of the experiment, the participants were asked to take part in an unstructured interview.
Participants completed all three tasks twice, once with each technique.
To avoid learning effects due to knowledge of the data, all tasks where available with two different sets of keywords or features.
To reduce the influence of learning effects due to the repetition of tasks, the order of the conditions and the assignment of the task sets was counterbalanced.
The goal of the user study was to compare the effectiveness and efficiency of our hidden content visualization techniques and traditional search for finding hidden content.
We formulated the following three hypotheses for this experiment:  Using the hidden content visualization leads to a faster retrieval of hidden data.
Our techniques visualize all hidden regions that are placed within the boundaries of the screen and offers a preview for regions which are outside the screen.
By interacting with these links, every hidden region can be accessed with one or two clicks.
Thus, we expect our hidden content visualization to be faster than a sequential search through all hidden regions.
Because we visualize every occurrence of a search term, we expect users to miss fewer occurrences than by stepping through all windows and occurrences within windows sequentially.
Our hidden content visualization either shows the exact location of hidden regions or points towards the direction where they can be found.
All participants quickly developed successful strategies using our hidden content visualization.
Once a new search process is initiated, the viewport of each application is moved to contain the first occurrence of the search term.
This allowed the fastest participants accessing the required information directly in the see-through visualization or smart preview without moving the viewport to the highlighted regions.
This strategy could even be completed with the lowest zoom-level.
Most participants, however, zoomed in one level, which eased the reading of the preview.
For regions outside the viewport, participants developed different strategies.
If both regions outside the viewport and outside the screen appeared at the same time, participants most often used the smart preview only, because it also includes regions outside the viewport.
About half of the participants clicked on the regions to scroll them into sight; the other half hovered over the region and read the information directly from the superimposed see-through preview.
Many participants stated that they did not recognize regions outside the viewport very often and they would prefer the system treating these regions like regions outside the screen.
Some participants thought that this visualization is only useful with a maximum of two or three windows.
If multiple windows containing scrolled-away content had large overlapping areas, some participants had problems to recognize which window each visualization belongs to.
In the interview, they mentioned it would be useful to use different colors for different windows or have the covered window marker also for partially covered windows.
In the hidden content visualization condition, no participant used the window manager to switch between open windows.
Most of them mentioned that the hidden content visualizations enables them to locate target windows and regions faster than before.
Two participants stated that they would like to have the indicators for found information inside the task-bar or window list, as they think a one-dimensional search within a linear list is faster than a two-dimensional search for highlights on the whole screen.
With a small amount of interesting content, participants sometimes were slower at marking a search term, initiating a new visualization process, opening the smart preview and zoom/scroll to the location than simply scrolling there.
Some participants also mentioned that they think the hidden content visualization is not useful for simple search tasks involving little content, but gets increasingly useful with complex tasks involving multiple windows.
Participants said that they would especially like to see the visualization feature to support tabs within applications and connect spreadsheet applications as well as code editors and documentations.
We measured the time participants needed to complete each task, the correctness of the reported numbers, and subjective assessments, which were given on a seven-point Likert scale.
As no category tested entirely positive for being normal distributed, all measures were evaluated using non-parametric tests.
Wilcoxon signed rank tests  were used for completion time, error rate, and the subjective task evaluation.
The results comparing the individual approaches used by our hidden content visualization were analyzed using Kruskal-Wallis tests .
Timing results are illustrated in Figure 7, and questionnaire results are provided in Figure 8 and 9.
We found no significant difference in completion time between the techniques for Task 3 .
The average number of errors was very low for all tasks and techniques .
There was no measurable difference to be found for error.
We found a significant difference for the questionnaire items subjective search speed 
Future work will aim to reduce the visual clutter that may arise when a large number of regions are selected.
We envision a combination of more sophisticated bundling algorithms, context-preserving routing , and smart fading of the links over time to further improve the situation.
Moreover, to improve temporal consistency and reduce lag, we plan to extend our system to track changes of relevant objects over time and incorporate temporal coherence into the layout planning.
This would also allow us to avoid radical layout changes resulting from small changes  in the underlying scene.
Finally, we want to pick up comments from study participants and plan to integrate our hidden content visualization techniques with an integrated development environment such as Eclipse, where search tasks and visiting all references and modifications of specific variables are crucial tasks in developing and debugging software.
Figure 9: Mean questionnaire results for the different approaches combined our hidden content visualization given on a seven point Likert-scale.
No significant difference was found in the data.
Also enhancing the smart preview by showing only headings of the previewed document and expand or navigate to the sections content on demand would increase the acceptance as an everyday tool.
One participant tried to use scrolling within a see-through preview and stated in the interview the scrolling would be a useful extension to the preview.
Based on the significantly lower task time achieved with our hidden content visualization for Task 1 and 2 and the higher subjective search and navigation speed, we conclude that H1 is supported, and our hidden content visualization leads to a faster retrieval of hidden content.
The results also indicate that the usefulness of our technique increases with the number of windows containing no relevant content.
For Task 2 only half of the windows contained relevant content, which caused participants using standard search to check twice as many windows as required.
Task 3 required far less navigation to different windows and, additionally, involved a reduced number of windows during each step.
The largest part of the task required retrieving and combining information from the content.
We believe that the major time-consuming activity for Task 3 was understanding and interpreting content instead of navigation and that this resulted in no significantly faster results for our hidden content visualization.
Due to the low error rate, we can neither accept nor reject H2.
Based on the participant feedback that our visualization helps not to miss elements, it might be possible to confirm this hypothesis in a more extensive study.
Because all participants stated that our visualization helped them to get a better location awareness inside documents, we conclude that H3 is also supported.
The overall positive user feedback, in particular for the smart preview and the see-through visualization of the smart links , indicates that visualizing hidden content is a useful tool especially for complex information retrieval tasks possibly with a high amount of unrelated content.
Baudisch, P., and Gutwin, C. Multiblending: displaying overlapping windows simultaneously without the drawbacks of alpha blending.
Baudisch, P., and Rosenholtz, R. Halo: a technique for visualizing off-screen objects.
Collapse-to-zoom: Viewing web pages on small screen devices by interactively removing irrelevant content.
Bezerianos, A., Dragicevic, P., and Balakrishnan, R. Mnemonic rendering: an image-based approach for exposing hidden changes in dynamic displays.
Bier, E. A., Stone, M. C., Pier, K., Buxton, W., and DeRose, T. D. Toolglass and magic lenses: the see-through interface.
In this paper we presented techniques for visualizing search terms in areas of documents that are covered by other windows, outside the window's current viewport, outside the screen, contained in a minimized window, or in unopened files.
Byrd, D. A scrollbar-based visualization for document navigation.
Collins, C., and Carpendale, S. VisLink: revealing relationships amongst visualizations.
Dieberger, A., and Russell, D. Exploratory navigation in large multimedia documents using context lenses.
Eick, S., Steffen, J., and Sumner, E.E., J. Seesoft-a tool for visualizing line oriented software statistics.
Gustafson, S., Baudisch, P., Gutwin, C., and Irani, P. Wedge: Clutter-free visualization of off-screen locations.
Harrison, B. L., Ishii, H., Vicente, K. J., and Buxton, W. A. S. Transparent layered user interfaces: An evaluation of a display design to enhance focused and divided attention.
An experimental evaluation of transparent user interface tools and information content.
Hearst, M. A. TileBars: visualization of term distribution information in full text information access.
Hoffmann, R., Baudisch, P., and Weld, D. S. Evaluating visual cues for window switching on large screens.
Holten, D., and van Wijk, J. Force-directed edge bundling for graph visualization.
Hornbaek, K., and Frokjaer, E. Reading of electronic documents: The usability of linear, fisheye, and Overview+Detail interfaces.
