Despite the demonstrated benefits of multi-finger input, todays gesture vocabularies offer a limited number of postures and gestures.
Previous research designed several posture sets, but does not address the limited human capacity of retaining them.
We present a multi-finger chord vocabulary, introduce a novel hand-centric approach to detect the identity of fingers on off-the-shelf hand-held tablets, and report on the detection accuracy.
A between-subjects experiment comparing 'random' to a `categorized' chord-command mapping found that users retained categorized mappings more accurately over one week than random ones.
In response to the logical posture-language structure, people adapted to logical memorization strategies, such as `exclusion', `order', and `category', to minimize the amount of information to retain.
We conclude that structured chord-command mappings support learning, short-, and long-term retention of chordcommand mappings.
Through hand postures and gestures, multi-touch promises more flexible input than traditional WIMP interfaces .
Yet, today's commercial tablet interfaces provide a limited set of input gestures.
Gestural interface design for multi-touch interfaces is still emerging; we face similar challenges and goals today as designers did for keyboard-and-mouse interfaces in the 80s:  increase input expressivity, e.g.
This paper addresses both points in the context of multi-touch enabled hand-held tablets;  we extend input expressivity by proposing an approach to distinguish among a set of hand postures; and  investigate posture-command mappings, addressing the limited capacity of human memory.
By taking advantage of the rich dexterity of our hands, we can obtain large sets of postures and gestures .
Gesture designers of such multi-touch technology need to work on very limited information about the user's hand posture: e.g., capacitive touch technology provides the number and position of touch, but not the finger's identity.
Existing solutions have resorted to clumsy external hardware such as gloves or cameras , or additional time-consuming registration gestures .
We propose a method for recognizing a set of what we call multi-finger chords on off-the-shelf hand-held tablets.
We use this term to describe a positioning of particular fingers on a screen relative to the hand.
Similar to playing piano-chords, some fingers touch the surface, some are lifted up.
Fingers are not spread or flexed; instead they remain extended in a relaxed position.
This position is based on the shape of the hand and, thus, easily detectable and reproducible.
We present a novel approach to distinguishing among multi-finger chords using hand-shape characteristics to derive a hand model.
An effective posture language, however, must also face the limited human capacity of retaining a large number of chordcommand mappings.
People move back and forth between mobile device, tablet, and desktop interfaces: input gestures should be easy to remember even when not constantly performed or practiced.
Some previous studies proposed natural gesture sets .
Tablet computers are typically deployed to browse content rather than to perform complex data manipulation.
Still, touch-enabled tablet interfaces have been replacing many uses of the traditional keyboard and mouse.
To avoid complexity, application designers reduce the number of menu items when porting applications from PC to tablet environment.
For example Adobe Photoshop's1 menu is reduced from 648 menu commands on a PC to 35 commands on a tablet.
Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Since natural gesturecommand mappings use prior knowledge, it can improve the memorization of such mappings.
However, abstract gesture or posture sets and abstract domain-specific commands do not have such desirable properties: how should we design chordcommand mappings in such cases?
George Miller  contributed a famous insight to the understanding of information processing in human memory: organizing and grouping items into `chunks' can increase the capacity of human memory.
We investigate the effect of grouped chord-command mappings on memorization: similar input multi-finger chords map to similar commands.
We demonstrate that structured chord-command mappings support recall even if a given gesture had not been performed for a long period of time.
Compared to the diversity of investigations studying ways of augmenting mere touch input and proposing gesture sets , there is relatively little literature on the choice of mapping between gestures and commands.
Challenges in gesture interfaces comprise  discoverability and  memorability.
Discoverability had been addressed, e.g., by feedforward systems such as OctoPocus  or Arp ege , that guide the user with visual clues to perform gestures or postures.
Memorization is addressed in the context of `natural' gestures.
They found that participants preferred user-authored gestures over those created by HCI experts .
Natural gestures take advantage of pre-established associations which support memorization, and even more so when those associations are personally assigned by the user .
However, in the absence of such cultural references, linguistic associations, or metaphorical links, how should abstract posture sets be integrated into the interface so that they become easy to use?
We need to account for the lack of `natural' associations of postures.
Previous work showed that the method of organizing menu structures has an effect on visual search performance .
Indeed, we are used to virtual information being structured: we group tools in palettes, categorize menu items by meta-attributes, and save documents in tree-structures.
Similarly Buxton  presents examples of grouping input gestures in human-computer dialogs into meaningful units following two aspects:  gestures have a kinaesthetic connection that match the logical structure of two tokens and  the choice of the follow-up gesture is limited to a single choice reducing cognitive load.
Users are forced to follow a proper syntax, e.g.
Yet, we lack sufficient guidance for applying it to the design of posture sets.
In psychology, organization is assumed to be a necessary condition for memory .
Most gesture work in HCI investigated short-term retention of gestures .
However, we agree with previous discussions  that gesture sets should also be studied with respect to long-term recall in order to truly understand gesture memorability.
In the following sections, we introduce a novel multi-finger chord vocabulary for off-the-shelf tablets.
Postures of our vocabulary can be categorized into three families of postures due to similarities among input movements.
We then explore the effect of categorized chord-command mappings on long-term memorization: does it improve long-term retention if the structure of performed input movements matches the virtual menu structure?
Knowing which user is interacting where on the surface offers a powerful means to design personalized interfaces and incorporate social protocols in interface dialogs.
Some tabletop interfaces make use of built-in table cameras  or additional hardware, e.g.
However, to increase expressiveness of a single user, we are also interested in techniques to provide information beyond simple touch.
Previous work proposes a number of techniques to make touch more distinctive; Finger-count  uses the number of touches; MicroRolls  detects specific patterns in the trajectory of touch events while users perform small roll motions with their fingers; and SimPress  analyses the fingers contact area.
However, none of these approaches addresses touch-to-finger ownership.
One simple approach is the Lift-and-Stroke technique ; users place all five fingers of their hand on the surface and then lift the ones not required for a given chord.
Unfortunately lifting certain fingers while simultaneously holding others down is difficult to perform .
However, their approach requires visual attention and might be impractical in cases where the attention is focused on external devices, e.g.
On multi-touch tables, the built-in camera can infer the fingerownership of touch from the hand's halo  by analyzing - a shadow casted by hands seen by the camera - where the touch event occurs relative to the hand.
In fact, most existing approaches for user-, hand-, and finger- identification  require external hardware.
We contribute an approach for finger-identification for off-the-shelf tablets.
We present a basic posture vocabulary of nine postures and propose spaceand time-multiplexed ways for extension.
Multitouch-enabled technologies, can detect the location and number of touch contacts with our hands.
Without additional technology, however, they cannot identify the specific finger, which is touching the surface.
Two-finger gestures have become pervasive in tablet gesture languages.
But two fingers cannot suffice for identifying fingers reliably because they only define a segment of a line.
By contrast, three fingers define two segments which relative geometric properties guarantee a unique match in well chosencases.
At least three fingers are needed for the simplest determination of the hand posture of the hand.
Three fingers determine postures for a reasonably large set of noncontorted postures.
The hand could curl fingers under or raise one up to increase the size of this vocabulary, but this would generate variability and decrease accuracy.
We would require a more complex model of the hand to be accurate.
In the following, we present hand measurements for a classifier enabling us to identify the fingers performing a chord.
We present three observations  of human handshape characteristics  and simple ways of measuring them.
These measurements are entirely based on relative measurements designed to be insensitive to variations in the actual size of users' hand.
We propose three families of simple-to-sense, hand-size insensitive input postures:  Neighboring Fingers ,  Thumb-Pinky Base ,  Thumb-Index Base .
In the process of designing classifiers for the posture families, each hand-shape characteristic contributes one relative measurement that distinguishes that particular posture in its posture family.
Used together, these angle and geometric measurements can distinguish all postures.
In the following sections, we introduce the posture families and summarize the rationale behind our design decisions.
To distinguish T- INDEX  from NF , we designed this as a two-step posture: users have to simultaneously hold down the thumb-index basis first and then add the third finger touch in a second step.
Compared to previous approaches, e.g.
Moreover, this process highlights the structure of the command and the fact that it relies on the completion of the thumb-index basis.
One observation is that index, middle, and ring finger have a relative position to their neighboring fingers; e.g.
We call the three chords in Figure 2 elements of the neighboring fingers  family.
We suggest the relation between D1 and D2 as relative measurement independent of actual hand sizes.
The thumb-index base  family addresses the observation that fingers of our hand have common patterns in length; e.g., the middle finger is usually longer than the index finger and the pinky is usually shorter than the ring finger.
The relative position `P' is calculated by an orthogonal projection of the third touch to the basis line.
To distinguish T- PINKY  from T- INDEX , the TPinky family is designed as a two-step posture as well: users first hold simultaneously down thumb and pinky as a basis and then add the third finger touch in a second step.
Using , we can extend our 9 three-finger postures by 1 five-finger and 5 four-finger postures .
In order to investigate a final posture-set size when using , further studies are required to determine a suitable tapping sequence depth.
In summary, we introduced relative measurements invariant of users' hand size and contribute a posture set that requires the user to hold down a minimum of three fingers to identify the involved fingers and approximate the position of the remaining hovering fingers.
We introduced ways of extending our set.
Multi-touch sensors are capable of providing information about touch shape.
However, many commercial available tablet APIs, e.g., Apple's IOS 72 , or tablet providers, e.g., Samsung Galaxy tab 10.13 , do not provide such information to developers.
We present an approach that works on very limited data - the position of touch - to distinguish various multi-finger chords on all off-the-shelf hand-held tablets.
We collected data from 20 participants with varying hand size performing all postures.
We created a KNN classifier  and analyzed its accuracy.
We conducted several tests on our data in order to address various real-world settings with tablets:  private,  shared,  public device setup.
In a private device setup, only one user interacts with the device; a prior calibration process can collect user-specific data.
In a shared device setup, e.g., when used in multi-surface environments as controlling input device , each user can perform a prior calibration; it is, however, unknown at a given time which user is interacting on the device.
Lastly, in a  public device setup tablets are used in public places and for short period of time, e.g., in museum installations.
Users walk up and use the tablet without prior calibration or personalization process.
Our relative measurements are invariant to a limited range of rotation of the users hand relative to the interactive surface .
This is an acceptable rotational interaction range for hand-held tablets since it would be hard to work from other angles.
Further investigation could evaluate the addition of using a built-in camera for finger orientation recognition  in combination with our approach for use on interactive tabletops.
The approach is limited to a single hand since some postures are symmetric: e.g.
This is also an acceptable condition for hand-held tablets, since one hand is involved in the device support and not available for such input.
20 right-handed volunteers participated .
The hand length was measured between the middle fingertip and the distal crease of the wrist with the hand extended, and the hand width was measured between the lateral aspect of the index and pinky finger at the joint where the finger is attached to the palm .
11/20 participants practiced activities that train finger dexterity, e.g., playing instruments.
We present postures that meet the minimum requirement of three touches to identify a hand posture and identify the touching fingers.
The experiment lasted approximately ten minutes.
When participants arrived, they filled out a questionnaire inquiring about habits in interacting with capacitive-touch technology and activities that could train hand dexterity, e.g., playing instruments.
We measured the width and height of the hand of participants and captured the outline of their flat hand on millimeter paper.
Trials were blocked by POSTURE FAMILY and the order was altered using a Latin square design on the POSTURE FAMILY factor.
The order of POSTURE ID was randomized and no two equal postures appeared successively, to avoid the repetitive input of the same posture by remaining in a stiff hand position.
In each trial, users were instructed to perform the appropriate posture indicated by an instruction image on the upper left screen corner.
The experimenter and a video camera verified that the correct posture was performed.
This corresponds to the case where users share the tablet with others but first performed an initial calibration.
Although less accurate than the private tablet setup, the global accuracy rate remains reasonably high .
This may be because some participants tended to perform pinched positions of the thumb and index finger instead of keeping their hand relaxed.
We used a m-fold cross validation procedure with the appropriate size of `m' for each tablet setup: a cross validation partitions a sample of data into a training set and test set and validates the test set against the training set; each part of the data becomes a test set once and the accuracy result of all validations are averaged.
Table 1 present the average accuracy value by device setup and vocabulary.
Figure 5 illustrates the distribution of accuracy by vocabulary.
It is interesting to notice that its performance is almost the same for the three setups, showing a low between-subject variability.
However, the global accuracy rate  is probably not sufficient for real usage.
In summary, our classifier is accurate enough to apply the tested nine posture vocabulary in private  and shared tablet setups .
The touch-positional data is, however, not sufficient for a public tablet setup .
Future work can include, e.g.
In addition, increased data on touch orientation might help as well if made available on a wide range of off-the-shelf hand-held tablets .
We determined one mean accuracy value by participant and took the average across participants.
The experiment was divided into two sessions and lasted in total approximately one hour.
Figure 7 shows that session 1 has 5 phases; session 2 has only one test phase and takes place 6-7 days later.
All participants were identically introduced to the chord vocabulary and the set of commands through an oral introduction of the experimenter.
If a multi-finger chord language is structured in such a way that it reflects the menu-structure of commands, users  learn the chord-command mappings faster and  keep those mappings more accurately in mind over a long period of time.
We test our hypothesis in the concrete case of mapping gesture families to command categories.
We performed a between-subjects design.
Subjects were randomly assigned to two groups:  subjects taught CATEGOR ICAL associations, the other  subjects taught RANDOM associations.
All participants were instructed to learn nine commands organised in three command-categories: transportation, animals, and sports.
Each category has three commands, e.g.
The goal of Session 1 was to make participants learn nine chord-command mappings by heart.
In Phase 2 and 3, each block contained 9 trials, each eliciting one element of the vocabulary in random order.
Each block is one repetition of all items in the vocabulary.
A trial had the following procedure: participants hold down a button until a stimulus image appeared showing one of the command stimuli in Figure 6.
Participants then performed the appropriate chord that maps to the particular stimulus.
They received feedback about errors: the screen flashed red and an instruction image of the correct chord appeared.
Chord-command mappings were different for all participants of both groups.
Participants learned a novel posture set, new command symbols and the mappings between them; to reduce the learning effort to learning mappings, we showed two sheets of paper to the user: one illustrated all hand postures, another one showed all commands.
The chord-command mapping was not shown.
Participants reached the objective end criterion of the memorization phase when they successfully reproduced all chords of the vocabulary twice in sequence .
Participants reached the subjective end criterion when they decided that they trained enough to be able to reproduce the command-gesture mapping 6-7 days later in session 2.
Participants performed one block as in phase 2+3 all items of the vocabulary were asked once; participants had to perform the corresponding chord of their mapping for a given stimulus.
Phase 5 in session 1 tested the short-term retention and phase 6, six or seven days later, tested the long-term retention.
Sessions were video recorded to eliminate recognition errors.
Chord-command mappings were validated post-hoc by analyzing the video.
Reported misclassification: participants received error feedback during phase 2+3 and were instructed to report recognition errors.
Objective end-criterion: number of required blocks until participants recalled correctly all items twice in sequence.
Objective end-criteria are always reached before subjective endcriteria.
Subjective end-criterion: number of required blocks until user subjectively feels 'trained enough to successfully recall the vocabulary one week later'.
Number of errors: the number of chord-command mappings participants did not recall correctly.
Trial time: time from the moment a stimulus appeared to the performance of the corresponding chord.
Our classifiers accuracy decreased from 98.44% in the first study to 94.06% in the second study; the cognitively demanding caused probably that participants tensed up their hands.
A one-way ANOVA of subjective end-criterion showed no significant difference between groups : participants in the CATEGORICAL group required in average 10.33 blocks  and participants in the RANDOM group required in average 12.67 blocks .
A one-way ANOVA of objective end-criterium, however, showed a significant difference between groups : participants in the CATEGORICAL group required less repetition to reach the objective end-criterium  compared to participants in the RANDOM group .
The CATEGORICAL mapping accelerated the learning and successful repetition of the vocabulary.
Both groups, however, continued the training.
To make our findings stronger, it was particularly important that participants end the training with the confidence to recall the items in later tests.
During the training and memorization process , we collected a total of 2421 trials, in average 134 trials by participant .
Participants reported on average 7 misclassifications; one user reported 22 misclassifications with an accuracy of 79.63%.
However, this was a particular case: this participant had a long thumb that triggered several touch events.
This detection issue can easily be addressed by updating our hand model to ignore such touches.
We performed a non-parametric Mann-Whitney test on number of errors in both retention tests.
We found no significant difference between groups in the short-term retention test, `p' being slightly greater than 5% : 1 participant in the CATEGORICAL group did one error; and 5 participants in the RANDOM group did one error; the remaining had no errors.
There might be a significant different result with a larger sample size.
We were surprised how well participants in both conditions retained nine mappings for approximately one week without further training or practice; especially, since previous work indicate difficulties in learning more than two abstract gestures .
Figure 8 shows the distribution of number of errors during the short- and long-term retention test.
Participants in the CATEGORICAL group made in average.
Participants in the RANDOM group made in average 0.56  errors in the short-term retention test and 3.4  errors in the long-term retention test.
Note that not only the mean values are different between groups in the long-term retention test, but also the variance .
We analyzed the errors and categorized them into three types of errors:  right family wrong finger ,  wrong family right finger , and  completely wrong .
Participants in the CATEGORICAL group had few errors: P2 had 1 RFWF in the short-term retention test and P6 had 2 RFWF in the long-term retention test; he swapped two postures of the same family.
Participants in the RANDOM group had in comparison lots of errors, a total of 5 in the short-term test and 36 in the long-term retention test.
We found 2 WFRF, 2 RFWF, and 1 CW in the short-term retention test and 8 RFWF, 9 WFRF, and 19 CW errors in the long-term retention test.
Our results indicate that a structured mapping leads to less error-prone long-term memorization, which is highlighted by the types of errors participants made: participants in the CATEGORICAL group did not mix up mappings between families and menu category, and did not perform a completely wrong posture.
All participants required more time to perform postures in the long-term retention test  than in the short-term retention test .
This supports ongoing discussions that some effects on memorization might first show up after some time has passed .
This result is consistent with participants rating of postures with respect to both perceived comfort and ease-ofuse.
Figure 10 illustrates participants' rating of ease-of-use on a 5-point Likert scale .
We found an interesting effect between groups on the qualitative rating of participants.
All participants performed the same multi-finger chords, only the mapping changed.
However, when asked about perceived ease-ofuse - directly below the question about comfort - participants answered more positive in the CATEGORICAL condition than in the RANDOM condition .
Figure 10 illustrates the difference by chord fam-
Participants equally rated comfort of postures independent of group.
This is not surprising, since they performed the same postures; it is, however, interesting to note that participants seem to rate to above demonstrated quality of the mapping as easier to use.
This might be explained through the integrality of posture and mapping: the demonstrated advantages of the CATEGORICAL mapping might have led to more positive rating of perceived ease-of-use.
We demonstrate that the accuracy of our gesture recognizer is acceptable for private  and shared tablet setups .
It remains future work to improve the detection accuracy in public tablet setups .
Our posture vocabulary introduces a categorical structure of physical input movements to access items in a menu; similar input movements access similar commands.
This introduces an organization on two levels:  the posture vocabulary leverages a hierarchical order and  the corresponding commands are hierarchical structured.
We found that a homomorph structure between the input posture set and corresponding command set leads to increased long-term retention of chord-command mappings.
We compared categorical and random mappings in a between-subjects experiment.
We found that participants in the categorical group learned quicker; they also retained a 9-item chord-command vocabulary with fewer errors for the time period of one week.
Moreover, people in the categorical group performed trials faster and rated 'ease-of-use' of the identical posture set more positively than people in the random group.
The logical input structure we introduced to facilitate memorization has a consequence on participants' strategies to cope with the memorization task: participants adapted their strategies correspondingly to order, category and exclusion, minimizing the amount of information to retain.
This research demonstrates that large posture vocabularies can be learned and memorized.
Participants reported on their strategies to remember mappings.
We classified answers into five types of memorization strategies summarized in table 2.
The introduction of structure leads to logical and ordered memorization strategies in the CATEGORICAL group.
5/9 participants mentioned `exclusion' as strategy to minimize the amount of information to retain.
