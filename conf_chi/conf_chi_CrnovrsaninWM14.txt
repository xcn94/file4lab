Computers make incredible amounts of information available at our fingertips.
As computers become integral parts of our lives, we spend more time staring at computer monitor than ever before, sometimes with negative effects.
One major concern is the increasing number of people suffering from Computer Vision Syndrome .
CVS is caused by extensive use of computers, and its symptoms include eye fatigue, frequent headaches, dry eyes, and blurred vision.
It is possible to partially alleviate CVS if we can remind users to blink more often.
We present a prototype system that uses a camera to monitor a user's blink rate, and when the user has not blinked in a while, the system triggers a blink stimulus.
We investigated four different types of eye-blink stimulus: screen blurring, screen flashing, border flashing, and pop-up notifications.
Users also rated each stimulus type in terms of effectiveness, intrusiveness, and satisfaction.
Results from our user studies show that our stimuli are effective in increasing user blink rate with screen blurring being the best.
Not surprisingly, many computer users are affected by CVS.
A contributing factor to CVS is a reduced blink rate when using computers for extended periods of time.
The spontaneous eye blink rate  is reduced significantly from 1516 blinks per minute in conversation to 5-6 blinks per minute during computer use .
The problem is exacerbated as our eyes open up wider when looking at the computer screen, increasing tear evaporation.
Computer users can fight against CVS by developing good habits that help prevent the symptoms.
These preventative strategies are a mixed bag.
Methods that require one time setup such as computer screen being placed at least 20 inches and viewing angle of 15 degrees lower than the horizontal level are easy to implement and work well for most symptoms.
Unfortunately, methods that help with dry eye require frequent attention from the user, such as the 20/20/20 rule  .
These methods are not practical as users have a difficult time taking regular breaks when they are focusing on their work.
Dry Eye Syndrome  is often overlooked but studies have shown that DES has significant impact on quality of life .
DES causes itchy or burning eyes, discomfort wearing contact lenses, increased sensitivity to light or excessive tearing and in extreme cases, blurred vision .
The recommended treatment for DES is to blink more  or replace with artificial tears .
Artificial tears can be expensive over prolonged use and do not solve the cause of the problem.
Blinking more is a good idea but it is hard for the user to pay attention to their own blink rate throughout the day.
Researchers have studied methods for helping individuals with DES.
There are software packages that help users manage their exercises and rest brakes .
They usually measure activity level by keyboard and mouse interaction, which does not correctly represent user's behavior with activities that do not use input, such as reading or watching a movie.
Researcher have also worked on stimulating a blink, but these methods require special hardware to work and do not take the person's blinking into account.
Therefore, they are not practical for daily use.
There are systems that detect blink, but these applications are mostly used for fatigue detection  and not for preventing the problem in the first place.
Computers have greatly influenced how we interact with the world.
More of the population are finding themselves in front of computer than ever before .
This long-term use of computers can have to negative effects on one's health.
The symptoms range from headaches, fatigue, blurred vision, eye strain, dry/irritated eyes to difficulty focusing, which are all signs of Computer Vision Syndrome .
The formal definition of CVS is a group of eye and vision-related problems that result from prolonged computer use.
Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
To help the user with DES, it is necessary to create a system that can not only detect blinks but also apply a stimulus when the users had not blinked for an extended period of time.
In this paper, we present a prototype application that does this using only the monitor and a standard monitor-mounted webcam.
The idea is to increase the user's blink rate when using a computer and thereby help reduce occurrence of dry eyes.
To test the effectiveness of our prototype, we conducted two user studies.
Our first user study looks at different media types and their effect on blink rate.
Does looking at text, image or video cause different rates of blink?
We then conduct a second user study to see if our prototype can increase users blink rate and which stimulus methods work the best.
The contributions of our work can be summarized as follows: * The design and evaluation of a prototype system that leverages the state of the art vision-based object detection algorithm for human-computer interaction; * The development of a set of stimuli taking into consideration both the habit of computer usage and the human blink mechanism; * The design, conducting, and presentation of a qualitative user study which confirmed that the human blink rate can be improved based on these stimuli.
Table 1: SEBR is largely dependent on the type of tasks being conducted; the more the user is focused, the less is the SEBR.
The room temperature and humidity can also affect blink.
Blink rate fluctuates when changing gaze direction , during line change , or squinting .
However, present results show that there is no significant influence to the change in SEBR given the above factors .
However, we have found no comprehensive study from this perspective.
Computer users are often engaged in various visual tasks.
The intensive use of our eyes results in decrease of SEBR and eye fatigue.
Several utilities  have been developed to notify computer users to blink voluntarily.
These utilities try to follow the 20/20/20 rule and notify the user to rest regularly.
For fragmented tasks, regular breaks may help restore and relax the accommodative system, thereby preventing eyestrain .
However, when dealing with long-lasting tasks that require more concentration, people tend to compensate for interruptions by working faster.
This comes at a price of experiencing more stress, higher frustration, time pressure, and effort .
According to their study, the reflexive eye-blink rate  was higher in tasks with the device properly set up.
One defect of their experiment setting is that the LED timer device can only be programed to flash based on a predefined time interval .
To actively detect blinking event in real-time, vision-based eye detection systems have been implemented for both desktop  and mobile devices .
A general eye-blink detection algorithm starts with detection based-on facial biometrics.
The eye region is then extracted to reduce the dimension of data used to detect and quantify eye-blinks.
The ability to detect eye-blink in real-time makes fatigue detection, anti-spoofing recognition and other general HCI tasks possible .
However, none of these previous systems provided provided an effective solution to increase the REBR.
Blinking is a common facial motion that consists of rapid closing and opening of the eyelids.
It can be further classified into spontaneous, reflexive and voluntary blinking .
Most blinks are triggered unconsciously, reflecting a person's emotional or cognitive state .
Reflexive eye-blinks, on the other hand, are elicited in response to a variety of environmental stimuli , such as loud noises and flashing lights.
Blinks can also be voluntarily, like as in clinical experiments where test subjects were instructed to blink as fast as possible after a verbal command is given .
There are many factors that affect blink rate.
Studies reveal that SEBR largely depends on the type of tasks being conducted.
Different tasks have different visual demands.
As depicted in Table 1, the reading-SEBR  is lower than the primary gaze-SEBR, and they are both lower than face-to-face conversational-SEBR .
Primary gaze is an act that subjects directing their gaze to a distant target adapt with their habitual palpebral aperture.
Our blink detection and stimulation system is configured using a personal computer together with a consumer affordable web camera with 720p  video acquisition capability .
This gives us enough resolution for detection of subtle changes on the face.
The camera is set on top of the computer screen facing the user.
To ensure the whole face region is obtained, the user is seated 50 to 60 cm away from the display.
An overview of the eye blink detection algorithm is depicted in Figure 1.
We use an eye blink detection algorithm similar to the one described in  using OpenCV  due to its high accuracy .
In out implementation, we counted double-blinks as one blink instead of two, which led to even lower false-positive rate .
We determined our false-positive rate by counting blinks manually from the recorded videos in our study and compared it to our system results.
The video frames are obtained at 30 frames per second.
For each video frame, a cascade of boosted classifiers is applied.
The cascade classifier was trained using a few hundred sample images for identifying human faces.
After the facial regions have been extracted, a second set of cascade classifiers is applied to detect opened-eyes, yields the corresponding positions of opened-eyes within the facial region.
Geometrical constraints are also used to verify candidate eye regions to avoid mis-detections.
Since eye blinking consists of rapid closing and opening of the eyelid, we can detect a blink event by recording the sequence of historical eye open-states.
We can also use this sequence to trigger stimuli after a target interval of time.
Both of these tasks are accomplished using Algorithm 1, where s denotes the eye open-state at a certain time stamp, and 1 and 0 denote the opened-eye and closed-eye states, respectively.
This simple algorithm is capable of detecting long-closing voluntary eye blinks as well as double-blinks.
A stimulus response is triggered when the user has not blinked for a certain timespan - the fatigue limit.
Previous studies used a constant time of 4 seconds in accordance to the average blink rate of 15 blinks per minute .
When we conducted our pilot study, we found two problems with this fatigue limit.
First, people started to expect the stimulus response.
This stems from the fact that individuals do not blink at a constant rate, and therefore using a constant time feels unnatural.
Second, users found it bothersome and annoying to have stimulus applied so frequently.
This makes sense, as each person has a different blink interval and the interval can change based on external factors .
We decided to use a interval of time instead of constant time, thereby making harder to expect the stimulus.
We conducted several pilot studies to find the correct interval of time.
The fatigue limit should be set such that blinks could be triggered frequently enough for the eyes to be moisturized, while not disturbing the user.
We found setting the interval between 4 and 8 seconds after the blink, worked well.
For our study, we implemented four blink stimulation mechanisms: Flash, blur, flashing border, and pop-up notification.
Flash and blur stimuli are designed to trick the eye into blinking, while flashing border and pop-up notifications provide a reminder to blink.
The flash stimulus makes use of the fact that when a person blinks, there is a flicker that occurs.
Instead of using extra hardware as suggested in Miura et al.
The tinterval is chosen such that it is long enough to be noticed by our visual system but not long enough to be considered to be intrusive.
We found white to work well for our given task as it was more effectively at getting a blink response, though other colors can work.
A drawback of the flash is that the user could miss the stimulus since it only happens once.
Given that under certain circumstances, e.g.
In addition to the text log, the screen shots of users performing tasks are also recorded.
To prevent critical blink screen shot from being smoothed out in videos, we chose a static image log instead.
The images logs are outputted at the frequency of 30 to 100 milliseconds per image, which is fast enough to store information for checking blinks event afterwards.
Figure 2: Three of the four stimuli used in our study.
The camera and task control button are found on top of the user interface .
The blur stimulus tries to mimic how our eye sight behaves when our eyes get dried.
Once the stimulation event is triggered, a Gaussian blur filter is applied to the screen as the task is being conducted.
As shown in Figure 2, this effect tricks the user into thinking their eyes have lost focus, thereby stimulating a blink.
The Gaussian weights are calculated accordingly to the Gaussian function with standard deviation of 2.7.
The blurring effect is carried out in two passes, first horizontally and then vertically to guarantee least memory fetches.
We slow down the transition of the blur, making it less disturbing for the users to finish their tasks.
The drawback of the blur is the user has to respond with a blink or they will be unable to continue working.
This similar problem can occur if the blink detection does not capture the user's blink, thus causing the user to waste time trying to clear the blur effect.
The flashing border stimulus is the middle ground between the blur and the pop-up notification effect.
When the fatigue limit is reached, the border of the task window will flash, until the user blinks to clear the effect.
A demonstration of the flashing border stimuli is depicted in Figure 2.
Unlike the blur stimulus, the border flashing does not prevent the user from completing the task and thus acts more like a notification.
Nevertheless, some users might find the flashing border quite annoying and distracting.
The pop-up notification stimulus as the name implies creates a pop-up window in the bottom right corner of the screen.
This window is purposely kept in the peripheral vision as to not disturb the user, as shown in Figure 2.
This method is used in most of the eye fatigue relief software packages.
It suffers from two drawbacks, the user can easily choose to ignore it and because it is in the periphery, and it tends to draw the attention of the user away from their tasks.
One limitation of the system is that the camera cannot be set right in front of the user's sight.
When conducting different tasks, the eyes of the users are focusing inside the area of the computer screen.
It is possible for the user to be too close to the screen and part of his or her face is not captured by the camera.
This will result in miss detection of the eye blinks.
We want to test how effective our system is, but before that we need to know how different media type affect blink rate.
Hence Study 1 will seek to find out what kind of media type lead to the lowest blink rate  and with that in mind Study 2 will see how the various stimuli described above influence blink rate .
This user study tries to find a task with the lowest blink rate, as these are more likely to exacerbate CVS symptoms.
We do this by seeing if the blink rate changes depending on what computer task is being performed.
Specifically, we were interested in seeing which media type has the lowest blink rate and if there is variance within the media types.
The lowest blink rate should have the most impact on dry eyes and is therefore the best media type to use for Study 2.
The participants had normal or corrected vision and used the computer on average 8 hours per day.
The experiment was conducted in a well lit room.
The study took between 20 to 30 minutes for each subject to complete.
The study was conducted on a 27 inch display with 1920x1080p resolution and a camera installed on top of the monitor.
The task themselves were on a smaller resolution  window to fit the necessary buttons for switching to the next task.
We asked the user to sit at least 50cm away from the monitor and make sure the monitor was at least 15 degree below the horizontal level.
Therefore, each task was kept short, ranging form three to five minutes to complete, enough time to capture the SEBR.
Before we describe each of the task, we should define what are passive and active tasks in the context of this user study.
An active task elicits/requires more attention from the user to complete a task than a passive task.
Text tasks: For the passive text task, the subjects were asked to read a set of paragraphs on a general topic.
A Wikipedia page on Principle Component Analysis was used because all subjects are familiar with the topic.
For the active text task, the subjects were asked to read a passage, displayed on the left, and answer questions on the passage on the right .
This requires more attention as the user has to go back and forth between the passage and the question to answer them correctly.
Image tasks: We asked the user to do a memory test for the passive image task.
The user was shown a set of equally sized images for 30 seconds.
The user was then asked to pick out those images from a collection 20 images.
The memory test was repeated twice with an increase in the number of images the user had to remember.
In the case of the active image task, the user was given two images side by side and asked to spot the difference between them.
Memorizing a set of images uses more mental power.
The user thinks of ways to associate the images or create a rich context by adding together auditory, visual and other information to the image.
In either case, the user was spending more time making the necessary connections than staring at the images.
Spot the difference is a good active task because it requires the user go back and forth between two set of images.
Blinking actually makes detecting the difference harder as it disrupts iconic memory  .
Video tasks: The passive task was to watch a presentation, while for the active task, the user watched an action trailer.
Trailers are designed to grab the attention of the viewer, showing series of clips to entice the viewer into watching the movie.
They have 2 to 3 minutes to sell the audience on the movie.
On the other hand, talks are more slowly paced and provide more content.
A talk is more about what is being said than what is being shown.
Therefore, the visual content is not as important as in the trailer.
It should be noted, that we did not track how well they completed each task, since it has no relevance to our study.
Figure 3: The SEBR ratio over the average SEBR per test subject for each of the six tasks.
Images frames were recorded in case the blink events are not properly detected.
The users were asked to always stare forward and not to touch their face as it will affect the blink capturing software.
Between tasks, the user is given a small break and shown live feed to check positioning.
An experimenter recorded observations, rating and follow-up interviews.
To make sure false-positives were not counted, captured video data was manually counted and compared against our system.
False-positives occurred less then 0.4% across both studies and were removed from the dataset.
Figure 3 summarizes the results from Study 1.
The ratio was acquired by taking the absolute SEBR of each task over the average SEBR per individual.
We used One-way analysis of variance to analye the SEBR ratios.
Posthoc Tukey analysis shows a pairwise difference between image active and image passive  as well as video passive .
There was also a pairwise difference between text active and video passive .
We used a within-subject design.
Each user was asked to fulfill a quick survey before starting the study.
The survey covered basic question such as age and gender, as well as questions about their vision and computer usage.
Before starting the task, the participants saw a live feed of themselves with the eye detecting software enabled and were asked to make sure the software could detect their face, as shown in Figure 1.
The user started a task by clicking on one of the task buttons as shown in 2.
Once a task was completed, the task button is grayed out.
The tasks were given in a random order assigned by the computer.
When we looked at the SEBR, we noticed some individual had higher or lower baseline.
For instance, one participant had SEBR of 20.57 for passive image and 10.42 for active image, while another had a SEBR of 5.3 for passive image and 1.94 for active image.
There is a clear difference between the passive and active image, though just averaging the SEBR on each task would create quite bit of variance.
This pronounced variance is typical for averaged SEBR measurements.
Blinking in real-life settings depends on a large number of parameters, which may influence the SEBR positively or negatively and contribute to the observed large variation in SEBR within normal population.
This is why we chose to use the ratio of absolute SEBR of each task over the average SEBR per individual as it was a better indicator.
Study 1 has shown that active image computer tasks have the lowest SEBR ratio.
This might be due to the fact that an active image task uses iconic memory to complete the task.
Iconic memory is known as a very brief , precategorical, high capacity visual memory.
Therefore, blinking during the task becomes a disadvantage and reduces subjects' performance.
This could also explain why stimuli that force the user to blink are found to be more intrusive, especially if the blink does not get detected.
We can not directly compare the studies as they consider watching a video to be a passive task.
They defined video as a passive task because it does not require interaction with the computer.
For the active computer task, they used Birch et al.
The task presents a graph to the subject and they have to reconstruct the graph, in the correct location, by selecting and linking a set of equally distributed points together.
In both, the subject is processing a small area of an image or graph at a time, going back and forth, and looking at what is supposed to be there or not .
Comparing our image active task with the passive video task, we obtained results similar to that of Skotte et al.
Figure 4: Comparing the four types of stimulus.
The x-axis is the users sorted based on their SEBR obtained from the nonstimulus condition.
The y-axis encodes the rate  of increase for stimulus blink rate over the nonstimulus condition.
The plots indicate that all four stimuli helped to increase the blink rate compared to the non-stimulus condition, as almost all the ratios are greater than one.
Blur and Flashing Border have a negative correlation to SEBR.
The control has no stimulus.
The stimulus user study tests to see which methods are more effective in stimulating a blink response from the user.
We are also interested in the user opinion of the stimulus.
Did they find the stimuli annoying and how effective did they feel the stimuli were?
We used the active image task for our task as it had the lowest blink rate.
We used a within-subject design.
Subjects were asked to fill a quick survey about their computer usage and vision.
We gave each subject 5 minutes to get accustomed to each type of stimulus before starting on the tasks.
The subject was presented with a series of spot the difference tasks and spent between 3 to 5 minutes on completing each task.
The tasks were given in random order.
The users were asked to always stare forward and not to touch their face as it will affect the blink capturing software.
After each task, the users were asked to rate each stimulus based on effectiveness, distraction, and satisfaction.
We were curious to see if there was a difference between perceived effectiveness versus the qualitative measure.
The rating was done on a 1 to 5 scale where 5 equals very effective, very distracting, and very satisfied.
An experimenter recorded observations, rating, and follow-up interviews.
The participants had normal or corrected vision and used the computer on average of 8 hours per day.
The experiment was conducted in the same location as the first experiment and under the same conditions to avoid introduction of any new variables.
The study took each subject approximately 30 minutes to complete.
This user study asked each user to complete a set of tasks and measured how often they blink per minute  during each task.
If the user did not blink for a designated amount of time, a stimulus was triggered.
There are four stimulus types plus one control.
Our previous user study showed that active image task has the lowest SEBR, and therefore we chose to use that for all of the tasks.
We want to mimic the situation where the software can assist the user in remembering to blink.
The five types of stimuli are Flash, Blur, Flashing Border, Pop-up notification, and control.
The Blur stimuli causes the screen to slowly Blur until the user blinks.
This method, unlike the rest, forces the user to blink or else the image becomes unreadable after a while.
The flashing stimuli administers a quick white screen flash .
The Flashing Border pulses from white to black.
As with Study1, video data was compared against our algorithm.
False-Positives were removed from the dataset.
Figure 4 shows the four stimuli where the x-axis is the users, sorted by their SEBR from control test.
Y-axis is the ratio of the stimulus blink rate over SEBR.
The larger the x value is, the higher the SEBR.
Almost all ratios are larger than 1, which indicates all four stimuli help to increase the blink rate compared to the control.
The results for the Blur and Flashing Border stimulus also reveal a pattern of negative correlation; that is, users with lower blink rate tend to have higher blink rate increase, when these two stimuli are applied.
All four stimuli increased subjects' SEBR.
Figure 5: Subjective evaluation of the four types of stimulus.
The higher the value, the better performance a stimuli has, where 5 = very effective, not intrusive at all and very satisfied.
As expected, individuals that had higher control SEBR had the lowest increase in blink rate and stimulus rate.
Figure 5 shows the results of the user feedback.
We asked users what they thought of each stimulus.
Half felt the Flash was annoying, while only one liked Flash because it was quick and did not block the content.
One individual commented that the Flash made him feel uneasy.
An interesting comment was made by two individuals about how once they got used to the flash, it lost its effectiveness.
Blur received more positive comments.
Several users liked the steady change effect because of the way that it cleared the screen.
However, several subjects could not clear the Blur in the first try and thus found Blur effect annoying.
This can be fixed by using a more robust detection system.
Users found the Flashing Border to be less noticeable than the flash.
One user mistook it as a system alert.
We also received several suggestions to change the border color according to the background color, so flashing would be more noticeable.
Two users liked the Pop-up stimulus because it was something they were used to.
Almost half of the users commented they wanted the pop up window to be in the center, suggesting a need to have the option to select the position of the Pop-up.
We kept track of whether the user responded to a stimulus or not.
A response to the stimulus was counted if there was a blink between two stimulations .
This was done because some stimuli are persistent such as the Blur, Flashing Border, and Pop-up notification.
Note that we started the timer again right after the stimulus was applied, independent of them being persistent or not.
Figure 6 summarizes the results of the response rate.
We used a one-way ANOVA with Tukey.
We logged the time taken for the user to respond to a stimulus.
It should be noted, we ignored cases where the stimulus was triggered but the user did not respond.
We used a oneway ANOVA with Tukey.
The variance for the Blur stimulus was smaller because the time interval from the blurring being noticed to the content being unreadable was small.
The results from our Study 2 indicate all of our stimuli helped to increase blink rate.
The lower the blink rate, the more the stimuli helped.
This makes sense as having a low blink rate means a stimulus is triggered more often and thus going to be more effective.
Though all the stimuli helped, not all were liked.
Between the survey and user feedback, it is clear that Flash was the least liked.
This is very interesting as Flash is the shortest stimuli.
This might be explained by the way Flash is delivered.
Blur has a steady change while Flashing Border and Pop-up are sudden but happen on the peripheral.
Flash, on the other hand, happens suddenly and covers the entire screen, which might cause individuals to lose focus.
Another possible reason why screen size can affect blink rate is due to large amplitude saccades.
Saccades are fast movement of the eye.
Large screens require more and/or larger saccades to inspect and saccades are often  followed by blinks .
This same study found a correlation between head movement and large amplitude saccades .
Therefore, the size of the screen has to be relatively larger to elicit head movement.
In the case of our studies, all the tasks were centered so large amplitude saccades did not play a big role.
Figure 7: Response time of each stimuli.
Y-axis: the response time in second.
The Flash stimuli has the lowest response time in average.
All except the Blur stimuli have large standard deviations.
We were surprised to see that there was no clear winner among the stimuli.
We expected stimuli that were supposed to trick the eye into blinking, such as Blur and Flash, to do better.
In some cases Blur did do better such as being better than Pop-up in effectiveness.
A potential reason why Blur and Flash did not do clearly better than the other stimuli is because they failed to trick the eye.
As we can see from the response time in Figure 6, it took on average 1.5 to 2 seconds to blink after a stimuli was applied.
For Flash it is safe to say that most of the blinks were voluntary; otherwise, the response time would be close to 0 seconds.
It is a bit harder to tell if the blinks were reflexive or voluntary for Blur stimulus as it takes time for the Blur effect to be seen by the users.
Being able to detect a blink plays a huge role in how intrusive the subject feels a stimulus method is.
This affects methods that require the blink to be detected to reset, such as the Blur and Flashing Border.
Even with a 95% detection rate, some blinks may not be registered.
If this happens more than once during a specific task, subjects may become flustered with the stimulus, as it is preventing them from completing the task.
This explains why certain methods have higher variances than others.
It also explains why certain methods are highly effective in stimulating a blink  but at the same time are very intrusive to the subject.
It is difficult for us to determine the impact on performance as we did not gather task performance data.
Hence, it's unclear from Study 2 how the different blink stimulation techniques might impact task performance.
Unfortunately, this is not easy to fix, as any system will have margin of error.
However, improving the detection rate will reduce the chance of multiple negative detections occurring within a small time interval.
We noticed from the pilot study that the size of the screen area occupied by the task affects blink rate considerably, especially in video and image tasks.
Reducing the font size could produce the same results in the text tasks.
For instance, reducing the size of the image task to half the screen drops the blink rate by at least half.
We surmise that trying to focus or do comparison on a smaller image requires more concentration.
In some cases, the subjects would lean forward in order to see greater detail.
This prevents users from maintaining a proper viewing distance from the screen, possibly exacerbating CVS.
Our system is not meant to replace existing utilities or fatigue detection systems , but works alongside them as a first line of defense.
First, our system would increase blink rate and help with alleviating some of the effects of dry eyes.
When the system detects the user is suffering from fatigue, it can suggest the user to take a break or recommend any set of utilities .
Combining both sets of approaches would be straight forward as our system uses the same method of blink detection as the fatigue system.
Different parameters: Each stimulus has parameters that can be tweaked, such as size, duration, location, and intensity.
Also, there are other tweaks suggested by the test subjects.
We did not want to add these variables to Study 2 as they would over complicate the study and our goal was simply to show that our stimulus worked.
Further studies are necessary to see how tweaking such parameters affects the effectiveness and perceptions of the stimuli.
Glasses: Wearing glasses can affect the system's ability to detect blinks.
If the user is staring directly ahead, then there is no effect on the detection.
However, the blink rate drops if the glasses' frame blocks the user's eyes.
This can also affect people's perceptions of the stimuli, specifically those which require the system to detect blinks to reset the effect.
Screen size: One limitation of our system is that the size of the screen affects how well the stimuli work.
The greater the field of view the screen covers, the more likely the subject is to respond to the stimulus.
This implies that mobile use of our method would be less effective.
However, from our Study 1, attention effects blinks per minute as well.
Therefore, another would need to be conducted to see what kind of effects a smaller screen size has on the stimulus methods.
Different types of blink: Our studies only looked at blink as a whole and did not take into account different types of blink.
Further studies are needed to see if our stimulus methods cause a reflexive or voluntary blink.
Long term effects: We would also like to run a longer study to determine the long term effects of our system.
Can the system help someone with dry eyes?
Is training viable, and if so, what effect does that have on the different stimulus methods?
Detection systems will never be perfect.
Touching one's face, movement and glasses will all reduce the chance for the blink to be detected and increase user frustration.
This is especially a problem for methods like Blur that prevent the user from continuing their work.
The problem stems from not being able to determine where the eyes are.
Once eyes are found the detecting process is highly accurate.
Therefore, our suggestion is when the face is not detected, to clear the effect and not start fatigue limit until the face is detected.
This has potential of reducing effectiveness but will also reduce user frustration, which is more important.
No single stimulus is the best.
Our Study 2 found a large variance in which stimulus subjects preferred.
This variance can be attributed to both detection rate and subject preference.
Some liked the effect taking up the entire screen, while others wanted something less intrusive.
Since one method is not necessarily better than the rest, the system should let the user decide what type of stimulus they want to use.
Do not be afraid to experiment with other stimuli.
The goal of our paper was to show that software-induce stimuli work.
There are other stimuli that can be tried.
For instance, instead of blurring the entire screen, the effect can start from the edge of the screen and slowly move toward the center or where the eyes are focused.
Another possible idea is to track eye movement and apply effect to peripheral vision.
Stimulus responses do not have to be just for blinking.
As we mentioned before that proper viewing angle and distance can help with CVS.
Though when working on a tough problems it is easy to slip out of these proper position.
If the camera is stationary, it is possible to detect the location and size of the head.
With this information, the user can have stimulus response applied, such as Pop-up, to let them know when they slip out of the proper position.
Acosta, M., Gallar, J., and Belmonte, C. The influence of eye solutions on blinking and ocular comfort at rest and during work at video display terminals.
Arai, K., and Mardiyanto, R. Eye based hci with moving keyboard for reducing fatigue effects.
Bacher, L. F., and Smotherman, W. P. Spontaneous eye blinking in human infants: a review.
Birch, L., Juul-Kristensen, B., Jensen, C., Finsen, L., and Christensen, H. Acute response to precision, time pressure and mental demand during simulated computer work.
Biswas, N. R., Nainiwal, S. K., Das, G. K., Langan, U., Dadeya, S. C., Mongre, P. K., Ravi, A. K., and Baidya, P. Comparative randomised controlled clinical trial of a herbal eye drop with artificial tear and placebo in computer vision syndrome.
Voluntary, spontaneous and reflex blinking in patients with clinically probable progressive supranuclear palsy.
Caffier, P. P., Erdmann, U., and Ullsperger, P. Experimental evaluation of eye-blink parameters as a drowsiness measure.
Cardona, G., and Quevedo, N. Blinking and Driving: the Influence of Saccades and Cognitive Workload.
Divjak, M., and Bischof, H. Eye Blink Based Fatigue Detection for Prevention of Computer Vision Syndrome.
Consideration of Three Types of Spontaneous Eyeblink Activity in Normal Humans: during Reading and Video Display Terminal Use, in Primary Gaze, and while in Conversation.
We present a prototype system that tracks a user's blink rate and administers a stimulus to trigger the user to blink when the user has not blinked for a while.
Our system is unique in that it stimulates a blink response by only using the screen itself.
We considered a range of different stimulus methods that can be used to cause a blink response.
We conducted two user studies.
The first user study determined that active images have the lowest blink rate.
We used these results to conduct a second user study to access our system.
The results of this study indicate that it is possible to prompt a blink response with our stimulus methods.
Our methods use a standard setup that can be found on any modern laptop.
Therefore, a full system of our prototype can be created to help individuals alleviate dry eyes symptoms.
Our findings can help others build future blink stimulus systems.
