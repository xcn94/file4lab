Creating film content for broadcast is a high pressure and complex activity involving multiple experts and highly specialized equipment.
Production teams are under continuous pressure to produce ever more creative and groundbreaking content while reducing the budgets and human resources required.
While technologies are being developed for digitizing and streamlining sections of the production workflow, a gap remains between creative decisions made on location, and those made during digital editing and post-production.
We describe a prototype tangible, tabletop interface to be deployed on a film shoot, which uses a storyboard as a shared data representation to drive team creativity.
We define creativity in terms of team production, discuss our implementation and describe a deployment in which the prototype was used by a professional production team during a film shoot.
Finally we describe a number of interesting interactions that were observed and consider the implications of our design decisions on the creative process of film making and the benefits of tangible, tabletop collaborative interactive displays in live film production.
H.5.3 : Group and Organization Interfaces - Collaborative computing.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Recently BBC has developed a set of digital workflow tools to improve efficiency in the production process.
This paper describes a collaboration between interaction design researchers and BBC Research and Development which aimed to integrate the media production process and its multiple technological components, bridging in-house digital production workflow products and new interaction techniques and technologies to drive existing production staff to produce better content.
To enable our understanding of this domain we developed a technology prototype designed to facilitate collaborative production in a broadcast scenario, which we deployed and evaluated during a professional film shoot.
We present our design rationale, the prototype implementation, and report on our initial findings regarding the use of interactive technologies to support the complex processes involved in these types of broadcast production.
Rather than assume that design paradigms from other domains translate directly to this domain, we present specific elements that drive creative practice in an existing live production workflow.
Making broadcast television involves multiple skilled personnel each with an expertise in a different aspect of the production process.
Many of these roles are highly reliant on digital and other technologies and developments in camera optics, HD recording and cloud media storage are having a significant impact on production practice.
Although production processes vary tremendously, ranging from blockbuster movie sets with hundreds of crew to wildlife documentaries with three multi-skilled team members, they typically share a common workflow pattern.
This workflow consists of a number of stages in which separate groups of people contribute to the final product.
A typical workflow, shown in Figure 2, follows a linear order:  a concept is developed through a group creative process;  this is written as a script;  the director designs camera angles through the script;  this is translated into a shoot order, the actual order in which shots will be filmed on set;  the shoot order is followed by the crew on set, and annotated with metadata by hand e.g.
Better support for creative decision-making earlier in the process, and better capture and communication of these decisions should reduce the time currently spent searching and interpreting notes for clips during the editing phase.
Because the director's vision drives content creation, they set the agenda for the shoot and make the principal creative decisions during the filming process.
They lead a team of specialist production staff, including lighting and sound engineers, camera operators and a script supervisor, who must all be given enough information to perform their function effectively.
Such teams are usually organized within a hierarchical team structure, where the further away in the hierarchy team members are from the director, the less awareness they will have of the current progress, the creative rationale and the end result.
In addition to this, many decisions that are made during the shoot are not acted upon immediately, but are decisions that the director and editor will act upon later, during editing.
This workflow is implemented throughout the television production industry, and generally performs well in cases where the production team has a rigid and well defined production process and a fixed script.
However, it is less appropriate for smaller, multi-skilled teams where there is an expectation of quicker throughput from scripting to broadcast.
Our goal was to develop digital tools to support creative decision-making and the production process of such smaller production teams.
Our hypothesis is that by creating a shared, visible representation of the shoot phase of production we can push the point at which a number of creative decisions are made earlier in the workflow.
By having earlier decision-making, more members of the team can be involved and the number of decisions that have to be made at edit time  by director and editor will be reduced.
By allowing crew members to have more awareness of the effect of their role on content creation we aim to:  facilitate more flexibility and opportunities for trying new ideas;  allow the transfer of production notes transparently between processes; and  facilitate creative contribution by all members of the production team.
A script, written for production, represents the creative vision of the writer.
A director interprets the script by turning it into a sequence of camera angles or `shots',
Systems such as INGEX  for tape-less recording, and Redux   for distribution, archiving and playlist creation, are innovations that digitize this workflow, but are primarily used for either a specific digitization task, or disseminating media to the public.
Although these systems facilitate capture, transport and storage of content, footage still needs to be interpreted by the director and editor, this requires a re-reading of paper annotations made on location by other members of the team.Many of these new production technologies aim to integrate media and metadata throughout the workflow, from shooting to broadcast, to streamline data transmission, storage and access.
Instead of facilitating data transfer forwards through the workflow, our proposal is to move creative decisions that would traditionally be performed in the editing and post-production phase back up the workflow into the shoot phase, thereby making use of the creative team already in place.
This is then visualized using a still image of each shot , laid out alongside the script.
Most often this is a sequence of stylized drawings, representing characters, props camera angles and perspective .
Big budget productions such as Hollywood blockbusters use storyboards to plan high-risk sequences and special effects to reduce re-shoot costs and manage risk.
Before the advent of digital filmmaking, storyboards were also used extensively for smaller productions and documentaries.
The process of planning and creating storyboards was a timeintensive, but valuable and money-saving, part of the workflow in which a cross section of the crew would preplan all required shots to reduce lengthy camera setups and tape slicing .
In modern television production, practices have changed and these lists of shots are produced by, and distributed to, a much smaller subset of the production team  or not produced at all.
We therefore chose to reproduce and revise the storyboard in digital form, as a dynamic shared representation for collaborative use by members of the production team during film shoots.
As an external representation it aims to allow any team member to have access to shoot progress and to understand their own role in relation to it.
Rather than facilitate a specific team function, our goal was to facilitate individuals existing roles, supporting creativity in the context of their skill area within the team.. Our prototype design therefore needed to take account of the different forms of creativity and creative input in film production.
A review of the literature on creativity, including Shneiderman et al.
Using a grounded approach to inform our prototype design, we have drawn on aspects of actionable creativity within the literature and have categorized collaborative creative practice within broadcast media according to the following six themes.
A number of design elements can facilitate this process, for example, Santanen et al.
As multi-faceted individuals we are used to re-applying skills to new scenarios.
When users change roles , we share our experience and skills implicitly across role boundaries.
Users change roles depending on the situation, sharing experience and skill dynamically throughout the production process without explicit intention to multi-skill.
In the `Handbook of Creativity', Yamamoto supports this by describing how role flexibility within a scenario leads to a higher creative output within a group .
In addition to the exploration of alternatives, we can consider team members' levels of spontaneous use of unexpected or unplanned processes to accomplish tasks as a measure of group creativity.
These unexpected outputs may be new ideas that don't relate exactly to the task in hand, but that drive the creative process further by linking unrelated ideas together.
As individuals we manipulate an internal representation of the problem space in order to drive creativity.
If members within a team each have access to other members' representations, they are less limited by their own and can use these external inputs as triggers for creative thought.
A study by Warr et al.
A study on Visual DJs reveals building displays to support externalization encourages creativity within subtle creative expression .
It is well understood that during collaboration group members communicate on a variety of levels.
By facilitating a wide range of interaction types and styles, interpersonal conversations should be richer, and lead to a quicker understanding of each other's ideas.
This communication can be explicit, e.g.
In computer science, random access is the ability to access data out of sequence at any time.
In media production, the ability to playback and reference media that was recorded at other times is an important capability that is likely to support creativity.
Although the measurement of creativity is still an open question, defining discrete aspects of collaboratively driven content creation informs the interaction design process, allowing us to gauge success and inform study design.
Our design response was developed through a process of:  mapping our thematic categorization of the creative process onto the roles, skills, processes and practical constraints of television production; and  selecting and configuring interaction technologies and techniques to support these mappings while respecting the practical constraint of television production.
Although modern displays offer multi-touch interaction , using physical tools or objects has the potential to offer a more natural externalization of a user's actions, of which colocated users are more likely to be peripherally aware.
Production crew already carry a number of physical objects, such as radios, clipboards and recording equipment, so providing a space to place these while they interact with any system is an important design factor to consider.
Using these physical representations we can drive group communication, facilitating role changing by providing expressive yet natural interaction for nonexpert interface users.
Elrod supported this argument, and described how electronic whiteboards in presentation scenarios encouraged a wider audience to participate in discussion .
Conversely, he warns of a potential design problem: that users may actually collaborate less.
That is, since users can act on their own, there may be no imperative to communicate with others in order to complete a task.
Peripheral awareness interfaces are a category of information display that provide situated contextual information in a user's environment.
Slideshow is a typical example of such an interface and allows users to ingest an array of information relevant to a task at hand both directly and indirectly .
Placing the point of interaction with the system within reach of all members of the team reduces physical barriers, and encourages spontaneous use and the exploration of ideas without the risk of having leaving the relative safety of their natural location within the shoot.
Current infrastructure demands that video equipment be physically connected on set to operate reliably.
Since film shoots can be in any location, the envisaged prototype must also be easy to transport, configure and operate outside of a controlled environment as discussed when designing MediaCrate .
Furthermore, crews are naturally reticent about use new or untested equipment, and it is therefore desirable that any prototype has a `look and feel' that is consistent with traditional equipment and requires as little specialist knowledge to operate as is possible.
Our understanding of the creative practices we wished to support, the realities of television production, and the limitations and affordances of interaction technologies led us to select a tabletop interface for our prototype implementation.
Tabletops not only afford collocated collaboration and peripheral awareness, but readily support tangible interaction, and can be cast in a physical form that is both appropriate to a production environment and familiar to crew members.
StoryCrate is an interactive table consisting of a computer with two rear-projected displays behind a horizontal surface creating a 60" x 25" high-resolution display, with two LCD monitors mounted vertically behind it.
Shaped plastic tiles used to control the system are optically tracked by two PlayStation 3 Eye Cameras in infrared through the horizontal surface using fiducial markers and the reacTIVision  tracking engine.
The entire device and all associated hardware is housed in a 1.5m long flight case on castors, with power and Ethernet inputs on the exterior, and was built to be robust and easily transportable to shoot locations.
StoryCrate is written in Microsoft .NET 4, utilizing animation and media playback features built into Windows Presentation Foundation.
StoryCrate is built to take on location, and connects via Ethernet to the digital recording system used by BBC.
StoryCrate uses Secure Shell to connect to the Linux based recording system, and monitors the recording directory, downloading new clips and XML metadata as they are created.
StoryCrate keeps track of all media recorded during the shoot so that content can be used at any point, regardless of when it was filmed, providing random access to content for users.
Before shooting, StoryCrate is preloaded with a storyboard  that includes the script, shot descriptions and storyboard images edited into expected timings.
On StoryCrate, this is represented as a linear timeline, where each media item is represented as a thumbnail of the media on the display.
Almost the entire display is filled with this shared representation of filming state, providing users with a single focal point for keeping track of group progress.
The interface is based on a multi-track video editor, where all footage is presented on the display together, allowing users to see and make links between all available clips.
Time is represented horizontally, and a selection of multiple takes  of a shot vertically  and  in Figure 4.
StoryCrate provides discrete functional elements for the following tasks, where each task is independent of another, allowing for complete flexibility and role sharing in how users choose to operate it: * * * * * Adding textual metadata to clips; Playback of both the timeline and individual clips; Selecting in- and out-points on clips; Moving, deleting, inserting and editing clips on the timeline; Adding new hand-drawn storyboard content.
The interface is divided into four key areas , ,  and  in Figure 4 within which Media Tiles can placed.
Clips from the recording system arrive in area  within ten seconds of a take being filmed, and can be moved from here to either the timeline  or the shelf  for later use.
This flexibility in workflow allows users to delay decisions about incoming media, and the ability to quickly move clips around provides an easy method of trying out sequencing and edit ideas, as well as exploring alternatives.
Actions are performed by physically moving acrylic control objects which when placed on the surface interact contextually with elements of the interface, providing a critical externalization of digital actions.
Clips are moved around the display by placing one end of the move control on the clip to be moved, and the other end at the destination point.
The control consists of two tangible objects joined by a sprung cord.
Lifting the destination end control moves the clip, and lifting the source end control cancels the operation.
Metadata takes the form of text key-value pairs and can be added by placing the add meta control onto a clip  in Figure 4.
A list is displayed next to the control and extra buttons located on the control allow the user to navigate the list and select the required metadata tag.
This fine-grained list control is implemented using physical contextual buttons as more than one parameter  is required to navigate the list.
Metadata presence is displayed as an icon on a clip, and in more detail by placing the meta-view control on the Media Tile  in Figure 4.
By using both tangible and bi-manual controls, users' actions are externalized and other members of the team are more readily aware of changes.
Clips are animated between positions both to avoid losing context while performing actions, and to support others' understanding the context when viewed from a distance.
Clips located on the timeline  are played back sequentially using the play head control, which when placed on the timeline represents the current playback position, with the timeline scrolling horizontally underneath it.
When rotated, it can also be used to scroll or scrub through the timeline.
The full resolution output is displayed on the right hand vertical monitor , which is visible from a distance to all team members.
Clips can also be looped on the left-hand monitor by placing the preview control on a clip.
By placing the preview control to the right of the play head control spatially, previews of future clips are automatic.
Clips can be removed from the interface at any point by placing the delete control down.
After a two second timeout, the clip is removed when the control is lifted.
This prevents accidental deletions and allows other users to intervene in critical actions.
Depending on the director, footage may arrive in large sections with multiple takes within a single block of video.
To segment these and cut out useful shots, the clipping control is used .
This controls the left-hand monitor and is physically attached, and oriented perpendicular to the preview control so that they cannot be placed down simultaneously, thereby enforcing an important functional constraint within the tangible control.
When placed on a clip it takes over the entire timeline display, and controls for the in-point and the out-point are used to place accurate markers within the clip.
This forces all users to collaborate on one specific task, while also allowing a high-resolution positioning.
When the operation is complete, the clipping control is removed and the clip is updated.
Multiple takes of the same shot can be stacked on top of each other, as shown in  in Figure 4, by using the take selector control to select the clip to playback within the main sequence.
An important feature of StoryCrate is its facility to allow the addition of new storyboard content during a shoot, allowing users to explore different creative avenues.
This is accomplished using a digital Anoto pen  in Figure 4 and drawing a new still frame on the pad provided.
When docked, this image appears immediately as a clip on the shelf  in Figure 4 like other media.
New metadata pairs can be added by typing directly on the keyboard  in Figure 4, and these are directly available to the add meta control.
These text and freehand drawing capabilities are the only uses for the keyboard and Anoto pen, which prevents ambiguity regarding their functionality, promotes the visibility of these actions, and facilitates faster and more spontaneous input.
Potential conflicts during use, such as two users simultaneously wanting to add metadata are negotiated by providing only one physical control for each action.
This requires users to negotiate for functionality, forcing externalization of their intentions.
When a tangible control is manipulated by a user it displays a subtle expanding circle animation emanating from the center of the object.
Similarly, when the software moves thumbnails beneath an object on the surface a smaller visual indication is made around all tangible objects placed on the display.
These promote users' direct and peripheral awareness that the interface is responding to their input and that of others.
When the shoot is complete, StoryCrate exports the timeline as an Apple XML Interchange  file, which can be directly imported into a video editing system, retaining all metadata, editing and take information.
An editor can use this file directly at a later date, using it as a starting point for the editing process.
A film shoot is a time-constrained, multi-disciplinary creative process which is dependent on a multitude of changing factors e.g.
Production teams have learnt to thrive in these un-predictable environments, and members perform skilled roles and maintain relationships of trust and mutual understanding that minimize the need for complex and detailed communication between team members.
It is impossible to replicate all of the factors that characterize television production environments in a laboratory experiment.
Rogers "Why it's worth the hassle", comments that Ubiquitous computing is difficult to evaluate due to context of use, and that traditional lab studies fail to capture the complexities and richness of a domain .
Consequently, beyond obvious usability issues, lab-based studies are unlikely to be able to predict how a real production team will use, and adapt to, the new technology when it is deployed `in the wild'.
Consequently, we chose to deploy StoryCrate on a live film shoot to evaluate how a real crew would use specific aspects of its functionality, and see the impact StoryCrate had on their workflow.
Deploying a prototype for real world use involves creating a robust system, both in terms of the software and its mechanical properties.
Although high fidelity prototyping has been shown to be an effective approach it is not as widely deployed in interaction design as, say, agile programming for systems design.
One notable hurdle to prototype deployments in a highly skilled environment, such as television production, is the trust that crew have in their equipment.
Crew members come to rely on specific functionality and become used to idiosyncrasies of their own equipment, knowing possible pitfalls and fault points.
They are also acutely aware of the long lead-in times of learning to use new equipment effectively, and the inevitable process of discovering pitfalls and idiosyncrasies in new equipment.
This is especially the case when there is an awareness that the equipment has not been extensively tested in a live environment.
When designing for such critical systems we cannot naively assume that errors will not occur, and consequently our approach was to implement extensive backup and restore functionality, in addition to the clear visual feedback associating all user actions.
StoryCrate's discrete elements of functionality were based on activities performed as part of a traditional workflow.
However, three use cases reflect our expectations about how StoryCrate could potentially improve creativity during a shoot, and in our study we paid particular attention to observing whether aspects of these emerged.
This is where StoryCrate is used by production assistants and crew to log shots and add metadata useful for editing.
The director does not have direct interaction with the system, but allows its use as a logging tool for monitoring shoot progress and logging by the rest of the crew.
In all these cases, we expect shots to be inserted into the storyboard during the shoot.
This creates a rough edit by the end of the active shoot that can be reviewed immediately or at a later stage.
To effectively observe a crew in their natural environment we reproduced a standard configuration for a TV short production.
We commissioned a three-minute script, specifying two to four characters  and four distinct scenes.
We used each of these scenes as a different phase of the test.
The director then worked with a visual artist to develop a pictorial storyboard representing his vision for camera angles and shots.
These frames were combined with the script into a Final Cut Pro project, and imported into StoryCrate before the shoot.
During the shoot, we used aspects of Millens's `rapid ethnography' approach for field tests .
Three ethnographers were paired with filmographers, who were tasked with observing different areas of the team; crew at StoryCrate, crew around StoryCrate, and crew physically distant from StoryCrate.
The ethnographers were briefed with suggested thematic codes to use while observing, and notes were to be time stamped throughout.
In the outer observation space, two further observers filmed and documented the study process as a whole.
Figure 6 summarizes the full set of participants and the members of the film crew and the actors.
This is where StoryCrate is used for clip reviewing.
The director maintains control over it and uses it during breaks to explain current progress and show the rest of the crew what they produced and how content is progressing.
Clips are batch processed into the storyboard at intervals by the production team and only shown to actors when director is happy with a complete section of the storyboard.
This is where StoryCrate is updated whilst filming.
The director explains shot context and ideas using StoryCrate to get the crew up to speed.
Specific shot characteristics can be demonstrated and continuity aspects discussed.
We hired a crew of seven who work full time in the industry to fulfill their normal roles  and four actors, exactly as in a traditional shoot.
Some had experience working together, and some had not.
We ran a half day training session to introduce the crew to basic operation of the device.
The crew was asked to create short thirty-second clips about themselves, each time rotating roles.
Each member was encouraged to try a variety of tools in StoryCrate.
The main film shoot was split into four sessions  each lasting half a day.
At the start of each session, we gave a briefing to the crew about the technology they had at their disposal, and the scene they were to shoot.
From that point onwards, all organizational responsibility was handed off to the production team themselves.
At the end of each session, short interviews were performed with each member of the crew.
After the initial training session, we were informed by the director that they would be appointing Daniel, the runner, to be the designated operator of StoryCrate .
Violet, the script supervisor reported: "I found it helpful having one person that was permanently there moving clips down because I felt like I wouldn't have had time to do that myself."
This suggests that although our design facilitates non-hierarchical operation of the device, a designated operator was needed to maintain data in order to for the rest of the crew to spontaneously interact.
Violet explained: "it's too slow to keep anything up so you can't really build up a full storyboard on what you are doing."
Daniel's primary role as operator was to enter logging information that was called out by Violet, marking clips as they were shot.
Here we can clearly see our expectation of a logging system coming into play, although we had expected crew to use it for their own data individually and independently.
It appeared that the trust relationships within the team were quickly established, and that the runner was given the operator role because it was perceived that he was the most competent.
Daniel supports this: "I spent quite a long time with story crate yesterday getting used to it so maybe they thought `Dave can do it'".
But even within this designated role he was subject to hierarchical overruling: "when the Crate needed to be used and the director wanted to use the Crate then actually he displaced me from the Crate and took over himself."
The goal of the study was to understand the impact of StoryCrate on the practices of this particular production team.
Furthermore, because storyboards are not in common use , it was important to distinguish between team interaction based around the existence of a storyboard, and interactions facilitated by StoryCrate.
We therefore only allowed the crew to use StoryCrate for the first and last session, used a printed paper storyboard for the second session, and no storyboard at all for the third session.
Although the film shoot was managed in a traditional manner, with the director taking operational control, we explicitly encouraged the use of StoryCrate.
The director was briefed to use the system in a way that facilitated the shoot, but also to be open to changes in team working practices.
Importantly, our briefing emphasized the importance of concentrating on quality of product.
At the beginning of the fourth shoot the director decided that he was going to shoot the scene completely differently to the way it was storyboarded.
While waiting for actors to finish makeup, he gathered the crew around StoryCrate and spent 20 minutes drawing out each new storyboard tile as Daniel inserted them into a new timeline.
The script supervisor commented: "in gathering round and discussing round the storyboard, I felt like that was a good moment to make your creative input and it facilitated that."
This clearly supports our expected use case of facilitating creative input within the team, allowing users to contribute to a discussion, and be aware of resulting changes.
The cameraman mentioned that displaying this new content in a timeline context was helpful: "it was a useful opportunity to just have a glance at what he was planning to do.
The way he was explaining it wasn't particularly clear.
But because most of the storyboard was already there, being able to see the thing at a glance helped."
This also suggests that although StoryCrate was too timeconsuming for operation during the shoot, the ability to have a shared public representation of the new plan was helpful.
The facility for hand-drawn input to the system motivated the lighting engineer to contribute.
He had initially declined to engage with the StoryCrate as he felt it was outside of his professional role.
Here we report the result of our initial analysis, for which we selected five significant facets of interaction that were observed during the deployment.
Demonstrated with specific examples, we have selected quotes from crew interviews to discuss how our design choices influenced the shoot and explore avenues of investigation for later analysis.
Although this was not subsequently inserted explicitly into StoryCrate, a digital copy would be transferred to the editor.
These initial observations demonstrate that the ability to create new content during the shoot was a useful functionality of the interface, and that the director's use of the shared display to scaffold explanation and discussion of plans within the group drove creativity and ownership of ideas, even without passing this data through the workflow to the editor.
During the second session, where the crew was without StoryCrate, an `over the shoulder' camera angle became difficult as no one could recall the previous shot angles, and where actors were stood .
Using the digital recording system, playback is limited to single files from a list, and vital sections have to be memorized to recall them.
Enraged at the inability to play back previous clips to match against, the director shouted "this is where we really need the  Crate".
It was decided by the crew that to start session four, various shots from the first day would be re-taken.
For the crew, this involved re-dressing the set, re-setting the lighting and matching the camera angles.
The director commented: "Then we used it  to check the sequence of storyboards and whether we had got the shots we needed.
It became a much more general reference point as the two days had gone on because we had done so much that we could - needed to go back and check we weren't missing stuff."
At this point StoryCrate was used primarily for reviewing clips from the previous day to match up the current environment with the pre-recorded version, using it is a master reference to what had been shot and what was good quality.
This functionality was a key aspect of our expectations, the use of playback for clip review to assess continuity.
The sound operator summarized this functionality: "you see and hear playback, which otherwise on a film set may not be quite so easy.
I mean, there's like a central place that you can go to."
Without the independent units of functionality that StoryCrate provides this would not have been possible, as this practice was outside the traditional workflow of a production team.
With this analysis we hope to ascertain how this playback functionality drove efficiency within the team, for example, by allowing them to re-shoot parts they would not have had time to otherwise.
Interestingly the large vertical display was used by most of the team from a distance while performing their roles in situ, so this physical aspect of its configuration alone was a useful component.
We integrated StoryCrate into the recording infrastructure so no additional effort was required on the part of the user.
Daniel commented: "I do wonder if I've just been sat there dragging clips to a viewable area where  is doing that at the same time."
Due to this seamless integration, it was confusing for the crew to separate which piece of equipment was of interest to the study, and which was well tested equipment, as both were new to them.
As we observed, this led to StoryCrate primarily being used as a large screen playback device, visible to the whole crew.
Interestingly this differs from our expectation of playback at the end of a shoot, as it was used primarily to guide new shots, rather than review an entire scene.
Due to the design of the study, the crew were unaware how the resulting data from StoryCrate was going to be used by an editor later in the production process.
Daniel stated: "It's difficult to know without seeing a finished product and seeing how well it helps the editors but just from being able to show someone who has just taken shots `oh what does this look like?'
This highlights an interesting aspect of prototyping in the wild: although we have expectations as to how users may interact with a prototype, we cannot design for transient factors produced by external equipment which affect the process as a whole.
During implementation, the issue of how robust a prototype needed to be to effectively elicit information about key design features rather than be overshadowed by `in the wild' operational problems relating to deployment.
As it turned out, hardware tracking issues were raised during the study, and these were partly overcome by the designated operator learning other ways to accomplish a task.
Violet commented: "I found it frustrating trying to drag stuff down and it wouldn't, and that just becomes more timeconsuming than it's worth when it's not obeying."
Whereas Daniel said: "having all the lumpy bits you put on, I found I needed another couple of  and couldn't quite put my hands on them, but that's just a storage thing if you get into the habit of putting everything in the right place, then you know where they are."
This suggests that although at first the implementation was problematic, tangible controls became usable by spatially arranging them in known locations.
The issue of durability and robustness come into play here, and it is worth noting that although the interface became hard to use for particular tasks, these were nondependent tasks and thus the system was flexible and could function even through technical problems.
As in Daniel's earlier quote, tangible objects facilitated the transfer and holding of power over the interface, primarily during points where users gathered around it.
While one person held control over the move and play head tangible, most other actions were irrelevant as they interfered with the primary user's task.
We have presented a prototype collaborative system for augmenting traditional film production during a shoot..
The interface uses a storyboard to present a single point of reference for the entire crew, enabling a greater awareness of current progress, facilitating creativity and ownership of content within the team and driving decisions made on site directly into the current digital workflow.
Rather than design for a particular workflow, we define aspects of creative practice relevant to film production, using this to inform our implementation.
We then use a prototype to elicit responses from the domain by placing it on a real film shoot, observing user communication, creativity in practice and team awareness, towards understanding collaborative design in this context.
We articulate five interaction scenarios from our observation, discussing how tabletop and tangible design decisions influenced team interaction with the device, and how this may drive the creative workflow within the team.
We will be using these initial scenarios to guide further indepth investigation into our data, at all times referring back to the creative aspects which we defined and the affordances of co-located surface computing for media production.
Wider concepts can also be investigated from this study, such as the benefit of the storyboard in modern film practice and the value of a single reference point in unpredictable environments.
We describe the context and environment in which shared tangible interactive displays can be used to encourage practice, and hope to encourage other researchers to use exploratory prototyping as a method of driving forward existing processes in complex social domains.
The case for domain specificity of creativity.
Bartindale, T., Hook, J., Olivier, P. Media Crate: tangible live media production interface.
Designing and deploying an information awareness interface.
Liveboard: a large interactive display supporting group meetings, presentations, and remote collaboration.
Firestien, R. and McCowan, R. Creative problem solving and communication behavior in small groups.
