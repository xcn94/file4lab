People sometimes miss small parts of meetings and need to quickly catch up without disrupting the rest of the meeting.
We developed an Accelerated Instant Replay  Conferencing system for videoconferencing that enables users to catch up on missed content while the meeting is ongoing.
AIR can replay parts of the conference using four different modalities: audio, video, conversation transcript, and shared workspace.
We performed two studies to evaluate the system.
The first study explored the benefit of AIR catch-up during a live meeting.
The results showed that when the full videoconference was reviewed  at an accelerated rate, users were able to correctly recall a similar amount of information as when listening live.
To better understand the benefit of full review, a follow-up study more closely examined the benefits of each of the individual modalities.
The results show that users  preferred using audio along with any other modality to using audio alone,  were most confident and performed best when audio was reviewed with all other modalities,  compared to audio-only, had better recall of facts and explanations when reviewing audio together with the shared workspace and transcript modalities, respectively, and  performed similarly with audio-only and audio with video review.
As a result, they may need to review the material they missed.
The majority of the previous work in the area of meeting review has focused on post-meeting review .
Post-meeting review is beneficial when the missed segments are not critical for the rest of the discussion and can be reviewed after the meeting has finished.
However, in other cases, the missed content provides necessary context for rest of the discussion, and participants would benefit from being able to review it during the meeting.
In our work, we focus on enabling users to review during the meeting, which we refer to as in-meeting review.
Since asking others about missed content can be disruptive, we investigated mechanisms that enable participants to privately catch up.
Our initial focus is on providing in-meeting review for fully-distributed videoconference meetings.
Additionally, our focus is on scenarios in which participants miss small portions  of the meeting.
A key requirement for in-meeting review is that it should enable users to review past content without missing new content being generated in the live discussion.
One approach is to present only past information during review periods but present it in such a way that users can catch up to the live discussion.
Recent work by Tucker et al.
Their results showed that users understood the meeting better and were more confident in their understanding when they were able to review the missed content using audio-gisting.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Our work investigates the potential of accelerated multimodal review for in-meeting scenarios.
We built a new system that enables users to review content in real-time during an ongoing meeting called Accelerated Instant Replay  Conferencing , shown in Figure 1.
AIR incorporates DVR-like features, including pause, rewind, and accelerated review, to support several catch-up modalities including audio, video, shared workspace actions, and conversation transcript.
We evaluated the benefit of AIR through two user studies.
The first study explored the benefits of AIR catch-up during a live meeting.
The results showed that when reviewing the full videoconference  at an accelerated rate, users were able to correctly recall a similar amount of information as when listening live.
To better understand the benefit of full review, a follow up study more closely examined the benefits of each of the individual modalities.
The results show that users  preferred using audio along with any other modality to using audio alone  were most confident and performed best when audio was reviewed with all other modalities,  compared to audio-only, had better recall of facts and explanations when reviewing audio together with the shared workspace and transcript modalities, respectively, and  performed similarly with audio-only and audio with video review.
Next, we present relevant work for in-meeting review.
We then describe the AIR Conferencing system.
Then, we describe the results of our initial study that evaluated the system in a three-way distributed meeting.
Following this, we describe the results of our second, more in-depth study that more closely examined the benefits of each of the individual modalities.
Finally, we conclude with discussions, the future potential of in-meeting catch-up systems, and the insights we gained from this work.
However, dropping frames may degrade the replay experience.
While the resulting quality problems with video are difficult to solve, audio quality issues, such as pitch shift, can be corrected .
Experimental results suggest that a compression ratio of 2 is reasonable  for audio.
The low computational overhead and the lossless features of this approach make it tractable as a method of catching up in a live videoconference.
Linear compression, however, is not content driven.
Video skimming  is a technique that takes into account the context of content to create abbreviated content-driven summaries.
More recently Tucker et al.
Their system uses a compression ratio of 2.5.
Contrasting our catch-up approach to Tucker et al.
However, the quality of the resulting gist depends on the accuracy of the mechanisms used to create the gist.
Current state of the art speech-to-text systems typically require several hours of training for each user to gain reasonable levels of accuracy.
Also, gisting can result in the loss of information because the gist summarizes most but not all content.
Providing users with the ability to review recorded meetings has been explored extensively in previous research.
Prior work has investigated ways to facilitate automatic meeting capture , ways to automatically index meetings , and methods to replay multimedia content .
Compared to these approaches, our work focuses on fully distributed videoconferences and addresses techniques to review multimedia content.
Previous research has identified several key approaches for efficient multimedia playback including static summaries , linear compression , and video skims .
Static summary systems convert video segments into less rich modalities, such as a textual summary or a single image .
While they can be helpful for reviewing large amounts of content quickly, they reduce the fidelity of information by removing temporal aspects and serve as a lossy conclusion of what was presented.
These issues can be solved by compressing content instead of changing its modality, which is the approach taken by linear compression systems.
The AIR  Conferencing system  is a multi-user desktop videoconferencing system with in-meeting review features.
The videoconferencing portion of the system provides users with high quality audio and video of all participants, a shared workspace for data collaboration, and a real-time text transcript of the audio.
When observing the live content , users interact with AIR through a window containing four panels shown in Figure 2 .
The Video panel shows live video feeds for all remote users.
The Shared Workspace panel provides a shared workspace that any user in the conference can interact with.
The Transcript panel displays the conversation transcript generated by an automatic speech recognizer.
Each user's text is preceded with the user's name and is shown in a different color than the text of other users.
The Review panel contains review controls to mark catch-up sections and start in-meeting review.
When using the in-meeting review feature, users interact with AIR using a separate window, shown in Figure 2 , that contains the same four panels as those in the live window with minimal differences.
In particular, the Control panel displays a timeline allowing users to select a section of the conference to be reviewed.
The other three panels display the reviewed content at an accelerated rate instead of the current meeting discussion.
Both the live and review windows are visible during catchup sessions, enabling users to monitor the live meeting while simultaneously reviewing content from an earlier point in time.
Users can choose whether to listen to the live meeting or past audio, but not both.
By default, the playback is accelerated to a rate of 1.6 times normal to enable catching up to the live meeting.
We solved the audio pitch and intelligibility issues that arise when audio is played back at an accelerated rate by using an audio speedup technology that employs pitch correction and silence adjustment techniques to make sure the audio sounds meaningful even when played back at a faster rate .
The meeting took place in three adjacent usability lab rooms.
Upon arrival the participants were given a brief introduction to the study and then asked to fill out a short background questionnaire.
Participants were then given a ten-minute training session on the AIR Conferencing system, after which they began the main study task.
The main study task was designed to mimic a "status update" meeting, where each person is asked to give a short presentation on their project.
These types of meetings are common in business environments.
Instead of requiring our participants to prepare a presentation, we provided them with a presentation that prompted them for their preferences in a number of areas  through multiple choice questions.
Each participant was given twelve minutes to answer as many questions as possible .
For example, one question was "Which of these web browsers is your favorite?"
The participant  read each question out loud,  picked one of the choices, and  gave a short explanation.
The other group members were asked to remember answers and explanations.
Each group member answered the same set of questions but in a different order than the other group members.
We wanted to simulate interruptions during real meetings.
Thus, during each presentation, the participants experienced two interruptions where they left the experiment room and stayed out for 90 seconds before rejoining the meeting.
This ensured that content from the live presentation was missed.
After an interruption, the participants were instructed to review the portion of the meeting that they missed using one of three catch-up techniques.
At the end of the meeting, each participant completed two quizzes.
Each quiz repeated the multiple choice questions answered during one of the presentations the participant observed.
Each question also asked for the explanation given by the presenter.
The question order in the quiz corresponded to that of the presentation.
We recruited eighteen participants  between the ages of 24 and 45 , from a large software company.
The participants all had a technical background, were comfortable with technology, and most  considered themselves to be early adopters of technology.
Participants were recruited in groups of three.
All members of a group knew each other well .
We first conducted 30 minute interviews with each participant to gather background data, measure interest in a system like AIR, and train the speech-to-text system used by our prototype.
We explored three different review conditions in this study: transcript-only, muted-review, and full-review.
In the transcript-only condition, users manually scrolled the speech-to-text window so that they could see a transcript of the conversation that they missed.
No separate review window was launched and audio from the live meeting was still played.
In the muted-review condition, a muted version of the video conference was reviewed in a separate window, including video, shared workspace , and transcript.
The live meeting was still visible in the live window, and its audio was still played.
In the full-review condition, a full version of the video conference was reviewed in a separate window, including audio, video, shared workspace, and transcript.
The live meeting was still visible in the live window, but its audio was muted.
In the muted and full-review conditions, content was reviewed at a rate of 1.6 times the normal speed.
We chose this rate over 1.4 times, which was used previously , and 2.0 times the normal speed, which has been shown to be on the upper end of what users can understand .
Through our own pilot testing, we felt that this rate was a good compromise between speed and understandability.
As mentioned above, each participant gave one presentation for a total of three presentations per group.
Each nonpresenting participant was interrupted twice during a presentation.
After an interruption, the participant used one of the catch-up conditions to catch up.
All conditions and orders were counterbalanced to create eight orderings.
Getting to know what was covered and who said it and the body language would put me back into the meeting very quickly."
While many of the participants felt that it would be beneficial to "get context and avoid interrupting the meeting with questions that had already been covered," for a number of participants, the answer ultimately depended on the context of the meeting, how much they missed, and the type of catch-up mechanism.
One participant explained, "It would depend mostly upon the importance of the meeting, followed by the duration of how much I missed, and finally, on how discreetly I could review the video."
Some participants were concerned that the review might be disruptive to the rest of the meeting, "If it can be done discreetly, then all the better."
Also, there was concern that if they spent time catching up on missed information, they would end up missing more of the meeting, "I wouldn't want to miss more information  reviewing missed parts."
Another participant mentioned that "Reviewing the video may force me to stay behind, but maybe if it looks like an unimportant or uninteresting  conversation is taking place and that gives me a window to catch up."
One participant expressed desire for an accelerated review feature, "If it was short and especially if I had a way of speeding up the content or seeing a transcript to help me multi-task and also not miss any  content."
These interviews suggest that users could benefit from a DVR-like in-meeting review system that allowed them to review missed content and catch up to the live discussion quickly.
The background interview gathered information on users' previous experiences with missing parts of meetings, videoconferencing systems, DVR systems, and their interest in having a real-time review option during meetings.
All of the participants reported sometimes missing parts of meetings, typically for less than five minutes.
While they employ various strategies to review missed content, none of the strategies included viewing recordings of other participants or whiteboards.
Thus, some content, such as facial expressions, gestures, and whiteboard data, are apparently never reviewed during meetings.
Moreover, no participant brought up the idea of recording a meeting for in-meeting review, even though many of them use DVRs to pause, replay, and fast-forward TV content to handle scheduling conflicts, breaks, and interruptions.
When asked whether they felt it would be useful to review what they missed during a videoconference, ten participants indicated yes, seven indicated maybe, and only one indicated no.
One participant explained, "Often you miss Some of the results from the background interviews were presented in a poster at ACM Multimedia 2010 .
We analyzed the participants' scores on the quizzes from the group session to assess the effectiveness of the catch-up techniques on participants' recall.
The system crashed for one participant so we report on data from seventeen participants in this section.
We calculated a baseline recall score for each participant based on the percentage of correct answers they had for the parts of the presentations they viewed live.
We compared the participants' scores for the baseline, as well as the transcript-only, muted-review, and full-review techniques.
The percentage correct for each category is shown in Table 1.
Pair-wise post-hoc analyses of the experimental condition results  revealed that participants' recall using the full-review condition was not significantly different than their baseline recall .
However, recall in the transcript-only and muted-review conditions were significantly worse than both the fullreview condition and the baseline recall .
Examining the results by answer type revealed that the participants performed significantly worse on the explanation answers than the fact answers, and this result was consistent across the experimental conditions .
An important question is whether the additional modalities  have additional benefits.
Second, despite the fact that we trained the speech-to-text system for each user, the quality of the conversation transcript was poor for many users.
This effect likely had a significant impact on users' performance and preference.
Four participants explicitly commented that they preferred the full-review condition because the "transcript quality was low" in the other conditions.
We asked participants to re-rank the conditions assuming perfect transcription .
Assuming perfect transcripts, there were no significant differences between the conditions .
The idea of a perfect transcript swayed some users away from the full-review to transcript-only and muted review: seven preferred transcript-only; six wanted full-review; and two desired muted-review.
Therefore, it is important to reevaluate the benefit of transcript-only review when the speech-to-text system is perfect.
Third, the fact that users swayed away from full-review when the transcript is perfect indicated that they believe that they can use the transcript to catch up on past information while simultaneously listening to the live audio.
To investigate further, we asked the participants to indicate whether it was difficult to attend to both the past and the present at the same time on a five point scale .
Fourteen people strongly agreed  or agreed  that attending both the past and the present at the same time was difficult.
Two participants found it neither easy nor difficult, and two found it somewhat easy.
The debrief interviews revealed that while the participants had different preferences for whether or not they would like to hear live audio and read the past transcript or vice versa, one constant across all participants was that if the speech-to-text engine generated more accurate transcripts, it would have been easier to pay attention to both past and present at the same time.
As it were, reading and understanding the transcript made it difficult to listen to audio concurrently.
Next, we describe a second user study of in-meeting review mechanisms that addressed the role of audio relative to other catch-up modalities and accuracy of the transcript.
We leave the issue of divided attention for future work.
After completing the main task and the quizzes, the participants were asked whether it would be useful to use a system like AIR to catch up on what they missing during a meeting.
A 5-point scale  was used.
Eleven participants strongly agreed that it would be useful to use a catch-up system like AIR, six somewhat agreed, and one somewhat disagreed.
Participants were also asked to report which of the three catch-up mechanisms they preferred.
These participants commented that:         "It was fast, easy to concentrate and auto catch-up" "Easier to playback and comprehend" "Ignore what was live as I had full fidelity" "Leads most smoothly into rejoining live" "The only one that let me digest information" "Seems like the only way to catch up in a focused way" "I feel like I can cheat in time with fast forward" "I can listen to audio while watching the live slide show and transcript"
The lengths were different because the actors took longer to answer questions in the second meeting.
After each meeting, the participants were asked to complete a quiz which contained all questions from the meeting but in a random order.
The participants had to recall  the answer to the question,  the identity of the presenter who answered it, and  the explanation given for the answer.
Following the quiz, the participants completed a questionnaire regarding their confidence in their answers and their experience during the live and review parts of the meeting.
At the end of the session participants also completed a free-form questionnaire regarding their preferences for the catch-up mechanisms they used.
They were also told that they would be interrupted and asked to catch-up on what they missed using two different catch-up mechanisms.
The simulated status meeting task from the first study was re-used in this study, modified slightly to have two presenters per meeting instead of one.
To maintain consistency, two meetings were pre-recorded using two actors who answered questions from the shared presentation.
The participants took on the role of the third person in the meeting .
For both meetings, the presentation, complete with audio, videos, and shared workspace, were recorded.
The audio was also manually transcribed and synchronized with the audio and video to ensure a perfect transcript.
The meetings were then played back using a system that matched the look and feel of AIR .
Because of the divided attention challenges reported in the first study, this version of AIR showed either the review or the live window, but not both, and automatically switched between them.
Each meeting consisted of 40 questions, where the presenters alternated every five questions.
Additionally, the presenters clicked on their answers in the shared workspace to provide visual confirmation of their choice.
The first meeting was 7.5 minutes long and the second meeting was 8.25 minutes long.
These six conditions are shown in the six smaller images in Figure 3.
We refer to conditions three through six as the enhancedaudio review conditions.
The audio-only condition was used as a baseline for all 58 participants.
The remaining five conditions were evaluated as a between subjects factor with each participant completing the task using one of these modalities .
Each of the enhanced-audio conditions had twelve participants, while the transcript-only condition had ten.
Condition and meeting order were counterbalanced across participants.
The main goal of this study was to explore whether video, shared workspace, and transcript added value over an audio-only catch-up.
We first analyzed results for the four enhanced-audio conditions  compared to audio-only and live , followed by a separate analysis of the transcript-only condition .
For the recall results, we analyzed participants' answers for the multiple choice questions , the short answers , and identification of the person answering the question .
We calculated recall scores for each participant based on the percentage of correct answers they had for the questions they viewed live, the catch-up questions in the audio-only condition, and the catch-up questions in the enhanced-audio or transcript-only conditions.
For the preference and confidence ratings, we analyzed ratings from the post-meeting questionnaires which were based on a 7-point scale where 7 was extremely confident .
Participants had significantly higher recall in the enhanced-audio session than the audio-only session but significantly lower recall when live  as shown in Table 2.
Audio+All: For all question types, recall was significantly higher in the audio+all condition than the audio-only condition , but not significantly different than live  as shown in Table 3.
Audio+Workspace: For facts, recall was significantly higher in the audio+workspace condition than audio-only  but not significantly different than live .
For explanations and identification, recall in the audio+workspace condition was significantly lower than live  and not significantly different than the audioonly condition .
Audio+Transcript: The results were mixed for the audio+transcript condition.
For facts and identifications, the audio+transcript condition was not significantly different than either the live or the audio-only conditions .
For explanations however, the audio+transcript condition had significantly higher recall than the audio-only , but significantly lower than the live condition .
Audio+Video: For all question types, recall was significantly lower in the audio+video condition than the live condition  but not significantly different than the audio-only condition .
During the post-meeting questionnaire, we asked participants to rate their confidence in the accuracy of their answers overall and for facts, explanations, and identifications separately .
Wilcoxon signed ranks tests revealed that for all confidence ratings, participants were significantly more confident in their answers in the audio+all condition than the audio-only condition .
None of the other conditions had significantly different confidence ratings compared to audio-only.
Feedback from participants on the final questionnaire and during the debrief session provide insights on the benefits and weaknesses of the different enhanced-audio configurations.
For example, some participants indicated that in the audio-only condition, the audio was disembodied and difficult to follow: "The speeded up audio for me was difficult to understand sometimes;" "When it was audio only, I didn't have a place to look or focus at so I lost focus in the conversation.
It was really difficult for me to focus on the audio."
One participant stated that anything in addition to audio would help because there were no clues to understand audio when it went too fast, "There was no other reference.
A lot of things kind of blew by me ...
I would have liked to have any other clue at that point."
In the enhanced-audio conditions, audio could be correlated with other information and hence it was easier to understand and remember what was said.
Percentage of correct answers for the enhancedaudio conditions.
1Not statistically different from live but significantly better than audio only.
2Not significantly different than audio only.
3Recall of explanations significantly better than audio only, but significantly lower than live.
Significance was measured as p<.05.
Examining each of the enhancedaudio conditions separately, we found that all conditions were significantly preferred over the audio-only condition  except for the audio+transcript condition .
Recall results were analyzed using a mixed repeated measures ANOVA, with two within subject variables: session {live, audio, enhanced audio} and question type {fact, explanation, identification}; and two between subjects variables: condition {audio+all, audio+workspace, audio+transcript, audio+video} and gender.
Bonferroni corrections were used for all post-hoc analyses.
The results are shown in Table 2 and 3.
A significant interaction effect was found for session and question type , so we examined each question type separately.
For the audio+video review, participants indicated that the video review made it easier to remember which presenter answered each question, "Being able to see who was talking during catch-up helped to associate a face, name, and voice with the answers given," and "Video kept my attention and enabled me to focus on what and who said it."
Others, however, found the video less useful, "Video does not convey a whole lot," and "The video on the catch-up, that added nothing to the ability to pick up ."
For the audio+workspace and audio+transcript reviews, participants used the shared workspace and transcript as a reference to what they were hearing.
One participant in the audio+transcript condition found that she had trouble following the accents of the actors, and she used the transcript to double-check what she heard, "The written language was essential because the verbal was not enough for me."
Others said that they were visual learners, "I'm a visual learner, so I heard and remembered more."
Some participants who used the audio+all review mechanism noted that they mainly used the shared workspace to cross reference what they heard.
However, when that cross-referencing was not sufficient for full understanding of the audio, they also cross-referenced the audio with the transcript.
As one participant put it, "I used the presentation to answer the questions, I used the audio to see who was talking, and every time I missed something, I had the transcript which kept a recording of everything and I could just look back at it."
Others simply used the transcript to cross reference the audio and ignored the shared workspace, "It's easy to listen and watch with the ability to check the transcript for the things you miss."
Overall, some participants simply said more is better, "given the choice, the more information the better.
It seemed very clear when you had all three of them ," while some others said that a minimalist approach works best "I found that the more information that was there, the more confused I became.
I think I did better during catch-up when I had audio-only."
Finally, there were no significant differences in the participants' ratings of their confidence .
Feedback from the participants indicated that they found it more difficult to keep up with the text during review in the transcript-only condition than the accelerated-audio in the audio-only condition.
As they put it, "I had difficulty following the scrolling," "I would much prefer to hear you talking faster.
It was much easier to catch up than following the transcript," and "Transcript alone was way too fast to really understand what was going on.
I could kind of skim it and I got some information but I felt like I was just bouncing along."
Others realized later that they were not actually reading all of the information in the transcript, "I would read the words, but I would forgot to read the names."
Several of them commented that it would have been better to allow manual scrolling through the transcript.
While our mocked up version of AIR used in the study did not support this functionality, the real AIR system does.
Of the ten participants that took part in the transcript-only condition, only two preferred transcript-only.
Feedback from the participants indicated that they found it more difficult to keep up with the text during review in the transcript-only condition as compared to the accelerated audio in the audio-only condition.
Table 5 shows the recall results for the transcript-only condition compared to audio-only.
Examining each question type, recall was significantly higher for facts in the transcript-only condition compared to audio-only  but no significant difference was found for explanations .
The main results of this study demonstrate that enhancedaudio catch-up is superior to audio-only review.
Both the subjective and objective results are consistent with this finding: overall, users preferred, felt more confident with, and performed better with enhanced-audio than with audioonly review.
Closer examination of the individual modalities in the enhanced-audio conditions shows that compared to audio-only review, using all of the modalities to catch up showed the strongest benefit, with significantly higher user confidence and recall of facts, explanations, and identification.
Additionally, using audio along with the shared workspace and transcript modalities for catching up significantly improved the recall of facts and explanations, respectively, compared to using audio-only.
Finally, results from the transcript-only condition showed that this condition is slightly better than audio-only for fact recall, but was significantly worse for speaker identification.
In terms of preference however, most participants did not like the transcript-only condition.
We have presented results that show the benefit of the AIR Conferencing system in a practical scenario - a status update meeting - when user absences are brief  and the number of users is small .
In this section, we address our contributions with respect to their ecological validity and generalizability, and discuss other important issues concerning in-meeting review systems.
Data from the interviews in our first study indicate that a system like AIR would be useful in real meetings.
Specifically, users reported that they arrive late for meetings or get interrupted, and they want to be able to catch up on information they missed.
They also reported that these interruptions were relatively short .
In addition, most of the interviewed users had previous experience with both videoconferencing systems and DVR systems, and see benefits to both.
Given that people frequently take advantage of DVR-like functionality  when they miss something, or do not understand something when watching television, it is plausible that this type of behavior could easily transition to videoconferencing.
When asked about this possibility, most of the users in the study strongly felt that these features would be useful.
Overall, these findings suggest that an accelerated review technique for in-meeting review could be useful for reviewing missed content.
In this case, an attendee may want to jump from replay to live if something interesting comes up in the live discussion.
Similarly, a reviewing attendee may want to jump to the live meeting when asked a question.
Handling these situations requires that users divide their attention between past and live content.
In our first study, some participants did so by reading the transcript of one and listening to live audio of the other.
In general, participants could not act on divided attention cues because we controlled the replay to ensure consistency between participants and across conditions.
Our participants always reviewed all content from the point in time at which they were interrupted and were not allowed to jump to the live discussion manually; instead, they had to wait for the replay mechanism to catch up to live.
These replay restrictions allowed us to study replay effectiveness in absence of variables arising from control of the mechanisms; however, letting users choose when, what, and for how long to review would provide insights on how users multitask in meetings and help us better understand issues of divided attention.
In general, attaining ecological validity is a difficult task.
The studies presented in this paper were designed to evaluate the usefulness of an in-meeting review system.
Therefore, it was important to select a task that was both realistic and would allow for an objective evaluation.
Given the conflicting nature of these requirements, we chose to focus on subparts of meetings that are common to many different types of meetings.
Specifically, meetings typically have periods of presentation and recall.
Our studies targeted these meeting subtasks.
For instance, during presentations, facts are often presented, and when a participant wants to ask the presenter a question, the participant must recall some of these facts.
During brainstorming sessions, factual data is often presented, such as the explanation of an idea or the reasons for pruning or choosing an idea.
As brainstorming meetings are more interactive, people must recall not only facts and explanations, but also the participant who presented them.
The task we used in our studies focused on presentation and recall, which are common sub-tasks of real meetings; however, the structure of these in our task was simple and modular, consisting of alternating presentation and recall periods.
While some real-world meetings are modular, many have a more complex structure.
We did not evaluate how well in-meeting review systems support more complex meeting structures.
In addition to controlling the meeting structure, our study also controlled the interaction style.
In particular, the nonpresenting attendees were passive participants.
They did not interrupt the presenter and were specifically told not to ask the presenter to catch them up when they returned from an interruption.
In some real-world meetings, attendees are passive; however, in other kinds of meetings, all attendees have a stake in the outcome and are actively participating.
The results of this work demonstrate the potential of inmeeting review; however, there are several questions that have not been answered by this work.
One question is the social impact of review systems.
For instance, in some cases, such as a fully-distributed videoconference, the review can be done privately.
In such cases, in-meeting review may not have any social impact.
However, in other cases, such as face-to-face meetings, the fact that an attendee is reviewing is going to be obvious to other attendees, which may have negative side effects.
For instance, others may think that the reviewing attendee feels the current discussion is not important and is choosing not to participate live.
In-meeting review systems may also impact meeting dynamics.
For instance, what will happen if multiple attendees are reviewing at the same time?
How is the conversation impacted?
At what point does the meeting break down?
What happens if all participants are reviewing?
Before in-meeting review systems are introduced in real-world settings, the impact on social and meeting dynamics needs to be evaluated further.
Finally, we studied several modalities and their combinations as catch-up mechanisms.
However, we did not study all possible combinations of modalities.
Of particular interest is the combination that reviews everything but video.
Since video is typically the most expensive modality in terms of computation and bandwidth resources, if lack of video does not significantly alter user preferences and performance, then future systems could review video only when resources are abundant.
Also, some of the catch-up mechanisms we studied provided users with a computer generated speech-to-text transcript.
Until speech-to-text systems improve so that they are accurate with little or no training, the use of speech-to-text transcripts for catch-up purposes is going to be limited.
Eventually, when they do improve, the use of audio+transcript with or without any additional modalities may become a viable catch-up mechanism.
This work makes several significant contributions.
We show that users prefer reviewing audio along with any additional modality to reviewing audio alone.
We also show they are most confident and perform best when audio is reviewed simultaneously with video, shared workspace, and conversation transcript.
Additionally, they had better recall of facts and explanations when reviewing audio along with the shared workspace and transcript, respectively, compared to reviewing audio only.
However, when reviewing video along with audio, they performed similarly to when reviewing audio only.
Also, the transcript-only review improved their recall of facts but degraded their recall of speaker identification compared to audio-only review.
Finally, we designed a new in-meeting review system that goes beyond replaying just audio by incorporating audio, video, shared workspace actions, and a speech-to-text transcript into an accelerated review and demonstrated its usefulness in a live videoconference.
Our work also suggests several design considerations for future catch-up systems.
Feedback from our research indicates that there is a cost/benefit tradeoff.
The missed information needs to be important enough to warrant review and the system needs to be easy to use.
If either of these two dimensions is off, users may not utilize the system.
Additionally, users are concerned about disrupting the meeting or missing more of the meeting when trying to catch-up.
Care must be taken when designing the user experience to ensure that the process is seamless and does not detract from or disrupt the flow of the meeting.
We have explored several catch-up mechanisms in our AIR system; however, we have barely scratched the surface of in-meeting support.
We plan to explore the potential of catch-up mechanisms that use different combinations of the modalities we studied and other new modalities, such as spatial audio and shared workspaces that support pen and touch interaction.
We also plan to study how well users can attend to both the past and the present through audio spatialization by leveraging the cocktail party effect.
In addition, we intend to evaluate the social impact of inmeting review and study how it affects meeting dynamics.
