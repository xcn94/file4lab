Although typing on touchscreens is slower than typing on physical keyboards, touchscreens offer a critical potential advantage: they are software-based, and, as such, the keyboard layout and classification models used to interpret key presses can dynamically adapt to suit each user's typing pattern.
To explore this potential, we introduce and evaluate two novel personalized keyboard interfaces, both of which adapt their underlying key-press classification models.
The first keyboard also visually adapts the location of keys while the second one always maintains a visually stable rectangular layout.
A three-session user evaluation showed that the keyboard with the stable rectangular layout significantly improved typing speed compared to a control condition with no personalization.
Although no similar benefit was found for the keyboard that also offered visual adaptation, overall subjective response to both new touchscreen keyboards was positive.
As personalized keyboards are still an emerging area of research, we also outline a design space that includes dimensions of adaptation and key-press classification features.
Despite these challenges, touchscreens offer a major potential advantage over physical keyboards: they are software-based, and, consequently, the keyboard layout and key-press classification models can dynamically adapt to each user.
In previous work, for example, we used simulations of touchscreen typing data to show that a personalized input model for ten-finger typing greatly improves key-press classification accuracy over a model aggregated across all users .
However, we did not actually build an adaptive keyboard, leaving future work to capitalize on the implications of those findings.
Furthermore, other empirical exploration of personalized keyboards for ten-finger typing has been almost nonexistent, with the only user evaluation to our knowledge showing no performance benefit over a static keyboard .
To study the effect of keyboard adaptation on touchscreen typing performance, we designed and evaluated two novel adaptive keyboards for ten-finger typing .
These prototypes explore two points in the design space of personalized touchscreen keyboards.
While both use the same approach to personalize the underlying key-press classification model, one keyboard also visually adapts the location of keys while the other maintains a visually stable rectangular layout.
We used an iterative approach to design the keyboards, including simulation analyses of ten-finger typing data to select and tune the final underlying key-press classification model, a J48 decision tree classifier trained on finger location and movement features.
We conducted a three-session study with 12 participants to compare performance and subjective reactions with the two adaptive keyboards and a traditional, static QWERTY layout.
Our findings show that a personalized keyboard can improve typing speed over the static alternative.
The personalized keyboard that did not visually adapt improved typing speed by 12.9% across all three sessions, rising to 15.2% for the third session; no discernible difference was found in error rates.
Large touchscreen devices such as tablets and interactive tabletops are being adopted for an increasingly wide range of tasks.
While these devices support ten-finger text input and full size QWERTY keyboards, providing rapid text entry remains a challenge .
The reduced tactile and kinesthetic feedback of a touchscreen not only increases the visual attention required to position hands and fingers on the keyboard but also impacts the user's knowledge of whether a key has been depressed .
Spurious input may also occur from hands or arms touching the surface , further impacting text entry.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
It was, however, considered to be the most comfortable and natural of the three keyboards.
This paper makes the following contributions.
First, as keyboard adaptation is still an emerging area of research, we outline a design space for personalized touchscreen keyboards, including major dimensions of adaptation and key-press classification features.
This design space provides both a rationale for the design choices that we made and highlights open areas of future work.
Second, we provide two novel personalized keyboard interfaces that use more sophisticated classification models than previous work  and can accommodate a wide range of typing features.
Finally, we provide empirical evidence for the benefit of such personalization, both in terms of typing performance and user experience.
These findings show that the way in which keyboard adaptation is visualized can significantly impact the efficacy of and reaction to that adaptation.
While our focus is on ten-finger touch-typing, our contributions are also relevant to mobile devices, where research has only begun to explore personalized text input .
In contrast, with multiple finger input, Sears et al.
Regardless of the exact keyboard layout or method used to identify key presses, language modeling is commonly used to improve input accuracy with virtual keyboards.
For keyboards where a single key is overloaded with multiple letters, these models can clarify the ambiguity of key presses .
More generally, language modeling can be used to improve typing accuracy by reducing the chance of improbable key presses .
These approaches combine the user's key-press location with language model predictions for the next possible letter to more accurately classify which key the user was attempting to hit .
As discussed in the next section, work on language modeling is complementary to our research.
Our design space and, particularly, the comparison of visual and nonvisual adaptation in that design space are inspired by previous work on adaptive user interfaces.
Adaptive user interfaces can introduce new challenges compared to traditional interfaces .
Those most applicable to text input include: lack of user control, unpredictability, lack of transparency of the system's decision making process, and obtrusiveness, or the degree to which the adaptations are distracting.
Evaluations are also often more complicated than for non-adaptive user interfaces.
For example, not only does the user need time to learn about the system, but the system needs to learn about the user.
We discuss work most relevant to personalized touchscreen keyboards in the context of our design space .
Here, we focus on tabletop text input, touchscreen typing, and adaptive interfaces in general.
The lack of efficient methods for entering text on interactive tabletops is well documented  and may potentially detract from long-term sustained use of such devices .
As one solution, distal tactile feedback, applied not on the surface itself but on the wrist or arm, has been shown to improve typing speed .
The use of physical keyboards  and physical silicon keyboards overlaid on the surface  have also been proposed, highlighting the challenge of text entry on interactive tabletops.
Finally, although not for tabletops per se, techniques to support ten-finger typing on arbitrary flat surfaces using computer vision  or augmented gloves  have been explored.
The 1Line keyboard  has also been proposed to save visual space on smaller touchscreens.
In contrast to ten-finger typing, a large body of work exists on virtual keyboards for a single point of input, most often a finger or stylus.
These include techniques that utilize the geometric relationship between keys to improve input accuracy  or enable typing without a priori determining the position of the keyboard, albeit with a high error rate .
Alternatives to tapping a QWERTY keyboard have also been proposed, including alternate key layouts  and methods to stroke between keys .
Though highly relevant to our work, one difference between single point of input and multiple-finger typing is highlighted by comparing two past papers on keyboard size .
Before describing our specific approach, we first outline a design space for touchscreen keyboard personalization.
This design space is useful to introduce and define concepts that our classification models leverage as well as to map out this emerging research area.
Since the focus of this paper is on adaptive  forms of personalization, we use the terms "adaptive" and "personalized" interchangeably.
We also rely on a distinction made by Goodman et al.
A touch model describes how the user's finger touch is interpreted as a key press while the language model adds knowledge such as the distribution of words in a given language.
These two sources of information are often combined to improve overall typing accuracy .
Our focus is primarily on improving touch models, which has received less attention of the two.
For ten-finger typing, simulation results have demonstrated the potential of a personalized closest-centroid approach to increase classification accuracy over a model aggregated across all users .
However, user evaluations with a ten-finger keyboard  and a 9-key numeric keyboard  have so far found no performance improvement.
Bivariate Gaussian distributions computed for each key offer a more sophisticated, probabilistic classification approach and have been used for small touchscreen devices  though not, to our knowledge, for ten-finger typing.
Most work with bivariate Gaussian distributions has focused on models aggregated across multiple users; however, simulations by Rudchenko et al.
Both closest-centroid and bivariate Gaussian models only make use of the  location of the finger touch.
In this paper, we explore machine learning approaches that can accommodate a larger set of features.
While the previous two dimensions focused on individual keys, the keyboard itself can also adapt more holistically to the user's hand and arm placement.
This adaptation can occur when the user first places their hands on the surface: for example, the keyboard may be displayed automatically in two halves under the user's hands .
This type of adaptation has been previously proposed  but not evaluated.
The keyboard can also adjust itself more subtly over time to account for drift as the user is typing.
When the key-press classification model adapts to the user, the visual key layout may also change.
Figure 2 shows an example from Go and Endo : a Voronoi tessellation drawn about the adapted centroids of a closest-centroid classification model.
Not adapting the visual layout when the underlying model changes increases the chance that the classifier's output will not match the visual key the user appears to touch.
Thus, visual adaptation may increase the predictability of the keyboard.
How users react to visual adaptation, however, has so far been inconclusive .
This issue may reflect a broader challenge with adaptive user interfaces: adaptations can demand so much attention from the user that even theoretically beneficial adaptations have a negative effect .
The issue of visual adaptation can arise with language model predictions as well.
Some text input techniques increase the size of probable keys based on a language model's prediction of the next letter .
The above subsections defined three dimensions of adaptation for personalized touchscreen keyboards.
Here we focus on Dimension 1, key-press classification models, and consider what features may be most useful for classification .
Ultimately, the set of possible features will be determined by the input hardware used .
While our focus is on ten-finger typing, many features listed here are also applicable to smaller devices.
Our goal is to highlight the breadth of features that exist for personalizing keyboards as well as to introduce the particular features that we later test.
Touch location features are based on finger-down and finger-up locations.
These features can include:  finger center  and  fingertip  locations.
On large touchscreens, the keyboard can move, so these coordinates must be relative to some point of reference.
For adaptation to the left and right hands, two relative center locations can be calculated, e.g., one as an offset from the F key and one as an offset from the J key .
Absolute values can be used for smaller screens.
Touch area features describe the size and angle finger on the screen; these features greatly depend hardware device.
We used a Microsoft Surface, provides ellipses fitted to the touch area and allows major axis,  minor axis and  orientation.
Different keys may result in different movement signatures based on the finger used and how the user reaches for that key.
Specific features include  travel and  elapsed time between finger down and up.
Travel can be calculated as the distance in x and y directions for either the fingertip or the finger center.
Features relative to previous key presses incorporate knowledge about previous key presses.
These include  inter-key-press timing, or the elapsed time between key presses, and   distance offset from previous key.
The latter may be useful if, for example, the current key-press location is affected by whether the last key was to its left or right.
A simulation study by Rashid and Smith  showed low accuracies for a touch model based only on this feature.
Hand or arm features are based on the position of the hand and/or arm.
Again, these features are highly dependent on the underlying touchscreen system in that only certain systems can provide this information.
Additionally, each key was initially seeded from 5 points sampled from a bivariate Gaussian distribution around the key's center, with x and y variance of 40 pixels and no covariance.
The keyboards only began adapting after a minimum of 10 training points  were collected for every key.
Based on early user feedback, we required that all keys achieve this minimum for consistency so that some keys did not begin adapting sooner than others .
To accommodate the possibility that the user could adjust his or her typing patterns over time, the training history only stored the last 100 strikes per key.
The frequency of model-updating and the size of the training history used were determined by informal feedback from six early users and input from the research team.
This process allowed us to identify a reasonable rate of adaptation for the personalized keyboards.
However, determining the optimal rate is an open area of research and only one of many design considerations with adaptive user interfaces .
We have defined three dimensions of adaptation and a list of potential classification features for personalized touch models.
Of course, the particular touchscreen device used will dictate which subset of features is possible and useful.
In addition, any adaptive system needs to account for how the user model is trained: online, as the user types , or offline, perhaps in an explicit training period .
Furthermore, if the training occurs online, the rate at which the adaptation occurs may impact the effectiveness of a personalized keyboard.
We conducted a pilot study that informed the final keyboard designs in two important ways:  it inspired us to reflect on the role of visual adaptation in personalized keyboards;  it provided realistic typing data with which to evaluate and select an appropriate machine learning classifier for the key-press classification models.
We took an iterative approach to design and build two personalized keyboards that were the same in all respects except for their visual adaptation.
Here, we describe the general personalization method used, a pilot study of our early keyboard designs, and, finally, the designs that we ultimately evaluated in the full user study.
We built and tested three keyboards in the pilot study, two of which were seeded using a dataset we had previously collected on 10-finger typing patterns from 20 participants .
In particular, since we hoped to create novel keyboards that would allow for typing with reduced visual attention, we used data from a condition in the previous study that was meant to emulate just that: in the no visual keyboard condition in , participants typed on a blank surface.
The keyboards used in the pilot study were as follows:  Conventional was a static rectangular QWERTY layout.
Static-Centroid provided a static layout where the locations of keys were adjusted to the aggregate centroids of key presses across all participants from the previously collected dataset .
Adaptive-Bayes began with the same aggregate key layout and switched to a Naive Bayes classifier after 10 training points had been observed for each key  and fingertip  as the feature set.
As with all machine learning classifiers in this paper, we used Weka 3.6.
Naive Bayes was chosen for this early keyboard implementation because it performed well in simulations we ran on the dataset from .
The pilot study system provided language model correction trained on an existing corpus .
We implemented static  and personalized  keyboard interfaces in C .NET 4.0.
The most basic of these interfaces, used as a control condition, was a static rectangular QWERTY layout with keys 0.9" x 0.9" .
For the personalized keyboards, we used Weka 3.61 and IKVM2 to provide online adaptation in real-time.
That is, each personalized keyboard collected training data as the user typed and, at natural break points in the user's input, this training data was used to update the classification model and possibly the visual layout of the keyboard.
In our studies, model updating occurred at the end of each phrase.
Key presses whose letters were subsequently backspaced were considered errors and removed from the training set.
Four participants each volunteered for three 1.5-hour long study sessions where they used each of the three keyboards.
For each session they entered a combination of pangrams and random phrases from the MacKenzie and Soukoreff phrase set .
Participants were asked to type quickly and accurately, and corrected errors with a right-to-left horizontal swipe .
They typed 5 practice phrases and 40 test phrases with each keyboard during each session.
Mean typing speeds and uncorrected error rates were similar across all keyboard conditions, from 27.7 to 28.2 WPM  and 0.7% to 0.9% error rate.
Both keyboards were initially rendered as rectangular QWERTY layouts .
VisualAdaptive adapted the visual center of each key to be located at the centroid of all fingertip locations in that key's training history.
To avoid excessive visual overlap between keys, Visual-Adaptive also reshuffled keys to maintain a minimum of 30 pixels  between key centers .
For stability, reshuffling was done by maintaining the F and J "home" keys at a fixed location and translating neighboring keys away from F and J; this effect then cascaded toward outer keys.
Although we had predicted that the personalized keyboard  would offer a performance benefit over the control condition, typing speeds across all three conditions were similar.
We identified two potential areas for improvement.
First, the visual adaptation of the keyboard was unsettling to some participants, suggesting that the role of visual adaptation was more complex than we had expected.
Second, we had chosen the Naive Bayes classifier based on simulations with our previous dataset , but our current keyboard interface was substantially different; for example,  did not provide a visible keyboard or standard typing output.
As such, it seemed prudent to reassess the choice of machine learning classifier based on the newly collected pilot study data.
We ran simulations with the data from the Conventional keyboard condition to compare the accuracy of several machine learning classifiers on this new dataset.
The simulations tested personalized key-press classification models by running 10-fold cross validations on each participant's data.
We tested a number of classifiers provided in Weka, including Naive Bayes, Support Vector Machines, and Decision Trees.
J48, Weka's implementation of the C4.5 decision tree algorithm, produced consistently high classification accuracy .
In contrast, the Naive Bayes classifier that we had used for the AdaptiveBayes condition did not perform as well .
In addition, J48 was fast for building/updating the model and classifying key presses, which is obviously critical for a real-time system such as ours.
Based on these findings, we chose the J48 classifier for the full study, with a normalization filter and default classifier settings.
In contrast, NonVisual-Adaptive always retained a visually stable rectangular layout .
As discussed earlier, adapting the underlying key-press model without changing the visual layout increases the chance that the user will press one visual key but the system will output a different letter.
To mitigate this issue, NonVisual-Adaptive disabled the J48 classifier for one keystroke after a backspace, or if the user was typing slowly .
In those situations, the user is more likely to look down at the keys and target carefully, so the system simply checked which visual key boundaries contained the fingertip.
To select which subset of classification features to include in the J48 classification model, we used a wrapper-based feature selection technique .
That is, we incrementally added features to the model until no improvement in performance occurred.
This process resulted in all features in Table 1 marked with a `*'.
Additionally, we included the finger center y relative to the F and J keys for continuity, since the finger center x was already in the feature set; this inclusion did not reduce classification accuracy.
Explanatory power of classification features based on the pilot study data: mean 10-fold cross-validation results from a J48 classifier trained on individual features or pairs of related features.
The majority classifier is the accuracy rate if we always classify as the most frequent key .
Language model correction was not used in the full study because we observed in the pilot study that the accuracy of the language model--in our case perhaps unrealistically accurate--appeared to affect typing patterns.
As such, we disabled the language model to control this possible interaction between the language and touch models and to isolate the effects of the touch model personalization.
Finally, to reduce the chance of inadvertent or spurious input, the user had to activate the keyboard by briefly placing all 10 fingers on the screen.
The keyboards deactivated after 5 seconds of inactivity.
We used a Microsoft Surface running custom software written in C .NET 4.0.
The system recorded all down and up touch events during the typing tasks.
Participants sat at the Surface, which was raised ~5" off the ground with a custom-built platform to about the same height as a standard desk.
The task interface, shown in Figure 6, presented phrases to be typed at the top of the screen.
After typing a phrase, participants advanced by pressing the "Next Phrase" button.
At the end of each condition, the system wrote all information related to the personalized key-press classification model and visual key layout to an XML file.
This data was reloaded when the participant used the same keyboard condition in future sessions.
We conducted a controlled, three-session study to compare the two personalized keyboards to a conventional static keyboard.
We hypothesized that the personalized keyboards would improve typing performance and subjective experience compared to the conventional keyboard.
Since previous findings are inconclusive with respect to visual adaptation , this study also allowed for an exploratory comparison of the two personalized keyboards, one of which adapted visually and one of which did not.
The study was a 3x3 within-subjects factorial design with the following factors and levels:   Session: Participants completed three sessions each.
The Conventional layout was the same as the initial rectangular layouts for the personalized keyboards.
Key presses in Conventional were interpreted simply by which key's visual bounds contained the fingertip.
The personalized keyboards began adapting as soon as they had obtained 10 training instances for each key in Session 1.
Order of presentation for the keyboard conditions was fully counterbalanced within each session and participants were randomly assigned to orders.
Twelve participants were recruited through on-campus mailing lists .
Participants were volunteers and were compensated for their time.
All were regular computer users and had experience with touch devices, with 10 of the 12 indicating they enter text on mobile touch devices often.
In terms of physical keyboard use, one participant regularly used a natural or split keyboard, while the remaining participants used standard rectangular layouts.
On a physical keyboard typing test administered during the study, participants typed 79.2 WPM  and had an uncorrected error rate of 0.2% .
Participants completed three 1.5-hour sessions spaced at least 4 hours and at most 48 hours apart.
Session 1 began with a brief introduction to the Microsoft Surface and experiment software.
From the user's perspective, the adaptive keyboards behaved exactly the same as the Conventional keyboard until a minimum number of training examples had been recorded for each key; therefore, all participants began by typing 10 practice phrases and 20 test phrases with the Conventional keyboard.
This data was used to seed the personalized keyboards.
Participants then typed 5 practice phrases and 20 test phrases with each of the three keyboards.
In Sessions 2 and 3, participants typed 5 practice phrases and 40 test phrases on each keyboard.
The typing task interspersed two pangrams with randomly selected phrases from the MacKenzie and Soukoreff phrase set .
To ensure we collected sufficient training data for each key in Session 1, the ratio of regular phrases to pangrams was 1:1.
In Sessions 2 and 3, that ratio increased to 9:1.
Subjective questionnaires were given after each keyboard condition and at the end of each session.
At the end of Session 3, we interviewed participants about the keyboards.
Additionally, participants completed a physical keyboard typing test  at the beginning of Session 1 or end of Session 2.
Uncorrected error rate measures the errors remaining in the transcribed input, as opposed to those fixed "along the way," which take time and are thus subsumed in WPM.
For WPM and uncorrected error rate, we analyzed the 20 test phrases with each keyboard in Session 1 and the 40 phrases from each of Sessions 2 and 3.
Since presentation order was counterbalanced within each session, we tested for effects of Order on WPM within each session.
Two-way ANOVAs with Order as a between-subjects factor and Keyboard as a within-subjects factor revealed no main or interaction effects of Order on WPM.
Thus, our counterbalancing seemed effective.
We used a two-way repeated measures ANOVA for WPM with both Session and Keyboard as within-subjects factors for the final analysis.
For all post hoc pairwise comparisons, Bonferroni adjustments were used.
The main subjective measures were NASA TLX workload scales  and rankings of the keyboards based on ease of use, efficiency, preference, comfort, how natural the typing felt, and frustration.
We report the final subjective measures collected at the end of Session 3.
For workload data, we ran one-way repeated measures ANOVAs with Keyboard as a single factor.
For the ranking data, we used Chi-square tests to evaluate whether the number of times each keyboard was top-ranked in a category differed from chance.
When the expected frequency values were too low for Chi-square , we used a randomization test of goodness-of-fit, which uses a Monte Carlo simulation to calculate the probability of the observed frequency values occurring by chance; it is robust against low expected values .
Sample adaptive keyboard layouts from Participant 10 at the end of Session 3.
To the user, the NonVisualAdaptive keyboard looked exactly like the Conventional keyboard, so  is an illustrative visualization of the x,y coordinates stored in the underlying model.
This general pattern of increased adaptation from  to  is representative of all participants.
No significant difference was found between Visual-Adaptive and Conventional.
Trends shown in Figure 8 suggest that with additional sessions, typing speeds on all conditions would increase further.
No significant interaction effect was found between Session and Keyboard on WPM , indicating all keyboards improved at about the same rate during the study.
As hypothesized, the keyboards affected typing speed differently; see Figure 8.
Post hoc pairwise comparisons revealed that NonVisual-Adaptive was the fastest keyboard.
That keyboard offered a 12.9% improvement overall compared to Conventional , a gap which increased to 15.2% by Session 3.
All three keyboard conditions resulted in extremely low uncorrected error rates.
Because of the low error rates , we did not perform inferential statistics on this data.
Note, however, that the means for both adaptive conditions were the same as or lower than for the Conventional keyboard.
This data dispels the notion that NonVisual-Adaptive improved speed at the expense of increased errors.
Participants were asked to rank the three keyboards based on ease of use, efficiency, frustration, comfort, how natural the typing felt, and overall preference.
Since some of these questions appeared to be capturing redundant information, we calculated Cohen's   to group related questions.
The three groups shown in Table 2 emerged, suggesting that the six questions had only captured three underlying themes.
Cohen  values between each pair of characteristics in a group ranged from 0.86 to 1.00;  values between pairs across different groups ranged from .48 to .74.
Thus, we tallied and analyzed the top keyboard votes within each group.
The majority of the time, NonVisual-Adaptive was rated highest in the Efficiency/Ease/Preference group, whereas Visual-Adaptive received the most votes in the Comfort/Naturalness group.
Regardless, Conventional ranked poorly in both groups.
For Least Frustration, a randomization test of goodness-of-fit using a Monte Carlo simulation with 10,000 random samples was not significant .
NASA TLX workload ratings at the end of Session 3 were slightly higher for the Conventional keyboard  than for Visual-Adaptive  and NonVisual-Adaptive , but no significant differences were found.
P9 expressed this sentiment as: "...seemed easiest this time - as long as I didn't look and see the odd spacing."
In contrast, the NonVisual-Adaptive keyboard was designed to be much less obtrusive than Visual-Adaptive, yet to still provide adaptive benefits.
Highlighting this distinction, the majority of participants  stated they had trouble defining the difference between Conventional and NonVisualAdaptive.
For example, P5 said of NonVisual-Adaptive, "I felt I just got more into a flow.
I didn't notice a big difference between the two.
I just felt that I performed better with ."
Likewise, P7 said she couldn't "tell what the difference is but there's something about  that is easier to type with."
Since NonVisual-Adaptive and Conventional looked identical, these comments reflect NonVisual-Adaptive's benefit in terms of the mechanics or "feel" of the typing.
Unprompted, participants also commented on the ability to type without looking frequently at the keyboard.
While no one brought this up in the context of Conventional, 5 participants commented that either NonVisual-Adaptive or Visual-Adaptive allowed them to get into more of a "flow" than Conventional.
P6 also compared the keyboards to the iPad: "With the iPad you see the wrong letters and it corrects in front of you .
But this, I know I'm hitting in the wrong place and the right letter comes up, which is nice.
I'm just not used to it."
Finally, a few participants made negative comments about how the Visual-Adaptive keyboard chose to move the keys, suggesting that there may be room for improvement for this design.
For example, P10 commented that although he felt he was most consistent with the Visual-Adaptive keyboard, the keys had migrated quite close together, causing him difficulty.
Two participants also explicitly commented that Visual-Adaptive got easier across the three sessions, which suggests that more training  may further improve that keyboard's usefulness.
To contextualize the quantitative results, we interviewed participants at the end of the study.
One potential issue with adaptive interfaces is the degree to which the adaptation requires the users' attention and distracts them from users' primary task; Jameson  calls this obtrusiveness.
Eight participants remarked negatively on the visual adaptation in the Visual-Adaptive condition.
This keyboard appeared to increase cognitive overhead for at least some participants because of the unusual layout; for example, P8 stated, "I felt I was constantly looking at my hands."
Interestingly, however, negative comments about the visual look of Visual-Adaptive keyboard were not necessarily reflective of overall preference or perceived efficiency.
The NonVisual-Adaptive keyboard provided a typing speed improvement over Conventional, but Visual-Adaptive did not.
Both personalized keyboards, however, fared well in terms of subjective feedback.
NonVisual-Adaptive was ranked as most Efficient/Easy-to-use/Preferred, while Visual-Adaptive was considered the most Comfortable/Natural.
Qualitative feedback suggested participants recognized the performance benefits of NonVisual-Adaptive even though they could not necessarily recognize the source of those benefits .
Error rates in all three conditions were extremely low.
We found that the visually adaptive keyboard resulted in lower performance than the non-visually adaptive keyboard, which suggests users incurred a cognitive cost from visual adaptation that counteracted the benefits of personalizing the key-press model.
This theory is supported by comments from participants, which confirm previous research by Himberg et al.
Despite these issues, however, the visually adaptive keyboard shows promise in that it was considered to be the most comfortable and natural of the keyboards.
While we have focused on improving the underlying touch model for ten-finger keyboards, we envision that these personalized keyboards can be combined with language models.
As noted in the implementation section, we disabled language model correction for this study to isolate the impact of the touch model adaptation.
However, using a source-channel approach  to combine probabilities from the personalized key-press classifier with predictions from a language model should further improve typing accuracy.
An open question is whether the use of a language model will result in changes to user typing behavior such that the touch models also change--might the two models interact, and if so, how?
In addition to incorporating language models, augmenting the personalized keyboards with audio or tactile feedback is also possible.
Indeed, even the distal tactile feedback that has been previously used for tabletop interaction  should provide a benefit here.
In creating the two personalized keyboards, we made a number of design decisions that could potentially impact performance and user satisfaction.
For example, only the last 100 key presses were stored for each key and the keyboards only began adapting after 10 training points had been recorded for every key .
Future work should explore how these decisions ultimately impact the effectiveness of the adaptation.
One potential area for improvement is to ensure that over-adaptation does not occur.
Particularly with the visually adaptive keyboards, a cycle of adaptation exists between the user and the system .
Identifying points of stability in the input model may reduce the potential negative effects of this adaptation cycle.
With personalized interfaces, evaluations need to be designed not only to account for training time for the user, but also training time for the system.
Although we conducted a multi-session study, performance improvements from the second session to the third session indicate that learning had yet to plateau for any condition.
This issue may be most pertinent to the visually adaptive condition, since it was the most unfamiliar of the keyboards.
A longer study would be useful for determining where performance stabilizes for all three keyboards, but particularly for the visually adaptive one.
Although we have focused on ten-finger typing, much of the design space for personalized keyboards and the study findings have implications for other modes of touchscreen typing.
Two of the three major dimensions of adaptation-- the underlying classification model and the visual layout of keys--should be equally applicable to mobile devices.
Additionally, we tested a range of machine learning classifiers in the Weka toolkit that yielded reasonably high key-press classification accuracies, but further exploration likely will yield even better models.
We have introduced and evaluated two novel personalized keyboard interfaces that adapt their underlying key-press classification models based on an individual user's typing patterns.
In addition, these keyboards explore two points in the design space of adaptive keyboards: one visually adapts while the other always maintains a visually stable rectangular layout.
Results from a user evaluation showed non-visual personalization can significantly improve typing speed.
However, visualizing adapted key layouts can negatively impact speed.
Both adaptive keyboards received a positive subjective response and, as such, point to the further promise of this area of research.
We have also presented a design space for personalized keyboards to ground our design decisions and to identify areas for future work.
Although our focus has been on ten-finger touchtyping, the results and design space should also be applicable to adaptive text input techniques on small mobile devices.
We believe this work is one step in a larger trend towards increased personalized interaction with devices.
The authors thank Rebecca Fiebrink, Jon Froehlich and Mayank Goel.
This work was supported in part by NSERC, Microsoft Research, and the National Science Foundation under grant IIS-0811063.
Any opinions, findings, conclusions or recommendations expressed in this work are those of the authors and do not necessarily reflect those of any supporter.
