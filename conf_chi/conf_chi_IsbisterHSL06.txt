Our own efforts in developing an affective assessment tool have been shaped by our past work in understanding and enhancing nonverbal communication, our commitment to user-centered design, and our interest in trans-cultural methods to support global design practice.
Our development process was a user-centered one, conducted in several stages, with input along the way: an initial brainstorming stage; early, open-ended concept testing; refinement of the research instrument; and openended testing of the prototype tool.
In this paper we describe the development and initial testing of a tool for self-assessment of affect while interacting with computer systems: the Sensual Evaluation Instrument.
We discuss our research approach within the context of existing affective and HCI theory, and describe stages of evolution of the tool, and initial testing of its effectiveness.
Practitioners in the CHI community have become increasingly convinced of the importance of affect--both in terms of designing experiences for users which take it into account , and also in terms of developing measures for user satisfaction with such systems .
There are various modes of approach to measuring affect.
Traditionally, affect has been ascertained in two primary ways: using questionnaires administered after an experience, which ask the user to rate his/her feelings about what occurred, and analysis of videotaped sessions with users that typically combine interpretation of think-aloud commentary with deciphering of other cues of emotion  to develop an impression of user's affective reactions.
In recent years, additional tools based upon biometrics have evolved--measuring galvanic skin response, detecting small movements of the muscles of the face, tracking pressure on the mouse .
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
This project emerged from a European Network of Excellence initiative called Humaine , focused on the study of affective systems.
Our work group in the project is dedicated to exploring ways and means for evaluating a system's affective impact on users.
As we gathered sources and learned about existing methods, we found that there was still much work to do in refining methods for eliciting and understanding user affect.
In particular, there seemed to be a gap in terms of easy to use self-report measures.
System designers were either relying on questionnaires given after the interaction was complete, were laboriously coding data from videotape of sessions, or were using biometric equipment that requires relatively complex analysis in order to deliver reliable affective data.
We felt this was worth exploring, especially insofar as it could enhance the design process by enabling more rapid test-and-iterate cycles based upon affective responses to a system in development.
It is important to reiterate here that we wanted this tool to allow flexibility for users to adapt it to their own style of expressing affect, toward creating a dialog between designers and users that enhances design.
While we did aim for some level of consistency in response to the instrument's qualities, we were not solely focused on consistent use patterns nor would we claim that this is a highly accurate tool for measuring affect.
In this regard the aims of the project differ radically from other self-report measures, and our instrument should be viewed as complementary to rather than as an alternative to other measures.
Neurophysiologists and psychologists have in recent years proposed that our brains, rather than operating in a wholly logical, conscious verbal manner, actually process information and make decisions using various layers working in parallel, complementary ways.
They have demonstrated, for example, that we can learn something new and `intuitively' put it into action before we are able to consciously verbalize it .
Emotions are experienced by both body and mind.
Often, they are evoked by sub-symbolic stimuli, such as colors, shapes, gestures, or music.
If we rely on the verbal channel for self-report of affect during interaction with a system, we may be missing out on much of this information, as it is filtered through the person's verbal system.
The authors  have explored the role of nonverbal expression in interface in the past, and have found the body to be an important channel for communicating affect and other qualities.
We decided that our affective instrument would be sensual and physical in nature, to allow us to access this part of a person's experience more directly.
In addition, we hoped that avoiding verbalization would make it more likely that users could give in-line feedback without their task being as disrupted as if they had to explicitly verbalize their current affect.
A modicum of ambiguity in the tool at this stage is good rather than bad, as it allows users to co-define the meaning of their feedback with the designer, to reach a richer shared picture of what is going on .
This is especially appropriate for a tool to measure affect--models of emotion from the realm of psychology are not always fully descriptive of  measuring affective reaction to a system.
Some emotions rarely come into play when engaging with computer systems, and the ebb and flow of reaction to a system is not necessarily the same as that which occurs in face to face interaction among people.
Part of the hidden work of this project, then, was learning about which emotions are truly relevant in the context of evolving successful interaction with computer systems, and offering ways to express those emotions with our research instrument.
By avoiding verbalization, we also realized that we had a chance of developing a less culturally dependent research instrument.
Questionnaires must normally be translated and counter-translated to insure that they are truly measuring the target emotion, even though there is strong evidence for trans-cultural similarities in basic emotional response.
Perhaps a nonverbal, body-based approach could tap more directly into these shared responses, saving designers time and energy, and again, leading to greater likelihood of early user participation in design.
We were inspired by the work of Liz Sanders , Bill Gaver , and others, in conducting inquiries that move freely beyond the lab and into various cultural settings.
Thus from the beginning, one end goal of our project was the creation of a `kit' that could be easily shipped to others around the world for use.
Hook in particular has had a long-standing commitment to user-centered design practice, and finding ways to bring users into the design process earlier in development cycles to strengthen final design outcomes.
To the extent that a usability practice is intuitive and simple to operate and analyze, it becomes more likely to be adopted for use during development, especially during early stages when significant change is still possible.
Most work done on nonverbal systems of evaluation has involved anthropomorphic imagery .
Finally, there has been some work in the product design community on mapping product qualities to affective reactions, for example this facial wheel used by Wensveen and colleagues in developing an affectively appropriate alarm clock .
Our wish in this project was to move away from discrete, pre-defined emotional labels such as faces, figures, or names, and move toward some form of nonverbal code that allowed more open-ended interpretation but that still evoked emotion without explicitly representing the human form.
We also hoped to extend the sensory experience of this instrument beyond the purely visual.
There is some nonrepresentational work on sensing emotion in alternate sensory channels.
For example in his book Sentics, Clynes describes characteristic movement patterns on a touch pad when users are asked to `perform' a particular emotion with their finger .
Product designers know that surface materials and their tactile qualities can profoundly impact users' emotional response to products , but there has been little systematic work done up to know to asses the specific emotional effects of various materials.
To begin the project, we decided to apply one traditional model of emotion to everyday household objects, to see what sort of physical properties caused them to be arrayed in which places in the emotional spectrum.
We worked from the Russell circle , which arrays emotions along two axes: arousal and valence.
A high arousal, high valence emotion such as ecstatic joy would be located in the upper right quadrant, for example, whereas a low arousal, low valence emotion such as depression would be located in the lower left quadrant.
We had several researchers bring in objects that had emotional meaning for them, and array them upon a circle projected onto the floor 
Based upon these results, we made two key design decisions: 1.
We would move to a more biomorphic framework upon which to vary the objects, one that we hoped was less subject to narrative overlays.
We drew from work by Disney animators in crafting less explicitly anthropomorphic forms that still managed to strong convey emotion .
We would take note of the emotions that users expressed during this test, and incorporate system-use-based emotions into our subsequent design thinking.
How might one express mild frustration, confusion, and the like?
These were the sorts of feedback we wanted to support with our instrument.
We decided to isolate one dimension of the many object properties we found in step one, and test how people would use this dimension to convey their emotions while interacting with a system.
We chose color as our first variable, as color had strong connotations in the first test and with other projects by Hook and colleagues.
We crafted colored objects that could be held in the hand, and which were similar in weight, texture and other properties, differing only in color .
Then we brought in several people not familiar with our research, and asked them to do three things: 1.
Create their own taxonomy of the objects, using the projected Russell circle .
Interact with a computer game that evoked strong emotions, and use the objects to convey how they felt.
Discuss with us how it was to use the objects to convey emotion.
We found that users were experiencing emotions that didn't match neatly to their initial taxonomy, and were not sure how to indicate them--such as mild frustration, confusion, anticipation, and the like.
At this point we solicited the support of a professional sculptor who had experience in crafting biomorphic forms.
Rainey Straus  crafted a set of objects that had biomorphic qualities, working from ongoing discussions with us, and from a list of emotions we provided that was based upon our exploratory studies.
The initial list was confusion, frustration, fear, happiness, surprise, satisfaction, contentment, stress, and flow.
She crafted a total of eight objects, not necessarily meant to be a one-to-one mapping to these emotions, but rather a successful set of tools for evoking/expressing this range of emotions .
In this phase, the participant was shown the objects and encouraged to handle them, and the experimenter described the purpose of the research and emphasized that any type of usage of the objects to convey affective state was fine .
In this phase, the participant was shown a series of images taken from the IAPS , and asked to use the SEI objects to indicate affective response to each picture.
The images were selected because their arousal/valence scores mapped roughly to the feelings that the artist initially intended to convey with the objects.
In this phase, the participant played through the first puzzle in a PC adventure game, The Curse of Monkey Island, and was instructed to use the objects to indicate affect during play.
The experimenter was present during this phase, and was available to offer hints/tips on using the game during play.
After the game, the participant was asked to chat using AIM instant messaging with the experimenter's assistant, to discuss how it was to play the game.
The experimenter left the room during this portion, after instructing the participant to use the objects to indicate affect while chatting.
At the end, the experimenter returned and walked the participant through a series of questions about what it was like to use the objects, including solicitation of suggestions for improvement of the SEI.
Questions included: What was it like to use the objects to express emotion?
Did you find that you had a consistent set of mappings?
How hard or easy was it to use them?
Suggestions for changes or alternatives?
The sessions were digitally recorded , using a picture within picture format, so that we could later analyze usage in conjunction with what the participant was seeing on-screen .
Straus created the objects in clay, then we had them cast in plastic in order to have a durable surface and multiples for use in different lab settings.
Internally, we assigned names to the objects to make it easier to code data, as follows : back row--spiky, pseudopod; next row-- anteater, bubbly; next row--stone, doubleball, ball; front-- barba papa .
We did not use these or any other names for the objects with participants--these names are introduced only to aid you, the reader, in following discussion of object use in this paper.
With the cast objects in hand, we designed a study to assess whether this new instrument would allow people to provide meaningful affective feedback while they engaged in interaction with a computer system.
The aim of the study was both to explore use potential for the object set, and also to engage the students and faculty in a discussion of the act of using the objects, and potential interactions/innovations toward a refined design.
Considering the images arrayed by the primary dimensions used in the IAPS , we found that there were some visible trends in the use of objects.
Although there were definitely individual differences in participant reactions to the images , looking at the object use reveals some relation to the valence and arousal metrics compiled for the IAPS .
If we consider the IAPS images arranged from most negative to most positive valence, we can see that the objects with the sharp edges tended to be used in association with the negative valence imagery .
Participants used spiky and anteater more frequently in response to these images.
Objects with smooth edges and few protrusions  tended to be used in conjunction with images with more positive valence .
The trends are less clear when it comes to the arousal level associated with the IAPS images--those with the highest arousal level as well as negative valence: a gun pointed toward the viewer or a dog barking at the viewer, were associated with the sharper edged objects.
Mid-level arousal and positive valence images: the bride with arms out, the bride with child, were associated with rounded objects.
There was not a clear pattern for low-arousal images .
Spiky and anteater both got fear and anger attributions from most participants .
Barba papa was often used to indicate humor.
Bubbly was used for both humor and for confusion and frustration.
Many participants commented that the bubbly form seemed chaotic and suggested confusion or indeterminacy.
Pseudopod got some similar reactions--one participant used this to indicate that he had a goal in mind but it wasn't wholly resolved--a feeling of directed anticipation.
Despite these generally similar tendencies in associating the objects with particular affective states, participants used them in action in quite different ways.
There were also patterns in usage during the session, and in discussion afterward that echoed and also extended what was seen in the object calibration exercise outside the valence/arousal model.
Participants tended to describe the smooth, rounded objects with fewer protrusions as happy, or calm, or fun in the post-discussion, and to use them when in such situations during play or chat.
This participant  used multiple objects arrayed in a triangular formation to express his reaction.
His use of the objects was limited to those that were most rounded in form , and he said he probably would not use the sharper forms  unless he saw the `blue screen of death'.
Use of objects during the session  ranged from 4 to 53 times.
Participants used the objects to express emotion both when playing the game with the experimenter present, and when instant message chatting with the experimenter not present in the room, although usage was less frequent in the latter case .
This participant  shook the spiked object in response to a lag problem in the game during play .
He tended to hold the objects in his hands when they were `active'.
He made frequent and dramatic use of the objects including broad gestures--over 50 instances in the 30-minute session.
Much better than survey...feedback is more immediate."
Negative comments: "I didn't feel like I got a lot of leverage out of that one ."
I would make something larger than the others."
Participants also made some very interesting suggestions for evolving the instrument, which included: * adding the ability to squeeze or shape the objects somehow with one's own grip, to further indicate emotion.
One other factor for consideration in the object use was the tendency for participants sometimes to match the shape of the object with the shape of the thing they were reacting to.
This was especially so with the IAPS image calibration .
This tendency seemed to become less prevalent with the active system feedback sessions, but is a concern in further evolution of the shapes themselves.
The first and most important follow-up step is to establish that this instrument can provide helpful feedback to a designer of a system.
We are planning to conduct user feedback sessions with designs-in-progress in the coming year, and are seeking developers interested in using this method during their design process.
In particular, we suspect that being able to see the nonverbal gestural feedback as it unfolds will help designers in different and interesting ways than getting summarized results from other methods for measuring user affect.
One important claim we've made in this paper is that this instrument could be used across cultures.
We have completed a study replicating the method used in the U.S. in Sweden, and are analyzing those results, and would like to solicit interested groups from other cultural backgrounds to conduct replication studies.
We can provide an object set on loan for such studies.
The patterns in response to the objects created by our sculptor suggested the following sculptural dimensions of interest: * rounded versus spiky  * smooth versus bubbly or protruding surface  * symmetrical versus asymmetrical  We are planning to explore iterations of objects based upon these dimensions , perhaps even crafting an interface that allows people to use sliders to craft their own affective objects, to give us a better understanding of these shape variables and how they relate to affect .
This testing exercise seems to indicate that we are on the right track in our design of the Sensual Evaluation Instrument.
Specifically: * It seems to be fun and engaging for people, in part because it makes use of the body and sense of touch, and also because it allows for flexibility in response.
We believe this approach holds promise and are pursuing it further.
We've also made the claim in this paper that this instrument could act as a helpful supplement to other modes of detecting/requesting affective state information.
We are working toward a replication of our study that includes biometric monitoring as well as a post-survey, to compare results and get a more complete picture of what each method exposes so far as participant affect.
Through iteration and prototype testing, we believe we have demonstrated the promise and potential of the Sensual Evaluation Instrument as a real-time, self-report method for eliciting affective responses to a computer system, toward creating an additional form of exchange between users and designers.
We are excited about the possibilities for the instrument in further enabling design teams to engage in productive and reasonably-scaled user testing that improves the emotional experience for end users.
We hope that other researchers and designers in the CHI community will take up our offer of using the SEI in other cultural contexts, and toward the development of systems, so that we can further refine the instrument toward a final stage of having a `kit' that can be used by anyone, anywhere--a helpful addition to the range of methods we have to measure and understand affect in action.
Pleasure with Products: Beyond Usability.
Isbister, K., and Hook, K. Evaluating Affective Interfaces: Innovative Approaches.
Consistency of personality in interactive characters: Verbal cues, nonverbal cues, and user characteristics.
The Illusion of Life: Disney Animation, Disney Editions.
Interational Affective Picture System : Digitized Photographs, Instruction Manual and Affective Ratings.
The Center for Research in Psychophysiology, University of Florida.
New York, Simon and Schuster.
Intuition: Its Powers and Perils.
Emotional Design: Why We Love  Everyday Things.
Central Processing Limitations in Sen-sorimotor Tasks, Pp.
Evaluating affective interactions: Alternatives to asking what users feel.
Presented at the 2005 CHI Workshop `Evaluating Affective Interfaces'.
A Circumplex Model of Affect, Journal of Personality and Social Psychology 39, pp.
Proceedings of the conference Design and Emotion, November 3 - 5 1999, Delft University of Technology, 23-29 23.
Touch me, hit me and I know how you feel.
A design approach to emotionally rich interaction.
Proceedings of DIS'00, Designing Interactive Systems.
Pain in Children: Comparison of Assessment Scales, Pediatric Nurse 14, 9017.
We thank the European Union for the funding of researchers dedicated to this project; we thank Rainey Straus for creating the objects, and for donating time to the project; and we thank those in the U.S. and Sweden who participated in our studies.
Thanks also to those affective presence researchers who inform and inspire our work: Phoebe Sengers, Bill Gaver, Michael Mateas, and Geri Gay.
Sentics: The Touch of Emotions.
Measuring emotion: development and application of an instrument to measure emotional re-sponses to products.
The Structure of Nonverbal Decoding Skills.
Interaction Relabelling and Extreme Characters: Methods for Exploring Aesthetic Interactions.
Proceedings of the conference on Designing interactive systems: processes, practices, methods, and techniques, August 2000.
Emotion in the Human face: Guidelines for Research and an Integration of Findings, Pergammon Press.
Designing Design: Ambiguity as a Resource for Design.
