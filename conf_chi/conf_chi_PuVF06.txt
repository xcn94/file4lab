The internet presents people with an increasingly bewildering variety of choices.
Online consumers have to rely on computerized search tools to find the most preferred option in a reasonable amount of time.
Recommender systems address this problem by searching for options based on a model of the user's preferences.
We consider example critiquing as a methodology for mixedinitiative recommender systems.
In this technique, users volunteer their preferences as critiques on examples.
It is thus important to stimulate their preference expression by selecting the proper examples, called suggestions.
We describe the look-ahead principle for suggestions and describe several suggestion strategies based on it.
We compare them in simulations and, for the first time, report a set of user studies which prove their effectiveness in increasing users' decision accuracy by up to 75%.
The dark box is the computer's function, the other boxes show actions of the user.
For their performance, it is crucial that this preference model be as accurate as possible.
This poses new challenges for human-computer interaction at the cognitive level that have been poorly addressed so far, but are key to the user success rate of such systems on e-commerce sites.
Utility theory provides a solid mathematical foundation for recommendations .
However, it assumes complex preference models that cannot be obtained in e-commerce scenarios because people are not willing to go through lengthy preference elicitation processes.
Furthermore, they are usually not very familiar with the available products and their characteristics.
Thus, their preferences are not well established, but constructed while learning about the available products .
To allow such construction to take place, users must be able to explore the space of possible options while building their preference model.
A good way to do this is through a mixed-initiative system based on example critiquing .
Example critiquing was first introduced by  and works by showing k examples to a user in each interaction cycle.
If the target item is not among the k examples, then a set of user critiques will be collected to refine the existing model.
Example critiquing allows users to express preferences in any order, on any criteria, and with any effort they are willing to expend .
It has been employed by a number of product search and recommender tools .
People increasingly face the difficult task of having to select the best option from a large set of multi-attribute alternatives, such as choosing an apartment to rent, a notebook computer to buy, or financial products in which to invest.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
In an example critiquing interaction, user's preferences are volunteered, not elicited: users are never forced to answer questions about preferences they might not be sure about.
Thus, users will only state preferences that they actually have, and they can tailor the effort they spend on stating their preferences to the importance of the decision that they are making.
Example critiquing was first proposed in  and has since been used in several recommender systems, such as FindMe , ATA , SmartClient , ExpertClerk  and the system of Shearin & Lieberman .
The ATA system  is particularly important, as it was the first to incorporate the notion of suggestions, which is crucial to our work.
Evaluating example critiquing interfaces has been an active area of research lately.
Pu and Kumar  showed that example critiquing interfaces enable users to perform decision tradeoff tasks more efficiently with considerably less errors than non-critiquing interfaces.
More recently, Pu and Chen  showed that the implementation of tradeoff support can increase users' decision accuracy by up to 57%.
In dynamic critiquing , a popular family of example critiquing interfaces, a metaphor of navigation through the product space is implemented; the interface proposes precomputed critiques  that can be selected by the users.
Several researchers  recognized the need to suggest diverse examples in recommender tools.
This approach has been applied to recommender systems, and it has been shown in  that such techniques can reduce the length of the recommendation cycle by up to 76%, compared to the pure similarity-based recommender.
In , diversity is used to implement system recommendations to the query show me more like this.
Their adaptive search algorithm alternates between a strategy that favors similarity and one that favors diversity .
More recent work on diversity was motivated to compensate for users' preference uncertainty , where the utility function is parameterized over a probability distribution, or to cover different topic interests in collaborative filtering recommenders .
However, a more rational behavior is to evaluate potential candidates based on as many attributes as a user may have using compensatory decision strategies .
Therefore, users should be guided to not only express more preferences, but also expand on the number of attributes for which preferred values have been established.
The latter, called preference enumeration, is thus an important measure of quality for a preference model.
We have found that simply showing examples that are optimal for the current preference model may not be enough to overcome the prominence effect.
As the experiments described in this paper show, users are not likely to increase attribute enumeration after interacting with optimal examples.
This observation has led us to extend the example critiquing method to include both * candidate examples that are optimal for the preference model, and * suggested examples that are chosen to stimulate the expression of preferences.
In this paper, we take a deeper look at how suggestions should be generated and derive a family of new strategies, called model-based strategies.
Our final result is an evaluation of the impact of these strategies on decision accuracy through user studies.
We define decision accuracy as the likelihood that a user finds the most preferred option when using the tool.
However, to avoid the expense of using each of the different possible suggestion strategies in a study with actual users, we first carried out an evaluation based on simulated users.
As the purpose of suggestions is to stimulate expression of preference, we compare different suggestion strategies with respect to user's preference enumeration, defined as the number of preferences stated by the user.
We also show in the experiments that this preference enumeration is indeed positively correlated with decision accuracy.
The simulations compared 6 different strategies: three from our work, one based on random selection, the strategy proposed by Linden et al.
McSherry's algorithm is a further development based on .
The comparison with a random strategy was included to rule out any strategy that would have extraordinarily poor performance, while the strategies of Linden and McSherry represent the strategies that are commonly proposed in the literature.
Results suggest that the model-based probabilistic strategy performs best, and it was consequently used in a study with real users.
The study is a within-subject comparative user study where 60 live and 40 recruited users compared two versions of example critiquing systems, one with and one without suggestion interfaces.
Results indicate that users were able to state significantly more preferences when using the suggestion interfaces .
More importantly, the user study also indicates that a higher preference enumeration leads to more accurate decisions.
In our approach, a preference model consists of a user's stated preferred attribute values and their relative importance.
When preferences are inferred or constructed from a set of examples, human subjects have been found to favor outcomes based on the superiority of only one or few attributes.
This phenomenon is known as the prominence effect .
Assume that the system shows the 2 most promising ones: f1 and f2 , the two with lowest price.
Here f1 already dominates f2  according to the users hidden preferences, so she is unlikely to state any additional preference based on these examples.
A strategy that generates suggestions according to diversity might pick f7 as suggestion as it is most different from what is currently displayed.
However, the user is likely to discard this option, because it is very expensive and arrives very late.
Neither of them is likely to be taken seriously by the user: f4 is likely to leave at a very early and inconvenient hour, while f7 arrives much too late to be useful.
What makes f7 a bad suggestion to show?
If the hidden preference is for the city airport, then f5 dominates because it is cheaper.
If the hidden preference is on arrival time, then only if the user requires an arrival later than 16:30 there is a chance that it will not be dominated by f6 , which is otherwise significantly cheaper.
These examples differ from f4 and f7 in that they have a good chance of becoming optimal for a wide range of possible hidden preferences.
The problem faced when using a search tool is that the user has to learn how to state her preferences so that the tool can find her most preferred option.
We can assume that she is minimizing her own effort and will add preferences to the model only when she can expect them to have an impact on the solutions.
This is the case when: * she can see several options that differ in a possible preference, and * these options are relevant, i.e.
In all other cases, stating an additional preference is irrelevant.
When all options would lead to the same evaluation, or when the preference only has an effect on options that would not be eligible anyway, stating it would only be wasted effort.
This leads us to the following look-ahead principle as a basis for suggestion strategies: Suggestions should be options that could become optimal when an additional preference is stated.
As a simple example consider searching for a flight between two cities A and B.
For the departure airport, there is a city airport  which is very close to where the user lives and a big international airport  which takes several hours to reach.
Assume that the user has three preferences in this order of importance: * the lowest price * arrive by 12:00 * depart from the city airport and that she initially only states a preference on the price.
The other two preferences remain hidden.
Finally, assume that the choice is among the following options:
Since the suggestion strategies depend on the preference model that is used in the recommender system, we define the preference model that we assume further in the discussion.
We stress that these assumptions are only made for generating suggestions.
The preference model used in the recommender system could be more diverse or more specific as required by the application.
Also, similar model-based suggestion strategies could be derived for other preference models.
Given a fixed set of n attributes A = {A1 , .., An }, an option o is characterized by the values a1 , ..., an  that must belong to the fixed domains D1 , .., Dn , which can be explicitly enumerated or can be intervals of continuous or discrete elements.
The user's preferences are supposed to be independent and defined on individual attributes: Definition 1.
A preference r is an order relation r of the values of an attribute a; r expresses that two values are equally preferred.
A preference model R is a set of preferences {r1 , .., rm }.
If there can be preferences over a combination of attributes, such as the total travel time in a journey, we assume that the model includes additional attributes that model these combinations.
As a preference r always applies to the same attribute az , we simplify the notation and apply r and r to the options directly: o1 r o2 iff az  r az .
Depending on the formalism used for modeling preferences, there are different ways of combining the order relations given by the individual preferences ri in the user's preference model R into a global order of the options.
For example, each preference may be expressed by a number and the combination may be formed by summing the numbers corresponding to each preference, or by taking their minimum or maximum.
We can obtain suggestion strategies that are valid with most known preference modeling formalisms by using qualitative optimality criteria based on dominance and Paretooptimality: Definition 2.
We write o R o  We also say that o is dominated  Note that we use the same symbol  for both individual preferences and sets of preferences.
An option o is Pareto-optimal  if and only if it is not dominated by any other option.
Pareto-optimality is the strongest concept that is applicable regardless of the preference modeling formalism used.
Our techniques use the concept of dominating set: Definition 4.
The dominating set of an option o is the set + of all options that dominate o: OR  = {o  O : o R o }.
We will write O+  if it is clear from the context which is the set R of preferences we are considering.
In our applications, users initially state only a subset R of their true preference model R. When a preference is added, dominated options with respect to R can become Paretooptimal.
The following observation is the basis for evaluating the likelihood that a dominated option will become Pareto-optimal: P ROPOSITION 1.
A dominated option o with respect to R becomes Pareto-optimal with respect to R  ri , if and only if o is strictly better with respect to ri than all options that currently dominate + it: o ri o,  o  OR .
In general, the Pareto-optimal set increases when stating more preferences, as the dominance relation becomes sparser.
We propose 3 strategies that we call model-based suggestion strategies because they specifically choose examples to stimulate the expression of additional preferences based on the current preference model.
They use Pareto-optimality to implement the principle stated in the introduction: suggestions should not be optimal yet, but have a high likelihood of becoming optimal when an additional preference is added.
An ideal suggestion is an option that is Pareto-optimal with respect to the full preference model R, but is dominated in R, the partial preference model.
Following Proposition 1, the probability of a dominated option o becoming Pareto-optimal is equal to:
Evaluating this probability exactly requires the probability distribution of the possible preferences, generally not known.
Therefore we propose several strategies based on increasingly detailed assumptions about these distributions.
As a heuristic we use a normalized difference for interval domains: the chances that a new preference will treat o1 and o2 differently is directly proportional to the difference between their values.
For discrete attributes, it is sufficient to check if the attributes take different values.If so, there will be equal chances that one is preferred over the other and  = 0.5.
If the values are the same, the dominance relation cannot be broken by a preference on this attribute, so  = 0.
The attribute strategy selects f6 as the best suggestion.
Its dominators for price  all depart from a different airport and leave before , so the diff is equal to 1 on both attributes.
The attribute strategy cannot choose a second suggestion because all other options have the same values for diff on both attributes.
The probabilistic strategy chooses f6 and f5 since they are both dominated by four options  but have high chance of breaking this domination because they significantly differ on the other attributes .
Let's assume now that the user has stated her preference about price and time.
All suggestion techniques show an example with the city airport, and the user is stimulated to state that as a preference.
The attribute strategy considers the fact that for breaking the dominance relation with all options in the dominating set, there has to be one attribute where all dominating options have different values.
To express this concept, we define the function diff : Definition 5.
For an attribute ai and a given option o1 with dominating set O+ , dif f  = 1 if: * interval domains: ai  should be either greater than or smaller than the attribute values for ai of all options in O+ * enumerated domains: ai  should be different than the attribute values for ai for all options in O+ and 0 otherwise.
The reasoning is the following: for interval domains, we assume that preferences are continuous, i.e.
This applies to attributes like price or travel time and fits well with the majority of users.
For enumerated domains, a new preference may break the dominance relation whenever the attribute has a different value.
Then we count the number of attributes for which there are no preferences yet and where all dominating options have a different value:
Simulation results on a database of actual apartment offers.
For each strategy, we compare the fraction of simulation runs that discover at least x preferences.
100 runs, data-set with 6 attributes and preferences.
The suggestions strategies are heuristics, and it is not clear which of them performs best.
Since evaluations with live users can only be implemented with a specific design, we first select the best suggestion strategy by simulating the interaction of a computer generated user with randomly generated preferences.
In this way, we can compare the different techniques and select the most promising one for further evaluation.
This is followed by real user studies in the next section using the probabilistic suggestion strategy.
In the simulations, users stated a randomly generated set of m preferences on different attributes of available options stored in a database.
We are interested in whether the system obtains a complete model of the user's preferences in order to test the objective of the strategies, which is to motivate the user to express as many preferences as possible.
Previously in the example, f1 and f2 are shown as candidate optimal examples.
We will now consider which options will be chosen by the strategies as suggestions, omitting the calculations.
We investigated the impact of the number of preferences, the number of attributes and the size of the data set.
Surprisingly we discovered that the number of attributes only slightly changes the results.
Keeping the number of preferences constant at 6, we varied the simulations on the number of attributes set to 6,9,and 12 respectively.
The fraction of runs  that discovered all the preferences varied for each strategy and simulation scenario by no more than 5%.
We were surprised by the fact that the strategy of generating extreme examples, as originally proposed by Linden , performed so poorly and only outperformed the randomly selected suggestions by a narrow margin.
This shows the importance of considering the preferences that are already known and those to be discovered in the design of suggestion strategies.
The simulations show that the simulated user is much more likely to state new preferences using the probabilistic strategy .
Moreover, in the simulations the complete preference model was discovered up to 25 times more often with the probabilistic strategy than with randomly picked suggestions, up to 10 times more than using the extreme strategy, and 1.5 times more than the counting strategy.
The probabilistic strategy has a better average performance than the attribute strategy.
Among the three model-based strategies, the probabilistic strategy provides the best results.
However, it also makes the most assumptions about the preferences the user is likely to state.
When these assumptions are not satisfied, the performance is likely to degrade.
On the other hand, the counting strategy is the most robust among our strategies as it makes no assumptions whatsoever about the form of the user's preferences, while still achieving a large gain over simpler strategies.
In the actual user studies, we decided to use the probabilistic strategy.
The simulated interaction starts with the initial preference .
K options are selected as suggestions according to one of the following strategies: random choice, suggestion of extrema, maximization of diversity  and the three model-based suggestions that we propose .
Maximization of diversity consists of selecting the subset of the k most diverse options, so that the diversity  between each option is maximized .
The simulated user behaves according to our model, stating a new preference whenever the suggestions contain an option that would become optimal if such a preference were added to the user model.
The interaction continues until either the user model is complete or the simulated user states no further preference.
Note that when the complete preference model is discovered the user finds the most wanted option.
The results of the simulation for a catalog of student accommodations  are summarized in Figure 2.
It shows the percentage of runs  that discover at least x out of the 6 preferences in the complete user model.
We see that the suggestion strategies provide a marked increase in the number of preferences that are uncovered, and, in particular, the model-based strategies perform best.
In another test, we ran the same simulation for a catalog of 100 randomly generated options with 9 attributes and 9 preferences .
The results are shown in Figure 3.
We can see that random and extreme strategies now perform very poorly and model-based strategies appear much better.
Also, the difference among the three model-based approaches is smaller: the counting strategy performs only slightly worse than the attribute and probabilistic strategies.
This occurs because there is no correlation between the attributes.
In the user study, we are particularly interested in verifying: Hypothesis 1: using model-based suggestions  leads to more complete preference models.
Hypothesis 2: using model-based suggestions leads to more accurate decisions.
Hypothesis 3: more complete preference models tend to give more accurate decisions, indicating that the reasoning underlying the model-based suggestions is correct.
We performed user studies using FlatFinder, a web application for finding student housing that uses real offers from a university database that was updated daily.
The tool used the probabilistic strategy, as it was determined to be the best in the experiments with the simulated user.
We recruited student subjects who had an interest in finding housing and thus were quite motivated for the task.
We studied two settings: * in an unsupervised setting, we monitored user behavior on a publicly accessible example critiquing search tool for the listing.
This allowed us to obtain data from over a hundred different users; however, it was not possible to judge decision accuracy since we were not able to interview the users themselves.
Here, we could determine decision accuracy because at the end we asked the subjects to carefully examine the entire database of offers to determine their target option.
Thus, we could determine the switching rate and measure decision accuracy.
Each apartment comprises 10 attributes: the type of accommodation , the rental price, the number of rooms, furnished , the bathroom , the type of kitchen , the transportation available , the distance to the university and the distance to the town center.
For numerical attributes, a preference consists of a relational operator , a threshold value and an importance weight between 1-5.
For example, price less than 600 Francs with importance 4 indicates a relatively strong preference for an apartment below 600 Francs.
For discrete attributes, a preference specifies a preferred value with a certain importance.
Preferences are translated into numbers using standardized value functions and are combined by summing the results.
The options are ordered so that the highest value is the most preferred.
The users stated a set of initial preferences and then obtained options by pressing the search button.
Subsequently, they went through a sequence of interaction cycles where they could refine their preferences by critiquing the displayed examples.
The system maintains their current set of preferences and the user could state additional preferences, change the reference value of existing preferences, or even remove one or more of the preferences.
Finally, the process would finish with a user's final set of preferences, and a target choice chosen by the user from the displayed examples.
The search tool was made available in two versions: * C, only showing a set of 6 candidate apartments without suggestions, and * C+S, showing a set of 3 candidate apartments and 3 suggestions selected according to the probabilistic strategy We now describe the results of the two experiments.
Results of the supervised user study.
Decision accuracy and preference enumeration  are higher when suggestions are provided.
We collected logs from 63 active users who went through several cycles of preference revision.
In the following, whenever we present a hypothesis comparing users of the same group, we show its statistical significance using a paired student test.
For all hypotheses comparing users of different groups, we use the unpaired student test to indicate statistical significance.
This increment was on average 1.46 for the tool with suggestions C+S and only 0.64 for the tool C, showing the higher involvement of users when they see suggestions.
It is interesting to see that in both groups the users interacted for a similar number of cycles , and that the number of initial preferences is also close , meaning that the groups are relatively unbiased.
The result of the test shows clearly that users are more likely to state preferences when suggestions are present, thus verifying Hypothesis 1.
They also show that model-based suggestions are significantly better than random ones.
However, as this is an online experiment, we are not able to measure decision accuracy.
Thus, we also conducted a supervised user study.
The supervised user study used the same tool as the online user study but users were followed during their interaction.
To measure improvement of accuracy, we instructed all of users to identify her most preferred item after she searched the database using interface 1.
To evaluate whether the second choice was better than the initial one, we instructed the users to review all apartments  and tell us whether c1 , c2 , or a completely different one truly seemed best.
Thus, the experiment allowed us to measure decision accuracy since we obtained the true target choice for each user.
If users would stand by their first choice, it would indicate that they had found their target choice without further help from the second interface.
If users would stand by their second choice, it would indicate that they had found their target choice with the help of the second interface.
If users chose yet another item, it would indicate that they had not found their target choice even though they performed search with both interfaces.
40  subjects of 9 different nationalities, mostly undergraduate students, took part in the study.
Most of them  had searched for an apartment in the area before and 26 out of 40 had used online tools to look for accommodations.
Importantly, all subjects were motivated by the interest of finding a better apartment for themselves.
To overcome bias due to learning and fatigue, we divided the users in two groups, who were asked to interact with the versions in different order.
Group 1 used tool C  and then C+S , while group 2 used the tools in the inverse order.
Both groups then went through the entire list to find the true most preferred option.
For each version of the tool and each group, we recorded as decision accuracy as the fraction of subjects where the final choice made using that interface was equal to the target option.
We expected that the order of presenting the versions would be important: once they have realized their own preferences and found a satisfactory option, they are likely to be consistent with that; therefore we would have expected a2 > a1 in both cases.
However we would expect that average accuracy would significantly increase with suggestions, and so we would see a2 >> a1 in the first group and a2 only slightly higher than a1 in group 2.
For group 2, accuracy was already very high when using the version with suggestions .
Further interaction with the tool C  did not increase accuracy any further.
Users in group 2 used C+S directly and already achieved an average accuracy of 72%.
We would have expected that a consequent use of tool C would have a small positive effect on the accuracy, but in reality the accuracy decreased to 67%.
10 subjects changed their final choice using the tool without suggestions and 6 of them said that the newly chosen was only equally good as the one they originally chose.
The fact that accuracy does not drop significantly in this case is not surprising because users remember their preferences from using the tool with suggestions and will thus state them more accurately independently of the tool.
We can conclude from this group that improved accuracy is not simply the result of performing the search a second time, but due to the provision of suggestions in the tool.
Also, the closeness of the accuracy levels reached by both groups when using suggestions can be interpreted as confirmation of its significance.
We also note that users needed less cycles  to make a decision with interface C+S  than interface C .
Figures 4 and 5 show the variation of decision accuracy for the two groups.
For group 1, after interaction with tool C, the accuracy is on average only 45%, but after interaction with C+S, the version with suggestions, it increases to 80%.
10 of the 20 subjects in this group switched to another choice between the two versions, and 8 of them reported that the new choice was better.
Variation of accuracy against variation of the number of stated preference P in the two steps of the user test.
Finally, a third confirmation can be obtained by considering the influence that variations in the size of the preference model have on decision accuracy, shown in Table 4.
Each column corresponds to users where the size of the preference model decreased, stayed the same, or increased, and shows the fraction for which the accuracy increased, stayed the same or decreased .
We can see that a significant increase in accuracy occurs only when the size of the preference model increases; in all other cases there are some random variations but no major increases.
The statistical test confirms the hypothesis that an increase in preference enumeration causes an increase in accuracy at a level of p = 0.0322, t = 1.928.
Thus, we conclude that hypothesis 3 is also validated by the user study: a more complete preference model indeed leads to more accurate decisions.
We believe that subjects in the first group did not find a good choice and thus paid a relatively high price to get an apartment with which they would feel comfortable.
Conditioned by this high price they were then willing to spend even more as they discovered more interesting features through suggestions.
On the other hand, subjects in group 2 already found a good choice in the first use of the tool, and were unwilling to accept a high price when they did not find a better choice in the second search without suggestions.
Thus, we conclude that Hypothesis 2 is confirmed: suggestions indeed increase decision accuracy.
In this study, we notice that when suggestions are present, users state a higher number of preferences .
Therefore, Hypothesis 1 is again confirmed.
To validate Hypothesis 3, that a higher preference enumeration also leads to more accurate decisions, we can compare the average size of preference model for those users who found their target solution with the first use of the tool and those who did not.
In both groups, users who did find their target in the first try stated on average 5.56 preferences  while users who did not find their target stated only an average of 4.88 preferences .
This shows that increased preference enumeration indeed improves accuracy, but this result was not statistically significant .
In fact, there is a chance that this correlation is due to some users being more informed and thus both making more accurate decisions and stating more preferences.
As an evaluation that is independent of user's a-priori knowledge, we only considered those users who did not find their target in the first try.
As a measure of correlation of preference enumeration and accuracy, we considered how often an increase in preference enumeration in the second try led to finding the most preferred option on the second try.
Table 3 shows that among users whose preference model did not grow in size, only 45% found their target.
However, for those that increased their preference enumeration, 83% found their target as a result.
Again, we see a good confirmation that higher preference enumeration leads to a more accurate decision with real users .
Search and recommender tools are an important part of computer usage today and present significant new humancomputer interaction challenges that have been insufficiently addressed thus far.
Among them is the problem of obtaining accurate user preferences through interaction.
Mixed-initiative systems such as example critiquing are a promising technology for efficiently eliciting accurate user preference models.
Determining how to stimulate the user to state preferences on as many attributes as she may have is a key issue concerning such systems.
We have developed a model for computing examples most suitable for stimulating preference expression and designed several suggestion strategies based on this model.
The main principle is that suggestions should be options that are dominated under the current preference model but would no longer be dominated with the inclusion of additional preferences.
In order to implement this principle with a minimum of assumptions about the user's preference model, we defined different strategies based on the concept of Pareto-optimality.
We first compared various suggestion strategies on simulations and determined the one that seemed to be the most effective.
We confirmed its strong performance with live user studies, where we observed that the quality of the preference model, as measured by the number of stated preferences, increased almost twice as much with suggestions as without.
We followed this online user study by a supervised user study which also allowed us to measure decision accuracy.
Optimal Recommendation Sets: Covering Uncertainty over User Preferences.
In Proceedings of the 20th National Conference on Artificial Intelligence , 2005, pp.
Pearl Pu and Boi Faltings.
Enriching buyers' experiences: the smartclient approach.
In SIGCHI conference on Human factors in computing systems, pages 289-296.
Pearl Pu and Boi Faltings.
Decision tradeoff using example-critiquing and constraint programming.
Pearl Pu, Boi Faltings and Marc Torrens, Effective Interaction Principles for Online Product Search Environments.
In Proceedings of the IEEE/WIC/ACM International Joint Conference on Intelligent Agent Technology and Web Intelligence, 2004, pp.
Pearl Pu and P. Kumar, Evaluating Example-Based Search Tools.
In Proceedings of the 5th ACM Conference on Electronic Commerce , ACM Press, 2004, pp.
Pearl Pu and Li Chen, Integrating Tradeoff Support in Product Search Tools for E-Commerce Sites.
In Proceeding of the 6th ACM Conference on Electronic Commerce , ACM Press, 2005, pp.
James Reilly, Kevin McCarthy, Lorraine McGinty, and Barry Smyth.
Expertclerk: Navigating shoppers buying process with the combination of asking and proposing.
Sybil Shearin and Henry Lieberman.
Barry Smyth and Lorraine McGinty.
In Proceedings of the 4th International Conference on Case-Based Reasoning , Springer-Verlag, 2001, pp.
A. Tversky, S. Sattath, and P. Slovic.
Contingent weighting in judgment and choice.
Improving Recommendation Lists Through Topic Diversification.
In Proceedings of the 14th International World Wide Web Conference , 2005, pp.
RABBIT: An Interface for Database Access.
D. Bridge and A. Ferguson.
Diverse Product Recommendations using an Expressive Language for Case Retrieval.
In Advances in Case-Based Reasoning, Springer, 2002 2.
The FindMe approach to assisted browsing.
Hybrid recommender systems: survey and experiments.
R. Burke, K. Hammond and E. Cooper.
Knowledge-Based Navigation of Complex Information Spaces.
In Proceedings of the 13th National Conference on Artificial Intelligence, AAAI press, 1996, pp.
Decisions with Multiple Objectives: Preferences and Value Tradeoffs.
Greg Linden, Steve Hanks, and Neal Lesh.
Interactive assessment of user preference models: The automated travel assistant.
K. McCarthy, J. Reilly, L. McGinty and B. Smyth.
In Proceedings of the 10th International Conference on Intelligent User Interfaces , New York: ACM Press, 2005, pp.
L. McGinty and B. Smyth.
On the Role of Diversity in Conversational Recommender Systems.
In Proceedings of the 5th International Conference on Case-Based Reasoning , 2003, pp.
Proceedings of the 5th International Conference on Case-Based Reasoning, LNAI 2689, Springer-Verlag, pp.
