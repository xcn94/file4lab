Large-scale, ground-level urban imagery has recently developed as an important element of online mapping tools such as Google's Street View.
Such imagery is extremely valuable in a number of potential applications, ranging from augmented reality to 3D modeling, and from urban planning to monitoring city infrastructure.
While such imagery is already available from many sources, including Street View and tourist photos on photo-sharing sites, these collections have drawbacks related to high cost, incompleteness, and accuracy.
A potential solution is to leverage the community of photographers around the world to collaboratively acquire large-scale image collections.
This work explores this approach through PhotoCity, an online game that trains its players to become "experts" at taking photos at targeted locations and in great density, for the purposes of creating 3D building models.
To evaluate our approach, we ran a competition between two universities that resulted in the submission of over 100,000 photos, many of which were highly relevant for the 3D modeling task at hand.
Although the number of players was small, we found that this was compensated for by incentives that drove players to become experts at photo collection, often capturing thousands of useful photos each.
Imagine having a huge collection of georegistered photos taken from every corner of a city, inside and out, at many different times of day, different seasons, across many years.
Such a photo collection would have many applications.
You could give your faraway friend a tour, or scope out a new part of town before going there.
For any location, you could see it during the day, at night, during summer or winter, and from any angle.
If a building was torn down or rebuilt, a snapshot of how it once was would be preserved.
These localized photos could be used to enable dozens of new augmented reality applications, could help in monitoring and analyzing building infrastructure, and could aid in urban planning and analysis of changes in cities over time.
The photos could even be used to build a detailed 3D model of the entire city using computer vision techniques .
While large sets of urban photos exist in very structured  as well as unstructured  collections, these existing collections have a number of drawbacks in the context of such mapping and analysis applications.
The structured collections  are quite expensive to acquire, only available in certain areas, and typically capture only certain areas such as city streets and popular footpaths.
These structured collections tend to be "refreshed" infrequently and thus photos may often be out of date; similarly, only a single time of day or year is usually available.
On the other hand, unstructured collections  are captured "for free" by thousands of people  walking around everyday with cameras.
However, only landmarks, such as the Colosseum and Trevi Fountain, are well-represented, and most of the rest of the world is very sparsely photographed.
For instance, in recent work in computer vision, 150,000 Flickr photos of Rome were downloaded and automatically reconstructed into a set of 3D models spanning the city , but these models only represent disconnected pockets of 3D structure corresponding to famous landmarks.
Less popular areas such as side streets were not photographed enough times to be modeled.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
We have developed PhotoCity to crowdsource the gathering of these photos in a fun and effective way, focusing on the application of 3D city modeling.
PhotoCity is a game played by simply taking photos.
The game processes the captured photos using computer vision techniques and uses them to incrementally expand 3D models; players `capture' virtual flags and castles as they contribute to digital 3D replicas of real buildings.
The result of the game is a set of detailed 3D models and a large set of photos that densely cover an entire area from many different angles.
A preliminary version of the game is described in , with attention on the design of a game that enables players to collaboratively construct 3D models by taking photos.
In this paper, we apply PhotoCity to the real task of modeling two university campuses, demonstrating what the game can accomplish with a small group of expert players who have been trained by playing the game.
We seek to determine whether the game dynamics we designed for PhotoCity are conducive to large-scale distributed data collection.
We present the detailed results of a field study to determine the effectiveness of our game PhotoCity, as well as present design changes made as we received feedback from this experiment.
PhotoCity, like other games with a purpose , provides incentives and game mechanics that drive people to perform a useful task, in this case, to capture missing photos needed for 3D modeling.
However, a unique challenge in PhotoCity is to find ways to take people's normal behavior when taking photos--i.e., to take a few well-composed shots from "canonical" viewpoints of the fronts of buildings-- and change them so that they take a larger, more useful set of photos for the task at hand.
PhotoCity addresses this through a map-based user interface design and competitive game mechanics, but we still found that it often takes some time for users to warm up to how to play the game.
To be a viable mechanism for large-scale data collection, the game must engage the interest of enough players for long enough for them to "learn" this new photo-taking behavior and collect a sufficiently complete set of photos.
To evaluate whether PhotoCity is an effective way to collect a comprehensive set of photos of a large area, we held a competition between two universities.
The competition brought in over 100,000 photos; compared to photos of the same areas available on Flickr, the PhotoCity collection provides much greater geographical coverage, and is much more effective for 3D reconstruction.
These 100,000 photos were contributed by a relatively small number of players .
Despite this small number, the game was engaging enough for these players to capture a very sizable collection of useful data, and the results suggest that crowdsourcing is a viable mechanism for large-scale acquisition of visual data.
In this paper, we will briefly outline the basic mechanics of PhotoCity and the ways in which we guide players' actions towards the purpose of the game.
Finally, we will discuss the outcome of our university competition: that the success of PhotoCity depends on the participation of highly-motivated expert players who become so involved in the game that they play for an extended period of time, are able to hone their skills, and contribute thousands of photos each.
A key contribution of this paper is the design and evaluation of a game for large-scale, targeted data collection.
An overarching lesson is that the success of such a game is not necessarily dependent on the number of players.
What is most important is focusing player effort and providing competitive or exciting situations that lure people in long enough to turn them into expert players.
A game with a purpose  is a means of extracting useful output from a human player in a game setting in a way that is fun for the player.
Many GWAPs are designed to have humans perform tasks that are difficult for computers, such as labeling images and folding proteins.
Our GWAP leverages humans for the physical activity of going outside and taking a picture  in a specific place.
In their seminal work on the ESP game , von Ahn and Dabbish designed a game for the purpose of labeling Internet images with relevant textual tags.
The general idea of the ESP game is that two players who can see the same image try to come up with matching tags.
The players are paired randomly and have no way to communicate with each other, so if they want to earn points, they must type words that are relevant to the image--words that make good tags.
PhotoCity uses automatic vision techniques as a verification mechanism, only rewarding players for verifiably useful input.
The key to labeling large numbers of images with the ESP game is to have a lot of people play, for minutes or hours each.
Accordingly, the game is very simple and quick to play, with rounds lasting two minutes, making it ideal for an audience of casual gamers.
In contrast, we found that PhotoCity could achieve its goals with a small player base, which is fortunate because the game is significantly more involved and time consuming than the ESP game.
Foldit  is a GWAP designed for human-assisted protein folding, taking advantage of humans' innate spatial reasoning abilities.
To play, players manipulate digital 3D protein structures, trying to find a configuration with the most tightly packed  shape for each protein.
Foldit is designed to have a wide appeal, with colorful proteins and gentle introductory levels, but all that is needed to find the best protein configuration is one or a few experts.
The problem is that no one knows what constitutes such an expert, so Foldit must attract many of players on the off chance that one of them discovers he or she is a protein-folding savant.
PhotoCity similarly relies on a small group of highly motivated, expert photo-takers.
Finally, another relevant GWAP is the photography game EyeSpy of Bell et al.
The purpose of EyeSpy is to collect photos and tags that would be useful for navigation and giving someone directions around a city based on easily recognized landmarks.
To play, a player walks around with a cell phone taking photos, entering tags, and trying to locate the photos or tags of other players.
Like PhotoCity, this game focuses on producing usable output, specifically photos that are useful for a specific navigation application, as well as of places that people would not ordinarily photograph.
The difference is that EyeSpy photos are used for navigation purposes and have different requirements than PhotoCity photos, which are used for 3D modeling.
A number of recent systems have utilized collaboration from large numbers of people to generate large-scale public goods related to online maps .
Most relevant to our work is OpenStreetMap , an online system that allows people to contribute GPS traces and edit maps in the service of creating a open map of the entire world, complete with street networks, parks, building outlines, and many other features.
Our work is complementary, seeking to supplement such maps with dense sets of ground-level photos contributed by the community .
A related project, Wikimapia , allows users to draw overlays and annotate regions on aerial photos, resulting in more semantically rich maps; the LabelMe system  provides similar functionality for Internet photos.
Google has also released several tools for individuals to create 3D models of real-world buildings, including SketchUp  and Building Maker ; the goal is to use these models to populate city maps.
These tools have grown out of work on interactive modeling in the CAD and computer graphics communities .
Unlike all of these systems, our work explores the use of competition in a game setting to provide incentives for users to contribute content.
While this data is extremely useful for understanding and visualizing where people take photos and reconstructing famous landmarks , in our context we seek a much more complete set of photos for our task.
Even extremely large sets of Flickr photos are insufficient for reconstructing complete models of buildings and cities .
In contrast to scraping the web for images, the Wiki-based city modeling approach  of Irschara et al.
By contributing their photos to a central repository, wiki users  are helping to build a 3D model of a location of shared interest.
The difference is that PhotoCity provides additional incentives for players to upload their photos, such as capturing virtual flags and scoring points.
PhotoCity is designed around the goal of acquiring photos for use in 3D modeling, and uses as a back end recent work in computer vision for automatic 3D reconstruction from 2D images.
This computer vision technology used stems directly from the work of Snavely et al.
This technology takes a set of photos and automatically reconstructs the viewpoint  from which each photo was taken, as well as a "point cloud" representation of the scene; example 3D point clouds are shown in Figures 3, 4 and 8.
PhotoCity exposes these models to players through a map-based interface, one for each building in play, and actively encourages players to capture views that extend and expand these models.
Unlike Photosynth, where each model is built by a single user, PhotoCity players collaborate to reconstruct the world.
These computer vision techniques can also be run on large collections of user-contributed photos on sites like Flickr.
A description of a preliminary version of PhotoCity and the underlying computer vision technology is given in , but we recap and expand on it here.
The core mechanic of our game involves players inspecting the state of the game world on a map, taking photos at locations of promising in-game value, uploading the photos to the PhotoCity website, and then observing the results of their play.
Through repeated cycles of this process, summarized in Figure 1, players introduce new photos of the game world into play, which in turn expand the 3D "point cloud" models stored on the servers.
The geometric points in these point clouds correspond to points on the surfaces of buildings, trees, and other objects, and also to the game "points" that players accumulate through the course of the game.
A seed made from 30 photos.
Players take photos to fill in the missing holes  and to expand this seed from a single facade to the entire building.
PhotoCity map with castles and flags at University of Washington.
Different teams  have different colored flags and castles.
When a player captures a flag, the flag becomes the color of her team.
When a player captures a building, her name appears under the castle icon.
If a player adds the most points to the school library, for example, that player "captures" the building, and his name appears next to the library's castle icon on the map.
Flags correspond to specific map locations in the real world, and are automatically placed along building walls to guide players to more lucrative, missing viewpoints.
A player controls a flag when her photos contribute the most points to that one section of wall.
As models grow larger, more flags appear along the edges of the model.
This basic game mechanic accomplishes two things towards the purpose of PhotoCity:  Photos are not just of the `popular' locations, but include many different locations and many different viewing angles of each location.
A verification mechanism is built into the game.
Every photo is compared against a 3D model when it is uploaded, and the only photos that earn points are photos that overlap with or fit into an existing model.
If a player uploads an irrelevant photo, of a different building or of a flower for example, that photo will fail to match the 3D model and the game will mark it as `unsuccessful'.
The game performs this matching in a matter of seconds and then the player views which photos failed and which worked.
They can use this information to modify their approach to taking pictures.
Occasionally, a photo of of the correct building fails to match because the virtual model of that building is not yet large enough to incorporate that photo.
The system automatically retries each photo three times, but if a photo repeatedly fails to match , players are free to re-upload photos.
When they do, the game considers these as entirely new photos.
Every virtual model in the game is represented as a dense point cloud, like the one pictured in Figure 4.
When a player adds a photo to a model, our back end server estimates the 3D pose of that photo with respect to the current 3D model, then matches pixels in that photo to existing, nearby photos, in order to triangulate new points--in essence, each photo acts similar to a "laser scan" captured at a particular viewpoint, with geometry created by matching points in that photo to other views.
This process literally adds new 3D points to the model, and the player earns one game point for each new 3D point.
To play the game, the typical player looks at the map of the game, identifies the flags she wishes to capture, and then takes photos of that portion of the building.
For a photo to earn points, it must  overlap with enough existing points in the model and  overlap the empty space next to a model.
The first requirement allows the photo to connect with the model and have its position within the model automatically calculated.
The second requirement, that the photo look beyond the existing model, allows new points to be added to that void as soon as there are enough other photos to triangulate the 3D positions of those features.
A photo can add up to several thousand new points.
Instead of taking a nice photo of the front of a particular building, an area that is likely already saturated in photos,
In addition to playing PhotoCity by growing existing models, players can also seed their own models.
Every model in PhotoCity starts off as a seed generated from a small batch of photos of the real building.
The number of photos used to make a seed is between 20 and 200.
Models in their starting state usually only span one face or one corner of a building and have rough edges and large holes where data for the building has yet to be captured.
Figure 3 shows the size of a seed made from thirty photos.
Once a seed has been generated, it is aligned with the map and added to the set of active, under construction models in the game.
Instead of carefully composing a single shot, the key to PhotoCity is to take as many photos as possible from many different angles.
The ideas of quantity over quality, and sweeping the camera around a scene, are probably the most radical notions that people new to PhotoCity have to learn.
Figures 4 and 11 show camera/photographer positions and how players walked around a particular model taking photos every few steps.
This is but one dimension on which to change how players take photos, favoring quantity and variety over nice composition.
In the end, the photos taken for PhotoCity should have the coverage, density, and variety to essentially blanket an entire location in photographs.
A near-complete model with camera positions shown as black triangles around the model.
The game requires a different style of photography, one that favors quantity and variety over artistic composition.
In order to expand a model, players must take photos that overlap the existing model, and then move to a new area, taking many photos along the way.
To do so, she takes a starting set of photos that capture just one side or corner of a building from all possible angles.
Then she uploads those photos through a separate web interface and waits for the game to generate the model using the techniques of  and .
This can take up to several hours, depending on the number of photos.
If the seed generation was successful, the player then aligns an overhead view of the model with a map and waits for the game developers to approve her seed and her alignment.
We make sure that each seed meets a minimum quality requirement and is neither offensive nor irrelevant.
Letting players start seeds themselves is beneficial to the game's purpose and to the player.
It is impossible for the game designers to seed a large number of buildings, especially if they are not physically present where PhotoCity is taking place.
But it is easy for players to start seeds anywhere and everywhere, and earn many points for each seed.
Players can choose buildings that have personal meaning to them or are convenient to photograph.
Having so many models active in the game gives other players variety for where to go and take photos.
In our setting, the main challenge is to acquire a different and much larger set of photos than what people normally take and post online.
This set of photos should also be large enough and comprehensive enough to be completely "cover" a target area .
This could be accomplished either by having many players stray slightly from their ordinary behavior and do a small amount of work, or having fewer players drastically change their photographic style and each contribute a large amount.
We designed PhotoCity to have a variety of different incentives, and deployed it as a competition against two universities to evaluate its success and find whether the game solicits many new users, a few passionate users, or something in between.
In the Spring of 2010 we instigated a rivalry between two schools.
For six weeks, split into two three-week rounds, Cornell University and the University of Washington in Seattle played PhotoCity and competed to see which school could reconstruct the "best" model of its campus.
Players could view the PhotoCity map for each school, or track the game on a single competition webpage.
Anyone at either school could sign up online and start contributing photos.
We advertised though school newspapers, department mailing lists, and temporarily ran an advertisement on Facebook targeted at students interested in photography.
The competition was not just between schools, but also between players .
The competition page featured a leader board where players were ranked by number of points and by number of successful photos.
There were also five `titles' that one player at each school could hold: Kingdom Overlord , Expert Expander , Expert Seeder , Master Flag Conqueror , and Best Recruiter .
Finally, within each school there was also a team competition; players could select from four teams  to join, and the webpage provided a ranking of each team by score.
The photography style required in PhotoCity is different from ordinary photography.
Van House  examines the types of photos posted on Flickr and finds that most represent a way of `life chronicling' and self-representation.
PhotoCity requires a more utilitarian approach to photography than the artistic approach seen on Flickr, but also requires more creativity than normal `tourist photography' to get away from canonical views and capture a scene from entirely new angles.
Cornell held the lead for the first two weeks, and when threatened by UW at the start of the third week, defended their first place position.
The competition took place in two rounds.
The first round lasted three weeks and players played with the game mechanics described above, seeding and expanding models.
We discovered at the end of the first round that while players seeded many buildings throughout each campus, most reconstructions were not complete.
The theme of the basic PhotoCity mechanics, and of holding the competition, is to focus player efforts to get something productive done.
For the second round, we expanded on this theme by adding a new mechanic designed to entice players to complete buildings.
This new mechanic was collectable gems.
Gems are very similar to flags in that they represent specific locations on the map.
But unlike flags, which are automatically placed on existing building walls, gems are manually placed  on the far sides of buildings.
Unlike flags, which different players can contribute points to, capture, and steal from each other, gems are collectable.
The first player to grow a model into the vicinity of a gem collects that gem and no other player can steal it from the first.
Figure 5 shows a building with a seed started on one side of the building and gems placed around the far side.
Gems turn from gold to purple when they are collected.
Figure 5 shows two buildings that were completed during the second round with the gem mechanic.
This graph shows the total number of photos submitted per day by students at both schools during the first and second rounds of the competition, each of which lasted for three weeks.
Daily photosubmission is higher in the first round, especially towards the end, because there are over 50 active buildings per campus instead of the 10 active buildings per campus in the second "gem-collecting" round.
Activity and enthusiasm at both schools was roughly equal, though Figure 6 shows Cornell maintaining a lead in the number of points for most of the first round, despite having fewer players.
The first round started with four seeds at each zone, and by the end, players had started 64 seeds at University of Washington and 55 seeds at Cornell, totaling 119 new seeds.
Figure 11 gives an idea of the distribution of seeds at the University of Washington.
The top two seeder players began 26 and 20 seeds respectively.
During the first round alone, players submitted over 76,000 photos.
During the entire competition, players submitted over 109,000 photos.
Players were able to re-upload photos that initially failed to match, and 31% of the final photo count were resubmissions.
About 68,000 photos of those photos registered, amounting to about 500 photos on average per model.
Three completed models from the game are shown in Figure 8.
We now compare our photo set against Flickr to see if the game accomplishes its goal.
In total, forty-five players played PhotoCity for the six weeks of the competition and submitted over 100,000 photos.
There were 26 students from University of Washington and 19 students from Cornell who participated, mostly recruited through department mailing lists and word-of-mouth.
Of a less popularly photographed location such as a university campus, this difference was even more striking.
Figure 10 shows 35,000 PhotoCity photos densely packed across University of Washington campus and there are only about 30,000 geotagged photos on Flickr, most of which are not suitable for modeling the campus buildings.
Even though there were only 45 players, these players took thousands of photos of views that had never been captured before and covered their campuses much more thoroughly than an unorganized effort could reasonably achieve.
Another round of PhotoCity could fill in the remaining gaps or even chronicle the campus changing over time.
This conclusively demonstrates that PhotoCity is an effective way to collect large, dense photographs of places previously not thoroughly photographed.
This graph shows the number of active players who submitted photos each day, and the average number of points per active player each day .
Towards the end of the first competition round, players had learned how to take effective photos and earn more points per day: 100,000-250,000 points on average .
PhotoCity collected 109,000 photos divided between University of Washington and Cornell.
In contrast, the Rome in a Day project used 150,000 photos in its Rome reconstruction.
We totaled up the photos of each of the connected components of Rome  and calculated that around 10% of the 150,000 photos were used in any 3D model.
The rest do not usefully contribute because they are of people, interiors, or other kinds of photos meant to provide some personal value to the photographer.
In contrast, 60% of PhotoCity photos are used!
Furthermore, while some of the unused photos are definitely unrelated, many are still likely to be of school buildings.
They did not overlap a model when they were added, but may have overlapped at the end of the game if retried.
Again compared to Rome, the largest connected reconstruction has 2,106 photos in it.
Our largest single model is of the Cornell Arts Quad with over 4,000 photos and 8,000,000 points.
Each campus reconstruction consists of several multithousand photo/multi-building reconstructions.
We found PhotoCity photos to be significantly more useful for 3D reconstruction than Flickr photos of a popularly phoFigure 10.
Locations of PhotoCity photos  on a map of UW.
Photos densely cover the parts of campus active in the game, especially walkways and open areas between buildings.
Real photos from the game shown below the map.
At the end of the competition, we presented players with a survey that included questions about what motivated them to start playing and keep playing, and what strategies they developed to gain a competitive advantage.
While this survey mainly captured the opinions of those who played through the end of the competition, the responses were in line with what we observed during the study: that competition was a good motivating factor and that most people who played were also interested in the resulting 3D models.
The graph in Figure 6 shows evidence of the competition between schools having an impact on play.
Cornell, in red, held the lead for the first two weeks of the competition.
When University of Washington temporarily surpassed Cornell, Cornell quickly stole back its lead.
In talking to students at both schools, Cornell students were more interested in winning the competition, while University of Washington students were interested in competing among themselves.
Most of the top players at the University of Washington were friends and spent their time trying to outdo each other.
Players also cared about the game's purpose.
More than half of survey responders cited it as a reason for trying PhotoCity initially.
Unlike Photosynth, PhotoCity produces dense, detailed 3D models of real world locations and allows for people to collaborate and improve models.
The popularity of Photosynth  suggests that people want to thoroughly capture the meaningful things around them in photos.
The main de-motivator of players, especially novice players who did not submit very many photos to begin with, was when their photos were rejected by the system.
Observing Figure 12, we suspect players have to take more than 10 or 20 photos to reap benefits like seeing a model actually grow, which make the game fun.
The walls of a building are shown in black and camera positions are shown as colored circles, colored in the order they were taken and submitted to the game, with blue being the oldest photos and yellow being the newest photos.
The top-left  faces of the building were photographed first, then a very straight and deliberate path of photos was taken slightly closer to the building, and finally, photos were taken from completely new viewpoints  as the building grew.
The most striking difference between players who became heavily involved in the game and played for many days  was simply the number of photos each group took on their first few active days.
Players who played very little  took very few photos their first day.
Players who wound up playing a lot  took almost 10 times as many photos their first day, and even increased the number of photos they took each day for the first several days, until leveling off.
The majority of point contributions  during the university competition came from the top 10 players.
The top player alone contributed 20% of the total number of points.
PhotoCity appears to be a game for experts, with the best players taking significantly more photos and earning significantly more points than novice players.
The difficulty for new players stems from the need to adopt a different photography style and to learn  what to take photos of.
The top line in Figure 12 shows players who played 10 or more days taking gradually more photos each day over the first few days.
The bottom line in the same figure shows players who only played for one or two days taking very few photos to start out with, and then apparently being so discouraged or uninterested that they took even fewer photos the next day.
A possible improvement to the game is to encourage a new player to take many photos  right away,  so that they can make a sizable contribution, and  so that they can earn a large number of points right away and feel inspired to play again.
Finally, several of the players mentioned how they planned their photo-taking sessions and kept their photos organized.
Organizing photos on external hard drive folders by campus region, building, then face of building provided good hierarchy to structure uploads."
I would then write out a checklist of places to go to take photos  If unsure, I would just check it again.
Further evidence of players' deep involvement in the game is the strategies they described to us in the survey.
Different strategies involved playing with a different game mechanic, finding the most lucrative types of buildings, or optimizing for time of day, but each was developed to give the player a competitive advantage.
Regarding what types of buildings were most lucrative: "Targetting buildings without huge slabs of glass/windows works best.
Buildings that have plain facades are tough to get points on.
Buildings with stone exteriors, especially rough hewn stone, have tonnes of points.
Brick buildings can give lots of points if the grout is especially thick."
Players mentioned that the corners of buildings and trees planted next to buildings were especially difficult to navigate around.
One player described how to tackle corners, while another mentioned an alternate strategy for earning points that avoided dealing with corners.
Some strategies optimized over lighting and time of day.
With that said, cloudy days were the best by far when dealing with corners because less contrast helped the game figure out the geometry from my pictures."
This allowed me to take crisp photos while not having to stop my stride.
Also bonus: less people stared at me!"
Although the primary purpose of PhotoCity is to collect photos, players experienced personal benefits through the game play.
In the survey, we asked players whether they felt they got to know their campus better.
Twelve of the 22 participants surveyed said yes.
We also asked whether they took photos as part of their daily routine or went out of their way to take photos.
Thirteen people responded, `I went out of my way to take photos,' eight said, ` I didn't stray far from my normal route, but did seek out new vantage points,' and only one participant responded with `I only took photos where I was already going.'
We can conclude that PhotoCity made many of the participants more physically active than their default state.
Only a small group of players participated, but they still contributed a surprising amount of data.
Given time to gain expertise and incentives to become deeply involved in the game, players can become extremely effective.
The problem we set out to address was to gather enough photos of a certain location, such as a university campus, to be able to thoroughly reconstruct that location in 3D.
We have demonstrated that our game, PhotoCity, is capable of bringing in many thousands of highly relevant photos-photos of buildings from a diverse set of angles and viewpoints.
During a competition between the University of Washington and Cornell, players took over 100,000 photos, over 60% of which were used in the resulting 3D models.
It only took 45 players to collect this data.
To achieve such success with a small number of players, we designed various game mechanics that made players' in-game actions productive and beneficial to our purpose, and motivated our players through competitions, prizes, and a leader board.
Some players became so deeply involved in the competition that they submitted many thousands of photos apiece, most of them usefully contributing to a 3D model of that player's campus.
To verify that our players' photos had more coverage and completeness than existing community photo collections, we compared our dataset to a Flickr set of Rome reconstructed by Rome in a Day, and to Flickr photo counts of each campus.
The message we hope to impart on others is that even with a small player base, games with a purpose can still take on large-scale problems, provided the players are trained to make efficient and massive contributions to the game.
Y. Furukawa and J. Ponce.
Accurate camera calibration from multi-view stereo and bundle adjustment.
A. Irschara, C. Zach, and H. Bischof.
Towards wiki-based dense city modeling.
L. Kennedy, M. Naaman, S. Ahern, R. Nair, and T. Rattenbury.
How Flickr helps us make sense of the world: Context and content in community-contributed media collections.
Smartboxes for interactive urban reconstruction.
World-scale mining of objects and events from community photo collections.
LabelMe: A database and web-based tool for image annotation.
Scene summarization for online image collections.
S. N. Sinha, D. Steedly, R. Szeliski, M. Agrawala, and M. Pollefeys.
Interactive 3d architectural modeling from unordered photo collections.
Photo tourism: Exploring photo collections in 3d.
Reconstructing the world in 3d: Bringing games with a purpose outdoors.
In FDG '10: Proceedings of the 5th International Conference on Foundations of Digital Games, Monterey, CA, USA, 2010.
Flickr and public image-sharing: distant closeness and photo exhibition.
L. von Ahn and L. Dabbish.
Labeling images with a computer game.
In CHI '04: Proceedings of the SIGCHI conference on Human factors in computing systems, pages 319-326, New York, NY, USA, 2004.
Sketch: An interface for sketching 3d scenes.
Building Rome in a day.
International Conference on Computer Vision, 2009.
Cross, T. Khaleel, and R. Beale.
Brown, S. Sherwood, D. MacMillan, J. Ferguson, and M. Chalmers.
Eyespy: supporting navigation through play.
In CHI '09: Proceedings of the 27th international conference on Human factors in computing systems, pages 123-132, New York, NY, USA, 2009.
Predicting protein structures with a multiplayer online game.
D. Crandall, L. Backstrom, D. Huttenlocher, and J. Kleinberg.
Modeling and rendering architecture from photographs: A hybrid geometry- and image-based approach.
Building Rome on a cloudless day.
