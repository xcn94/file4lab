This extends tabletops with additional interactive spaces:  personal 2D contents and storage on the personal screens and  3D contents above the tabletop.
We present MisTable, a tabletop system that combines a conventional horizontal interactive surface with personal screens between the user and the tabletop surface.
These personal screens, built using fog, are both see-through and reach-through.
Being see-through provides direct line of sight of the personal screen and the elements behind it on the tabletop.
Being reach-through allows the user to switch from interacting with the personal screen to reaching through it to interact with the tabletop or the space above it.
The personal screen allows a range of customisations and novel interactions such as presenting 2D personal contents on the screen, 3D contents above the tabletop or augmenting and relighting tangible objects differently for each user.
Besides, having a personal screen for each user allows us to customize the view of each of them according to their identity or preferences.
Finally, the personal screens preserve all well-established tabletop interaction techniques like touch and tangible interactions.
We explore the challenges in building such a reach-through system through a proof-of-concept implementation and discuss the possibilities afforded by the system.
In most tabletop systems the tabletop's surface becomes a shared space for information sharing and collocated collaboration while the space around it becomes a space for social interaction and discussion.
The always visible shared surface of a tabletop encourages collaboration, but it also limits the opportunities for customizing the views for each user around the table.
Recognizing this limitation, researchers have proposed systems that combine tabletops with tablets and other personal devices which can offer a level of customization and view management through the screen of this personal device.
Although elegant, such solutions require access to user's personal devices and can be cumbersome to initiate collaborations.
In this paper we take a different approach.
We provide a personal space between the user and the tabletop in the form of a see-through display which also allows the user to physically reach through it to interact with the table.
MisTable is a novel tabletop system that explores this concept of a reach-though personal display.
These personal displays are presented between each user and the tabletop surface providing a display surface to show relevant content to the user  while at the same time allowing users unhindered visibility and access to contents on the tabletop surface .
This feature of MisTable to create a see-through and reach-through display surface between the user and the tabletop surface opens a range of novel interaction possibilities.
Besides being able to use the personal screen as an auxiliary display surface to store content , MisTable can now use the space above the tabletop surface to present 3D content that is personalized to a user .
Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
The resulting system extends the capabilities of a common tabletop, aligning three interactive spaces, each of them with different dimensionalities and collaborative implications: the tabletop becomes a space for shared 2D interaction; personal screens hold personal 2D tasks and the volume above the tabletop supports 3D contents/interaction.
Also, all three spaces stay in the users' line of sight, allowing them to keep peripheral awareness of other users and tasks.
We implement the personal screens on MisTable using a laminar curtain of fog .
Unexplored challenges exist when using fog as a personal screen.
At short distances fog displays suffer from uneven brightness across the display.
To enable reaching through the fog, one should consider the direction of fog flow and the projector throw direction to minimize turbulences and shadows while maximizing the screen brightness.
Through a proof-of-concept prototype we measure the brightness profile of our fog display using a colorimeter and create a brightness compensation algorithm to create a uniform brightness profile.
We finally explore the features enabled by MisTable through example implementations of relevant interaction opportunities.
All pictures in the paper and the accompanying video figure are taken in standard indoor lighting conditions, the room lights were not dimmed during filming or edited in any way after shooting.
The images were taken using a canon EOS550 camera with 1/60 shutter speed and 3.5 aperture and ISO 400.
The rest of the paper is structured as follows.
We start with the related work followed by a description of the concept of MisTable.
We then provide detailed information on the design and implementation of the personal screen before presenting a collection of interaction possibilities enabled by MisTable.
The paper then finishes with a short discussion and conclusion.
Lenses  provide local changes to views in selected regions of the tabletop allowing a user to inspect new information locally.
However, these changes are visible to all users of the tabletop and can potentially occlude shared content causing interference to other users.
Systems like WeSpace , LUMAR  or E-conic  include multiple displays to alleviate interference.
However, since it is not possible to see-through these displays they are often pushed to the periphery of the interaction space, like in WeSpace .
This usually leads to a loss in the awareness of other user's actions.
To overcome this loss of awareness most systems use different forms of cursor and hand embodiments .
Lumisight , Ulteriorscape  and TaPS  overlay tabletop surfaces with diffusion control materials to create regions within the surface which are only visible from specific viewing angles.
Thus each user around the tabletop can see a different personal view based on their seating position.
However, the projection surface is still shared and users can accidentally occlude other's personal contents when interacting with the shared surface.
MisTable detaches the personal space from the tabletop surface, while maintaining direct line of sight of the tabletop.
MisTable can present and allows interaction with 3D content on and above the tabletop surface.
Most tabletop 3D systems , like the ImmersaDesk  or the responsive workbench  use shutter glasses to present stereoscopic contents for up to two users.
Other systems like TADS  or PiVOT  support more users using auto-stereoscopic technologies.
In all these systems, the display surface always lies behind the user's hands, which can cause problems due to incorrect depth occlusions.
Users' hands occlude contents even if their hand penetrates the virtual content, which does not fit the way occlusions happen in the real world.
Placing a see-through display between the user and the tabletop can solve this issue.
Other authors use see-through HMDs, either to augment a tabletop  or even a whole ecosystem of displays and spaces .
However, this forces users to be instrumented and partially occludes users' faces, hiding facial expressions and affecting social interaction.
SpaceTop  uses a see-through display over a regular desk and a depth camera.
This transforms the space behind the display into a continuous 2D/3D interaction space that keeps some resemblances with our approach.
Toucheo  uses a half-silver mirror similar to a virtual workbench  several centimetres above a tabletop.
Such a see-through display between the user and the tabletop can be beneficial.
They detach the location of personal contents from the tabletop avoiding accidental occlusions from other users' hands.
Depth occlusions like the fingers reaching into virtual objects can also be reproduced .
But their see-through element does not allow users to reach through the display.
Solutions exist that allow users to reach the space behind the image plane.
Some approaches place a common display behind a lens at a distance that allows the formed image to appear to float in front of the lens.
Virtual Panel  uses this feature to provide privacy lenses above a tabletop.
Even though the image surface appears to float in front of the lens, it is actually displayed on the lens surface, so any object placed between the image surface and the lens will destroy the illusion.
These approaches are unsuitable for our requirements.
A thin curtain of fog particles  can be used to create a translucent diffusion surface.
They also propose using them to create an extended desktop, in an office environment, visible from both sides.
We take this exploration further, illustrating how fog screens can be used in combination with tabletops to align three different interaction spaces .
The reach-though feature  becomes a key element.
First, it preserves tabletop interaction.
Other possibilities, such as relighting tangibles or users hands/arms had never been explored either.
When the user reaches in to interact with the 3D content we can provide correct occlusions such as the user's hand penetrating the 3D content.
Stereo techniques are available as explained in .
Furthermore, the personal screen can be used to relight objects on the tabletop surface.
For example, tangible objects or user's hands can be augmented with additional digital information.
The personal screen provides direct line of sight and access to the different interaction spaces .
Users can stay aware of each others' actions and effortlessly switch between interacting with the personal screen to the tabletop surface or the interaction volume.
This allows users to easily break in or out of shared tasks to better support mixed focus collaboration .
Users can also move contents freely between these interaction spaces.
Moving contents between the tabletop and the personal screen allow users to share it with others or to get exclusive ownership over it.
Content representation can also be adapted to the presentation space where they are moved.
A content dropped in the volume above the tabletop can enable 3D manipulation techniques.
A content moved to a personal screen can change its appearance or display controls according to the identity/preferences of the user.
Commercial fog-based displays such as FogScreen or IO2's HelioDisplay have demonstrated their ability to create thrilling experiences at TV shows, exhibitions, fashion events and concerts.
Presenters can enter the stage through a fog curtain displaying impressive special effects.
However, projection on these displays in the short range  raises several challenges.
First of all, fog and mist produce a non linear scattering of the light .
While this effect is not so important in a theatre or TV stage , it has a great impact when the observer is close to the screen.
Besides, reaching with an arm through the screen affects the flow of fog, producing turbulences that affect projection and, if the projector is not carefully located, arms can cast shadows on the display.
We start with an analysis of these issues and propose a feasible design to use fog displays in conjunction with tabletops.
Our implementation of the fog screen is adapted from the design proposed by Kakashara .
Specific details about the implementation of our screen and fog distribution system are provided later in the paper.
MisTable is a tabletop system that combines a conventional tabletop system with personal fog screens between the user and the tabletop surface.
Unlike solid see-though screens, MisTable allows the user to interact with the tabletop in a conventional way.
MisTable's personal screens are both see-though and reachthrough allowing users to interact with the tabletop in a conventional way , but at the same time extending it in several unique ways.
The personal screens provide a personal auxiliary interactive surface that can be used to undertake individual tasks or store personal contents , as show in Figure 1b.
The same screen can also be used to create an additional interaction volume above the tabletop surface.
Brightness across the screen varies greatly when the observer is close to it.
The spot on the screen between the user and the projector is blinding bright and the colours wash off as the image spans to the sides.
This attenuation is a function of the angle between the incoming light hitting a point of the screen and the observer.
We studied the brightness profile of our screen using a colorimeter and implemented a brightness compensation algorithm to attenuate brightness differences across the screen.
The results of applying this algorithm are visible in Figure 2.
We took three sets of ten measures of the colour profile  at nine different angles, for a total of 1080 samples.
Measures below five degrees were impractical as luminance was above the upper limit of 49,900 cd/m2 supported by our colorimeter.
The experiment was performed in a dark room without any other light sources or windows.
Figure 3.c present colour gamuts at different angles, representing the chromacity of the colours that can be generated.
We found no differences in chromacity related to the angle.
Although one might expect differences due to changes in refractive index with wavelength, we believe that the number of particles across our fog screen is high enough to counterbalance for these differences.
Figure 3.b shows the brightness profile obtained in a logarithmic scale , with intermediate points approximated using cubic splines.
Brightness is remarkably higher at small angles and it decreases almost linearly above 15 degrees.
Brightness becomes impractical below 75degrees.
We use the information of our brightness profile to produce an attenuation correction mask that creates a uniform brightness profile across the screen.
Figure 4.a shows the attenuation distribution used to correct the image in Figure 2 for a reference brightness at 33 degrees .
Figure 4.b shows the attenuation mask computed according to the attenuation function and the relative position of the observer and the projector.
The blue region corresponds to parts of the image where the brightness needs to be reduced.
The purple region corresponds to those parts that need to be over saturated.
Note the secondary purple ripple corresponding to the local maximum present at 60 degrees in our brightness profile.
Our approach is a best effort approach, given the capabilities of our projector.
There are situations in which it is not possible to achieve the desired colour.
These are visible as white regions in Figure 4.a.
A fog based system is made of particles of water.
If the particles of water are too large then they can condense in the hands of the user making the user's hand wet when interacting with the fog curtain.
Using a particle size of around 0.4 microns makes fog float around user's arms, avoiding condensation.
The curtain of fog particles must be enclosed between two laminar flows of air to avoid turbulence and maximize image quality .
In this case, these turbulences can have a significant impact .
To ease this problem, in our system the fog is dropped from above.
In this case , when a user extends their arm through the screen, it is the space below the arm that becomes turbulent.
This space is most often occluded by the user's own arm.
Furthermore, with the user's focus of attention on the target from above the arm rather than below a turbulent region below the extended arm causes minimal impact on the task.
On the other hand, fog rising from below  would cause visible turbulent regions in the region of the user's focus of attention.
The projector is located so that the observer can visualize the top part of the screen with an angle to the projector rays of 10 degrees.
This avoids the brightest parts of the image that blind the user and eliminates shadows due to users' hands.
The resulting screen is visible to an observer at 30 cm from the fog screen with a projector to observer angle between 10 to 65 degrees.
This range is chosen from our brightness distribution profile to maximize image brightness and avoid glaring.
Footprint and scalability issues were also considered.
Placing the projectors at bigger distances would allow a more reduced and brighter range of the brightness profile to be used, but it would also increase the footprint of the system and make it more difficult to scale for four users.
The location of the projector illuminating the fog screen is another important factor to consider when it is used in a tabletop context.
Commercial medium size displays, like HelioDisplay  place a projector behind the screen projecting upwards towards the users.
Although placing the projector below has the inconvenience that when the user looks directly into the projector the bright spot becomes visible, the regions around it get the benefit of the higher luminance values around the bright spot.
However, when a user reaches the arm to interact with 3D objects above the tabletop, shadows will be cast in the space behind the hand and the projector.
In a bottom-up projection , these shadows would occlude big parts of the screen and particularly, the target that the user is reaching .
For these reasons, MisTable, places the projector above the opposite side of the table, avoiding direct line of sight of the projector.
Thus, shadows are projected in the space below the arms which, in general is occluded by the arm itself .
The fog distribution system in MisTable contains a fog machine, a reservoir and a fog distribution chamber.
We use a glycerine based continuous fog machine.
Preliminary versions used piezoelectric foggers and water, but we found it difficult to achieve a stable fog generation and fog tended to condense in the pipes.
Fog thickness was also lower than that produced by glycerine based machines.
Two chambers are used to hold and distribute the fog.
The first one  stores a volume of 70 litres of fog and is important to allow a steady supply of fog.
When the fog machine is on, pressurized fog could travel all the way to the personal screens.
The reservoir helps prevent fog bursts.
Then, the second  chamber creates a negatively pressurized chamber that drags the fog and delivers it through the pipes to the personal screens.
We built two personal fog screens of 60x47 cm at two adjacent sides of the tabletop, designed as shown in Figure 7.
The screens have a fog distribution pipe, with a slit of 15 mm at the bottom.
We used 12 cm fans to blow air around the pipe into a stack of fluted plastic below it.
Adjusting the speed of the fans, we create a laminar flow of air to drag the fog.
The speed must be slow enough for the flow to remain laminar, but fast enough to cover the total height of our screen.
Extractors below the screen capture the fog and stabilize the image at its bottom part.
A leap motion device was added at the top of each fog screen for this task.
This selection of devices granted us accurate user registration without user instrumentation, but we expect that future sensing technologies, with a bigger FOV, range and accuracy, will allow more simple arrangements to be used.
Personal 2D contents presented on the fog screen are correctly visible independent of the user's location.
Presenting 3D contents, however, requires tracking the users' heads to support motion parallax and perspective correction depth cues.
Our prototype uses Kinect to track the users head position and to track hand gestures on and above the tabletop surface.
Its limited field of view  meant we used two Kinects, one to cover the space above the tabletop and another to track the head of the users around MisTable.
A four degrees of freedom head tracking  was implemented using the Kinect SDK and OpenCV.
Background subtraction and depth based thresholding was used to segment user's heads.
The information about the fingers and hands is used to build an approximate 3D model of the users' arms.
These models are used to account for incorrect depth occlusions as explained later in the paper.
The initial position of the hand when it appears into the volume above the tabletop is used to identify to which user the hand  belongs to.
The system, detailed in Figure 8, is built around a workstation using two graphics cards, in order to connect all three graphical outputs  to the same computer.
We built a software framework in C++, using the OGRE3D rendering engine.
The brightness compensation algorithm was implemented as an NVIDIA CG shader.
This shader requires computations that are expensive and could potentially interfere the real time requirements of the system.
To avoid this, we compute our brightness attenuation mask using a low resolution texture , which is then applied to the full resolution of our image .
This results in a sub sampling of the brightness profile and linear interpolation is used for intermediate pixels.
An XMOS XC-1A board was used to control the fog distribution chamber and fans in the fog screens.
The Kinect used to track users' hands and fingers and the Leap for the first user were also connected to this computer.
A secondary node was introduced to leverage the computing requirements of the application.
The second Kinect and its head tracking algorithm were executed in this secondary node.
The Leap used to detect finger interactions from the second user was also connected to this computer.
Both nodes were connected through a switch and a local ethernet connection, using the OSC/UDP to deliver finger and head tracking messages.
Figure 9 illustrates the capabilities of our personal screens as an auxiliary interaction territory  and storage space .
Each screen contains a side menu to store user's personal contents.
Users can select from contents from the side menu using a simple crossing gesture  and interact with them using standard finger interaction gestures .
As long as the user's hand is approximately within the plane of the fog, all user's finger movements are interpreted to mean interaction with the personal screen.
So pausing the finger on an image selects it and moving the finger moves the content.
However, if the user makes a quick inward gesture from the personal screen towards the tabletop, the selected content is pushed towards the tabletop surface where it becomes available to all other users.
As soon as the system detects this pushing gesture, the content on the personal screen changes its perspective to give the appearance of it falling onto the tabletop.
This gives the user clear visual confirmation of the system's action and the final position of the content on the tabletop.
Similarly, the user can direct this pushing action towards another personal screen and the content gets dropped as an icon in the other user's screen.
A simple confirmation mechanism can be implemented to check that the receiver wants to accept this content.
However in our current implementation the content merely appeared at the centre of the second user's personal screen.
Users can also pick contents from the tabletop and bring them to their screen.
When the user makes a quick and deliberate lifting gesture with their finger above the tabletop surface, the content controlled by the finger starts moving up towards the user's personal screen.
The personal screen presents the content in such a way that it appears to be moving out of the table and onto the personal screen.
Our current implementation only supports simple finger tracking and recognition, so the content is always moved to the personal screen in the direction of the finger lift gesture.
MisTable uses a conventional multi-touch table, but the volume above it can display 3D contents and other interactive augmentations.
To interact with them, MisTable can borrow well-established interaction techniques from the 3D user interface community.
However, it can also reuse techniques from traditional tabletop systems, providing a rich and flexible range of techniques.
Finally, tangible objects can be used to rotate the object using bimanual interactions.
Users can easily switch between these interaction techniques to adapt to the interactions style that best suits the application context.
The brightness of the fog display can be used to increase or decrease the visibility of the contents projected onto it.
Figure11 illustrates how brightness control is used in our system to adapt to the locus of interaction of the user.
When the user reaches the personal screen to interact with it , the brightness of those contents  are increased to enhance visibility.
Other contents not in focus are dimmed, allowing the user to see through them better.
If the user puts their arm through the screen contents can be made more transparent providing better visibility through it .
Our system makes brightness control a property of each object on the personal screen.
Depending on the context of interaction this parameter can be manipulated to either bring it to the user's attention or to fade it away leaving the user to focus on the tabletop, other objects or the users around the tabletop.
Within a collaborative context, brightness control could also be used to raise awareness of ownership and provide personal overlays over the 3D contents displayed.
3D objects above the tabletop could be equally visible to all users when they are located above the central part of the table, as they can be considered a shared content.
When a user grasps an object and moves it closer to their end of the table, its visibility to this user can be enhanced while other users' visibility can be reduced.
This could represent the user's intention to get exclusive control of the object and accompany granting ownership of the object to the user, allowing him/her to access extra functionality.
These are simple examples of the potential of this technique.
Its major difference when compared to any tabletop where object brightness can be dynamically controlled is that brightness also affects the see-through component of the content.
MisTable also deals with false occlusions to facilitate depth perception when users' hands reach into objects.
We implemented two techniques, illustrated in Figure 12.
In Figure 12a, user's fingertips are overlaid with bright white spots, as proposed in .
Spots represent 3D cursors to provide the user with a clear indication of the point of interaction.
When the cursor penetrates an object, it disappears inside the it, providing the user with feedback that they are actually inside the object .
Even though the 3D cursors become invisible, the virtual object is still incorrectly presented over the user hand, even if that part of the hand is actually outside the object.
Background lines are also incorrectly overlaid on the hand.
Figure 12c shows a second approach where we use brightness control and the 3D hand representation to create a more realistic presentation.
Using the approximate 3D hand model obtained through the tracking system, we present the hand in black , so the parts of the display where the hand model is visible are highly see-though.
This allows users to see their real hands when outside of an object .
When the finger penetrates an object, the part of the darkened hand model gets occluded inside and the 3D object overlaps the parts of the user's hands inside the object .
This creates correct occlusions, where parts of the objects can overlap a user's hands and can provide the users with an additional and valuable depth perception cue.
The ability of MisTable to augment real object enables some of the benefits of spatial augmented reality systems like Illuminating Clay, SandScape and URP .
In those approaches projection happens on the same surface of the objects, so the effects are visible to all user, and can reveal registration problems to some users.
In MisTable, projection happens on each users' fog screen, so the effect is only correct from their position.
This allows us to create different effects on the same object for each user or to minimize hindrance to other users.
These two examples illustrate the ability of MisTable to augment and personalise the appearance of real objects.
This could be used to provide embodiments and increase awareness of collaborative tabletop tasks.
When other users are interacting with content on the tabletop, both their hands and the content get overlaid with a common  colour in the observer's screen.
This informs a user about another users' locus of interaction providing additional task awareness to the observer.
Because these overlays are personalised to each user different forms of embodiments and awareness cues can be overlaid to each user to allow better contextualising of the cues.
Other elements, like tangibles or the whole users' silhouette could also be augmented this way.
We can also augment a user's appearance to create better effects in a gaming scenario.
For example, the dungeon master in dungeons and dragons can have different avatars overlaid on the other players to create a more compelling gaming scenario.
One needs to take great care in building the fog distribution and extractor system.
Fog leaks or even fog pushed away from the extractors when users interact with the system can have an impact on the continuous use of the system for extended periods of time.
When used continuously, these leakages could fill the room with fog and affect image quality.
The projector image would get scattered before reaching the fog screens leaving a visible light path from the projector to the personal screen.
It could also interfere with the tracking devices used, given fog's ability to scatter or even reflect the IR light on which many tracking technologies rely.
Our experience has shown that in extreme cases a fog leak can trigger a smoke alarm.
This is something to be aware of during the initial stages of system development where leaks are more likely to occur.
Our implementation required a complex arrangement of devices.
This choice allowed us to accomplish the kind of user registration required to explore the range of interaction possibilities of MisTable.
However, user's head tracking is not necessary if only 2D content is going to be presented on the fog screen.
The hardware arrangement in this situation would be minimal.
This paper has focused on exploring the interaction opportunities raised by using fog based personal screens around a tabletop system.
Our implementation of MisTable allowed us to explore these possibilities, focusing mostly on image quality and user interaction.
Other aspects related to the usage of MisTable should also be considered when designing interactive experiences for MisTable.
Touchless and 3D interaction  forces users to keep their arms stretched, which is known to cause fatigue.
Performance might also be affected due to the lack of tactile feedback.
Secondly, these touchless contents will float in the space between the users.
A high density of objects could clutter visibility of other users, affecting social interaction.
This could lead to situations in which one user could think another user is looking at him/her, while he/she is actually looking at a personalized content.
Peripheral awareness of other user's actions and our inherent ability to tell when somebody is actually looking into our eyes should help avoiding these issues.
There are also elements that need to be considered when building and deploying a MisTable system.
MisTable can be used in normal indoor lighting conditions and all images in this paper and the accompanying video was shot in the presence of ambient light.
However, the location where it is deployed can impact the quality of the system.
MisTable relies on a laminar curtain of fog to create the personal display surfaces.
MisTable is a tabletop system that combines a conventional horizontal interactive surface with personal screens between the user and the tabletop surface.
We used a projected fog based display to create the personal screens that are both see-through and reach-through.
We examine various design issues and through a prototype demonstrate that such systems can be built.
We further explore various interaction possibilities enabled by MisTable.
For example, MisTable allows the creation of a new interaction volume above the tabletop surface where interactive content  can be presented.
MisTable is able to accomplish this while preserving the social interactions enabled by tabletops.
We believe these features illustrate the potential of MiSTable as a novel tabletop system to support new forms of interaction and collaboration.
