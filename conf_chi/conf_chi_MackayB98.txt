Laboratoire de Recherche en Informatique2 URA CNRS 410 LRI - Batiment 490 - Universite de Paris-Sud 91 405 ORSAY Cedex - FRANCE mbl@lri.fr the World Wide Web.
An early tool for analyzing video data, VideoNoter  begins with data streams, and then uses hypermedia links to organize the relationships among different aspects of the data.
Another approach emphasizes streams instead of chunks of information.
Rather than treating all data as chunks and converting naturally-continuous information such as video into discrete units; all data can be treated as streams, mapping naturally-discrete objects onto event streams.
The analysis system can operate on all data in a uniform way, exploring directly the patterns that emerge from the streams.
Hypermedia lets users start and stop streams; the stream approach lets them highlight, examine and compute upon the patterns within and among streams.
EVA, the Exploratory Video Annotator,  was based on this approach.
We were not interested in authoring multimedia documents that treat video as "illustrations that move".
Instead, we were interested in helping researchers annotate and visualize patterns and relationships among time-based multimedia data.
EVA's stream metaphor derived from our work on Muse, a multi-media authoring language originally designed at Digital Equipment Corp. and enhanced significantly at MIT's Project Athena  for a description.
One of the authors  suggested that the exploratory data analysis techniques pioneered by Tukey   for a concise summary are more appropriate for examining video data than the standard statistical techniques used in controlled laboratory studies.
Sanderson and her colleagues  have pursued this idea extensively, coining the term Exploratory sequential data analysis  for systems that support the exploration of multimedia data.
Several systems have been developed to support the analysis of video data, including Harrison , Olson et al.
Other researchers working in related areas such as video conferencing have developed similar tools, e.g.
DIVA supports exploratory data analysis of multimedia streams, enabling users to visualize, explore and evaluate patterns in data that change over time.
The underlying stream algebra provides the mathematical basis for operating on diverse kinds of streams.
The streamer visualization technique provides a smooth transition between spatial and temporal views of the data.
Mapping source and presentation streams into a two-dimensional space provides users with a direct manipulation, nontemporal interface for viewing and editing streams.
DIVA was developed to help us analyze both qualitative and quantitative data collected in our research with French air traffic controllers, including video of controllers at work, audio records of telephone, radio and other conversations, output from tools such as RADAR, and coded logs based on our observations.
Although our emphasis is on exploratory data analysis, DIVA's stream architecture should prove useful for a wide variety of multimedia applications.
Video, audio and other data collected in field studies continue to be cumbersome to manage and analyze.
We are interested in the problem of how to compute with a variety of these multimedia data types: to visualize, explore, analyze and evaluate relationships among streams of data.
Early systems to support analysis of video records were influenced by hypermedia, which is a logical extension of hypertext.
Originally proposed by Vannevar Bush , the basic approach organizes text into separate chunks that are linked together.
Hypermedia adds images, audio and video, using hypermedia links  to organize them.
Hypermedia has become the dominant metaphor for managing multimedia data and is used in a wide variety of applications, including multimedia documents , education , games  and of course,
Our current research  seeks to provide air traffic controllers with the benefits of networked computing without forcing them to give up their successful existing work artifacts, in particular, paper flight strips.
We began with a four-month field study, following a team of controllers at the Paris en route control center .
We are now analyzing over 100 hours of coded event streams, based on researchers' observations, approximately 50 hours of video of controllers at work, with corresponding radio, telephone and local conversations, output from RADAR and other devices, and copies of relevant artifacts, particularly paper flight strips.
We use exploratory data analysis techniques to identify and analyze both qualitative and quantitative aspects of this data and are particularly interested in finding patterns that occur across media types.
For example, Figure 1 shows two controllers writing simultaneously on two different flight strips, a relatively rare event.
We are interested in understanding the circumstances that surround such situations.
Are there other patterns of activity correlated with this one?
Are the controllers more or less likely to talk to each other?
Are they likely to perform other activities at the same time?
Can we predict this pattern from other recurring patterns, e.g., stressful situations?
Are there any events that help predict when this occurs?
DIVA uses the same stream metaphor as the earlier EVA system, with a more powerful set of operations derived from a stream algebra.
Others have used algebras to deal with time-based data.
For example, Algebraic video  defines an algebra to describe the spatial and temporal composition of video segments.
However, the operators they use are different from DIVA, since the purpose of their system is the production of video presentations, not the analysis of time-based data.
Rivl  is a language that also focuses on video data and production tasks by providing graphical operators to create complex presentations.
This section describes the DIVA algebra, with examples derived from air traffic control data.
The algebra is based on the notion of multimedia streams and a set of operators to create, modify, play and present streams.
A stream s of type T is defined as a sequence  of n+1 clock times and a sequence  of n values: s =  The sequence  is increasing, so the stream can also be viewed as a sequence of stream segments .
The duration of the segment is di = ti+1 - ti.
The values vi are either undefined  or a value of type T, e.g.
The value of a stream s at time t is noted s@t and is defined as follows : * if t < t1 or t  tn+1 then s@t =  * if j is such that tj  t < tj+1 then s@t = vj The empty stream, noted  is a stream whose value is undefined for any time t.
Discovering the answers to these and related questions not only increases our understanding of the complexity of their work, but also helps us better understand how to create tools that support rather than interfere with their existing work practices, addressing problems without adding unnecessary costs .
This article describes DIVA, a system designed to support computing with streams of multimedia data, enabling users to visualize, explore, analyze and evaluate patterns of data that change over time.
We present the underlying system architecture, which involves a common representation for multimedia streams and an algebra for manipulating them.
We next present the user interface, which provides interactive temporal and spatial views of the data.
Before computing with streams, it is useful to normalize them: segments with a duration of 0 are removed, successive segments with the same value are merged, and leading and trailing segments with value  are removed.
In other words, if two segments with the same value are adjacent to each other, the normalized stream contains a single, longer segment.
All streams in this discussion are assumed to be normalized.
We define the extent of the stream as the interval  of its normal form.
Normalizing streams provides a canonical representation of a stream so that, for example, we know that two streams are equal if and only if their normal forms are the same.
Normalizing streams also minimizes storage and reduces processing costs.
Like editing, insertion and deletion are common operations on streams .
Inserting a segment into a stream creates a new, undefined segment and offsets the subsequent segments accordingly.
Usually, the inserted part is then replaced with the edit operation described above.
Deletion removes and/or shortens segments so that a given interval is removed from the stream.
The offset operation is a short-hand for inserting or deleting a segment before the start of the stream.
The offset d can be positive or negative so that an entire stream can be offset forward or backward in time.
New streams can be created from existing streams by stream expressions, comparable to the expressions used to compute a cell from other cells in a spreadsheet.
A common stream expression is editing : a source stream s and an edit stream e, both of type T, are combined with the following edit function: edit  = if  then vs else ve The resulting stream is the same as the source stream except that it is replaced with the edit stream where the edit stream is defined .
We need to present collections of examples of activities observed in our data.
For example, we have a video that presents a series of clips of controllers writing on strips, pointing to the strips, and rearranging the strips.
When we videotape a new session, we can easily insert new examples of these activities into the existing set of streams.
It is often useful to analyze when a given condition occurs before or after another condition.
The interval  defines how close  we want the values to occur .
A variant of time filtering uses a condition that tests whether the whole segment containing v2 in stream s2 is within the time interval defined by .
These conditions generalize Allen's  algebra on time intervals by introducing the notion of temporal vicinity .
This is necessary for the type of data analysis we are interested since we need to be able to look for events that occur at times close to each other.
When two controllers interact with the same set of strips at the same time, it is an indication of a "charged" situation.
We can find out if there is always a corresponding rise in the number of new flights or an increase in conversations between the radar controller and the pilot, just prior to this event.
We can then perform a time series analysis on the result with an external tool to determine which activities cluster together and whether or not we can predict the occurrence of some activities based on the occurrence of others.
Finally if the diagonal appears in the other direction, the clip plays backward .
Time warping makes it possible to take any combination of clips from the streams and play them in any order and at any rate .
Each segment is extended at the beginning and at the end by d if the adjacent segment is undefined.
Stretching is very useful to create a control stream  that includes some context around a specified set of clips .
In order to play a stream, it must be bound to a time base.
Several streams are synchronized by binding them to the same time base.
A time base is defined by a start time, a stop time and a rate.
It generates a time value that changes over time at a pace defined by its rate.
The rate is a real number that specifies whether the time base runs forward or backward at slow, normal or fast speed or whether it is stopped .
A time base can have a control stream: the time base skips undefined segments of the control stream as it runs, making it easy to play sequences of clips not originally adjacent to each other in the original streams.
If we are interested in looking at situations where more than one controller writes at the same time on a strip, we create a stream identifying this condition, stretch it by 1 or 2 seconds, and use the resulting stream as the control stream.
We can then view in succession all clips in which more than one controller writes at the same time.
A more sophisticated method of controlling playing is to define the mapping between the time delivered by the time base and the time used to index the streams.
This mapping is defined by a stream called the warping stream.
Values of a warping stream ws are pairs  of time values and rates.
Let tb be the time delivered by the time base  and let  be the segment of the warping stream such that ti  tb < ti + d. Then ws@tb = vi =  where t is a time and r is a rate.
The warping tw of time tb is defined as tw = t + r*.
Time warping of a segment is illustrated in Figure 6.
The slope of the diagonal line indicates the rate.
If the slope is 45, the rate is 1 and the clip plays at normal speed.
Like EVA and later Video Mosaic , DIVA provides two views of the stream data: temporal and spatial.
Spatial views show the current value of a set of streams at the current time of their time base.
Figure 8 shows an example with a video stream in the middle, boolean streams on the left side and text streams at the bottom.
Two air traffic controllers are writing on the strips at the same time .
The radar controller is telling the pilot to "Maintain flight level"  and the corresponding boolean stream for talking to the pilot  is on.
Other activity codes, including pointing to the RADAR , adjusting the Digitatron  and adjusting the RADAR image  are also off.
Note that these activity codes are defined by the user.
We have generalized this technique to display the changes in multiple streams of any type.
Figure 10  illustrates the smooth transition between the spatial and temporal views.
The streamer display includes a spatial view in the center of the main window and a temporal view around it.
When the set of streams is played, the temporal view streams up or down  so that the spatial view in the central display is always positioned correctly relative to the streams: streams along the edge of the spatial view seem to leave a trace that corresponds to the temporal view.
When the temporal view is "streaming", the parts to the left and top of the central screen show a trace of what has already occurred whereas the parts to the right and bottom of the central screen show what is about to occur .
We have also experimented with the display depicted in Figure 11-b.
Here, the streams are fixed: instead of moving when playing the sequence, a cursor indicates the current time in the temporal view.
The first display works well for very large sequences because it provides context around the current time.
The second display collapses long streams into a small screen space, reducing accuracy for both the display and the interaction.
Either display makes it easy to detect changes in state as the image "streams" forward or backwards in time.
On a 21" screen, the streamer display can accommodate a large number of streams: up to 2 video streams, 5 to 10 text streams and 30 activity streams.
The user can decide which streams to display and can define groups of streams that can be displayed or hidden together.
The bottom of the display  contains a VCR-like interface to control the time base.
Any stream can be designated as the control stream and warping streams can be edited in a separate window.
Temporal views show abstracted versions of the changing state of a set of streams in relation to each other.
This gives us the ability to "lay out time in space" and interact with various streams in parallel.
The temporal view of a stream displays the stream segments along a timeline.
In horizontal display, segments are represented by rectangles whose position, size and color represent the segment time interval and value.
A boolean stream can be displayed by assigning a different color to its true and false segments or by appearing and disappearing.
An integer stream can be displayed as a histogram and more complex streams can combine color and height .
For a video stream, the temporal view can present a sequence of video "best frames", as is often done in commercial systems such as Adobe Premiere.
Spatial and temporal views complement each other.
Spatial views help capture relationships between the current values of different streams and, since they are animated, provide a dynamic display that helps identify patterns of changes over time.
Temporal views help identify longer term patterns within and among streams.
By showing both past and future events, temporal views help anticipate what is coming up in the spatial views.
Streams can be created from files in various formats: recorded video or audio signals, a column or row from a spreadsheet, a text file, the output of devices such as the Digitatron or the RADAR, etc.
Figure 10 shows actual data imported from an Excel spreadsheet.
Streams can also be exported to these file formats, which makes it easy to use spreadsheets or statistical analysis packages to conduct other kinds of data analysis.
Streams can also be created explicitly by the user: the user defines the type and names of the stream in the stream's creation box .
The user can then work in live mode by starting the time base and clicking the value buttons in the creation box to create segments.
Each click creates a segment that starts at the time of the click.
The user can also work in off-line mode by selecting a start and stop time in the time base control panel and a value in the stream creation box.
This creates a new segment in the stream with the specified times and value.
Several streams can be created simultaneously by opening as many creation boxes as necessary, and keyboard equivalents can be defined for each stream to speed up input.
For example, to code the data in a video stream, a user may create a set of binary streams that identify specific activities of the controllers.
The user then starts the time base and records stream values by clicking the on/off/undefined buttons in the creation box at the appropriate times.
Since the rest of the interface is active, the user can see the other streams play in the main display, especially the video streams.
Streams can also be created with the stream algebra.
After selecting the "expression" type in the stream's creation box, the user can enter a stream expression using any of the operators of the stream algebra.
By default, the resulting stream is re-computed every time a stream that appears in the expression is changed, as in a spreadsheet.
In order to find situations where the two controllers write at the same time shortly after the radar controller talks to a pilot, the expression uses time filtering: 2W = on within  of R>P = on The user can further investigate these events by stretching the stream to provide context, making it the control stream and playing the result.
We use QuickTime  to implement the time base and to play audio and video streams.
The stream algebra is implemented in C++ for better efficiency.
The current version is functional and we are re-implementing a larger part of the system in C++.
DIVA allows the user to edit existing streams in several ways, depending on the type of the stream and the scope of the edit.
Streams that result from stream expressions cannot be edited directly since they are re-computed each time one of their dependent streams is modified.
However the stream expression itself can be edited to re-create the stream.
The value of a segment can be changed by clicking on it when it is visible in a temporal or spatial view.
The start and stop times of a segment can be changed in a temporal view by selecting a segment and dragging or resizing it.
They can be changed in a spatial view by selecting the view when the segment is visible and setting the start and stop times in the time base control panel.
Such editing is used mostly to fine-tune a stream after it has been created in live mode.
More radical editing is achieved by creating an "edit" stream with one of the stream creation methods  and using the "edit" operation of the stream algebra on the original stream.
This modifies the original stream and creates an "undo" stream that can re-generate the previous version of the stream from the modified version with the same "edit" operation of the stream algebra.
This is often used to re-record a part of a stream that is incorrect.
The stream algebra can be used to apply the same operation to a set of streams.
This is mostly used with the insert, delete and time-warping operations to reorganize the contents of a set of related streams.
For example, once a specific set of events has been identified, all the irrelevant segments in all the streams can be deleted to keep only the interesting material.
DIVA provides a significant advance over the earlier EVA system at both the architectural level and the user interface level.
The major contributions at the architectural level include: 1.
A stream algebra that provides a simple but mathematically powerful model of streams and operations upon them, 2.
Precise and powerful control and editing functions such as time warping and time filtering.
DIVA's user interface is designed to support the generation and analysis of not only the multimedia streams themselves, but the relationships among them.
The major contributions at the interface level include: 1.
The smooth transition between the temporal and spatial views of the data, using the streamer visualization technique, 2.
The ability to browse, edit and modify the data using either view  or the stream algebra, 3.
The two-dimensional direct manipulation interface for editing streams, using spatial rather than temporal views, and 4.
The ability to use an external package to perform statistical computations, such as identifying correlations, on the results of stream operations.
Informal evaluations using data from our study of air traffic controllers have shown the power of linking the spatial and temporal views.
Compared with a spreadsheet display, the dynamic aspect of streaming gives an entirely different perspective on the data.
We were also able to isolate key events using the stream expressions.
We plan to conduct more in-depth evaluations of DIVA as we analyze additional data sets.
DIVA is clearly designed to support a particular kind of interaction with multimedia data, i.e.
Yet the stream algebra and the streamer interface should be useful for a variety of other multimedia applications, including analysis of video conferencing, editing for multimedia presentations, educational applications and games.
Thanks to Eddie Elliot and Glorianna Davenport for conversations about the streamer technique, which we found to be a wonderful solution to our interface problem.
Also, thanks to Anne-Laure Fayard for all her work on data coding and analysis and to the members of Equipe 9West at Athis Mons en route air traffic control center, for generating all that data!
In IHM'97 Actes 9emes Journees sur l'Interaction Homme-Machine., Poitiers, France: Cepadues Editions.
Minneman, S. and Harrison, S.R.
CHI '97 Human Factors in Computing Systems.
CHI'96, Human Factors in Computing Systems.
Behavior Research Methods, Instruments and Computers.
Sanderson, P. & Fisher, C.  Exploratory sequential data analysis: foundations.
Trigg, R.H.  Computer Support for Transcribing Recorded Activity.
ACM SIGCHI Bulletin: Special Issue on Video as a Research and Design Tool, 21, pp.
Proceedings of CHI'94, Human Factors in Computing Systems.
