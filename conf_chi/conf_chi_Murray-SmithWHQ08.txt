Stane is a hand-held interaction device controlled by tactile input: scratching or rubbing textured surfaces and tapping.
The system has a range of sensors, including contact microphones, capacitive sensing and inertial sensing, and provides audio and vibrotactile feedback.
The surface textures vary around the device, providing perceivably different textures to the user.
We demonstrate that the vibration signals generated by stroking and scratching these surfaces can be reliably classified, and can be used as a very cheaply manufacturable way to control different aspects of interaction.
The system is demonstrated as a control for a music player.
Vibrations generated by touching, scratching or stroking the case are picked up by the microphone.
The basic concept is shown in Figure 1 below.
The use of a piezo-microphone as a sensor means that the device is highly suited to mass-production, providing designers with a flexible new approach for interaction design.
Capacitive sensing is widely used to detect the position of touch in touch screens and touch pads.
Multi-point touch screens have become prominent recently in Apple's iPhone.
One problem with touch-based interaction has been the poverty of proprioceptive feedback  during touch interaction, and the lack of coupling between the functionality accessed, and the feedback perceived by the user.
This requires the user to devote more visual attention to interaction based on touch, and makes it impossible to use reliably in an eyes-free manner.
Mobile use of capacitive sensed touch screens is often challenging, and again, in-pocket interaction is almost impossible.
This paper presents an approach to tactile input which uses a hand-held device we call "Stane" , with a range of textures in the surface design of the case, coupling the physical form of the device with its input controls.
The user can stroke, rub, scratch or tap the case to control another device such as a mobile phone, music player or computer.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
We believe the use of case texture design to explicitly support vibration-controlled interaction is a novel approach to input.
PebbleBox , is an example of a granular interaction paradigm, in which the manipulation of physical grains of arbitrary material, sensed by a microphone, becomes the basis for interacting with granular sound synthesis models, and there is extensive work on real-time synthesized contact sounds .
When we add audio and vibration feedback to the Stane it is, in structure, very close to a musical instrument, so we find elements in the literature close to these concepts.
The main difference is the direct use of the classification of inputs to explicitly control a computer.
The TAICHI project used sound to infer user position when tapping or stroking , using multiple microphones and high sample rates, while  is closer to the work in this paper, focusing on fingerprinting sounds generated by rubbing interactions.
Gradient ridged texture , which could be used for e.g.
Ridges are especially useful for, e.g.
Having different elements at different depths creates a structure to the sound which varies depending on how hard the user presses.
The dimples are 0.5mm high.
Rigid shell prototype with a range of control surfaces .
Shell opened to show electronics .
The contact microphone is mounted on the bottom below the two copper pads onto the interior of the device shell.
The aims of the case texture design are to create an aesthetically pleasing object which empowers the user as much as possible, by providing a rich set of textures which can be easily recognised and accessed in a range of conditions, and which fit appropriately with the form of the device.
The textures used can be varied to provide different audio and vibration responses, and to invite different styles of interaction .
The vibrations generated by the user acting on the textures should be as easy to classify as possible.
The texture is composed of individual elements such as lines, dots, dimples or other geometric forms.
The elements of the texture can be designed so that stroking the texture in different directions will give significantly different sounds.
The material used for the case would also have a significant effect.
Different texture types, spacings and texture gradients will offer natural opportunities for different types of interface control.
We give some examples of texture patterns in Figures 3 and 4, which we developed to explore different possible uses in this prototype.
Each texture provides different constraints, and therefore encourages different types of stroking action, and generates different expectations in the user.
Understanding the tactile affordances will be a key to successful design using this technology.
The relative location of different textures will certainly also be a critical aspect of any design, as that will be a memorable aspect for the user.
Ridges on inner circle, and a dimpled effect on the rim.
Inside the outer shell we use the Bluetooth SHAKE  inertial sensor pack for sensing, as described in .
The SHAKE model SK6 is a small form-factor wireless sensor-pack with integrated rechargeable battery, approximately the same size as a matchbox .
It features tri-axis accelerometer, tri-axes angular rate sensor, tri-axis magnetometer, dual channel analog inputs, dual channel capacitive sensing and an internal vibrating motor.
The vibrations of the shell are captured with a low cost filmstyle Piezo contact microphone 1 which is attached to the inner exterior of the body with a thin doublesided adhesive tape .
It offers excellent robustness to interference from air-borne sound.
Even in very noisy environments, vibrations from physical contact with the shell are of much greater amplitude than those caused by external noise.
A custom expansion module was designed for the SHAKE that includes a high-impedance microphone data acquisition circuit and a vibration driver suitable for driving a linear vibration actuator.
Since the purpose of the contact microphone is to sense the vibrations of the enclosure that surrounds the SHAKE, we limited the bandwidth to 2kHz as there is little useful information above this frequency and it reduces the load of further processing stages.
Once the audio signal has been acquired by the custom expansion module, it is digitized and passed to the SHAKE microcontroller where it is filtered, re-sampled -law encoded and packaged to be sent to the host device over the Bluetooth radio using the serial port profile.
The effective resolution of the microphone signal once received by the host is 13bits and the -3dB bandwidth is 1.5kHz.
The value of the integrator at time t is given by: xct = k  if class=c xct = k  otherwise, where the 0 < k < 1 governs the decay of the intergrator and f gives the increase per classification.
Continuous outputs  are directly integrated and then clipped to the appropriate range.
The sensed vibrations are classified in real-time, with signals from rubbing different areas of the device assigned to discrete classes.
We used a two-stage classification process, with low-level instantaneous classification and higher-level classifiers which aggregate the evidence from the first stage over time.
This structure is well suited to real-time audio and vibrotactile feedback which can be a function of instantaneous classifications.
Before classification, the incoming audio is windowed and transformed into a suitable feature space.
The signal is windowed with a Hamming window, 512 samples long , with 8 overlap.
The classification stream therefore has a rate of 64 classifications a second.
The Fourier transform of the windowed signal is taken, and the phase component discarded, leaving only the magnitude spectrum.
The spectrum is then rebinned so that bins are four times their original size.
These features are sufficient to separate the scratching sounds.
The feature vectors are classified by a multi-layer-perceptron, with 64 hidden units.
The low computational and memory requirements of such model, produce very fast classification performance, suitable for implementation on mobile devices.
Four different classes are trained; these are: Scratching circular front clockwise, Scratching dimples on right side, Scratching tip with fingernail and a Miscellaneous noise class.
Each class is trained on 120 seconds of input data, with a range of speeds of motion, and a variety of grip postures and pressures.
The way the device is held significantly affects the body resonances of the exterior shell.
All data is captured with the shell held in one hand, while being rubbed with the finger of the other hand.
In these examples, the surface is stimulated with the back of the fingernail.
The noise class includes recordings of the device being manipulated in the hands, being placed in a pocket, picked up and replaced on a table and other background disturbances.
We also tested sensitivity to loud noises near the device, but these had negligible effect.
The classifier was trained on 26880 examples, and tested on 11520 unseen pairs, and identifies the different regions of the device with 75% accuracy for these five 1 classes, based on a 64 th of a second of data.
Although this seems relatively low, the high rate of classifications  means that simple integrators can aggregate evidence from the stream of instantaneous classifications into useful control signals.
The style of interaction with the Stane is one where the device is held in one hand, and can either be activated by thumb and fingers of that hand, or in a bimanual fashion using both hands.
The user scratches or rubs the device along its various control surfaces and this generates changes in the interaction.
Given different textures it is fairly straightforward to have a mapping between these and equivalent key-presses.
While possible, and in some cases useful, this is not the primary interaction mechanism envisaged.
Stroking motions feel quite different to button-pushes, and are more appropriate for linking to gradual changes in values, such as volume control, zooming, browsing.
The idea of using this style of interaction is that the user can navigate through a high-dimensional state space, generating incremental changes in state, being pulled or pushed by their stroking actions.
The fact that there are many different textures allows control of multiple degrees of freedom in this manner.
In many cases it will be interesting to map properties of the variable controlled to the type of texture.
The structure allows both discrete increments, when the user `picks' at a single textural component, and continuous ones, when they brush through several.
Depending on the parameterisation of the classification dynamics, partial completion of a stroke could give initial preview information about the consequences of continuing that action.
If the user then continues the stroke, the threshold is reached, and the associated action is performed.
The classifier output stream is used as input to a simple dynamic system.
This smooths out the fluctuations in the classifier.
The dynamic system can support with discrete events and continuous values.
In this introductory paper, we limit the complexity of this stage, although complex recurrent classifiers could be used.
Here, for discrete events, the system functions as a leaky integrator, which triggers an event once the integrated value crosses some threshold.
After this threshold is crossed, the integrator is inhibited for short pe-
While the proprioceptive feedback inherent in the texture is a key benefit of the technique, it is important that we can augment this with software-controlled audio and vibrotactile feedback.
The Stane has an in-built pager motor in the SHAKE module, and an additional VBW32 actuator2 for higher-frequency components.
The augmentation of the raw texture with application-specific sound and vibration makes this more feasible, which is why we have partitioned the classification component into multiple levels, so that we can provide instantaneous augmented feedback.
The user can potentially learn the affordances of the Scratch by just manipulating it, and feeling the changing responses to stroking actions, where each mode of the system might be associated with subtle changes in the response behaviour of the system.
Currently only audio augmentation is implemented.
Unlike capacitive sensing, the case can be metal, for aesthetic design or electromagnetic hardening purposes.
The simplicity of the case technology provides the potential for userdriven design.
Creating `skins' for mobile devices could become a much more important market than just creating different stylings for the visual appearance of phones - it could also allow designs customized for specific families of applications.
We can envisage scenarios where instrument makers create bespoke cases out of materials which allow users to generate their own potentially richly expressive and aesthetically pleasing modes of interaction.
The Stane is also likely to be a productive research tool which stimulates a wide range of applications.
The inertial sensing allows the exploration of combinations of stroking movements with gross motor activity, such as shaking or twisting the device,or rubbing against other devices for, e.g.
The tactile feedback from the physical case can be augmented with context-dependent audio and vibration feedback.
Use of magnetometers for bearing allows us to also use the device for pointing at objects in mobile spatial interaction settings, where the rubbing is used to tease out properties of the content.
We have implemented an interface for a music player, which is controlled by scratch-based interaction with appropriate mappings from surfaces to controls.
The use case scenario is a user walking, listening to their music player, and controlling the volume and track choice while the Stane is in their jacket pocket.
The major actions used are start/stop , volume adjustment and track change.
Each of the classified outputs is fed to an integrator.
The output of this integrator is either used directly , or is thresholded to activate events .
This results in reliable control, even though the underlying classification has regular glitches.
The textures are easily navigated by the user by touch alone, and the system was tested with five different users, who were able to use it without problems, despite the system being calibrated for a single user.
The rotary texture was felt to be particularly pleasant to use, while the dimples at the tip were perceived to be `more fiddly'.
Antonacci, F., Gerosa, L., Sarti, A., Tubaro, S., and Valenzise, G. Sound-based classification of objects using a robust fingerprinting approach.
Soap: a pointing device that works in mid-air.
UIST '06: Proceedings of the 19th annual ACM symposium on User interface software and technology.
Bornand, C., Camurri, A., Castellano, G., Catheline, S., Crevoisier, A., Roesch, E., Scherer, K., and Volpe, G. Usability evaluation and comparison of prototypes of tangible acoustic interfaces.
Hummels, C., Overbeeke, K. C., and Klooster, S. Move to get moved: a search for methods, tools and knowledge to design for expressive and rich movement-based interaction.
Marshall, D. Carved stone balls.
O'Modhrain, S., and Essl, G. Pebblebox and crumblebag: tactile interfaces for granular synthesis.
NIME '04: Proceedings of the 2004 conference on New interfaces for musical expression.
Rath, M., Avanzini, F., Bernardini, N., Borin, G., Fontana, F., Ottaviani, L., and Rocchesso, D. An introductory catalog of computer-synthesized contact sounds, in real-time.
Wang, Q., and Hayward, V. In vivo biomechanics of the fingerpad skin under local tangential traction.
Williamson, J., Murray-Smith, R., and Hughes, S. Shoogle: Multimodal excitatory interaction on mobile devices.
CHI '07: Proceedings of the SIGCHI conference on Human factors in computing systems.
Data for a session where the user flicks forward two tracks, lowers then raises the volume, then flicks back two tracks.
The top plot shows the spectrogram of the signal recorded from the input data.
The middle plot shows recognition events , and the integrated values from these , which approximate P .
The bottom plot shows the changes in controlled variables 
The technology illustrated in Stane3 allows the use of very cheap sensing hardware, coupled with an arbitrarily textured device case.
This technology can compete with or be combined with capacitive sensing, buttons, or inertial sensing.
The initial experiments demonstrated robust classification of stroking movements on a custom-designed case, using vibration sensor information alone.
