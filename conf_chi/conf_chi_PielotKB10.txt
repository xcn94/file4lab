A group of friends visiting a crowded and noisy music festival is an example of a situation where knowing the location of other people is important, but where external factors, such as darkness or noise, can limit the ability to keep track of the others.
By combining theories about situation awareness and cognitive processing we inferred that communicating information via the sense of touch is a promising approach in such situations.
We therefore investigated how to present the location of several people using a tactile torso display.
In particular we focused on encoding spatial distances in the tactile signals.
We experimentally compared encoding spatial distances in the rhythm, duration, and intensity of a tactile signal.
Our findings show that all parameters are suited to encode distances.
None of it was clearly outperformed.
We then embedded our tactile location encoding into a fastpaced 3D multiplayer game.
In this game, team play and the awareness of the team members' locations are crucial for the success in the game.
The results provides evidence that the locations of the team members could be processed effectively despite the game's high cognitive demands.
In addition, the team equipped with the tactile display showed a better team play and a higher situation awareness.
We employ our senses to perceive what is going on around us interpret the signals and make decisions.
Important entities for our perception of the environment are the location, direction and distance of places and possibly moving objects and persons.
This information contributes to our decision to wait at the crossing, to turn right to reach a point of interest, or just follow our friends through the city centre.
However, the environment may not be suitable to the perception capabilities.
Consider going out with your friends visiting a large music festival: you and your friends stroll around on the festival ground but darkness, the crowd, and noise make it very difficult to stay together.
In stressful environments like these, perception and interpretation might be impaired, which consequently degrades the situation awareness.
The emitting signals of the environment simply do not match the free resources for our perceiving of the environment.
It is too dark to see well, too loud to hear well, too busy to continuously focus on the group .
At the same time, perceptual resources are still free and can be used to perceive the information over a different sensory channel, the sense of touch.
Previous research has shown that providing information by an underused sense, such as the sense of touch, can improve the cognitive processing of that information while reducing the probability of a cognitive overload .
In order to improve situation awareness in situations, where one needs to keep track of moving entities, we propose to display their locations by a tactile display.
The display we employed consists of several vibro-tactile actuators and is worn around the torso like a belt.
It allows stimulating sites around the waist, which can be easily understood as directional cues.
For example, a vibro-tactile stimulation with actuators near the navel corresponds to the forward direction.
Based on this tactile display we developed an information presentation that allows conveying the direction and the distance of surrounding objects, places, or friends.
We present two experimental studies we used to evaluate the display.
In a first study, we focused on comparing different methods for conveying the distance, as this turned out to be the biggest issue.
Exploring the design space of a vibro-tactile display different distance encodings were implemented and evalu-
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Intensity and rhythm-based encodings proved to be the successful ones in presenting and perceiving the position of team members.
The second study evaluated the effectiveness of this information presentation in a demanding situation.
Embedded in a 3D multiplayer team game the tactile belt was used to convey the locations of the team members.
The studies show that the tactile information can effectively be processed.
There was a significantly better understanding of the situation and improved the team play.
The remainder of this paper first introduces the reader in the background related to situation awareness, cognitive processing, and related approaches that use spatial displays.
We then elaborate our approach on presenting spatial locations with tactile displays and the investigation of different encodings for spatial distances.
The section on TactileCS shows how we embedded the encoding of positions of team members in a multiplayer team game in which each player has to be well aware of the location team to be successful in the game's task.
The rest of the paper describes the experiment we conducted to investigate the effect of the tactile spatial information encoding on the spatial awareness of the team in the respective multiplayer game.
We close the paper with a discussion on the results can be generalised.
Since these steps build on top of each other, subsequent steps are dependent on the previous one.
If the initial perception of the relevant elements in the environment fails the subsequent comprehension and projection steps are not possible.
Consequently, for a good SA a sufficient perception of the environment and the comprehension of the perceived elements are crucial.
For a user interface this allows to conclude that we should support a good perception of the elements relevant for situation awareness while leaving sufficient attentional resources to process that information in steps two and three.
When using a mobile application to mediate the location of people it is most likely that there will be considerable environmental interferences that impede the interaction with the device.
In addition, there will be parallel tasks, such as navigating through a crowd, which compete for the user's attention.
Therefore, perceiving and processing of information displayed by a mobile device, such as the location of people, may be impeded.
The perception can be improved by using an information carrier that is rarely disturbed by environmental interferences.
Improving the processing of perceived information can be done by reducing the cognitive load of the user and freeing attentional resources.
The latter point can be addressed by applying the Multiple Resource Theory  .
It states that each sense has its own pool of attentional resources.
Information is more likely to be processed if it is perceived via an "idle" sense rather than a sense that is already under high load.
It also states that providing the same amount of information via different senses will decrease the overall cognitive load.
Specifically in demanding situations in which our sensory and cognitive load is high a promising approach is to support the perception by using an "idle" sensory channel.
The sense of touch represents a suitable solution for both issues.
It is hardly affected by typical interferences in mobile situations.
It is also barely used by mobile applications to convey information to the user and thus can be considered "idle".
The work by Chan et al.
We assume that mediating the location of a people with a tactile display will result into a better perception and comprehension of the situation.
The presented approach aims at improving situation awareness for groups of people by visualizing the location of the group members with a tactile display.
In this section we embed our work in the related work in the field.
To formalize the problem we address and provide a theoretical framework by reviewing theories regarding situation awareness and cognitive workload.
We elaborate how the understanding of a situation, respectively knowing the location of people, can be improved by using the sense of touch as information carrier.
A review of the related work on displaying spatial information with tactile displays presents existing approaches to encode and visualize information in spatial displays and shows how this relates to our approach.
Situation awareness  is a term that first came up in the avionics and was used to describe how well a person understands a situation.
It involves the perception of the elements in the environment, the comprehension of their meaning, and the projection of their status in the near future .
Situation awareness is formed in three steps: perception, comprehension, projection.
Perceiving the relevant elements in the environment is the first step and leads to level 1 SA.
In the comprehension step, the isolated knowledge about the relevant elements' states will be joined into a comprehensive picture of the current situation.
The final step is the projection of the state of the observed elements in the near future and leads to level 3 SA.
The higher the level of SA becomes the more effective one can react to the environmental state.
Previous research has shown that tactile displays can effectively be used in conjunction with mobile applications to mediate spatial information, such as the location of people.
Stimulations around the torso by tactile displays can be easily externalized to horizontal  and three dimensional directions .
This has for example been applied for navigation  where the direction of the next waypoint has been expressed in that way.
Showing the location of multiple places has been investigated by Lindeman et al.
To understand where an object is exactly location one need to convey its distance in addition to the direction.
However, conveying distances with tactile torso displays has not received much attention yet.
They altered the stimulus duration to encode four distance classes.
They could show that interpreting distances from pulse duration works but they offer no baseline to judge the quality of the presentation.
In particular, the participants were reported to have problems in distinguishing the middle distance classes.
On the application level, studies have shown that spatial information conveyed via tactile interfaces can reduce the overall cognitive load and improves the understanding of the situation .
However, the motivating scenario of presenting the location of several people who share a common goal or work on a common task with tactile displays has not yet been investigated sufficiently.
In order to describe a location through its direction, its distance has to be conveyed as well.
When encoding distance, the decision has to be made what kind of distance information shall be presented to the user.
According to McDaniel et al.
We therefore decided to convey distance classes instead of a continuous distance value.
We assumed that people might find distance classes easier to process, while at the same time there is less information to encode for the tactile display.
One general finding of the Psychophysics field is that a sensation does not grow linearly with the stimulus intensity.
According to the Weber-Fechner Law the subjective magnitude of a sensation is a logarithmic function of the stimulus intensity.
A famous example by Daniel Bernoulli from 1783 is that adding one dollar to two dollars is perceived as greater value than adding one dollar to 100 dollars, although the value of the added dollar does not change.
Consequently, the distances classes described by McDaniel et al.
For example, the size of the intimate distance class is only 18 inch the size of the social distance class is 8 feet.
We therefore arranged the distance classes in a similar way so their size grows exponentially.
An outer bound was defined, beyond which a distance would not be displayed anymore, similar to the fact that humans have a limited hearing range.
Given a number of distance classes and the outer bound's radius the size of each distance was computed to be conforming to the Weber-Fechner law.
This section describes the design and the evaluation of a tactile user interface for presenting the location of other people to the user.
For the remainder of this paper we will use the term tactile position display to refer to the tactile display in conjunction with the way of encoding locations.
As conveying directions with tactile displays has been sufficiently addressed by previous research, this work focuses on how to encode distances.
Similar to previous research we choose to present locations from the perspective of the user.
This design choice was motivated by the fact that conveying directions in that way through tactile torso displays has proved to be very effective .
People can easily externalise tactile stimuli around the torso to directions .
For example, a stimulus at the spine is intuitively interpreted as "behind the user".
A special form of these torso displays, which we used in the presented work, is tactile belts.
A tactile belt is basically an array of tactile actuators sewn into a belt.
When it is worn these actuators arrange themselves equally around the waist.
It therefore allows to stimuli locations around the torso when can be externalised to horizontal directions.
The actuators in the used in this work are off-centred weights fixed to the axis of an electric motor to generate vibration stimuli.
While this actuator technology limits control over the stimulus generation they are cheap and robust.
A solution for displaying the location of multiple objects is displaying them simultaneously as proposed by Lindeman et al.
An actuator would be turned on if there was a relevant spot in the corresponding direction.
As there are just a few initial studies on how to encode distances with a tactile torso display, we investigated the potential parameter space.
According to  or  the generally modifiable parameter of tactile stimuli are amplitude, frequency, duration, waveform, rhythm, and body location of the stimulus.
In the case of our tactile belt, the parameter space is however limited.
Body location is already used for encoding the direction of a location and therefore cannot be used for distance encoding anymore.
In addition, the actuators use off-centred weights to generate the vibro-tactile stimulation.
This technology further limits the parameters which can be altered for encoding information: First, the waveform of the stimulus cannot be controlled.
Second, according to the manufacturer Precision Microdrives1 amplitude and frequency change almost linearly when the applied voltage is altered.
They therefore cannot be treated as independent parameters anymore.
In the following we will refer to intensity as the result of changing amplitude and frequency at the same time through changing the voltage.
As there are no guidelines yet which parameter is best suited for distance encoding, we designed and evaluated a display method for each of those three parameters.
The design of these methods and their experimental comparison is described in the following sections.
Rhythm is a complex parameter where groups of pulses with different lengths are used to compose pattern.
In this study we simply used the number of pulses to denote the distance class.
The closest distance class is displayed by a single stimulus; the second distance class is displayed by two stimuli in short succession, and so on.
A single pulse had a duration of 200ms followed by a 200ms pause.
Each series of pulses was succeeded by a 800ms pause.
Figure 1 shows the rhythm-based distance encoding  for three people in different positions.
In the centre of the figure the user wearing the tactile torso display is shown from a bird's eye perspective.
The dashed circle right around the user represents the tactile torso display including the location of the actuators.
The other three circles illustrate the outer bounds of three distance classes.
The different parts of the picture  show how the position of each of the three people would be presented to the user.
Again we applied the Weber-Fechner Law to the intensity, meaning it would decrease exponentially.
Figure 3 illustrates the intensitybased distance encoding  used in this study.
The pulse length for displaying each person was 400ms followed by a 400ms pause.
We evaluated the three above described display methods in a lab experiment.
The goal was to compare the methods in terms of accuracy of the location information and how easy and intuitive their interpretation was.
In the study, participants were presented the virtual locations of three people via the tactile belt.
They then had to report the perceived location via a graphical user interface.
Stimulus duration as tactile parameter denotes the time between the onset and the offset of a single stimulus.
Using stimulus duration to encode spatial distance can be done by simply mapping the duration to the distance, as proposed by .
The further the location is away the longer the stimulus gets.
For the mapping we applied the Weber-Fechner Law, so the stimulus durations increase exponentially with increasing distance.
The stimulus duration ranged from 0.6s form the closest locations to 2.4s for the furthest locations.
The duration-based distance encoding  is illlustrated in Figure 2.
Nine participants  took part in the study.
We used a repeated-measures design, i.e.
The order of the conditions was counterbalanced to cancel out sequence effects.
The accuracy was measured by recording the direction error, the distance error, and the position error for each virtual person.
The direction error  was obtained by comparing the angle difference between the proper and the judged positions of each location.
The distance error |a - b| was obtained by calculating the absolute difference between the proper position's distance and the judged position's distance to the virtual user.
The position error  was obtained by calculating the length of the segment connecting the proper and the judged positions.
Figure 4 visualizes the accuracy related measures.
Intensity is - in this case - the combination of the stimulus amplitude and the frequency.
Similar to duration, we mapped the intensity of the stimulus to the spatial distance.
Pilot tests indicated that people find it more intuitive if far objects are presented by weak stimuli and closer objects are presented by strong stimuli.
Every time five test sets had been completed with one distance encoding the participants were asked to fill out the questionnaire for the respective distance encoding before switching to the next encoding.
In the end, we encouraged the participants to express their thoughts, ideas, and comments about the display methods.
The intuitiveness of the display methods was measured by recording the time needed to arrange the three figures as well as by issuing post-session administered questionnaires.
The questionnaires let participants rate on five point Likert-scales how easy or difficult they found to judge the direction and the distance of the displayed locations.
The participants were able to interpret the successive presentation of locations with all three methods.
Table 1 summarizes the obtained scores.
The distance error was similar to the error we had experienced in previous studies where only a single direction had to be judged.
The studies were conducted within a custom built test environment.
It allowed us to quantify how accurately and intuitively spatial information can be perceived with different display methods.
It can be fed with the virtual locations of several people in relation to the user.
A tactile belt can be connected to the test environment.
Then, different display methods can be used to display the people's location.
The user can express the perceived locations of these people through a graphical user interface .
This is done by placing graphical figures in relation a blue circle in the centre, which represents the user's location.
Only few significant differences between the distance encodings could be found.
Distance judgements were more accurate and judged easier with the rhythm-based distance encoding.
However, intensity and duration were found easier to judge directions.
Duration was found hardest to judge distances and the participants needed significantly longer for their judgements.
However, with short training all participants were able to effectively interpret the tactile cues.
Altogether, the study showed that it is possible to effectively cue the location of several people with a belt-type tactile display.
Since there was no clear "winner" we decided to keep the rhythm-based and the intensity-based distance encoding and allow the participants of the following study to choose according to their preference.
The test environment allows creating test sets, where different situations can be tested in random order and with alternating display methods.
Each test set contains the positions of three virtual people.
Each virtual person's position is defined by a direction and a distance in relation to the user.
To teach the participants the different distance encodings the evaluation began with a demonstration of all three display methods.
Printouts of the Figures 1, 2, and 3 were provided in addition to support the learning process.
Once the participants had learned the location encodings, we presented different test sets to them and asked them to judge the relative locations of the haptically presented people by using the above described test environment.
In order to evaluate the effectiveness of the tactile position display on the situation awareness we needed to deploy it in a situation where knowing the location of other people is a highly relevant element of the situation awareness.
In addition, the situation should generate a high load on the auditory and visual senses, so improving perception and processing of information becomes a significant factor.
Inspired by recent studies  we favoured a virtual environment over a field study, since the lab situation allows better measurement and the results would be less affected by unsystematic variance.
As evaluation environment we chose a well-known 3D multiplayer game called CounterStrike.
In this game each player controls a virtual avatar from a first-person perspective, i.e.
The players are organised in two teams that have conflicting goals and compete in preventing the other team from reaching them.
Via network or internet people can populate those teams and join via different PCs.
The game generates a high cognitive load on the player.
There is a fast-paced game action, players need to concentrate on the current situation, and they experience constant auditory and visual stimuli.
At the same time, if the team advances according to a previously agreed plan, it is important to track the location of each team member.
Figure 6 shows two avatars through the eyes of a player.
The goal of this study was to show whether the tactile position display is effective in high cognitive workload situations and where knowing the location of the individuals of a group is important for the situation awareness.
Our hypotheses were that: * H1 Despite the high cognitive workload the spatial information presented through the tactile position display can be processed effectively, * H2 the perception and the processing of relevant information bits improves , * H3 the comprehension of the situation improves , * H4 and the collaboration between the team members improves 
The game play is separated into rounds.
Each round, both teams try to score by reaching their respective goals.
After each round, the game state is reset and both teams are put back into their starting locations.
For this work we used game type called "defuse", where one team has to place a explosive charge at a specific place while the other team needs to prevent this or defuse the charge in time.
This scenario was chosen, as good team play is most effective here.
The members of the charge-laying team can try to distract and sneak around the defending team.
The members of the defending team need to be sure that all possible routes are monitored.
A system called TactileCS was developed to display the positions of the team members via the tactile belt.
It consists of a plug-in for Counter-Strike servers using the AMX mod2 which distributes the locations of the players through a UDP port.
On the tactile belt's side a component written in C# was used to receive and process the player locations transmitted via the UDP port.
The component provides a graphical user interface where the player can adjust how the locations are presented with the tactile belt.
Players can choose between the display methods using intensity and rhythm to encode distance, can alter the "loudness" of the tactile signal, can choose the number of distance classes, and alter the speed of the presentation.
We allowed this degree of freedom to see if common usage patterns emerge over time, such as the preference of one of the two parameters for encoding distances.
Each participant was provided with a notebook where an instance of the game was installed.
A network switch was used to create a local area network between the notebooks.
On half of the notebooks we additionally installed our TactileCS software that was used to control the tactile belts' output.
To each of these notebooks a tactile belt was connected via serial cable or Bluetooth.
We used a repeated measures design, so each participant attended the game with and without the tactile belt.
Using the tactile belt was considered the experimental condition, while using no belt served as baseline condition.
To cancel out sequence effects, half of the participants would use the belt initially while the other half would use it in the second part of the study.
Following the categorisation by Salmon et al.
The subjective self- judgement was done by a SART-3 questionnaire  where the participants had to reflect their situation awareness in the past round.
The SART-3 asked the participants to rate  the demand of attentional resources,  the supply of attentional resources, and  the understanding of the situation.
While more complex SART questionnaires exist, we chose this scaled down variant to not overburden the participants with the need to answer too much questions each round.
In addition to the SART-3 questions, the participants had to rate their subjective impression of how well the team play went in the past round.
1 would mean bad and 5 would refer to good situation awareness or team play.
The external judgement of the situation awareness was conducted by the so called situation present assessment method  .
In this method, an external person interrupts the participants in the middle of the task to probe the participants understanding of the current situation.
The experimenters asking the participants to describe the current situation and judge how well the own team progresses according to plan.
The experimenters rated on five-point Likert scales how fast and accurate the response was and how certain the participants made their judgements.
The objective performance measurement was based on how often and in which way the round was won or lost.
A team can win a round by throwing out all players of the other team or by deploying the explosive charge at a given spot, respectively denying that.
We counted how often a team won the round, how often the charge-laying team could plant the charge, and how often the other team could prevent that.
For all type of winning conditions it is favourable if the team plays in a well coordinated way.
Statistics of individual players were ignored, since those scores are mostly based on the skill of the player and thus are less likely to be influence by situation awareness.
16 and 17 another training session was conducted to give the teams time to adjust to the new situation with or without the tactile belts.
Since most of the procedure was already known, this second training session was shorter.
We obtained 192 SART-3 self-judgements, 64 external SPAM judgements, and 32 objective game scores.
We closed the experiment by an open discussion where the participants were asked to elaborate their experience with the tactile belt, how they used it, and what differences there were between using and not using the tactile belt.
As there were some problems in the pilot session regarding responding to SPAM questions, lack of team play, and technical problems, the quantitative results are only reflecting the second session.
We therefore analysed 192 subjective ratings , 64 external ratings , and 32 performance measures.
The study took place on two evenings.
Each evening the participants were divided into two equal sized groups.
The two groups were split up to sit on the opposite sides of a broad table so they were facing each other.
Each group always joined the same team in the game.
The members of the group on one side of the table were equipped with a tactile belt each.
Every round comprised three phases:  filling out the SART3 questions for the past round,  agreeing on a plan,  and executing the plan while possibly having to explain the situation to the experimenter.
In order to allow the participants to familiarise themselves with this procedure the evaluation started with an open training session.
The participants learned how to use a printout of the virtual environment to silently agree on a plan by announcing it through the team chat of the game.
They trained to stick with that plan and keep track of their team mates.
During this training phase the experimenters already conducted SPAM questioning, so the participants could get used to being interrupted during the game and describing the situation.
The participants also learned to judge the subjective situation awareness by the SART-3 questions.
The training session was continued until the participants had internalised the procedures.
This took about 90 minutes.
During the evaluation session 32 rounds were played in four different constellations: each group played both game teams twice, once equipped with tactile belts and once without.
Table 2 shows the four resulting constellations.
When the belts were switched to the other group after round 16 we there was a short break for regeneration and to give the experimenters time to adjust the belts to their new wearers.
The state of attentional resources was assessed by analysing the items demand of attentional resources and supply of attentional resources from the SART-3 questionnaire.
The demand of attentional resources referred to the question of how much effort the participants had to devote to keeping track of their team mates.
The supply of attentional resources referred to how well they could keep track of the team mates' locations thanks to the additional cues.
Understanding of the situation referred to how well the participants understood the current situation.
Each item was rated on a 5-point Likert-scale where 5 meant least demand and best supply of attentional resources.
Figure 7 shows the means of the three SART-3 items.
The demand of attentional resources was perceived to be significantly lower when using the tactile position display .
The middle diagram shows a significantly higher perceived supply of attentional resources when a tactile position display was used .
The understanding of the situation was rated significantly higher as well .
Regarding the SPAM probing the situation awareness was quantified by how prompt, accurate, and certain the participants answered the question how the game was progressing with respect to the initial plan.
Certainty, accuracy, and promptness were rated on a 5-point Likert-scale where 5 denoted the highest level of situation awareness.
The average results for these three items are shown in Figure 8.
According to the judgements of the experimenters the participants were significantly more certain with their descriptions of the situation when using the tactile position dis-
Results of the SART-3 items.
The demand of attentional resources decreases and there is a better supply of attentional resources when using the tactile position display.
In addition, the participants estimated their understanding of the situation higher when using the tactile position display.
The quality of the team play was assessed by self-reports and external observations.
Every participant and both observers rated the team play of their team after each game round.
Again, team play was rated on a 5-point Likert-scale where 5 denoted very good team play.
Figure 9 shows the average quality rating for both conditions.
The upper diagram shows that the participants judged the team play to be significantly improved when using the tactile position display .
The external observers' judgements also indicated an improved team play as illustrated in the lower diagram .
At the end of each session we had a loose discussion with the participants about their experiences with and without the tactile position display.
There was a general impression that the tactile position display altered the awareness of the situation.
Without the system the groups found to need much more verbal communication to execute their plan.
The participants felt that using the tactile position display did not distract them from perceiving other important things from the virtual environment.
Two participants explained that using the tactile belt gives a sense of well-being: Feeling the positions of the team members in the right direction indicates that the situation is under control.
It was also reported that the tactile pulses were processed without being explicitly noted after a while.
The external observers found that when using the tactile position display the individuals of a team spread further out, whereas without the system the team stayed closer together.
Nineteen of the 32 rounds where won by the team that was equipped with the tactile belt.
However, the difference turned out not to be significant .
How successful the team was in laying the charge  was also not affected by the belt.
Both success rates were nearly equal in both cases between the experimental and the control condition.
So, while the tactile position display could partially improve the performance, the difference was at a significantly level.
The evaluation showed that displaying the team mates' locations had significant positive effects on the situation awareness and the team play.
The participants reported an increase in attentional resources and a better understanding of the situation.
According to the external judges, the participants were able to express current situations faster, more accurate, and with higher certainty.
Team play improved according to the self-perception of the participants and the judgements of the experimenters.
The objective performance improved but not at a significant level.
Also, a prolonged training of putting the additional information to good use might make the information added by the tactile position display more valuable.
In the case of the presented study other factors, in particular how good participants were in playing the game, seemed to have a larger impact on performance.
Hypothesis H1  is supported by our findings.
Since H2 and H3 are both supported the tactile position display must have been effective in improving the perception and comprehension of the team mates' locations.
This means that the tactile position display had a positive effect on mediating the relevant information bits to the user.
According to Endley's situation awareness model  important factors for gaining situation awareness are interface design, stress & workload, and complexity.
Drawing on the Multiple Resource Theory we infer that reducing the cognitive workload was one of the causes for the improved situation awareness.
Again, this supports the findings by Duistermaat et al.
The study's results support H2 .
The significantly lower perceived demand of attentional resources confirms the prediction of the Multiple Resource Theory .
Since we conveyed information by the tactile modality, which otherwise was not used for information presentation, the overall cognitive load reduced.
The participants' comments further support this finding as the tactile position display was found to be intuitive and not distracting from the game play.
Our findings also go conform to the results reported by Duistermaat et al.
Drawing on these results we believe that the tactile position display improved the perception of elements that are relevant for situation awareness  and therefore lead to a better level 1 situation awareness.
Hypothesis H3  is supported as well.
Both, the SART-3 questionnaire as well as the SPAM probing indicated a significantly higher situation awareness for the team with the tactile position display.
According to the SART-3 responses the participants felt better supplied with relevant information and had a subjective better situation awareness.
In addition, they were able to better describe their current situation to the experimenter.
Altogether these findings indicate a better comprehension of the situation with the tactile position display.
Hypothesis H4  is not clearly supported by our results.
Regarding the qualitative results the participants reported an improved feeling of having the situation under control.
The need to communicate verbally also reduced.
In addition, the collaboration seemed more efficient as the individuals spread further out with the tactile position display.
The performance measures recorded nineteen wins versus thirteen losses with tactile position display, however, the number of wins was not different at a significant level.
We presented a comparison of three different parameters for encoding spatial distances, namely rhythm, duration and intensity.
Although there were a few significant differences, spatial distance could be successfully encoded in all three parameters.
We then used this distance encoding to build a tactile position display that successively presents spatial direction and distance of several objects via a tactile display in relation to the wearer's position and orientation.
This presentation was then used in a 3D multiplayer game to inform the players about the location of their team members.
A comparative experiment showed that the players have a better situation awareness when being equipped with the tactile position display.
These results show that the presented design can effectively convey location information.
To be able to generalize our findings beyond the game we based our work on two scientific theories: Endley's situation awareness model, which predicts that getting a good SA is impaired by high cognitive load, and Wickens' Multiple Resource Theory, which predicts that the overall cognitive load will not much increase if information is present through an "idle" sense.
In combination both theories predict that conveying relevant information with a tactile display leads to a better SA when eyes and ears are "busy", as in the presented experiment.
The presented study can be seen as a falsification attempt to the combination of the two theories.
The results we found support the theories' predictions.
Since those theories claim to be valid for any situation, not only the 3D multiplayer game, we can hypothesize that the same effect can be observed in different situations, e.g.
However, more falsification attempts are needed before we can trust our findings to be general.
Supporting map-based wayfinding with tactile cues.
In MobileHCI '09: Proceedings of the 11th International Conference on Human-Computer Interaction with Mobile Devices and Services, pages 1-10, New York, NY, USA, 2009.
Sensing your social net at night.
In Night and darkness: Interaction after dark.
Workshop at the International Conference on Human Computer Interaction  2008, April 5-10, 2008.
Wearable interfaces for orientation and wayfinding.
In Assets '00: Proceedings of the fourth international ACM conference on Assistive technologies, pages 193-200, New York, NY, USA, 2000.
An instrumentation solution for reducing spatial disorientation mishaps.
Situation awareness measurement: A review of applicability for c4i environments.
Effects of mobile map orientation and tactile feedback on navigation speed and situation awareness.
In MobileHCI '08: Proceedings of the 10th international conference on Human computer interaction with mobile devices and services, pages 73-80, New York, NY, USA, 2008.
Guidelines for the use of vibro-tactile displays in human computer interaction.
Presenting directions with a vibrotactile torso display.
A tactile cockpit instrument supports the control of self-motion during spatial disorientation.
Waypoint navigation with a vibrotactile waist belt.
Waypoint navigation on land: Different ways of coding distance to the next waypoint.
In Proceedings of the 4th International Conference EuroHaptics 2004, 2004.
In Processing resource in attention.
S. Brewster and L. M. Brown.
Tactons: structured tactile messages for non-visual information display.
A. Chan, K. MacLean, and J. McGrenere.
Designing haptic icons to support collaborative turn-taking.
Vibrotactile localization on the abdomen: effects of place and space.
B. F. van Erp, and R. E. S. Human factor issues in complex system performance, chapter Tactile land navigation for dismounted soldiers, pages 43-53.
Shaker publishing, Maastricht, The Netherlands, 2007.
Toward a theory of situation awareness in dynamic systems.
A comparative analysis of sagat and sart for evaluations of situation awareness.
In 42nd Annual Meeting of the Human Factors & Ergonomics Society, Oktober 1998.
Designing for situation awareness - An approach to User-Centered Design.
Effectiveness of directional vibrotactile cuing on a building-clearing task.
In CHI '05: Proceedings of the SIGCHI conference on Human factors in computing systems, pages 271-280, New York, NY, USA, 2005.
T. L. McDaniel, S. Krishna, D. Colbry, and S. Panchanathan.
Using tactile rhythm to convey interpersonal distances to individuals who are blind.
In CHI EA '09: Proceedings of the 27th international conference extended abstracts on Human factors in computing systems, pages 4669-4674, New York, NY, USA, 2009.
M. Pielot and S. Boll.
Tactile Wayfinder: comparison of tactile waypoint navigation with commercial pedestrian navigation systems.
In The Eighth International Conference on Pervasive Computing, Helsinki, Finland, 2010.
