We describe concepts to support the analysis of cell phone menu hierarchies, based on cognitive models of users and easy-to-use optimization techniques.
We present an empirical study of user performance on five simple tasks of menu traversal on an example cell phone.
Two of the models applied to these tasks, based on GOMS and ACT-R, give good predictions of behavior.
We use the empirically supported models to create an effective evaluation and improvement process for menu hierarchies.
Our work makes three main contributions: a novel and timely study of a new, very common HCI task; new versions of existing models for accurately predicting performance; and a search procedure to generate menu hierarchies that reduce traversal time, in simulation studies, by about a third.
Categories and Subject Descriptors: H.5.2 : User Interfaces--Evaluation/methodology General Terms: Human Factors, Design ACM Reference Format: St. Amant, R., Horton, T. E., and Ritter, F. E. 2007.
Model-based evaluation of expert cell phone menu interaction.
The information in this article does not necessarily reflect the position or policies of the U.S. government, and no official endorsement should be inferred.
Authors' addresses: R. St. Amant and T. E. Horton, Department of Computer Science, North Carolina State University, Raleigh, NC 27695; email:{stamant; horton}@csc.ncsu.edu; F. E. Ritter, College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA 16802; email: ritter@ist.psu.edu.
Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted.
To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee.
INTRODUCTION There are 2 billion cellular telephones in use today, and this number is expected to reach 3 billion in 2008 .
Cell phones are used for more than making calls; they now include tools for managing contact information, voice mail, and hardware settings, and often software for playing games, browsing the Web, and connecting to specialized information services.
The market penetration of cell phones is much higher than that of conventional computers, which raises significant opportunities and challenges for HCI.
This article presents techniques for evaluating and improving cell phone usability, in particular the usability of the hierarchical menus that provide access to most functionality aside from dialing and data entry.
While cell phone menu interfaces may appear simple at first glance, they pose a nontrivial design problem.
Consider the menu hierarchy for the Kyocera 2325 cell phone, the first 25 items of which are shown in Table I.
If we count as terminals those selections that open an application , a list of data , or a set of choices in the cell phone equivalent of a dialog box , then this hierarchy contains 98 terminals, reachable through 22 intermediate selections.
The longest menu contains 12 items-all associated with the selection of different sounds.
The shortest menu contains a single item, for entering a voice memo.
Terminals in the hierarchy are up to four levels deep, and the mean number of actions to reach an item , over all 98 terminals, is 13.3, taking on the order of 7 seconds for an experienced user.
This menu hierarchy is as large as that of a moderately sized desktop application .
This is not unusual for cell phones; the menu hierarchy for the Samsung MM-A800, which includes a digital camera, contains a remarkable 583 items .
Designing menu systems for any platform, including desktop systems, can be challenging, but for cell phones the problem is made more difficult by several factors: -- Discrete selection actions in the form of button presses1 are usually needed to move between menu items, because most cell phones lack more direct selection capabilities .
Many cell phones lack functionality for paging up or down, making display limitations even more significant.
Some phones have two-way directional buttons, others four-way; some have a labeled "Menu" button, while others rely on a button with overloaded functionality.
Button placement can vary significantly, with "Cancel" and "OK" buttons reversed from one phone to another.
If interfaces are developed for the lowest common denominator, independently of specific hardware , then even cell phones with elaborate interaction support become less efficient.
These factors suggest that cell phone menu interfaces deserve close analysis, and that they need specialized techniques for their development and evaluation, which this article takes up in two parts.
All the models give good accounts of qualitative patterns in user behavior, and the latter two models give good to very good quantitative predictions of behavior, at both aggregate and detailed levels of analysis.
In Section 3, we use our empirical results to define a novel evaluation metric for the efficiency of cell phone menu traversal.
We define a search procedure that generates improvements to a menu hierarchy with respect to a given set of characteristic user profiles.
This article makes several contributions to the HCI literature: a novel and timely study of a very common new HCI task , new models for accurately predicting performance on this task, and a simple, theoretically motivated search procedure that generates menu hierarchies that reduce traversal time in simulation studies by a third, which should be generally applicable to all menu-based systems.
A PERFORMANCE STUDY Our interest is in expert  use of cell phone menu systems.
For control purposes, it was not feasible to collect data from experienced users on their own cell phones, with all the potential differences in hardware and software.
As a compromise, we had users practice a small number of tasks, so that all tasks could be remembered easily, and then carry them out on a single cell phone.
Though restrictive, these conditions give a reasonable starting point for an empirical study and model validation.
We used a Kyocera 2325, as shown in Figure 1.
At the top level of its internal menu, the Kyocera display shows a single selectable icon.
The OK button selects the current item; on the four-way scrolling button, RIGHT and LEFT move through the item list horizontally.
For lower-level menus, three items are displayed at a time, oriented vertically.
Each new menu list is displayed with the top item highlighted.
The OK button, on the left, is used to select the currently highlighted item in these menus, while the CLR button, on the right, returns to the previous level in the hierarchy.
The UP and DOWN regions of the four-way button move through the menu.
Downward scrolling is incremental, with items appearing one at a time at the bottom of the screen.
2.1 Procedures We recruited fourteen experienced cell phone users for our study, students who took part for course credit.
The remaining twelve users, male undergraduates in computer science, provided the main body of data for the study.
All but one used their right hand to hold the cell phone, and all used the thumb of the right hand to press keys.
To collect data, we recorded the tone produced by each key press as transmitted through the earphone jack of the cell phone.
Collection was initiated by the first key pressed by the participant and ended with the last key pressed.
The onset of each key press is detectable by a threshold test on the audio output waveform from the earphone jack, using software we wrote for this purpose.
Each tone lasts approximately 0.095 s, during which time the display changes, before the key is released.
System responses are much faster than key presses and are treated as occurring within elementary key press actions and not contributing to the duration of user actions.
Participants started with a practice stage, in which they familiarized themselves with the cell phone and its menu system.
We gave each participant a paper form describing how five terminal menu items were to be reached, as shown in the first column of Table II.
Each ">" represents a scrolling action, with commas separating consecutive selection actions.
Reaching each of the terminal items  constituted a task in the study.
Participants practiced each task until they could carry it out three times in a row without error.
Each trial in the study required reaching one of the five target terminal items without access to the paper form.
Tasks were presented to participants in a randomized order.
We obtained five correct trials per participant , discarding fewer than 10 trials across all participants, less than 3% of the data.
Table II shows the mean duration per task, over all participants in the study.
User performance is much slower than for single-level menu selection with a mouse on a standard desktop platform , which highlights the importance of specialized models for this task, as we discuss below.
The framework provides a common specification of the Kyocera cell phone, including the sizes and positions of keys and the distances between them, as measured on the physical device.
The framework also supports a common representation of the menu hierarchy shown in Table I.
The models use the same software environment that includes a simulation of the cell phone's interface and produces output in a consistent form.
Our model is based on MacKenzie's  version of Fitts' Law for one-finger typing for text entry on mobile phones.
The value for D in our study was 14.5 mm, which separates the OK button and the DOWN button area, with widths W of 6 mm and 10 mm, as provided by the cell phone specification.
This model, as with the other models described below, makes the simplifying assumption that all scrolling actions can be represented by DOWN key presses, even though the first action is a RIGHT key press, with a slightly different size and distance from the OK button.
To execute the Fitts' law model for each of the five tasks, a path is generated from the root of the menu hierarchy to the terminal item for the task.
Each step on the path is associated with a movement action or a key press action.
Durations for all the steps are accumulated to produce an overall task duration.
In our model, a method is defined for each task in the study.
All of the methods are automatically generated from the menu hierarchy specification, based on the same path traversals used for the Fitts' law model.
Within a method, each step corresponds to the selection of a menu item.
The GOMS method for selecting the terminal item Ringer Volume is shown at the top of Figure 2.
Each of the steps in this method in turn decomposes into a selection method, such as Select Menu or Select Sound, which involves scrolling until a specific item in the sequence is reached--selection in a menu at a single level.
There is one selection method for each menu item, from Select Settings to Select Ringer Volume.
All of the selection methods have the same form, as shown in the example at the bottom of Figure 2.
Specifications of these lower-level methods are created automatically from a generic template.
Performance was altered by no more than a few percentage points.
The qualitative behavior of the models and comparisons between them remain unchanged from their earlier description.
Processing in a selection method involves iterating through a sequence of four exhaustive tests of whether or not the target intermediate or terminal item is currently highlighted and whether the finger is on the appropriate key for selection or scrolling.
The durations of the steps follow the guidelines established by Kieras  in his work on GOMSL and GLEAN3 .
Each test in a decision step requires 0.050 s, plus the time to execute any actions in the body of the decision if the test succeeds.
Steps that involve key presses last 0.280 seconds plus the duration of tests or auxiliary operations .
Movement times are based on the movement component of the Fitts' law model in the previous section.
The model assumes negligible system response time and that there are no verification steps.
Further, the initial visual action to acquire the first menu item occurs before the first key press , and as the highlighted menu item changes no visual re-acquisition is needed during selection or scrolling activity.
Processing is entirely sequential, with no overlapping of steps.
Modeling results, based on the description above, are generated by a GOMS interpreter that we implemented specifically for this project.
While there would have been some benefit to using existing GOMS modeling tools and environments , we judged that the value of a single simulation and modeling framework , for the Fitts' law, GOMS, and ACT-R models, and the phone simulation would provide a worthwhile degree of consistency across our evaluation.
We picked ACT-R as a representative cognitive modeling architecture and as a common choice in HCI work.
ACT-R models simulate the time course and information processing of cognitive mechanisms, such as changes of attention and memory retrievals, as well as external actions, such as movement of the fingers.
Roughly speaking, ACT-R models provide details that can explain behavior in cognitive terms at a level not addressed by the coarser GOMS representation.
In our ACT-R model, a virtual  display maintains a representation of the current items in the cell phone's menu interface hierarchy.
Menu items are presented in a vertical list, and one of the menu items is always highlighted.
All items are presented for each list, independent of the physical display size.
When an item is selected in the virtual display, the list is refreshed with the appropriate submenu.
The model's memory is initialized with a set of declarative memory chunks that represent the parent-child relationships between the intermediate menu items needed to reach terminal items.
For example, for the Ringer Volume task, pairs of declarative memory chunks for the Menu/Settings, Settings/Sounds, and Sounds/Ringer Volume relationships are included.
Chunks representing the parent-child relationships are generated automatically via traversal of the menu hierarchy specification.
ACT-R's model of the hand is initialized with the thumb on the OK button.
Procedural knowledge in the ACT-R model consists of eleven productions: -- Find-top-item searches the visual field for a highlighted menu item immediately after a selection action.
The model starts with the goal of selecting a specific terminal menu item.
The simulation environment shows a single highlighted item.
The model first retrieves a target intermediate item to be selected.
It then searches for the currently highlighted menu item in its field of view.
Once found, the visible item is attended and then encoded, so that its text representation becomes accessible.
If the text matches the target item and this is the same as the terminal item, then the model initiates motor actions to move the thumb to the OK button  and press it.
Model execution completes at this point.
If the text matches the target item but it is not the terminal item, then this means that the currently highlighted item is on the path to the terminal.
The OK button is pressed and another target item is retrieved from memory.
Visual processing repeats as before.
If the text of the highlighted item does not match the target item, then motor actions are initiated to move the thumb to the DOWN button and press it.
Control is transferred to the visual search action, as before.
In the model, manual scrolling actions can trail behind visual processing by an unspecified amount ; the visual and manual modules become synchronized when a new menu is presented.
User errors, such as pressing an incorrect key, are not modeled.
Model execution is deterministic, with no noise parameters used.
Our model is defined in the ACT-R modeling language, but its execution depends on an extension to perceptual-motor processing in the architecture.
In ACT-R, the keyboard is represented as an array of locations.
Neighboring keys are a unit distance apart in a rectilinear arrangement, and each key has unit width and height.
Standard key presses are modeled as finger movements from locations on the home row to the location of a target key.
To handle interaction with a cell phone keypad, more flexibility is needed in models of finger movements and the keyboard.
We extended the ACT-R environment representation to support a layout-based keypad in which the size and placement of keys can be specified individually.
The new representation allows us to build specifications of different cell phone keypads that can be integrated with ACT-R motor processing in a straightforward way.
Fingers are modeled as moving between locations, which, in the case of this experiment, are key locations, but may be arbitrary if needed.
2.3 Model Performance We can describe the performance of the models at two levels: the accuracy with which the models predict the overall duration of tasks, and the accuracy of their predictions of the duration of individual actions.
These two levels are discussed in the sections below.
Other factors commonly explored by modeling, such as learning behavior and the occurrence of errors, are excluded by the design of the experiment.
Table III shows summary model performance and user data broken down by task.
Both the GOMS and ACT-R models give good approximations of user performance.
GOMS predictions are within the 99% confidence interval for mean overall task duration for all target items except View Day.
ACT-R predictions are within this interval for two of the target items.
The Fitts' law model does less well, for reasons that are worth discussing.
Many models of cell phone interaction, such as keypad dialing and one-finger text entry , have been based on Fitts' law, which motivated this aspect of our evaluation.
Our Fitts' law model performs relatively poorly, despite the success of such models elsewhere.
The Fitts' law model produces times that are about half of the observed times.
This is not surprising--much of the activity of this menu selection task is outside the scope of the model.
For some cell phones, text entry is aided by lexicon-based word disambiguation.
While typing, the user ordinarily refers to the display in order to decide whether the system has correctly disambiguated the word being typed.
In text entry, such cognitive processing may not be needed by expert users familiar with the disambiguation system.
In other words, significant visual and cognitive processing is necessary at each step in the process, but this is not captured by the Fitts' law model .
The consistent linearity of user performance across tasks in Figures 3 through 7 suggests a straightforward way to measure the predictive power of the GOMS and ACT-R models through comparison with a least squares linear model.
Because the models' predictions apply to each task, a harsh way to test them is to compare them to a linear regression model fit to data from each task.
Table IV shows the coefficient of determination, R 2 , for these linear models for each button press.
The remaining columns show analogous values for the ACT-R and GOMS models.
Although neither the GOMS nor the ACT-R model accounts for as much variance as a general linear equation, both are close; the comparable values are 0.809 for the GOMS model and 0.796 for the ACT-R model.
The aggregate linear model has appealing conceptual and computational simplicity; we use Eq.
GOMS model, the ACT-R model, and even the Fitts' law model.
First, the latter are a priori models--they were not tuned specifically to the data.
Second, as we discuss later in this section, the models give predictions at a more detailed level than the linear model can provide, including the ability to carry out actions to produce this behavior.
Third, and most important, the GOMS, ACT-R, and Fitts' law models have theoretical underpinnings that give them explanatory power.
In the case of GOMS, performance is explained by the specific tasks that are represented, the hierarchical structure in which they are combined, and dependence on a cognitive processing framework that provides specific timing predictions .
The ACT-R model extends the level of detail in its explanations, in accounting for the interval between actions by explicit visual processing and memory retrievals, and in modeling visual processing and motor actions as proceeding in parallel for scrolling actions but synchronizing with selection actions.
This allows performance on multiple tasks to be based on models of single tasks .
Like all model-generated explanations, these are provisional and subject to further testing.
In particular, the predictiveness of a linear model raises a warning flag: because task-level performance accumulates the durations of actions in sequence, almost any reasonable cumulative function is likely to have the same qualitative shape.
The accuracy of the models over tasks of different durations suggests that the models have some generality, but this is far from conclusive.
If, as with computing, the purpose of modeling is insight rather than numbers , we should look more closely at our results.
Table V shows the predictions of the mean time between user key presses that each model makes over all the menu selection tasks.
There are three different categories: all actions aggregated over all tasks, only selection actions, and only scrolling actions.
The ACTR and GOMS models both provide good predictions at this level, with differences of at most 0.045 s, about 8% error.
The results in Table V are limited in two ways.
First, they distinguish only between classes of actions in the abstract, independent of the task context in which they are executed.
Second, the results neglect the inherent variance in user performance.
Even under identical task conditions, the actions of different users  may have different durations.
We address these two limitations in the remainder of this section.
One way to describe the execution of a menu navigation task is as a simple repeated pattern: each task is carried out through a number of scrolling actions followed by a selection action, repeated until a terminal item is reached.
We define a selection run as a sequence of scrolling actions leading up to a selection action.
As in our per-task analysis, user performance is basically linear for the overall duration of selection runs and is well predicted by both the GOMS and ACT-R models with respect to overall duration.
What is more interesting is differences in duration for actions of the same type.
In selection runs, the first scrolling action after a selection action lasts much longer than subsequent scrolling actions, as shown in Figure 8.
Two factors appear to contribute to the longer duration of the first scrolling action.
One factor is movement time, in that for the first scrolling action, the thumb must move from the OK key to the DOWN button; movement between keys is unnecessary for further scrolling.
The other factor is visual processing: each time that a selection action takes place, a new set of menu items appears on the display and must be read.
All of the models include a movement component and thus reflect the general qualitative pattern, but they vary in how they handle visual processing.
The GOMS model does not include an explicit visual processing step, but each selection entails decision-making tests as well as a call to a new method, adding to the duration of motor movement.
Both models produce slight underpredictions of the duration of the first scrolling action.
A less obvious pattern is also present in Figure 8.
For users, the first scrolling action lasts the longest, the second the shortest, and all succeeding actions in between.
We believe that three factors explain the increase in duration between the second and remaining actions.
The first factor is an environmental constraint on users' visual processing.
Because only three menu items are presented on the display at a time, we can expect the duration of the fourth and succeeding scrolling actions to be slower than the second and third, because the items to be traversed are not immediately available for visual processing.
The second factor is a possible strategy that users took in dealing with menus that are known, via practice, to be long: users may quickly execute several scrolling actions with less attention to the display, until the approximate region of the target item is reached.
The third factor is parallelism in visual processing and motor action.
Related experiments on menu selection with a mouse  suggest that eye movement is not strictly synchronized with motor activity in the discrete menu traversal actions of our domain; this means that the eyes may scan ahead of the items being highlighted by button presses.
The first factor is not reproduced by our simulation environment and the second is not yet included in the model.
The third factor, parallelism in motor and visual behavior, is represented in the ACT-R model.
This parallelism accounts for the increase in duration after the fourth scrolling action, as the duration of motor actions dominates that of visual processing.
The exact point in the user data at which the increase occurs is not captured by any of these models; neither is the remaining variability in the duration of scrolling actions.
Finally, we note that the cognitive and visual processing component of actions in selection runs is much higher than the movement component.
The Fitt's law model provides a baseline for movement-only duration, but underpredicts the duration of user actions by a factor of two to three.
The GOMS and ACT-R models, for reasons discussed above, come much closer to user performance.
Overall, the mean error for mean action duration during all selection runs is about 14% for the GOMS model, 19% for the ACT-R model, and 60% for the Fitts' law model.
Our results so far show that the GOMS and ACT-R models give accurate predictions of the mean duration of user actions, when actions are grouped into classes or, as in the analysis of selection runs, associated with a specific task context.
These predictions, however, give no information about the accuracy of the models for specific instances of actions.
In evaluating model predictions at the action level, the issue of inherent variability in user performance is perhaps the most important.
Two common measures of error that give insight into this issue are root mean squared error  and mean absolute error .
The prediction error for the GOMS and ACT-R models, per action duration, is much higher than for mean duration, about 42% of the mean action duration  for the RMSE measure and 32% for MAE.
The values are similar for the subcategories of scrolling and selection actions.
By these measures, the models are very close in performance, with neither GOMS or ACT-R having an obvious advantage.
While these values of RMSE and MAE are disappointingly high for the GOMS and ACT-R models, it is worth asking how much they might be improved.
As in our task-level analysis, we can define a post hoc model, based on the user data, for comparison with the models we have built.
We begin by observing that the predictions of the models abstract away performance differences between individual users and across trials.
For example, a model will give the same predicted duration for the sixth action in the Ringer Volume task, regardless of which of the twelve users or which of their five trials is involved.
The variance in the 60 data points per unique action, in context, gives rise to the error measured in Table VI.
How well would an optimal model perform?
For a sample of data points, the best estimator with respect to mean squared error is simply the mean of the sample.
The best post hoc model  thus returns the mean duration for each unique action, over users and trials.
The error for this model is shown in the MD  columns of Table VI.
These errors are lower than but still relatively close to those produced by the GOMS and ACT-R models.
As percentages of mean action duration, the models might improve from 42% to 35% with respect to RMSE and from 32% to 26% for MAE.
This comparison suggests that the GOMS and ACT-R models are performing almost as well as is possible in predicting user behavior at the action level, given the variance in the user data.
2.4 Discussion All of the models we have presented have proved robust in our analysis, though at a sufficiently detailed level they break down .
Our results indicate that detailed, rigorous models of low-level interaction with cell phones is possible, and that such models make good predictions.
Aside from the use of this work as a possible exemplar of the application of cognitive modeling techniques to HCI evaluation, we can note a few observations.
Modelers need to consider the trade-off between modeling effort and the value of increasingly veridical results.
For modeling efficiency, a reasonable heuristic is to apply simple formalisms to model simple procedures.
This is especially relevant if the simple formalism can predict all the observable information or all the needed behavior.
All the data we have in this study  can be predicted by both ACT-R and GOMS, though in other situations , GOMS would be at a distinct disadvantage.
Further, GOMS offers considerable flexibility in modeling.
A coarser formalism does not necessarily imply stricter constraints on modeling, which is perhaps an unintuitive observation; rather, the reverse can be the case.
In our GOMS model, for example, the specific ordering of decision steps, as shown in Figure 2, is not governed by cognitive constraints.
A different ordering  would have produced different predictions.
It turns out, in our case, that user behavior is sufficiently regular that the GOMS model we developed for a single user's behavior generalized very well to a larger sample; if this had not been the case, the modeling flexibility we describe would not have been helpful.
Our ACT-R model, for the same task, does not allow such direct fine-tuning to be carried out in the same way, because of tighter architectural constraints on the interactions between visual and motor actions.
The remaining differences between the models' predictions and the data suggest further improvements to the models are possible.
Most importantly, the comparison in Figure 8 shows that only the ACT-R model starts to account for the faster second keystroke, and none of the models predict this  very well.
There are limitations to this work so far, aside from model performance.
For example, many cell phones have additional interaction features, such as shortcut menus and non-linear graphical icon displays, that are not captured by the models we have built.
Further studies, perhaps extending to include novice users, could take error types and error distributions into account, to help extend the range of application of these models.
We believe, nevertheless, that our work lays out clear directions for future research.
One issue we have begun to explore is the performance differences between the GOMS and ACTR models.
As can be seen in the evolution of cognitive modeling architectures such as ACT-R and EPIC , there is considerable overlap in basic assumptions about the way that perceptual-motor constraints should be modeled , and so it is not unreasonable that the models produce similar predictions.
Nevertheless, because ACT-R represents behavior at a greater level of detail than GOMS, the ACT-R model is capable of more detailed performance predictions than the GOMS model.
That GOMS outperforms ACT-R in some areas of our study is disappointing from a cognitive modeling standpoint, but not entirely unexpected, for the reasons described above.
Further, the models were developed independently of each other, and different modeling paradigms and modelers can lead to different opportunities for errors in modeling to occur .
USER PROFILES AND SEARCH Once models of menu traversal have been built, the models can be applied toward improving menu hierarchies so that end users can traverse menus more quickly.
This is a key concern for developers who may be less interested in modeling theory or model development than in the pragmatic issues of increasing usability.
An evaluation of a menu hierarchy independent of usage patterns would be uninformative: different users choose different items, and items are chosen with varying frequency.
In other words, different usage patterns favor different designs.
We define a user profile to be a probability distribution over the set of terminal items in a menu hierarchy that specifies the probability of each terminal being chosen, relative to the entire set.
Each user profile is also associated with the frequency that the menu system is accessed.
For the entire population of users of the menu hierarchy, there may be many different user profiles, some more common than others, a distribution captured by the coverage of individual profiles.
As an example, imagine that 20% of the users of a given cell phone access only two items, Recent Calls and View All Contacts, each on average twice a day.
In the probability distribution of the profile for this set of users, these two items have probability 0.5 and all others have 0.0; the coverage of the profile is 0.20; and its frequency is 4 .
A reasonable evaluation measure for a given menu hierarchy h is its efficiency: the expected cost of reaching a terminal item.
This turns out to be straightforward to represent.
This would mean maintaining a local log of menu selections on individual cell phones, to be uploaded opportunistically to a central repository, or making these local actions visible remotely as they are carried out.
If this is not practical due to storage or bandwidth constraints, an alternative is possible.
The conditional probability p is given by the distribution associated with each user profile as described above.
Values for p can be estimated from the coverage and frequency of a profile at the time the profile is assigned to a user.
In practice, we can imagine individual users being asked questions about their cell phone usage when they are assigned to a specific user profile: how often they will access their cell phone's menu system and the types of functions they expect to use.
The trade-off, compared with direct sampling of p, is between accuracy and resource demands.
All that remains is to define a specific cost function ch , which we can do with our study results.
For pragmatic reasons, we use the easiest metric available to compute cost, the linear regression given in Eq.
The factors that make the linear regression less appropriate for modeling do not apply here.
Our choice for ch means that EC produces the expected duration of choosing an arbitrary terminal menu item in hierarchy h. This measure can be used by an automated search algorithm to identify alternative designs of the menu hierarchy that improve user performance.
A complication is that the automated modification of a menu hierarchy cannot arbitrarily rearrange structure purely for efficiency.
Changes should respect the semantic relationships between the items.
That is, the item Ringer Volume is under the Settings category rather than vice-versa for good reason.
To avoid the difficulties of representing and reasoning about menu item semantics , we rely on two search operators that produce only small changes.
For a terminal item with non-zero probability, these operators can be applied: -- Promote item moves an item to the beginning of its menu list, to reduce scrolling time.
An item or subtree rooted at an ancestor may only be promoted once.
Even with these constraints, the search space size is exponential in the number of target items with non-zero probability in any profile .
Exhaustive search is thus impractical for the phone hierarchy shown in Table I; for just the menu containing 12 items mentioned in Section 1, half a billion permutations are possible.
A best-first search algorithm, however, gives good results after as few as 100 steps.
3.1 Results Ideally, we would be able to validate the search procedure based on real user profiles found in the most commonly used cell phones.
We have been unable to acquire such data, unfortunately.
Lacking real cell phone user profiles, we can only illustrate the search procedure in practice, but our results are promising.
Based on the Kyocera menu hierarchy, we defined random profiles of different sizes, where size refers to the number of non-zero probability menu items contained in the profile.
The probabilities for each profile were drawn from a uniform random distribution and normalized.
Because these profiles were randomly generated, we used only a single profile for the search, rather than composing arbitrary probabilities from different random profiles.
Table VII shows the results for user profiles of size 20, 30, and 40 terminals.
In each case, 10 different random profiles were generated for each size, and a best-first search, bounded at 500 steps, was applied to produce improvements.
The cost values are means of the time estimates produced by the linear model.
The last column gives the time savings in traversing the reordered menus, as a percentage of the duration of the traversals in the original menu hierarchy.
Because these results are based on random probabilities of accessing menu items, rather than actual user experiences, they can only be viewed as suggestive.
Anecdotal evidence from industry contacts indicates that performing usability studies on menu hierarchies is not common practice.
We expect that with improvements in data collection, however, this approach may help to make cell phones more efficient in the future.
Targets for future research include examining the plausibility of a uniform distribution for selectable menu items in user profiles, more efficient search to optimize menu layouts, application to other types of menu layouts, and the inclusion of other factors  in cost computations.
3.2 Discussion We have presented formulas and a search algorithm to show how menu efficiency can be improved by about a third.
The modifications to the menu hierarchy produced by the search have the effect of reducing the depth of the hierarchy and increasing the length of individual menus.
This was a simple change, but clearly one that could be applied to at least one commercially available phone.
It could plausibly be applied to other systems with similar menu structures.
The general approach laid out in this section is related to two areas of HCI other than cognitive modeling, both of which provide opportunities for further research.
The first area is adaptive user interfaces.
The issue of finding the best menu hierarchy for a given user profile is separate from that of deciding when the menu structure should be put in place.
Our discussion in this section assumes that a static hierarchy is associated with each user profile, even if new usage data were to become available over time.
This function should not be performed lightly, but one now quite real possibility is to treat the automated adaptation of the menu hierarchy as a customization option that users can select at their own discretion, whenever they choose.
It should also be possible to incorporate a theory of learning that could predict when to do this and the costs involved in learning the new menu structure.
The second related area is support for navigation.
A menu hierarchy is a small, restricted information space in comparison with other spaces such as the World Wide Web.
The modifications explored by the search procedure are only a small subset of possible transformations that might be applied to an interface.
Nevertheless, some of the same conceptual issues apply to the analysis of navigation in general.
In practice, the most effective approach to navigation redesign addresses the semantics of the information space rather than focusing only on its surface organization and presentation .
For menu hierarchy modification, this implies that greater potential benefits can be gained from examining the semantic relationships between menu categories and menu items than their ordering.
The most relevant research along these lines is Pirolli's work on optimalforaging theory and information scent .
Optimal-foraging theory explains behavior adaptations in terms of resource availability and constraints.
In its application to menu navigation, information scent is a metaphor for visible semantic cues that lead users to information they seek.
Pirolli has developed an extension of ACT-R, called ACT-IF, to evaluate a foraging model of information navigation.
ACT-IF relies on a spreading activation network to capture associations in memory processing.
The models described in our article are based on the assumption that associations between menu items such as Sounds and Ringer Volume can be directly retrieved from memory by an expert user.
A more general model, based on ACT-IF, might be able to explain the strength of these associations, based on measures of semantic distance.
With such flexibility in representation, it would be possible to explore additional modeling issues, such as how novice users might traverse an unfamiliar menu hierarchy, which paths through the hierarchy are more likely to result in errors, and how renaming or recategorizing menu items could influence navigation performance more than just reordering.
CONCLUSION In this article we have described a set of evaluation concepts and tools to support cell phone menu design.
The GOMS model is able to predict user performance very well.
The ACT-R model performs almost as well.
It took more effort to create, but also provide more detailed predictions and could be used for a wider range of analyses.
Although our work has relied on a simpler performance model, both of these models could be used by a simple, efficient algorithm to optimize the redesign of cell phone menus.
This menu redesign approach is simple; we believe it is simple enough to be taught to and used by designers.
This approach is based on knowing users  and knowing their tasks.
In its simplest form, the approach is to reorder the menu items to put the most commonly used tasks earlier and higher in the hierarchy.
Where users' task frequencies are not known or vary widely between users, it appears reasonable to allow the system to reorder itself upon a user's request after a sufficient break-in period.
Of course, the semantics of the task and the semantics of the task titles will have a role to play as well, which we did not explore here.
Others are working with ACT-R to create models that start to take account of this aspect of interaction .
These models and the optimization algorithm bring together several interesting aspects of human behavior and show how a simple AI algorithm can help in HCI design.
It also gives rise to both theoretical and practical implications.
Theoretically, novice user actions, learning, error recovery behavior, performance under stress, and generality across different devices are now areas ripe for further exploration.
Having the models in hand also let us explore and explain new regularities in user behavior, such as the variations in key press time shown in Figure 8.
From a practical standpoint, developers have models that are ready for use-- these models are general enough that they do not require cognitive modeling expertise or programming skill to apply them to different traversal tasks, in different menu hierarchies, or on different cell phones.
We believe that as modeling concepts and techniques become more accessible to HCI developers, they will become increasingly significant in their contribution to improving user interfaces.
Wide application of the menu design approach in this article could, for example, save significant amounts of time.
If 2 billion users were to use their cell phone menus every day for just three seconds, our improvements could save almost 30 years of user time per day.
