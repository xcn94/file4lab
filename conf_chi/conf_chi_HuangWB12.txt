Past studies of user behavior in Web search have correlated eye-gaze and mouse cursor positions, and other lines of research have found cursor interactions to be useful in determining user intent and relevant parts of Web pages.
However, cursor interactions are not all the same; different types of cursor behavior patterns exist, such as reading, hesitating, scrolling and clicking, each of which has a different meaning.
We conduct a search study with 36 subjects and 32 search tasks to determine when gaze and cursor are aligned, and thus when the cursor position is a good proxy for gaze position.
We study the effect of time, behavior patterns, user, and search task on the gaze-cursor alignment, findings which lead us to question the maxim that "gaze is well approximated by cursor."
These lessons inform an experiment in which we predict the gaze position with better accuracy than simply using the cursor position, improving the state-of-the-art technique for approximating visual attention with the cursor.
Our new technique can help make better use of large-scale cursor data in identifying how users examine Web search pages.
But could the mouse cursor be a cheap and scalable alternative to eye-tracking for the same purposes?
If so, cursor tracking systems can be deployed on any website without the need for an eye-tracker.
Most people use a mouse cursor to interact with Web pages; this interaction data can be efficiently collected at scale in a natural setting without disrupting the user .
There are reports that the cursor is a suitable substitute for eyetracking for determining people's attention and examination behavior.
Academic studies  and commercial offerings  have analyzed the cursor in usability settings to learn about engagement on Web pages.
Past research has found a correlation between gaze and cursor positions  and that cursor movements can be useful for determining relevant parts of the Web page with varying degrees of success .
However, cursor interaction spans a variety of behaviors  including reading, hesitating, highlighting, marking, and actions such as scrolling and clicking.
Identifying these behaviors is a prerequisite to understanding what meaning the cursor interactions convey.
In this work, we aim to further quantify the relationship between cursor and gaze.
Prior work has shown that gaze and cursor are correlated but the goal of our work is to determine when gaze and cursor are aligned.
We want to know when the cursor position is a good proxy for gaze position and the effect of various factors such as time, user, cursor behavior patterns, and search task on the gaze-cursor alignment.
Through this, our research will contribute to knowledge of how people use their cursor and how they examine Web search pages.
The lessons from this analysis also inform an experiment in which we predict the gaze position with better accuracy than simply using the corresponding cursor position.
In addition to the cursor position, we also use dwell time1 , temporal features relating to cursor behavior, and future cursor positions to determine the current gaze position.
The findings from this work can be applied to many practical situations.
Predicting gaze will improve state-of-the-art techniques for approximating visual attention with the mouse cursor.
Billions of people navigate the Web as part of their daily lives by looking, finding, reading, pointing, and clicking.
Because the flow of using a site is such a fundamental experience for so many people, usability professionals and site designers seek to optimize the experience by analyzing which parts of the page grab a visitor's attention, and what information people read on the page.
To achieve this, they conduct laboratory studies using eye-tracking equipment to track users' gaze while they navigate the site.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Our findings will inform these and other applications that remotely collect large amounts of cursor data at scale by showing how to more effectively use this data.
More broadly, our work supports collecting user attention data in situations where eye-tracking equipment is costly, such as for large numbers of Web users.
One particular domain that may benefit from this research is Web search, in which searcher examination behavior represented by probabilistic models  may be improved by uncovering the latent variables representing which search results the users examine.
We study the gaze-cursor alignment of 36 subjects and 32 search tasks with an eye-tracker in a controlled lab setting.
The findings show that while subjects vary their gaze-cursor alignment substantially, they lag their cursor behind their gaze by at least 250 ms and on average by 700 ms.
Both dwell time and the user's personal style affect the distance between the cursor and gaze positions.
This distance is longer when the cursor is inactive, shorter when the cursor is used to help examine or read the page, and even shorter when the user is performing an action.
Finally, we predict the gaze position using cursor features and achieve 23.5% more accuracy than simply using the corresponding cursor position alone.
In the search domain, Guo and Agichtein  captured mouse movements using a modified browser toolbar and found differences in cursor travel distances between informational and navigational queries.
Furthermore, a decision tree could classify the query type using cursor movements more accurately than using clicks.
Guo and Agichtein also used interactions such as cursor movement, hovers, and scrolling to accurately infer search intent and interest in search results .
They focused on automatically identifying a searcher's research or purchase intent based on features of the interaction.
They found that scrolling behavior in connection with information on the browser's viewport could be as effective as gaze tracking feedback in search scenarios comprising query expansion.
By applying a reading detection method, Buscher et al.
Two lines of research relate to this work.
One focuses on inferring user interest and intentions directly from the user's interactions with a SERP or a Web page, specifically based on cursor movements, clicks, and gaze.
The second explores the relationship between cursor position and gaze position in order to infer users' visual attention from cursor movements.
In early work, Goecks and Shavlik modified a Web browser to record themselves browsing hundreds of Web pages .
They found that a neural network could predict variables such as the amount of cursor activity on the SERP, which they considered surrogate measurements of user interest.
They found that cursor travel time was a positive indicator of a Web page's relevance, but could only differentiate highly irrelevant Web pages.
They also found that the number of mouse clicks on a page did not correlate with its relevance, despite the intuition that clicks represent links that users found appealing.
Hijikata  used client-side logging to monitor five subjects browsing a total of 120 Web pages.
They recorded actions such as text tracing and link pointing using the cursor.
The findings showed that these behaviors were good indicators for interesting regions of the Web page, around 1.5 times more effective than rudimentary term matching between the query and regions of the page.
They found that the ratio of mouse movement to reading time was a better indicator of page quality than cursor travel distance and overall length of time that users spent on a page.
Another line of research examines the relationship between eye gaze and cursor positions.
An early study by Chen et al.
They showed that the distance between gaze and cursor was markedly smaller in regions of encountered pages to which users attended.
Liu and Chung  recorded cursor activity from 28 students browsing the Web and noticed patterns of viewing behaviors, including reading by tracing text with the cursor.
Their algorithms were capable of predicting users' cursor behaviors with 79% accuracy.
They found that gaze and cursor positions were better correlated when the cursor was in motion and in sessions comprising a higher proportion of motion.
Other work has focused on the relationship between cursor and gaze in search tasks.
In a study involving 32 subjects performing 16 search tasks each , Rodden et al.
They found that the distance between cursor and gaze positions was larger along the x-axis than the y-axis, and was generally shorter when the cursor was placed over the search results.
Guo and Agichtein  reported similar findings in a smaller study with ten subjects performing 20 search tasks each.
Like Rodden et al., Guo and Agichtein observed that distances along the x-axis tended to be larger than the distances along the y-axis.
They could predict with 77% accuracy when gaze and cursor were strongly aligned using cursor features.
The research presented in this paper extends previous work in several ways.
The focus of previous work was in examining the relationship of cursor and gaze position by measuring the distance between them.
The conclusions were that a strong correlation existed between them, however there was little further differentiation of alignment along a temporal dimension and no differentiation by cursor behavior patterns.
Here we look at the degree of alignment at different points in time, quantitatively analyzing behaviors made using the cursor, and we are predicting the gaze position using a variety of cursor behavior and time features.
In addition, our analysis of the gaze-cursor relationship involves a larger number search tasks and subjects than prior studies, giving us more leverage in feature comparisons.
We used a Tobii x50 eye tracker with 50 Hz tracking frequency and an accuracy of 0.5 visual angle  on a 1280 x 1024 resolution 17 inch monitor  and 1040 x 996 resolution Web browser.
Cursor and gaze coordinates were collected in an eye-tracking study with 38 subjects , recruited from a user study pool.
They ranged in age between 26 and 60 years , and possessed a wide variety of backgrounds and professions.
Two subjects had incomplete data due to technical issues and were dropped from the analysis.
We prepared a set of 32 Web search tasks  which each subject completed on the Bing search engine in a randomized order.
Half of the tasks were navigational  and half were informational .
Each task started with a description of what subjects should look for on the Web.
The browser cache and cookies were cleared after each subject to prevent subjects from noticing previously viewed pages  and search engine personalization effects.
Going through an eye tracker calibration phase in the beginning, completing all 32 search tasks, as well as filling in a demographics questionnaire in the end took about one hour per subject.
Gaze and cursor positions were recorded for each SERP as well as subsequent Web pages .
In total, we collected data for 1,210 search tasks, which included 1,336,647 gaze positions, and 87,227 cursor positions .
Additional details about the experimental procedure are described in Buscher et al.
Gaze-specific findings on this data set, unrelated to cursor features, have been reported elsewhere .
Other studies measuring gaze-cursor alignment  have presented evidence of alignment with charts nearly identical to Figure 1.
In the search logs, the gaze positions were recorded approximately every 20 ms, whereas cursor positions were recorded approximately every 100 ms. Gaze positions are estimated by the eye-tracker and given the saccades  of the eye, recording at a higher frequency can give more accurate positions; but the cursor position is an exact value and recording at 10 Hz is sufficient--the cursor is not radically changing directions at sub-second speeds such that we cannot interpolate them.
We had tested different frequencies of interpolation and found negligible differences.
Since cursor and gaze events did not necessarily have identical timestamps, a gaze position was interpolated for every cursor position.
Interpolation was performed by computing gaze x and y coordinates weighted by the coordinates of the nearest gaze coordinates before and after the cursor position.
The interpolated y -coordinate was computed the same way, substituting x for y in the above equation.
To reduce interpolation inaccuracies due to noise from the eye-tracker, cursor positions were only captured if they occurred between gaze positions that were at most 100 ms apart.
To begin our analysis, we view gaze-cursor alignment through the lens of time, user, and search task.
Different people behave differently on the Web in the queries they issue , how they gaze at the page , and how they interact with the page .
The amount of time spent reviewing the search results page can affect where they are pointing and where they are looking.
Additionally, we investigate the possibility that gaze and cursor may not be most aligned at each instance in time, but may be better aligned when one variable is temporally shifted.
The average gaze-cursor distance for each search task with error bars representing the standard error.
The variance between search tasks is modest .
Queries are sorted by ascending click entropy so queries with more diverse result clicks are on the right; five queries with unknown entropy are on the left .
People visually examine Web pages differently , and have individual styles in their control of the cursor.
Past findings have shown that users behave differently depending on search tasks .
Guo and Agichtein analyzed gaze-cursor alignment  on a smaller subject pool and found differences in user  and search task type .
Here we explore whether search task or individual differences  have a stronger effect on alignment.
Larger variances in alignment would indicate that a search system might have difficulty predicting alignment for users or queries that have not occurred before.
To study alignment differences among subjects, we macroaveraged the gaze-cursor distance across their queries .
The results in Figure 2 show that subjects are fairly distinct in terms of gaze-cursor alignment.
Some keep their cursor within about 130 px of their gaze, while others average about 280 px.
The standard deviation representing the variation among subjects is SD = 33.9.
We checked for gender differences in gazecursor distance using a two-tailed t-test and found no statistically significant effect  = 1.31, p = 0.20.
There was a Spearman correlation of  = 0.22 between age and gazecursor alignment, but this was also not statistically significant .
Therefore, we conclude that whether the subject tracks their gaze closely with their cursor is more likely to stem from personal habits rather than age or gender.
Next we look at the average differences in gaze-cursor alignment for different search tasks.
Since the subjects were given predefined queries to begin with, we filtered out reformulated queries since they may be reflective of personal style or individual search skills.
A search task is therefore represented by a single query in this analysis.
The search task averages are shown in Figure 3, which reveals that there are modest differences between tasks.
The alignment distance ranges from about 150 px to about 220 px, and the standard deviation among search tasks is SD = 20.2.
To gain some insight into the attributes of the search tasks, we computed the click entropy for each query, a measure of result click diversity .
The click entropy is computed as the Shannon entropy of the click distribution on the search result links.
This was done to look for correlation between click entropy and gaze-cursor alignment; we thought it was possible that gaze and cursor would align differently depending on query type.
We used the past year's search logs of the Bing search engine to find the click distributions.
Five queries had not appeared in the search logs in the past year and thus had unknown entropy.
From the remaining queries, we found no Spearman correlation between click entropy and gazecursor alignment .
This contrasts findings from Guo and Agichtein's study  which found alignment differences between navigational and informational queries.
The standard deviation in gaze-cursor alignment across means for different subjects is higher than across means for different search tasks.
A Levene's test for homogeneity of variance shows that the differences in variance are statistically significant .
This suggests that users have individual preferences and that these differences are stronger than the differences between search tasks.
We experimented with not normalizing the data when computing the mean averages , but the differences in standard deviation between search task and subject were similar.
Users examine the SERP in a sequence of evolving behaviors.
A user may possess the habit of quickly scanning the page first to see what kinds of items are on the page, then skimming it quickly to see if there is an answer to their information need while neglecting the cursor, then finally reading the text wordby-word.
As the time spent dwelling on the SERP increases, the alignment between gaze and cursor may change due to the dynamism of the behaviors.
Averaging gaze and cursor distances for different dwell times, Figure 4 shows the relationship between gaze and cursor over time for the first five seconds following the pageload.
Indeed, the time since the page has loaded has an effect on alignment.
Specifically, the alignment distance ranges from 170 px to almost 240 px.
Right when the page loads, gaze and cursor are closely aligned, perhaps from the previous action that led to the page.
The peak at 240 px is within one second of the page loading, suggesting that the subject may first scan the displayed page without moving their cursor.
The gaze-cursor alignment narrows after about two seconds when the subject may start to examine the page more closely and perhaps prepare to click a link.
While the subject's actions at this stage change from query-to-query, the aggregate alignments provide clues of typical examination behavior.
This behavior led us to ask--given that we see the eye moving within a second of the page loading, does the cursor move as quickly?
The last hypothesis is consistent with findings from early work by Ware and Mikaelian  that showed that the eye fixation was a faster method for target selection than the mouse.
While target selection is not the objective of this study, the difference between eye and mouse speed may cause the cursor to lag behind the gaze.
We used a technique similar to cross-correlation in signal processing that computes when two waveforms are most aligned .
The root-mean-square error for gaze and cursor distance at different intervals  of gaze-cursor lag, representing how well gaze positions correlate with future and past cursor positions.
The thick solid line plots the RMSE macro-averaged over subjects, and thin dashed lines plot the RMSE for three example subjects.
This equalized the periods between positional data points, computing the cursor positions at different time shifts  after each gaze position.
Then we computed the root mean square error  between gaze and cursor3 for each shifted time interval for each subject.
The cursor and gaze positions are considered most correlated at the time shift with the lowest RMSE.
Figure 5 shows the macro-averaged RMSE values across subjects compared with three example subjects.
The first thing to note is that for the macro-averaged values, shifting the cursor positions 700 ms into the future minimizes the RMSE.
This means mouse cursor lags behind eye gaze by about 700 ms, so the user looks at something and then  later their cursor is moved to that location on the page.
Temporal alignments vary depending on the user and query session; the per-subject RMSE values showed that different people had different delays in moving their cursor to their gaze.
In the same manner, the cursor lagged behind the gaze for each individual subject; the inverse situation--gaze lagging behind the cursor--did not occur, refuting the hypothesis that some people lead with the cursor when examining the page.
Still, some subjects were quick, moving their cursor to their gaze in 350 ms , while others took over one second.
Several studies have reported different behavioral patterns when using the cursor.
Mueller and Lockerd found users hesitating before clicking and resting the cursor on white space .
Our taxonomy of cursor behavior resembles that reported by Claypool et al.
Each of the previously mentioned studies discusses the cursor behavior qualitatively and most do not have corresponding gaze data.
Our study involved more subjects and search tasks than the largest prior study, facilitating a quantitative analysis of the cursor behaviors.
Informed by prior work and our own qualitative observations of user interactions with the SERP, we separated cursor behaviors into four categories: Inactive cursors are not moving and are ignored by the user for some time.
Reading cursors are used to follow the text while the user is reading the page.
Action cursors are used when the user is about to perform an action .
Examining cursors move around while the user is examining the page, not including time spent in `reading' or `action'.
The remaining interactions, in which the cursor was neither inactive nor reading nor performing an action, were labeled as `examining'.
We therefore arrived at five cursor behavioral patterns  as behaviors that warranted further analysis.
We studied gaze-cursor alignment in these behaviors next.
For each of the five cursor behaviors, we computed the distance between gaze and cursor.
Table 1 summarizes the proportion of time spent in each cursor behavior and the corresponding median distance between gaze and cursor.
As expected, gaze and cursor are further apart when the cursor is inactive, since the eye is still roaming the SERP--233 px.
Alignment is much closer when the cursor is being actively used to examine, read, or perform an action.
The median distance when examining the page using the cursor is 167 px, while the alignment is closer when using the cursor to read-- 150 px.
When the subject is moving the cursor to perform an action involving a click, alignment is extremely close--77 px, and even closer at the actual click--74 px.
This agrees with findings from Hauger et al.
We use a heuristic-based method to classify the different cursor behaviors.
This method entails iteratively examining replays of the recorded interaction behaviors, deciding which behaviors belong to each category, classifying the behaviors using simple rules, and finally comparing the classified behaviors with the judged behaviors.
The process is ad-hoc to develop a simple classification scheme that captures the essence of each behavior type.
We developed classification rules informed by watching replays of the interaction in a query session.
The cursor is considered inactive if the user leaves it in one location  while they examine the page.
We define `inactive' as the cursor staying still for at least one full second.
The behaviors occurring when the cursor's position is active can be classified in three ways.
However, the cursor also serves the purpose of interacting with elements of the page or with the Web browser, typically by clicking on controls on the browser or Web page.
We classify these `action' behaviors as those occurring in the one second preceding a click.
The remaining interactions were classified as either examining or reading.
The movement to the right was not enough to classify as reading, since the cursor may be moved to the right for many reasons.
During the study, the cursor was inactive a total of 18,554 seconds , representing time the subject may have been looking through the page without moving the mouse or just pausing for a few moments to read or think.
This is more than the combined time of examining, reading, and performing an action on the page, meaning that a substantial period exists in which it is difficult to predict the gaze position.
Anecdotally, some people believe they rarely use the cursor while examining Web pages.
But in aggregate, a large portion of time is still spent actively moving the cursor, most of which does not produce an action.
We quantified individual differences in gaze-cursor alignment and cursor behavior; Table 2 presents the duration of each cursor behavior and gaze-cursor alignment for each subject.
The distances were macro-averaged over search tasks for each subject to negate the effect of a subject spending more time on certain search tasks.
Leaving the cursor idle from 50% to 79% of the time was common, like Subject 29 who left the cursor inactive during the majority of the time.
Reading behavior comprised 2% or less of total search time for more than half the subjects , who exhibited nearly no reading behavior .
At the other end of the spectrum, Subject 9 spent 8% of their time reading with the cursor.
Turning to gaze-cursor distance, some subjects had poor alignment  when not performing an action.
While in the aggregate, subjects had stronger alignment when the cursor was active, Subject 18 had essentially unchanged alignment between inactive, examining, and reading behaviors.
These differences show that individuals vary substantially in their cursor behavior usage and gaze-cursor alignment.
We initially thought that perhaps the variation in users' gaze-cursor alignment could be explained by choice of cursor behavior, but for each cursor behavior, gaze-cursor alignment still varied substantially among our subjects.
To do this, we extract four types of features from the interaction data, aiming to select features that seemed to influence the gaze-cursor alignment, as informed by our earlier analysis.
At each time t that we want to predict the gaze position, we have the cursor position at that time, represented by a tuple .
The cursor position alone is suggested for approximating gaze position in some prior literature and current Web analytics services.
This approach is the baseline against which we will compare our performance, but we also use cursor position as a feature in our gaze prediction model.
Cursor behavior has a strong effect on gaze-cursor alignment.
Both our earlier analysis and a study by Hauger et al.
To generalize this, we use the idle time following the last movement before t as the behavior feature, representing activity level.
Each recorded interaction on the Web page has a corresponding timestamp, allowing us to deduce the length of time since the SERP has loaded.
Our analysis has shown that the time since the SERP loaded influences the gaze-cursor alignment.
So far, we have seen the effects of user, query, dwell time, cursor behavior, and future cursor positions on gaze-cursor alignment.
These features can provide guidance about whether the alignment is stronger or weaker.
Predicting the strength of alignment is useful in determining the confidence of the gaze position from only interaction features--without using an eye-tracker.
We now focus on a more aggressive predic-
Guo and Agichtein also use this feature to predict gaze-cursor alignment .
Our analysis showed that for every subject in our study, the cursor position lagged behind the gaze position, since there is a stronger correlation between a future cursor position and the current gaze position.
We refer to the most likely later cursor position for the current gaze as the future feature.
The future cursor positions were only used if the last movement was within 10 seconds of the target future time.
We also used the interaction effect of cursor position with dwell and cursor position with behavior, since we know that behavior and dwell affect alignment.
The user or query were not treated as features for two reasons.
First, in practical situations, a user's gaze data is not available to train the model.
Second, there is unlikely to be enough gaze data for most queries to train the model, and in our analysis described earlier in the paper, we found that query only has a modest effect on gaze-cursor alignment.
Our current features are all global and so require fewer training examples in the form of eyetracking data .
The cursor position , the gaze position predicted by the linear regression model , and the gaze position as determined by the eye-tracker  are drawn over the SERP presented to the subject following the query "rent a stretch limo hummer" from our study.
The figure omits the right and left columns of the SERP.
We predict the subject's gaze position using a linear model of interaction features.
The ground truth is the gaze position measured by the eye-tracking system.
The x- and ycoordinates of the gaze position were predicted separately.
To compute the weights  for each feature, we performed a multiple linear regression.
Figure 6 illustrates the value of gaze prediction in an example query session with cursor positions, gaze positions, and predicted gaze positions overlaid on the SERP.
The model for the regression for the x-coordinate is:
The regression for the y -coordinate was similar, but substituting x for y in Equation 2.
The evaluation was a 36-fold cross-validation, where each fold was an individual subject; this is essentially a leaveone-out evaluation for each subject.
By testing each subject separately with the training data of all 35 other subjects, we achieve a practical method of predicting the gaze position for users that we have not seen before .
Essentially, we ran a multiple linear regression on the gaze and interaction data of 35 subjects to compute weights , then used those coefficients to predict gaze data from just the interaction data for the test subject.
This process was repeated for every subject being the test subject.
For each subject we tested, we computed the RMSE for their predicted gaze with and without the future feature, as well as the RMSE for just the cursor positions.
Without using the future feature, there is a potential application for real-time gaze prediction, while with future cursor positions, the gaze prediction must be performed offline .
Table 3 shows the results of the prediction experiment.
When using only the cursor position for prediction, the distance RMSE is 236.6 px.
But using a multiple linear regression with cursor position, behavior, and dwell time, the predicted gaze position is significantly better--186.3 px, a 21.3% decrease in RMSE.
Adding future cursor data from that query session to the model reduces RMSE further to an overall 23.5% decrease in RMSE compared to just using the cursor position.
The RMSEs in the x- and y-coordinates alone were similarly improved by the linear model.
The Lindeman, Merenda and Gold  metric   determined the relative importance of the features for predicting the x-coordinate.
They were in descending order of importance: log, cx , fx , cx x log, log, and cx x log; the relative importance of the features for predicting the y-coordinate in descending order: cy , fy , log, log, cy x log, and cy x log.
The computed accuracies in cross-validation evaluations of estimating the gaze position using the cursor position, the cursor position along with behavior and duration using multiple linear regression, and the cursor position along with behavior, duration, and future cursor positions using multiple linear regression.
The accuracy is measured by root-mean-square error for the x-axis, y-axis, and Euclidean distance.
Our study has shown that gaze-cursor alignment is situational, as it depends on the time spent on the page, personal browsing habits, and a user's current cursor behavior .
An experiment showed that a model using these features could predict the subject's gaze significantly better than using the cursor position alone.
These findings have implications for using large-scale cursor data more effectively, which has already been demonstrated to be efficiently obtainable at scale .
Our findings suggest that for certain circumstances, it may be possible to predict the actual gaze position on SERPs using only cursor features.
This extends previous work  which attempted the binary prediction task of whether we can be confident of gaze-cursor alignment within a threshold.
Using a linear model, we show that there is room for improving gaze prediction by using other factors on top of solely the cursor position.
Our predictive model reduces the RMSE by 60 px in the x-direction and is 15 px more accurate in the y-direction.
15 px is around two lines of text on a SERP, and 60 px is around 10 characters of that text.
These gains could be significant for differentiating between engagement with regions on the SERP, especially when the cursor is near the boundary of two or more regions.
However, since the linear regression fits using least squares, the predicted gaze tends to be conservative and often stays around the center of the screen.
This leads us to believe that gaze prediction may be improved further by a more complex combination of the features, perhaps in non-linear models, since we intuit that interaction effects of time, behavior, and cursor position exist.
The gaze prediction results in Table 3 suggest a counterintuitive finding.
While several past studies  agree that the cursor is better correlated with the gaze in the ydirection than the x-direction, the x-coordinate of the gaze is easier to predict than the y-coordinate.
This subverts the expectation that better correlation leads to better prediction for gaze.
This may be an artifact of our model, but perhaps leftright eye movement is less surprising than up-down movement.
Scrolling may cause the cursor to move down relative to the page, making it a good estimate of vertical attention, whereas most SERPs require little horizontal scrolling.
Cursor tracking, deemed the "poor man's eye tracker" , may approximate gaze tracking without the eye tracker depending on the accuracy required.
Although cursor features would allow us to model many aspects of user attention in situ as they browse the Web from home, they cannot completely replace gaze.
For example, eye-gaze fixation is a positive signal of interest because the user pays more attention to that position, but prolonged cursor fixation may not be since given our findings in this study, the user's attention is probably elsewhere.
Here we elected to focus on understanding different cursor behaviors rather than gaze fixations to support cursortracking applications that can be remotely deployed on a Web site.
More work is needed to study in more detail the relationship between cursor and gaze fixations, especially to determine if and when there are cases in which cursor fixations can be reliably interpreted as attention.
Bringing subjects into an eye-tracking lab creates inherent limitations to our study.
Subjects may behave differently in the lab with a camera monitoring their gaze than in a natural setting.
They are unlikely to take breaks in the lab or multitask by doing other things at the same time, factors which may affect cursor behavior outside of the lab.
We also gave them artificial search tasks; while we tried to ground the search tasks in realistic information needs, the tasks might not be a representative sample.
Additionally, though SERPs provide a controlled environment for our studies , more work is also needed to generalize this research beyond SERPs to any Web page.
Previous work has already shown that cursor is less aligned with gaze on non-SERP pages , so the prediction task on such pages may be more challenging and is reserved for future work.
The results show that we predicted gaze more accurately when we used past and future cursor movement data, rather than only past data.
Using past data alone would allow us to build applications that could respond to user attention in realtime, such as a focus-plus-context view of the SERP, in which the context could update dynamically with new content based on where the user had already attended during their engagement with the SERP.
More valuable however, is inferring gaze positions after the user has left the SERP.
This would allow us to accurately model where on the SERP the user examined and use this data for applications such as building richer searcher models , usability assessments , or profiling users .
We have found that user, time, and search task  each contribute to the variation in gaze-cursor alignment.
The gaze and cursor positions are also better aligned when the gaze position is compared to a future cursor position.
Furthermore, by distinguishing between five different cursor behaviors--inactive, examining, reading, action, and click--we get a better idea of the strength of alignment.
In fact, we have been able to improve upon using cursor position alone to predict the gaze position by using several cursor features.
Cursor movements, scrolling, and other client-side interactions are easy to collect at scale, which many Web analytics services offer to do.
But claiming that the cursor approximates the gaze is misguided--as we have shown, this is often not the case depending on time and behavior.
Instead, it is important to predict the real location of the attention when an eye-tracker is unavailable.
Arroyo, E., Selker, T., and Wei, W. Usability tool for analysis of web designs using mouse tracks.
Knowing the user's every move: user activity tracking for website usability evaluation and implicit interaction.
