A common effect of aging is decline in spatial cognition.
This is an issue for all elders, but particularly for elder drivers.
To address this driving issue, we propose a novel concept of an in-vehicle navigation display system that displays navigation information directly onto the vehicle's windshield, superimposing it on the driver's view of the actual road.
An evaluation of our simulated version of this display shows that it results in a significant reduction in navigation errors and distraction-related measures compared to a typical in-car navigation display for elder drivers.
These results help us understand how context-sensitive information and a simulated augmented reality representation can be combined to minimize the cognitive load in translating between virtual/ information spaces and the real world.
There is consistent evidence that spatial cognition ability declines with increasing age.
Particularly, older adults have more difficulty in cognitive mapping, the ability to accurately represent a spatial environment mentally, and way finding, the ability to navigate efficiently in an environment.
For example, it has been found that older adults have difficulty in understanding and using `you-arehere' maps .
Fortunately, these driving-related issues can be lessened by applying situational awareness and providing navigation guidance that can support decision making of drivers.
For example, with a GPS-based navigation system, drivers can more easily access and act on current and future driving information  and be more confident in turning onto the correct road in intersections or complicated forked roads.
At the same time, however, providing such in-vehicle information does not only add to task complexity but it also creates issues with divided attention in having to focus on both the information display and the road, and extra cognitive load in matching the computer-generated streets on the GPS system to the real streets in the 3-dimensional perspective that drivers have.
Even putting aside their unfamiliarity in operating such systems, this added mental effort is a more problematic barrier to overcome for elder drivers than for younger drivers.
Not surprisingly, technologies such as GPS systems are often considered to be too difficult to use to be a useful driving aid for elder drivers , despite their seeming promise to support the mobility of elders.
To overcome these problems with existing GPS systems, we propose a concept of windshield-based 2.5-dimensional in-vehicle navigation display system .
As our society is aging, the number of elder drivers  is rapidly growing.
These individuals' quality of life is acutely linked with their ability to maintain independence in mobility .
While there is a decrease in the number of work and business-related trips they take, daily trips for shopping and multipurpose trips for various social activities increase with age .
Nevertheless, they may be forced to abandon these trips and have a reduced sense of independent mobility due to decreased cognitive ability and difficulty in interacting with navigation devices  that could potentially help address declines in driving ability.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
As the effort required for either of these components grows, the overall cognitive distance grows.
Furthermore, if users are required to switch between these two spaces frequently, the impact of the cognitive distance can be even greater.
This is particularly true for people who either have a cognitive difficulty, or are completing a task that is time-sensitive or has a high cognitive load associated with it, and certainly applies to elder drivers who may be suffering from age-related cognitive decline.
The results of an evaluation of a simulation of our novel windshield-based display compared to the typical display of a personal navigation device with 24 subjects  and 12 younger drivers demonstrated that our display induces less divided attention and fewer navigation and driving errors.
While these results hold for younger and elder drivers, they are especially true for elder drivers.
In addition, elder drivers prefer our display over traditional in-vehicle navigation systems  and find it more intuitive .
This paper is structured as follows: we begin with a discussion of divided attention and cognitive load and how augmented reality can be used to address these for drivers.
We review related research on augmented reality-based invehicle information displays and then present a detailed description of our proposed windshield-based navigation display.
We then describe the virtual test-bed we developed for our user study, comparing our novel display to a conventional in-vehicle navigation device.
We present our results that demonstrate our display's ability to improve driving performance for elder drivers and reduce divided attention issues for elder and younger drivers.
We end with a discussion of our results and plans for future work.
Divided attention is the ability to respond simultaneously to multiple tasks or multiple task demands and is regarded as the highest level of attention .
The greater the cognitive distance, the harder it is to have divided attention across information and physical spaces.
When users are unable to maintain divided attention, this is often referred to as the split-attention effect , and often occurs when the same modality is being used  by both the information and physical spaces.
This suggests two important design issues: the types of information in the information space and the manner of presenting the information are important for reducing cognitive distance.
The former can help users feel that they are not working on multiple tasks, but are working on one, focused task, making it easier to move between spaces and apply information.
The latter can also help users in moving between spaces, and can help users to locate information in the virtual space.
There have been a number of driving-related studies that have examined the issue of divided attention from this information presentation perspective.
One such study had younger and older drivers use a virtual driving simulator to drive a particular route while performing a secondary task: reading a series of four-digit numbers either superimposed on the windshield or displayed to the lower right of the driver on a portable display .
Older drivers performed much better in terms of controlling their vehicle and accuracy in reading the numbers with the windshield-based display.
The problem with the portable display is that it caused drivers to switch their attention from the road to the display.
As the task difficulty increased, the difference in performance between younger and older drivers also increased.
A subsequent study with subjects with traumatic brain injury and healthy individuals used the same basic experimental setup and method, but varied the time between the presentations of numbers and varied the location of the numbers on the windshield .
Both factors impacted performance on the primary and secondary tasks.
From this we infer that cognitive load increases with variable workloads, which could result from many issues including timeliness of information, and that cognitive load increases when information is presented poorly and without context, either with respect to the presentation location or the content.
Research on cognitive load from the aviation domain reinforces these lessons .
Technology is giving us the ability to present information anywhere and anytime.
Despite this ability, there is often a large gap or distance between physical spaces  and virtual information spaces.
Depending on the relevance of the information being provided, the method of conveying information, and the user circumstances, this distance may be small or large.
With a large gap, a user may take more time and may have to expend more cognitive effort to adjust from one space to another.
We refer to this gap as the cognitive distance between computing and physical spaces.
There are two distinct components that comprise cognitive distance.
The first is the cognitive effort required to move one's attention from the physical space to the information space, and to locate the appropriate information within the information space.
However, this can be reduced by selecting an appropriate manner for presenting information, and by presenting information that is context-sensitive and relevant to a user's primary task.
We can apply these results to our problem: reducing the impact of divided attention and reducing cognitive load for elder drivers who have difficulty using navigation aids and may suffer from cognitive decline.
We will now discuss how these results relate to the two components of cognitive distance.
Presenting information where users are already focusing their attention will reduce the effort required to shift attention from the physical space to the information space.
Contextually presenting information and focusing on presenting only task-relevant information will make it easier to locate and extract appropriate information in the information space.
Again presentation location can greatly impact the effort required to move back to the physical space.
Finally, by presenting only task-relevant information, it will be easier for users to apply the information in the physical world.
An interesting approach to presenting current location information is to use a trolley-cable-like line that appears as if suspended over the road .
While this supports simple and intuitive route guidance, it does not support global awareness .
AR-based visualization has also been employed for the purposes of supporting navigation and perception in the cases of hidden exits or roundabouts , and for parking assistance and tourist guides .
From a review of the literature on in-vehicle AR-based display systems, we note that two significant informational aspects, global awareness and local guidance, are necessary for an effective navigation aid.
As referred to in , global awareness pertains to knowledge regarding the route to the destination, and local guidance is related to the tasks that involve controlling the vehicle and knowledge about the surrounding environmental situation.
A large number of applications have focused on supporting local guidance using AR, particularly in driving situations such as lowvisibility, upcoming dangers or visually-occluded roads.
Most AR-based display systems, however, have focused on providing global awareness, mostly through use of a bird's eye view perspective.
Very few systems attempt to incorporate both global awareness and local guidance.
We now combine our understanding of cognitive distance and related work in augmented reality displays to describe our novel AR-based display for addressing cognitive distance.
Recently, car manufacturers have been pointing to Augmented Reality  as the next-generation visualization technology for in-car driving displays.
It provides the necessary technology for displaying information where users' attention is focused in the car.
Researchers have investigated the concept of projecting navigation instructions onto a video image of a road to make it easier for the driver to orient himself in complex traffic situations .
Others have shown that it is useful to have two views of the environment, an egocentric user view of the environment and an exocentric view of the whole 3D environment like an overview map ; further, cues for orientation and motion used in the real world will also be of great help for navigation.
To this date, the focus on automotive HUD -based AR visualization has been on technical challenges related to the compatibility of AR processing modules or producing reasonable image quality.
Current commercial automotive HUD platforms mainly employ small displays so as not to interfere with drivers' abilities to drive safely.
Academics have investigated and evaluated a number of AR-based visualization concepts using mobile platforms or projector-based driving simulators .
One AR system combined GPS/inertial measurements with real-time road video footage to display highlighted road boundaries and surrounding vehicles in low-visibility conditions .
A number of solutions to solving the camera registration problem  have been built , making it simpler to build such AR-based systems.
Other research has compared two information presentation approaches for focusing a driver's attention in difficult driving situations: a bird's eye view and an AR-based 3D arrow .
Our navigation display has been designed with the ultimate goal of minimizing a driver's cognitive load and issues of divided attention induced in attending to both the real driving space and the virtual space of a GPS-based map visualization.
Accordingly, we have mainly focused on two specific issues in our work.
The first issue is how to improve a driver's ability to cognitively synchronize the dynamic images from driving and from a secondary display that are moving in two different coordinate systems with potentially different orientations and scales.
The second is how to reduce issues of divided attention caused by the visual and spatial separation between the view of the actual road through the windshield and the secondary navigation display.
While both issues impact all drivers, they certainly place an additional burden on elder drivers.
In our work, we assume that the technical challenges necessary for displaying images on an entire windshield and accurately registering these images to features of the road will be addressed in the near future by other researchers.
This is not an unreasonable assumption since, as described in the previous section, researchers have had successes in tracking the road and projecting upon it in real-time  and auto manufacturers see whole windshield displays as the future of in-vehicle displays .
By synchronizing this movement with the current car movement, we expect the driver to experience a seamless transformation of the display and its information into the real road.
Further, this display should not only help elder drivers achieve an intuitive awareness of road network information near their location, but also has the potential to be useful for displaying contextual or local guidance information about the driver's location .
Our windshield-based display uses the same scale and orientation as the real streets viewed through the windshield.
The map visualization also adapts to the current car position, allowing the local road network to be contained in the driver's view.
This supports drivers in interpreting both the real and virtual spatial context in a single view.
As a result, we expect our display to induce a lower cognitive workload and fewer issues of divided attention than current navigation displays.
An important measure of cognitive workload is driving performance.
As cognitive load increases, driving performance often decreases correspondingly.
So, for the validation of our display, we form three hypotheses with respect to two metrics: driving performance and distraction due to divided attention.
Regardless of a driver's age group, her primary task, driving, should not be impeded by other secondary tasks ; that is, the display systems should not generate any excessive distraction while supporting enhanced navigation.
While we expect the simulated AR windshield display to be effective in aiding elder drivers' navigation abilities, highly-visualized in-vehicle information media may cause unexpected driver distraction.
In actuality, both display types have different features that may lead to potential distraction.
In typical in-car navigation devices, frequent separation of attention from the real driving view  is required for a driver.
On the other hand, in our simulated AR windshield display, the computergenerated images dynamically superimposed on real driving view portion  can attenuate the driver's attention in concentrating on traffic situations.
We implemented a driving simulator, using OpenGL, to conduct our experiment, due to the safety issues of conducting an experiment in live traffic environments as well as the technical challenges of implementing a full windshield-based high resolution HUD platform in a car.
Geospatial information from Google Maps is graphically rendered in this simulator on a 26-inch widescreen LCD HDTV  for both Pittsburgh and Chicago.
Subjects navigate through the simulated cities using a wheel joystick and two foot pedals .
Each driver participates in 4 different driving task conditions: AR-based windshield display  for Chicago and Pittsburgh and regular GPS-based display  for Chicago and Pittsburgh, in a counterbalanced order based on the Latin square method.
For each task, a highlighted route that is 3.36 km long is displayed using either the ARD or the RD.
Subjects are expected to refer to it as they navigate from the starting position to their destination, typically as they navigate through intersections.
They need to obey traffic signals and common driving rules .
Each presented route includes 12 intersections: 4 right turns, 4 left turns and 4 to go straight through.
In the case of missed turns, a U-turn needs to be made to get back on the route again.
In addition, during each driving condition, they will encounter 12 signal lights, 3 stop signs, 5 pedestrians  crossing the road from right to left and 5 other pedestrians  which they are expected to avoid.
The driving input from the wheel joystick and foot pedals provided by each subject is automatically recorded for later analysis of driving performance, our proxy for realtime cognitive load.
In particular, our measures are task completion time, number of missed turns, number of interactions with pedestrians, and the number of signal light/stop sign violations.
To assess whether drivers have issues with divided attention, we track their eye gaze to see where they are looking.
We employ the Smart Eye Pro 4.5 contactless gaze tracker to observe where subjects have been looking  while driving .
Gaze distance and speed are measures of how noisy the eye gaze movement is, and can indicate the degree of divided attention.
While conducting our experiments, we observed drivers stopping the car the re-orient themselves, particularly after making a driving mistake .
Therefore, we report these gaze measures both over the total driving task time and when the driver is in motion.
A post-questionnaire and interview is used to get a qualitative understanding of users' feelings about both displays and how the displays impacted their driving.
Before discussing our results, we will first describe some of the limitations of our experimental setup.
First, our current focus is on the user interface concept rather than on how it can be applied in a real optical-see-through windshield display for a final product.
In this first study of our novel display, the test-bed has been implemented as a `simulated' AR windshield display prototype; therefore, its simulated visuals would differ from those seen in a real car, from a cockpit-based platform or from a system that used videos rather than graphics.
However, prior studies reporting a relationship between divided attention and driving were mostly based on correlation analysis between psychometric tests and behind-the-wheel driving observations rather than a direct examination of driving behaviors.
As a result, our current experimentation was framed on an alreadydemonstrated basis that using graphical simulations can manipulate divided attention tasks, and allows actual driving measures such as speed and lane deviation to be used.
Our approach allows for an objective and direct evaluation of the relationship between cognitive impairment  and functional performance , as addressed in  and , which also used driving simulators.
The distance subjects sat from the display meant that the eye gaze space was smaller than in a real driving situation, but this does not impact the comparison of the two displays, although it tends to reduce overall eye gaze movements.
Changing the location of the RD to just above the dashboard, another common mounting location, would likely positively impact the driving performance and divided attention of our subjects.
Similarly, increasing the number of traffic incidents would likely negatively impact these factors, as it would be more difficult for subjects to distinguish between the traffic incidents and the actual road.
Next, in order to better understand the impact of displays on divided attention, we examined several aspects of our subjects' eye gaze movements.
However, truly measuring divided attention is quite challenging.
For example, we tried to define a `secondary display zone' to designate the zone where a driver's mental focus is not on the road.
Accordingly, we defined the upper boundary of the `secondary display zone' much lower than the top of the windshield.
However, it was not lowered up to the horizon because, in our pilot studies, drivers often glance at simulation elements such as signal lights and pedestrians in the area between current upper boundary and the horizon.
In an ideal case, we would be able to determine the factor that caused the driver to focus on a particular part of the display, particularly where the simulation elements and the map are semi-transparently overlapped.
We did try to divide the space into a larger number of sub-zones; however this was still insufficient to confirm that a driver's mental focus was taken off the road and the primary driving task.
As a practical approach, other physiological measures like heart rate or pupil diameter variability can be employed; however, at this stage of our research, we chose not to use intrusive sensing to avoid imposing fatigue or discomfort on our elderly subjects.
In the end, we defined the `secondary display zone' as shown in Figure 4.
We present the results of our experiment by comparing the driving performance and gaze movement results for our different age groups, different display modes, and the interactions between these two factors.
We have conducted a two-way ANOVA for repeated measures  and then conducted the post-hoc contrast tests.
Note that `city' was not considered as a separate variable in our analysis because all traffic- & street- related configurations were the same for both cities.
We used multiple cities to avoid our subjects being too familiarized with the streets.
An analysis using `city' as a factor revealed no impact.
Our first hypothesis was that elder drivers  will have worse driving performance and exhibit more signs of divided attention than younger drivers , when driving with either in-car navigation display.
As expected, there were significant differences between the two age groups for most of our measures related to driving performance and gaze results .
There were no significant differences in the number of traffic signal and stop sign violations, nor in eye gaze movement speed.
Based on these results, we can say that the hypothesis 1 is supported.
We recruited 24 subjects for our experiment.
At the beginning of each experimental condition, all of our subjects received the exact same pre-written textual instruction.
Other than a gaze calibration step at the beginning of the experiment and the questionnaire at the end, there was minimal, if any, experimenter interaction with the subjects.
13 of our subjects were female and 11 were male, with the gender distribution being almost equal for the different age groups.
Our second hypothesis is that using the ARD will result in better driving performance  and fewer issues with divided attention .
Our ARD, the windshield-based display, did result in better driving performance and fewer issues with divided attention across most measures when compared to the RD, the typical GPS-based navigation display .
However, drivers have lower performance for traffic signals and stop signs when using the ARD, although the difference is not significant =1.71, p<0.195.
These results demonstrate that the ARD generally results in better driving performance while causing less distraction.
However, our primary display zone includes areas above the road .
Gazes in the primary display zone might not necessarily be related to the primary driving task when using the ARD; that is, despite having fewer issues with eye gaze focus in our secondary display zone, the ARD might attenuate the driver's attention when trying to concentrate on traffic situations .
Our subjects did not mention this during the exit interviews, and the ARD still resulted in better driving performance results.
We conclude that hypothesis 2 is supported.
Our last hypothesis is that elder drivers using the ARD will have better driving performance and fewer issues with divided attention, than when using the RD.
In other words, we are looking at the question of whether changing the representation of navigation information has positive effects on the people who feel increased mental workload while driving, by aiding navigation without increasing distraction.
In this comparative analysis, we conducted post-hoc contrasts following up our two-way ANOVA results with respect to four subgroups categorized according to age group and display mode: younger group and elder group x ARD and RD.
Among the four subgroups, younger drivers using the ARD had the best results across most of our measures, while elder drivers using the RD had the worst .
For younger drivers, there was no driving performance related differences between the two displays.
However, when using the ARD, there was significantly less impact of divided attention for all of our gaze-related measures.
That is, for younger participants, the ARD mainly exerted an effect on distraction reduction, and not on navigation performance improvement.
On our scale, `1' corresponds to the RD being much better and `5' correspond to the ARD being much better.
The first two questions, Q1 and Q2, are related to two fundamental elements of effective navigation aid.
For the local guidance , more than 70% of our subjects preferred the ARD to the RD with a rating average of 3.96.
66.7% of the elder drivers rated the ARD as a `much better' display.
For the global awareness , 58.3% in each age group  rated the ARD as a `much better' display.
Older participants felt more comfortable navigating when using our display, especially in the aspect of local guidance.
Next, Q3 and Q4 relate to being responsive to traffic events.
Most of the older participants had `no preference' for these aspects , while the younger participants slightly preferred the RD .
However, 33.3% of elder participants thought the ARD was a `much better' display for supporting less distractive driving in responding to pedestrians.
These results correspond with the performance results on pedestrian- and traffic signal-related measures .
Q5 relates to a driver's increased awareness of his/her location and navigation information.
58.3% of older participants and 41.7% of younger participants rated the ARD as a `much better' display.
Lastly, each subject was asked to specify an overall preference from the two displays.
70.8% and 79.2% of all participants selected ARD as their preferred navigation display to use and as being more intuitive, respectively .
Participant responses from the post-questionnaire reflect the results of the quantitative analysis.
Another subject spoke to herself about the next action she should take at each intersection.
She even acted out using an invisible turn signal indicator.
A real physical lever along with a virtual light on the dashboard could have helped her in remembering what actions to take, rather than holding this information internally.
On a related note, many of our participants wanted the ARD to more visibly indicate the next action they had to take  and the current state of upcoming traffic signals.
Older drivers also requested a pedestrian warning system and larger street signs that were more legible.
These requests all point to additional information that could be visualized through our ARD, and changes that could be made to our experimental simulator setup.
In a post-task interview, we asked subjects to comment on the relative merits and issues with the displays they used.
We also asked them for opinions on what improvements could be made to the displays.
The results of our interviews reflect our quantitative and questionnaire-based results.
Elder drivers, in particular, expressed appreciation for our augmented reality windshield-based display.
Several commented that when we first demonstrated how to use the two displays, they thought the more conventional navigation display would be better to use.
They had seen this type of display in their children's cars and it looked familiar to them even though they had little or no experience with it.
However, as they used the RD, they realized that they had to look away from the street to view the display, on a frequent basis and this was distracting.
They liked the fact that the ARD allowed them to look at both the navigation display and the street at the same time and that they were arranged appropriately from a spatial perspective.
Elder drivers mentioned that this made it easier to notice pedestrians crossing the street.
However, they also commented that if a navigation aid obstructed their ability drive safely even a little bit, they would be unlikely to use it.
On a related issue, our subjects liked being able to effectively turn off the RD by not looking at it, when the demands of the driving task were high.
The ability to selectively turn on and off the ARD was a feature our subjects said they wanted.
Our subjects had difficulty, at times, in understanding the ARD visualization.
All of the ARD visuals are superimposed on top of the real street scene .
This caused some drivers to misinterpret the depth of the added visualization.
For example, the ARD visualization shows all upcoming intersections and side roads vertically up the windshield , which means that upcoming side roads are superimposed on top of buildings and the street.
This gave the impression that all the side roads will actually appear before the driver reaches a building.
Because of this, when the visualization indicated an upcoming turn, some drivers made errors and turned at an earlier intersection than the one they were supposed to turn at.
Other drivers commented that when the visualization indicated that they go straight , they thought that meant they could continue to go straight, regardless of the state of the traffic lights.
Other subjects commented on the desire for additional situational information in the visualization.
One younger female participant said she forgot to make some turns: if there was a red light at the intersection where she should make a turn, she waited there and then went straight when the light turned green.
Our driving simulator did not provide a physical turn indicator or a visualization that the driver intended to turn , which could have been used to remind her of the turn.
In this study, we have proposed a novel windshield-based 2.5-dimensional in-vehicle navigation display system to aid driver's in reducing issues of divided attention from having to switch between navigation system and the real road view, and reducing cognitive load from having to cognitively map computer-generated map information of the navigation system onto a driver's real road view.
In an evaluation of simulations of this display and a typical GPS navigation display, 24 subjects, 12 elder and 12 younger drivers, participated in a virtual driving experiment.
Our results show that the drivers using our display system have significantly fewer navigation errors and divided attentionrelated issues when compared to using the regular display.
Most importantly, we have demonstrated both quantitatively and qualitatively that these results hold for elder drivers who are more likely to have difficulty in cognitive mapping and way finding.
In this work, we have mainly focused on validating the effectiveness of our novel display system compared to an existing navigation display.
In our future work, we would like to make the improvements noted in our evaluation, and explore more focused design guidelines for supporting older people's navigation preferences and perceptual abilities.
We would like to explore variations in our experimental setup, including increased traffic to create more realistic driving situations making it more difficult to differentiate between the visualization and traffic, variable location of the incar navigation display, and using physiological sensors to determine cognitive load.
To enhance driver's situational knowledge, we would like to understand the impact of adding information about real-time traffic  can be presented with local area information  on the road network image in our system.
Additionally, considering other divided attention factors in vehicles, we will consider how to use our display to represent information typically displayed on dashboards or reflected on side/rear mirrors.
Finally, we will incorporate our display system into a full windshield-based optical see-through HUD platform donated by General Motors, for real testing in a vehicle.
A car-navigation system based on augmented reality.
Seeing the Road Ahead: GPSAugmented Reality Aids Drivers.
The Future of Navigation: Siemens VDO Automotive works on Augmented Reality, Int'l Electronics Conf.
In Transportation in an Aging Society: A Decade of Experience.
PhD thesis, Technische Universitat Munchen , Informatics and Computational Science.
Effective Control of a Car Driver's Attention for Visual and Acoustic Guidance towards the Direction of Imminent Dangers.
University of Michigan Transportation Research Institute.
The assessment of older drivers capabilities: A review of the literature.
Interim report for the GM/US DOT project entitled: Improvement of Older Driver Safety through Self-Evaluation, Report No.
Human Navigation Performance Using 6 Degree of Freedom Dynamic Viewpoint Tethering in Virtual Environments.
PhD thesis, University of Toronto, Mechanical and Industrial Engineering.
Cognitive issues in virtual reality.
In Virtual Environments and Advanced interface Design, W. Barfield and T. A. Furness, Eds.
Engineering Psychology and Human Performance.
Upper Saddle River, NJ: Prentice-Hall Inc., Chapter 3.
