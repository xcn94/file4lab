We present the results of a controlled experiment to investigate the performance of different temporal glyph designs in a small multiple setting.
Analyzing many time series at once is a common yet difficult task in many domains, for example in network monitoring.
Several visualization techniques have, thus, been proposed in the literature.
Among these, iconic displays or glyphs are an appropriate choice because of their expressiveness and effective use of screen space.
Our results show that depending on tasks and data density, the chosen glyphs performed differently.
Line Glyphs are generally a good choice for peak and trend detection tasks but radial encodings are more effective for reading values at specific temporal locations.
From our qualitative analysis we also contribute implications for designing temporal glyphs for small multiple settings.
For data analysis in such a scenario, glyphs  are an appropriate choice to consider for visually encoding and presenting temporal data.
Their advantage lies in their compact way to use screen real estate and the possibility to use them in a small multiple setting.
In such a setting, glyphs can enable quick visual comparison of the development of data values over time.
However, glyphs come with a trade-off between resolution and increased data density for each time series.
They usually do not include axes for reading exact values since they are primarily designed to show multiple attributes in a compact way .
A notable example of such a technique is the well-known sparklines technique .
Yet, due to glyphs' power in presenting multiple time series for comparison, a multitude of designs have been proposed.
When confronted with the task of choosing an appropriate glyph design, a visualization designer or practitioner currently has little guidance on which encodings would be most appropriate for which tasks and on which visual features and factors influence people's perception of data encoded in glyphs.
While one could follow Cleveland and McGill's ranking of elementary perceptual tasks  and try to predict the performance of glyphs based on these results, it is not clear whether their results will hold.
Temporal glyphs include dual encodings, are used in specific temporal analysis tasks, and come in many different sizes and densities.
In order to address this lack of guidance on the use of temporal glyphs, we ran a controlled experiment to compare four carefully selected glyphs using two different data densities.
These four glyphs were chosen for their use of different combinations of visual variables to encode temporal position and quantitative value of a data point.
We evaluated all glyph designs in a small multiple setting as small multiple is the most common usage scenario for temporal glyphs.
To our knowledge no other evaluation has been conducted to compare the performance of time series glyphs for small multiple settings based on their data encodings.
In particular, we contribute: * results comparing the task-dependent performance of four glyph designs under two data densities, * plausible explanations for the observed performance patterns and resulting implications for design, * a first investigating into the broader issue of how glyphs perform and what factors influence their performance.
Time series data is the basis for decision making in many different application domains--such as finance, network security, or traffic management--and, thus, constitutes an important area of research for visualization and data analysis.
We collaborated, for example, with network security analysts from a large university computer center who need to make decisions based on the amount of daily network traffic for single hosts over time.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Willam Playfair , for example, used line charts to visualize exports, imports, expenditures or prices and their development over time.
Even today these line charts are among the most popular time series visualization techniques and their details are actively discussed in the visualization community, as for example the arc length-based aspect ratio selection .
Besides line charts, common techniques for visualizing time series are pixel visualizations  and glyph visualizations .
Furthermore, properties either inherent or assigned to time have resulted in the development of a number of specialized methods.
Periodic patterns can, for example, be visualized with the Concentric Circles Technique  or Spirals ; likewise several calendar visualizations have been proposed  to cope with the irregularities of our Gregorian calendar.
Properties assigned to time series often result in multi-dimensional data sets, which can for example be analyzed with axes-based visualizations with radial layouts .
Different visual variables can be used to encode these two attributes.
In Table 1 we show some meaningful combinations of visual variables taken from Cleveland and McGill  for quantitative data and how they form different glyphs.
Ward  describes several categories of glyphs.
To narrow down the design space for our experiment we only discuss temporal glyphs with many-to-one mappings where several or all data attributes map to a common type of graphical attribute.
This is important in order not to promote certain temporal dimensions and to enable easier intra-record and interrecord comparison, which is fundamental for many tasks involving time series, including the ones chosen for our experiment.
While many more different glyph types exist, such as face glyphs, arrows/weathervanes, box glyphs, sticks and trees etc., we focus on two main types of glyphs here: profiles and stars .
Both types have the advantage that relationships between adjacent data points are easier to see than for other glyphs .
While it is theoretically possible to encode temporal position using other visual variables such as length, direction, area, volume, curvature, or shading, no glyph design using these encodings has established itself in practice and is, thus, part of our study.
Time series comparison is the area most related to our work.
Some studies have already been conducted on the evaluation of multiple timeline representations  or the comparison of different value ranges for line charts .
Alternative techniques for displaying many time series at once are CloudLines  or Horizon Graphs .
More application driven visualizations, such as systems monitoring , project management , health , news  and geographic analysis  make use of various dedicated representation techniques.
Temporal glyphs, the subject of our experiment, are often used in small multiple settings for comparing many different time series at once.
Their layout on the plane varies to add additional information like the geographic context on top of a map , the ranking in a scatterplot, or a hierarchical data organization .
Pearlman and Rheingans use stacked circular glyphs in a graph layout to monitor network traffic over time and visualize the connections .
Circular glyphs positioned in a matrix for monitoring the daily traffic of many network devices were also mentioned by Kintzel et al.
These circular representations are similar to the ones used in our experiment.
Krasser, however, uses a parallel coordinates plot in combination with glyphs to investigate connections, type of network traffic and the timely sequence .
Many glyphs build patterns of different colored stripes over time.
We chose the Line Glyph , Stripe Glyph , Clock Glyph , and the Star Glyph  for their different characteristics and to assess their performance in a small multiple setting.
LIN was chosen as one of the best ranked and most commonly used glyphs in our space and STR for its similar temporal but different value encoding.
Glyphs are often designed to encode intuitive pairings of data to visual variables  and, thus, we chose two circular designs that take people's potentially intuitive notion of time encoded in a clock-like fashion into account.
We chose to test STA for its similar value encoding to LIN and CLO for its similar value encoding to STR.
The Dot Plot was excluded as in our experience the single dots became too small, making it nearly impossible to spot them.
Partial overview of the design space for temporal glyphs.
Other combinations are certainly possible.
Position CS = position along a common scale, Position NAS = position along non-aligned scale.
Glyph designs written with bold characters are the ones used in our experiment.
Therefore, we cannot safely test, which visual variable affects the perception of the data value.
When comparing glyphs visually, the distance between the representations matters.
We chose to keep the distance for the different designs identical and, therefore, to have the same uniform small multiple layout.
As a consequence it was important to set a fixed aspect ratio for each glyph.
To maximize display space for circular glyphs for a fairer comparison we chose a square aspect ratio for each glyph.
For the color encoded glyphs  we chose a heatmap colorscale, which was motivated by the yellow to red colorscale from ColorBrewer .
This scale takes advantage of the fact that the human visual system has maximum sensitivity to luminance changes for the orange-yellow hue  and it is also suitable for color blind people.
For each trial, the same type of glyph--but showing different data--was drawn on the screen in a small multiple layout of 8 x 6 = 48 glyphs in total .
Each glyph was drawn at a resolution of 96 x 96 pixel.
Our three tasks were: Task 1--Peak Detection: Amongst all small multiple glyphs, participants had to select the glyph that contained the highest data value .
This task, thus, involved scanning all glyphs for its highest value and comparing across glyphs using length  or saturation  judgements.
Task 2--Temporal Location: Among all small multiples, participants were asked to select the glyph with the highest value at a predefined time-point.
This task, thus, involved first identifying the location of a timepoint by making positional  or angular judgements  and then comparing the peaks as in Task 1.
Task 3--Trend Detection: Among all small multiples, participants had to select the glyph with the highest value decrease over the whole displayed time period .
This task, thus, involved first detecting all decreasing trends and then comparing the first and the last value.
Many different tasks exist that can be performed on timeoriented data .
We chose our tasks taking two criteria into account:  their ecological validity, i. e. how commonly they are performed in environments where the quick comparison of multiple time series is needed.
In terms of ecological validity our tasks were inspired by our work with network security analysts from a large university computer center who had to monitor large amounts of network devices.
In order to test the scalability of each glyph in terms of the number of datapoints it can encode, we tested two data densities.
The smaller density consisted of 24 data values , and the larger of 96 data values .
The rendered size of the glyphs holding these data points was not varied between each density .
Trend detection: The four glyphs demonstrate different kinds of trends.
From left to right:  visualizes a positive trend;  contains a positive and negative value development but for the whole displayed time interval there is no clear trend visible;  picture a negative trend over the whole displayed time period with  having the higher decrease.
The glyph with the highest decrease over the whole displayed time period is artificially highlighted.
H1: For tasks involving primarily a value judgement LIN & STA  are more accurate and efficient than CLO & STR .
This effect is strongest for LIN.
This hypothesis is based on Cleveland and McGill's experiments  on the perception of position, length, and color.
We expect the results to hold for both data densities.
Color perception may change drastically with varying context colors and size of the object being viewed .
We expect color perception to be more impacted than visual acuity on dense line and position encodings.
H3: When detecting temporal positions, STA & CLO 
This effect is stronger for CLO than STA as the clock shape is more clearly retained.
H4: When detecting temporal positions, increasing data density will negatively impact performance with each glyph..
This is because color judgements are impacted by the size of the object being viewed  and angular as well as positional judgements by visual acuity.
We expect CLO & STA to perform best as they spread out values towards the circumference of the circle giving additional space for perceiving color and position.
H5: For trend detection, LIN & STA 
We expect the first sub-task to be performed equally well with all glyphs but expect that the comparison of distances between two data values is more difficult with color compared to position/length.
H6: For trend detection tasks, the participants' performance for each design is not influenced by data density.
For detecting a trend comparing the overall shape rather than single data values is necessary.
We expect that increasing the data density will not influence the trend shape and, thus, has no effect on task performance.
We recruited 24 participants  mainly from the local student population.
All participants had normal or corrected-to-normal vision and did not report color blindness.
Each participant had at least finished high school, eight held a Bachelor's, two a Master's degree, and one a Ph.
D. The academic background of the participants was quite diverse with no one having a computer science background.
34% of the participants reported to use the computer for more than 30 hours per week and 50% less than 20 hours.
The experiment took place in a quiet closed room at our university.
In addition to the study participant, the experimenter was the only person present.
The participant sat in front of a table at a distance of approx.
Participants interacted with the study software using only a mouse.
The experimenter began by explaining the data, the single task, and the design of the different glyphs.
The data was presented as financial stock data to provide context.
Only when the participant was familiar with the current glyph design and task, he/she was allowed to proceed.
For each glyph and density tested, the participant stepped through four practice trials followed by the four actual study trials.
After each trial, the participant entered a confidence score for their answer on a 5-step Likert scale.
The task question was visible on the screen at all times.
The presentation order of each glyph was randomized in a Latin square fashion between participants.
The glyphs were presented in a 6x8 matrix layout .
Each participant saw the same glyphs per trial in different random configurations.
We used a mixed repeated-measures design with the betweensubjects variable task and the within-subjects independent variables glyph and data density.
The dependent variables were error, time and confidence.
Each participant conducted one task with all four glyphs, two densities, and four trial repetitions.
To control the data values and their resulting visual representations, we created synthetic data for the experiment.
In total, we created 48 data instances  for each repetition, task, and data density.
The data was created such that just one glyph represented the correct answer.
The glyphs with smaller density held 24, the ones with large density 96 data values.
In previous pilot experiments these two values were established as being sufficiently different from one another.
Data for each task was created as follows: Task 1: Each glyph was filled with random noise to a threshold of 80% of its value range according to our experience from pilot studies.
For the target glyph a peak value at 100% of the value range was added to the dataset at a random point in time.
Task 2: Each glyph was filled with random noise as in Task 1.
A peak value at 100% of the value range was added to the target glyph at a predefined point in time.
For the distractor glyphs, peak values of the same value were integrated but at wrong temporal positions.
Task 3: We designed different decreasing trends by varying the values of the first  and last data point .
The target trend decreased 75% of the value range from first to last data value while the distractor glyphs included a decrease of 55%.
Task completion time, error rate, and confidence score were recorded for the analysis.
We used a repeated-measures ANOVA for the analysis of completion time.
Time in our experiment was log-transformed where it did not follow a normal distribution.
For the error rate as well as for the confidence score, a non-parametric Friedman's test was used.
Except for the second task we did not observe a strong learning effect between trials.
Therefore, we analyzed all four trials for the first and third task, glyph and dataset for each participant.
For the second task we analyzed the results of the last three trials.
In addition, single answers were marked as outliers when each metric  was beyond two standard deviations from the mean for a given task and glyph per participant.
The tasks used in the study differed in their characteristics, so we analyzed the results of each task and dataset independently.
Finally, we analyzed the feedback and subjective preference from the post-session interview for a qualitative analysis.
Task 2 consisted of four training repetitions and four real trials for both densities.
After the initial training trials we asked participants to detect a different temporal location for the peak value.
Therefore, the first real trial was discarded due to the mental recalibration necessary by the participants.
In this section we combine both quantitative and qualitative data collected in our study to explain the varying performance of the different glyph designs according to our hypotheses.
An overview of the quantitative results for each task is given in Table 2 where values highlighted in orange signify the best result compared to the other designs.
The confidence score of the participants for this task was unambiguous with LIN having the highest ratings.
In the final interview the participants had to rank the different glyph designs according to their subjective preference.
LIN was the most preferred glyph type which matches the performance results of the quantitative analysis.
In the post-session interview, some participants argued that color was better than position/length for data value comparison especially when the distance between the values was very large.
Of course, this depends on the color scale used, but seems plausible when the color value is entirely different, which may lead to a preattentive recognition effect.
With smaller distances most of the participants commented that they would prefer the position/length encoding.
When explaining their performance with STA , participants argued that they had problems comparing lengths with different orientation which further supports our hypothesis that mental rotations may be necessary for comparison and make values harder to compare in these glyphs.
Especially in a small multiple setting this is an interesting finding and has to be further tested and considered when arranging glyphs.
In H1 we conjectured that LIN & STA would outperform CLO & STR due to their position and length encodings for value.
The analysis of error, however, revealed that nearly no mistakes were made with LIN and only few with STR and that STA had the lowest accuracy followed by CLO.
Apparently, the participants had more problems reading value with the circular layouts.
This becomes obvious by comparing the most with the least accurate glyph design .
Both use the same value encoding but differ in the layout of the time dimension.
This effect did not change across the two density conditions.
STA and STR had a similarly high error rate across densities, CLO deteriorated only slightly, whereas LIN still performed best.
We can, thus, only partially confirm H1.
We conclude that polar coordinates must have an effect on error for value judgements when the value is encoded with length.
The same effect seems not to take place when the value is encoded with color.
This can perhaps be explained by the different baselines of the designs.
Comparing position/length in a radial design perhaps involves mental rotation to transfer the overall design to a comparable linear layout.
This is not true for color encodings, since color does not need an identical baseline.
Another notable effect is the one between CLO and STR: while accuracy was not significantly different for low data density, CLO outperformed STR with high data density.
This suggests that CLO is more resilient with respect to data density than STR.
We believe this to be due to the fact that the slices in the circular design get more space near the circumference, wheras the slices in the stripe get too small, making the comparison more difficult.
This only partially confirms H2: while STR is strongly affected by data density, LIN and CLO are either not affected by data density or affected to a smaller extent .
Our results partially support H3.
In terms of accuracy both polar designs  outperformed the linear designs when data density was low.
To find an explanation for this result, we looked at the selections made by our participants and discovered an interesting side effect.
The data sets corresponding to these wrongly answered questions were enriched with distractors very similar to the correct data instances by showing the same high value but at a different point in time.
Participants seemed less likely to select such distractors when using the circular layouts for the time dimension.
Participants were significantly more confident and made significantly less mistakes with the polar designs.
The participants also reported to like the clock metaphor.
Some suggested, however, to visualize only 12 hours at a time for a more intuitive encoding.
When data density was high we observed the same trend, even though only STA showed significant differences with respect to STR and LIN.
The good performance of STA can be explained with the combination of the encodings.
The length encoding for the data values makes it possible to easily spot the highest value even with lots of datapoints.
With the color encodings, participants had problems spotting the peak value.
The circular layout performed better than the linear one and worked for estimating the correct point in time.
We saw almost no significant differences between the designs for efficiency .
Nonetheless, we observed that the overall trend for efficiency did not contradict the trend we found in terms of accuracy.
A significant decrease in performance between the two data densities can only be seen for accuracy.
All designs had an increased error rate except for LIN.
However, LIN's accuracy had been very low for the low density, thus, a significant de-
In terms of efficiency only CLO has a higher completion time, whereas, the other designs remained stable.
These investigations partially support our hypothesis H4 where we had conjectured that the performance for detecting temporal positions would drop for an increased data density.
This guideline results from the analysis of the second task.
Participants performed significantly better using CLO and STA compared to LIN and STR.
The clock metaphor increases users' chronological orientation.
This is independent from the combination of visual variables used as can be seen for task 2  and 3 .
The designs performing best for these tasks are encoded differently but still show the same behavior.
In H5 we had conjectured that LIN & STA would be most effective for this task with the required value judgement as the bottleneck of the two required subtasks.
As we expected, in terms of accuracy, the participants performed best using LIN independent from the data density.
There was no significant difference between STA, CLO and STR on error and no significant results for time and, thus, H5 can only be partially confirmed.
Independent from the designs, the participants needed around 30 seconds to complete the task.
With an increased data density the accuracy of LIN, CLO and STR dropped significantly.
The completion time remained stable with no changes between the two density conditions.
Our hypothesis H6 stating that the performance will not change by increasing the data density can, therefore, not be confirmed.
Interestingly, participants commented that subjectively the task difficulty was not impacted by higher data density.
The qualitative feedback almost matched the quantitative results.
Nearly all participants reported to prefer LIN  for solving the task.
As stated at the beginning, we were inspired by time series data for a daily monitoring task.
Especially CLO and STA with their 24 hour clock metaphor profit from this data arrangement.
The performance may change with different lengths of time series.
The same is true for the aspect ratio and the size of the single glyphs.
The aspect ratio was chosen in order not to greatly disadvantage the circular designs in terms of display space used.
However, especially STR would profit from an aspect ratio with more horizontal space.
With varying sizes of glyphs, the performance of the designs could change.
In our setting we used the minimal space possible to be able to assign one pixel to one data value for the higher data density.
With the results gained from the analysis and discussions we derive the following design considerations.
The polar design has a strong effect on the perception of the position/length encoding.
Even with an increased data density values could still be compared.
As can be seen in the results for CLO compared to STR, having more space near the circumference increased participants' performance.
Designers could experiment with adding triangular shapes in a linear encoding.
Having a higher data density leads to a decreased performance.
In this paper, we conducted a controlled experiment with 24 participants to assess the performance of time series visualizations when shrinking their size to glyph representations.
In particular, we quantitatively measured accuracy and efficiency, and qualitatively surveyed user confidence and preferences for four glyph types based on three tasks important to our domain experts: peak detection, peak detection at a certain point in time, and trend detection.
The four glyphs: Line Glyph, Stripe Glyph, Clock Glyph and Star Glyph were chosen for their varying use of visual variables to encode temporal position and the quantitative value of a data value.
The results show that depending on tasks and data density, the chosen glyphs performed differently.
We show that the Line Glyph is generally a good choice for peak and trend detection tasks but that radial encodings of time  were more effective when one had to find a particular temporal location.
Participants' subjective preferences support these findings.
Thus, our study shows that both accuracy and efficiency of tasks such as ours can be boosted when carefully choosing the most appropriate design.
In the future we plan to expand upon this work in two ways: First, we want to test the effect of different small multiple layout techniques for our glyphs .
This would allow us a more general judgement about the applicability of Cleveland and McGill's ranking of visual variables  with respect to glyph design.
With our current study we complement the research in the field of glyph evaluation by comparing the performance of four temporal glyphs for two peak detection and one trend detection task and provide a first set of design considerations for practitioners.
Aigner, W., Kainz, C., Ma, R., and Miksch, S. Bertin was right: An empirical evaluation of indexing to compare multivariate time-series data using line plots.
Aigner, W., Miksch, S., Schumann, H., and Tominski, C. Visualization of time-oriented data.
Andrienko, N., and Andrienko, G. Exploratory analysis of spatial and temporal data.
Ankerst, M., Keim, D. A., and Kriegel, H.-P. Recursive pattern: A technique for visualizing very large amounts of data.
Ankerst, M., Keim, D. A., and Kriegel, H.-P. Circle segments: A technique for visually exploring large multidimensional data sets.
B., Clamage, A., Czerwinski, M. P., and Robertson, G. G. Datelens: A fisheye calendar interface for pdas.
Brewer, C. A. Colorbrewer--color advice for maps.
Carlis, J., and Konstan, J. Interactive visualization of serial periodic data.
Clark, W., Polakov, W., and Trabold, F. The Gantt chart: A working tool of management.
Cleveland, W., and McGill, R. Graphical perception: Theory, experimentation, and application to the development of graphical methods.
Daassi, C., Dumas, M., Fauvet, M., Nigay, L., and Scholl, P. Visual exploration of temporal object databases.
Fischer, F., Fuchs, J., and Mansmann, F. ClockMap: Enhancing circular treemaps with temporal glyphs for time-series data.
Guttorp, P., Sain, S., Wikle, C., Wickham, H., Hofmann, H., Wickham, C., and Cook, D. Glyph-maps for visually exploring temporal patterns in climate data and models.
Havre, S., Hetzler, B., and Nowell, L. Themeriver: Visualizing theme changes over time.
Heer, J., Kong, N., and Agrawala, M. Sizing the horizon: The effects of chart size and layering on the graphical perception of time series visualizations.
