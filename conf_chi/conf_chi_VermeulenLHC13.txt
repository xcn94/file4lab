Feedback and affordances are two of the most well-known principles in interaction design.
Unfortunately, the related and equally important notion of feedforward has not been given as much consideration.
Nevertheless, feedforward is a powerful design principle for bridging Norman's Gulf of Execution.
We reframe feedforward by disambiguating it from related design principles such as feedback and perceived affordances, and identify new classes of feedforward.
In addition, we present a reference framework that provides a means for designers to explore and recognize different opportunities for feedforward.
Well-designed feedforward is an effective tool for bridging Norman's Gulf of Execution  - the difference between the user's intentions and the allowable actions - as it tells users what the result of their action will be.
This is illustrated in Figure 1.
A simple example of feedforward is a label on a button: the label tells users what happens if they push the button.
For instance, the design of the iPhone's lock screen combines perceived affordances and feedforward to tell users how they can unlock the phone, as shown in Figure 2.
However, feedforward also exists in many other forms and guises.
1 Norman later argued for replacing the term "perceived affordances" with "signifiers" to avoid confusion .
However, for historical relevance and to accurately reflect what others have written about the relation between feedforward and perceived affordances, we will continue to use "perceived affordance" throughout this paper.
All mentions of this term can, however, be replaced with "signifier".
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Even though few designers are familiar with the term feedforward, almost every designer has - in one way or another - already used feedforward in their designs.
Yet, opportunities for feedforward are often left unexplored because designers are not fully aware of this design aspect.
An important factor causing this limited awareness is the lack of a well-defined and generally accepted meaning of feedforward.
Additionally, there is no existing library of examples and proven so-
A well-designed combination of feedforward and perceived affordances in the iPhone lock screen.
The "slide to unlock" label, the slider and its button with an arrow icon, and the subtle animation of light that moves over the slider indicates what users can do to unlock the phone.
Feedforward tells users what they can expect when they execute an action - in this case, that the phone will be unlocked when they move the slider to the right.
Given their desired goal , they can select the appropriate action corresponding to that goal.
With this paper, we want to define feedforward more clearly.
In addition, we provide a reference framework for designers that differentiates feedforward from other design principles such as affordances and feedback.
As our everyday environments and devices become smarter and more sophisticated, it will become more difficult to convey to users what tasks are supported, what can be accomplished and how users can achieve their goals.
For example, it has been suggested that context-aware systems should provide support for intelligibility  - presenting to users what the systems know, how they know it, and what they are doing.
Similarly, while one of the strengths of tangible interaction is the fact that physical objects can communicate their purpose through their form and might therefore be easier for users to understand, Hornecker and Buur  warn against these simple, direct associations.
They argue that if tangible interaction is to become useful for complex domains and to scale up to real-world size examples, balancing legibility and computational power is one of the grand challenges in the field.
We believe that feedforward is an important design concept to consider for such systems which will help users in knowing what they can expect and thereby bridge Norman's Gulf of Execution.
As recently argued by Norman , we should not try to avoid complexity, but rather tame complexity through good design.
In summary, the contributions we present in this paper are twofold: * We use Hartson's four types of affordances  to distinguish feedforward from related design principles such as feedback and affordances and clarify their relationship.
By doing so, we raise awareness of feedforward and clear up some of the confusion surrounding the term.
Although the term feedforward has been used in other domains such as control theory , this paper focuses on the usage of the term feedforward in the context of interaction design.
The first definition of feedforward in this context was given by Djajadiningrat et al.
They have defined feedforward by disambiguating it from related concepts such as feedback and perceived affordances : We distinguish between information before the user carries out the action , and after the user carries out the action .
These phases correspond with feedforward and feedback.
Feedforward informs the user about what the result of his action will be.
Inviting the appropriate action is a prerequisite for feedforward but it is not sufficient.
The product also needs to communicate what the user can expect.
Feedback informs the user about the action that is carried out, shows that the product is responding, indicates progress, confirms navigation, etc.
Note that, unlike feedforward, perceived affordances do not communicate the purpose of an action.
We can situate perceived affordances, feedforward and feedback within Norman's Stages of Action model , as shown in Figure 1.
Feedback bridges Norman's Gulf of Evaluation  - the amount of effort users must exert to interpret the state of the system and to determine how well the expectations and intentions have been met - by helping users evaluate the state of the system.
When evaluating the state of the world, users go through the Stages of Evaluation shown on the right side of Figure 1.
Feedforward, on the other hand, bridges Norman's Gulf of Execution  - the difference between the user's intentions and the allowable actions - by helping users decide what action to take based on that action's expected outcome.
When users act on a certain goal, they go through the Stages of Execution seen on the left side of Figure 1.
Perceived affordances are also used for bridging Norman's Gulf of Execution, but serve a different purpose: they suggest a particular action to users, such as pressing a button, or turning a knob.
It has been argued that Norman's perceived affordances can be viewed in the context of semiotics : an object's appearance  signifies to the user that this object can be pressed.
A similar argument could be made for feedforward in the sense that it signifies to the user what they can expect when performing a certain action.
In the remainder of this paper we will explore feedforward in depth.
We start with current use of the term in practice which is at times inconsistent and thus illustrates the need for a clear and generally accepted definition.
Next, we discuss other definitions of feedforward to develop our own reframing of feedforward in which we further detail its relation with perceived affordances and feedback.
Finally, we give an overview of what the different definitions cover in terms of feedforward and analyze a few notable examples of feedforward.
Another example of feedforward for gestural interaction is ShadowGuides , which extends Bau and Mackay's concept of dynamic guides to multi-touch and whole-hand gestures.
Additionally, feedforward has also been deemed important for context-aware computing.
Context-aware systems  typically act based on implicit input collected from the environment.
Additionally, system actions are usually a result of complex reasoning about context data which might be hard for users to understand and makes the system unpredictable .
Bellotti and Edwards  argue that contextaware systems should be intelligible and inform end-users of their capabilities and current understanding.
One of the proposed design principles for realizing this is feedback which includes feedforward - an answer to the question "What will happen if I do this?"
Although Bellotti and Edwards adhere to Djajadiningrat et al.
They also provide examples of feedforward in WIMP GUIs that are often taken for granted, but as they argue, are necessary components of the interface that help users know what will happen when a certain action is performed: flashing insertion points; cursors, pointers and handles; window highlighting; and rubberbanding.
Lim and Dey have developed a toolkit  to support "What if?"
This can be seen as an example of the kind of feedforward that Bellotti and Edwards refer to.
By comparing Djajadiningrat et al.
Different communities seem to interpret the concept in a different way.
There are only a handful of HCI textbooks that talk explicitly about feedforward.
One of them is "Designing for Interaction"  by Dan Saffer, which refers to the definition by Djajadiningrat.
Saffer argues that designers should look out for opportunities to use feedforward - even though he states that it is harder to design into products and services than feedback .
However, there have also been other application domains in which feedforward has been successfully applied, such as gestural interaction.
A common problem of gestural interfaces is their lack of visibility: users lack awareness of the available gestures that are recognized by the system, and what these gestures do.
Feedforward can help users in performing the correct gesture by telling them what will happen when a certain gesture is invoked.
An early example of the use of feedforward in gestural interaction is Kurtenbach et al.
Marking menus are pie menus - circular menu's that support gestural interaction as shown in Figure 3 - intended to accommodate both novice and expert users.
They allow a user to perform a menu selection by either poppingup a pie menu, or by making a straight mark in the direction of the desired menu item without popping-up the menu.
The pie menu serves as a feedforward display that helps novice users who hesitate when they are unsure of a gesture of command, as shown in Figure 3.
When users become more experienced, they tend to use marks more, although they still look at the feedforward display once in a while to refresh their memory .
Note that marking menus show both the available gestures  and what users can expect when they perform one of these gestures.
Bau and Mackay developed OctoPocus , a dynamic guide that combines on-screen feedforward and feedback to help users learn, remember and execute gestures.
They state that "feedforward mechanisms provide information about a gestures shape and its association with a particular command, prior to the execution or completion of the gesture."
Like marking menus, OctoPocus takes advantage of possible hesitation by appearing after a "press and wait gesture".
In this section, we outline the differences between existing definitions of feedforward.
This overview will provide a thorough review on the notion of feedforward and its relation with affordances.
The table in Figure 4 lists different definitions and examples of feedforward alongside a number of important dimensions.
We will discuss this table in more detail later.
Feedback is a message about whether or not a goal was achieved or maintained  and is typically used to inform the user that the system is responding, to indicate progress or to confirm navigation .
However, while feedback is communicated during or after the action, feedforward is information that is offered before the action takes place.
Whereas feedback informs the user about the action that is carried out, feedforward informs the user about what the result of their action will be.
Next to feedforward, affordances also provide information to users before they carry out an action.
Gibson  defined affordances as: All "action possibilities" latent in the environment, objectively measurable and independent of the individual's ability to recognize them, but always in relation to the actor and therefore dependent on their capabilities.
As introduced in the HCI literature by Norman , perceived affordances  essentially invite the user to a particular action.
Affordances therefore "suggest" how one can interact with a product or system.
Typical examples in HCI are buttons which "afford" pushing, knobs which "afford" turning, or sliders which "afford" moving up and down .
Affording the right actions has been widely regarded as a crucial aspect of usability.
Even though perceived affordances are very useful, Djajadiningrat et al.
They state that the essence of usability lies not in communicating the necessary action, but the purpose of an action.
Inherent feedforward offers information related to the action possibilities of the product and appeals primarily to the perceptual motor skills of the person.
Inherent feedforward communicates what kind of action is possible  and how this action can be carried out .
Wensveen  states that inherent feedforward can be viewed as a limited interpretation of Gibson's affordances .
Note that Wensveen does not contradict Djajadiningrat et al.
Feedforward as a whole - the combination of inherent, augmented and functional feedforward - still goes beyond affordances, according to Wensveen .
The differentiation between the three different types of feedforward was mainly made for analysis purposes .
Augmented feedforward is information from an additional source about the action possibilities of a product or system, or the purpose of these action possibilities .
This type of feedforward appeals primarily to the cognitive skills of users.
Figure 5 shows examples of augmented feedforward, such as on-screen messages indicating what to do  and lexical or graphical labels communicating the purpose of the action possibility.
Functional feedforward goes beyond the action possibilities and their specific purpose and instead informs the user about the more general purpose of a product and its functional features .
A possible strategy for functional feedforward is making the functional parts visible , as illustrated for example by the candy vending machine in Figure 5 , where the available types of candy and the mechanism which delivers the products to the user are clearly visible.
Even though the above-mentioned definitions distinguish between feedforward and affordances, there have been a number of frameworks for affordances  that included aspects of feedforward without explicitly mentioning the term, further adding to the confusion.
In the next sections, we give an overview of these frameworks and explain how they relate to feedforward.
They state that application software also provides possible actions.
For example, a word processor affords writing and editing at a high level , but also actions such as clicking and scrolling.
Given Gaver's extension of nested affordances, Wensveen's functional feedforward  could be seen as a perceptible affordance  which conveys the general  function of a system - or what the system affords the user.
This top-level affordance can be seen as the root of a hierarchy of affordances.
As an example, in Figure 5 , the shape of the voice recorder conveys its general function to the user.
However, to actually record speech, users will also have to be aware of the nested functions and affordances for these functions .
One could argue that through the concept of functional feedforward, Wensveen implicitly suggests that feedforward might also be nested, just like Gaver's affordances.
Gaver also introduced sequential affordances which are only available at certain points in time.
This is common in graphical user interfaces since these can be updated during usage.
In contrast, physical objects usually have a static physical appearance and cannot update their form over time.
The information that specifies an affordance , can be quickly updated as new affordances become available  .
Similarly, feedforward could only be made available at certain points in time or be updated during the user's action to provide new information.
The examples of feedforward in gestural interaction that were discussed previously , can be seen as examples of sequential feedforward.
Sequential feedforward in combination with feedback could further blur the difference between the two concepts.
Feedback provided after performing an action might afterwards serve as feedforward for the action that logically follows the previous one.
In his paper titled "Technology Affordances", Gaver  argues that affordances are not always single, independent entities, but can be related to one another.
He describes two different relationships between affordances: nesting and sequence.
Nested affordances are grouped in space, while sequential affordances are sequential in time .
Gaver argues that affordances are not passively perceived, but explored .
He also hints at the possibility of conveying affordances through different modalities .
Nested affordances, in particular, bear resemblance to feedforward.
McGrenere and Ho  have analyzed Gaver's work, and clarify nested affordances with the example of a button.
They state that users are not interested in clicking on a button for its own sake, but are interested in invoking a certain function.
The function that will be invoked by a button is usually specified through its label or icon.
They explain that here the affordance of "button clickability" is nested within the affordance of "function invokability".
McGrenere and Ho stress that it is important to acknowledge that each of the levels of the affordance hierarchy may or may not map to system functions.
Kaptelinin and Nardi  call for adopting a mediated-action perspective on technology affordances as an alternative for Gibson's ecological psychology perspective.
They differentiate between two types of affordances: instrumental technology affordances which are comprised of a handling affordance and an effecter affordance; and a set of auxiliary technological affordances such as maintenance, aggregation and learning affordances.
We mainly focus on instrumental technology affordances - and in particular effecter affordances - here, as these appear to be quite similar to feedforward.
The difference between handling and effecter affordances is explained with the example of a knife.
A knife consists of two distinct parts: the handle and the blade.
The knife handle is used for holding the knife, while the blade is used to manipulate objects .
Kaptelinin and Nardi  argue that this distinction also applies to digital technologies, and, more specifically, to user interface widgets.
For example, the ability to drag the scroll box of a scroll bar is the handling affordance, while the ability to display a certain portion of the document in the window is the effecter affordance.
Like Djajadiningrat  and Wensveen , Kaptelinin and Nardi  distinguish between the purpose of an action  and the action possibility .
Indeed, they provide an example of a dialog where: "handling affordances are clear but the outcomes of user actions  are not immediately obvious.
They state that users will be confused when handling and effecter affordances are not coupled tightly enough.
Kaptelinin and Nardi's effecter affordances appear to be closely related to feedforward since they convey the outcome of a certain action.
The idea of tightly integrated handling and effecter affordances seems to be similar to how perceived affordances and feedforward can be combined to communicate both the action possibilities and the expected outcomes of those actions.
Hartson  further clarified the concept of affordances based on Gaver's  and McGrenere and Ho's  work.
He distinguishes between four types of affordances based on the role they play in supporting users during interaction: Cognitive affordances are considered to be an extension of Norman's perceived affordances , helping users with their cognitive actions.
Hartson  defines cognitive affordances as "a design feature that supports, facilitates, or enables thinking and/or knowing about something".
Example: A button label that helps users know what will happen if they click on it.
Cognitive affordances are associated with the semantics or meaning of user interface artefacts.
Sensory affordances have a supporting role, and are associated with the "sense-ability" characteristics of user interface artefacts, especially of physical affordances and cognitive affordances.
According to Hartson , it is design that connects sensory affordances to physical and cognitive affordances, so that they can be seen, heard or felt to be used.
Moreover, physical affordances carry a mandatory component of utility or purpose - the functional affordance - to which statements about physical affordances should refer.
Hartson's framework significantly broadens the scope of affordances, so that they also include both the notions of feedback and feedforward.
Hartson explains a cognitive affordance with the example of "a button label that helps users know what will happen when they click on it", which essentially explains the purpose of this button, and can thus be seen as feedforward.
Hartson explains how the four types of affordances helps user achieve their goals by plugging them into Norman's Stages of Action Model , as seen in Figure 6.
Earlier, we positioned feedforward and feedback in Norman's Stages of Action Model .
It is interesting to note that Hartson identified the need for cognitive  affordances exactly where we situate feedforward and feedback in Norman's Stages of Action model , which suggests that both feedback and feedforward are cognitive affordances.
Furthermore, Wensveen's augmented, inherent and functional feedforward  can be explained in terms of Hartson's four types of affordances: Inherent feedforward : Wensveen  clearly sees inherent feedforward as a limited interpretation of the concept of Gibson's affordance .
It communicates what kind of action is possible and how it can be carried out.
This is similar to Hartson's physical affordance, as a physical design feature that helps users to physically do something .
Physical affordances help users with their physical actions, and match with Norman's real affordances  .
According to Hartson , a physical affordance is "a design feature that helps, aids, supports, facilitates, or enables physically doing something".
Sensory affordances help users with their sensory actions .
Hartson  defines a sensory affordance as "a design feature that helps, aids, supports, facilitates, or enables the user in sensing  something".
Sensory affordances play a supporting role for cognitive and physical affordances.
Hartson thus explicitly separates sensing from understanding.
Functional feedforward : informs the user about the more general purpose of a product and its functional features .
As noted above, Wensveen's functional feedforward can be seen as a high-level nested affordance in Gaver's terminology.
Even though Hartson does not explicitly state that his four kinds of affordances can be nested, we feel this is implied by several examples in his paper .
Wensveen's functional feedforward might be categorized as a cognitive affordance that makes the highlevel functionality of the system - or its functional affordance - visible.
If this is achieved through physical design, the product's form can be seen as a sensory affordance which allows users to recognize its functionality.
Note that Hartson's framework unites both Gaver's  and McGrenere and Ho's  work on affordances, and can be used to explain feedforward according to both Djajadiningrat's  and Wensveen's  definitions.
We will later use Hartson's framework to reframe feedforward and disambiguate it from perceived affordances and feedback.
We conclude this section by giving an overview of aspects related to feedforward in Norman's work.
Moreover, with the integration of sensing into everyday artefacts, it is often even harder for users to reason about the result of actions they undertake.
It is important to note that complex systems that use labels and/or icons are not examples of bad design.
It is often overlooked that Norman did not disapprove of labels and icons altogether, he only said: "When simple things need pictures, labels, or instructions, the design has failed."
When Norman talks about more complex systems or devices, he provides two ways to help users determine the purpose of a user interface artefact: mappings and a good conceptual model .
As these mechanisms allow users to know what will happen when they perform an action, they could be seen as examples of feedforward.
Mappings allow users to determine the relationships between actions and results, between the controls and their effects and between the system state and what is visible by spatial coupling.
The controls are laid out in the same order as the artefacts in the physical world that they control.
However, according to Djajadiningrat , mappings fall short when dealing with abstract data that has no physical counterpart.
A good conceptual model allows users to predict what will happen when they perform an action by exploiting consistency.
Consistency in the presentation of operations and results helps users to form a coherent, consistent system image .
Two other important design principles proposed by Norman are symbols and constraints .
Norman argues that these are not affordances and that wording in the label on a button, for example, is symbolic communication.
Hartson  agrees, but states that under his own definition, communication is exactly what makes good wording effective as a cognitive affordance.
It helps the user in knowing .
In other words, Hartson  sees symbols, constraints, and conventions as essential underlying mechanisms that make cognitive affordances - and therefore also feedforward and feedback - work.
Hartson  argues that Norman would agree that cognitive affordances play an enormously important role in interaction design.
According to Hartson , they are key to answering Norman's question: "How do you know what to do?".
Hartson mentions that the design of cognitive affordances can indeed depend greatly on cultural conventions  as a common base for communicating the meaning of cues from designer to user.
While this section started with the assumption that feedforward goes beyond affordances, Hartson  argued that feedforward is just a special kind of affordance, namely a cognitive affordance.
Norman implies a purpose for a physical affordance , thereby eliminating the need for explicit feedforward.
This is confirmed by Hartson : In Norman's Design of Everyday Things world of non-computer devices, a purpose for a physical affordance is always implied.
The doorknob is a cognitive and physical affordance for operating the door.
The physical affordance offered by a doorknob does not mean merely that the doorknob can be grasped and turned.
It means that the doorknob can be grasped and turned in order to operate  the door; the user is enabled to operate the door.
In turn, the door itself is a functional affordance that, when invoked, allows passage.
In this interaction design view, a physical affordance gives access to functionality, the purpose of the physical affordance used to access it.
Hartson  notes that even though the addition of purpose to the description of a physical affordance is an obvious extension, it should be made explicit to avoid ambiguities in terminology.
There are several situations in which it is necessary to explicitly communicate the purpose of an action, especially in electronic products, graphical user interfaces  and tangible user interfaces.
In this section, we reframe feedforward informed by the above discussion of feedforward and related design principles such as affordances and feedback.
We further clarify the differences between feedforward,  affordances and feedback based on Hartson's four types of affordances .
As Hartson not only subsumes Gibson's affordances   and Norman's perceived affordances , but also significantly broadened the scope of affordances to include the notions of feedback and feedforward, we feel his framework is useful to reason about the differences and interrelationships between these design principles.
As discussed earlier, Hartson states that physical af-
As discussed before, Hartson situated his four types of affordances into Norman's Stages of Action Model .
Remember that Hartson identified the need for cognitive  affordances exactly where we positioned feedforward and feedback in Norman's Stages of Action model , which suggests that both feedback and feedforward are cognitive affordances.
Hartson later confirmed this in personal email communication .
Even though it is a cognitive affordance, feedforward is also connected to the three other types of affordances.
Perceived affordances occur before the user's action and invite them to an appropriate action.
Feedforward  is a cognitive affordance that is understandable through a well-defined sensory affordance  and reveals the functional affordance  coupled to a physical affordance .
Feedforward occurs before the user's action and tells users what the result of their action will be.
Feedback is provided during or after a user's action and informs them about the result of performing their action, Feedback can later turn into feedforward again  for another action that logically follows the previous one.
Figure 7 illustrates these definitions and shows how perceived affordances, feedforward and feedback relate to each other and are linked to Hartson's four types of affordances .
Both perceived affordances and feedforward tell users something about a particular action through a combination of a physical and functional affordances.
Perceived affordances and feedforward essentially provide different information about the action that users have to perform to achieve their goals.
While perceived affordances reveal the physical affordance, which tells users that there is an physical action available and how to perform it, feedforward reveals the functional affordance, which tells users what will happen when they perform that action.
An overview of how perceived affordances, feedforward and feedback can be explained using Hartson's four types of affordances.
C, S, F and PH refer to Hartson's Cognitive, Sensory, Functional and Physical affordances respectively.
The functional and physical affordances together constitute a possibility for a purposeful action.
While perceived affordances and feedforward provide information before the user's action , feedback occurs after the user's action.
Norman always implied a purpose  for a physical affordance .
As the purpose was implied, there was no need for explicit feedforward.
Similarly, Norman always implied that perceived affordances were provided with a well-defined sensory affordance.
As mentioned before, Hartson states that the addition of purpose should be made explicit to avoid ambiguities in terminology .
Additionally, we argue that the more complex a system or interaction context gets, the larger the need will be for elaborate feedforward in order to aid users in achieving their goals.
Note that feedback provided after performing an action might afterwards again serve as feedforward for the action that logically follows the previous one .
Wensveen refers to feedback that turns into feedforward as inherent traces of action .
In its simplest form, it is "nothing more than evidence for the user that he has acted on the action possibilities, as if it were a trace of the bygone action.".
An example of feedback turning into feedforward is a physical light switch.
When users flick the switch, feedback consists of the changed position of the switch, and, of course, also the light bulb that produces light .
However, the user's action also changed the possibilities for action, as the light cannot be turned on again, it can only be turned off.
In essence, the feedback of the glowing light bulb and the state of the switch, becomes feedforward indicating that flicking the switch again will reverse the state of the light bulb and thereby turn it off.
Another example of feedback that turns into feedforward can be found in marking menus .
Once a function in the marking menu is invoked, its label is changed to the corresponding inverse function.
This inverse function label, at first, serves as feedback to indicate that the previous function has been invoked,
Gaver's idea of sequential affordances, also applies to feedforward.
Notable examples of sequential feedforward are systems that use feedforward to make gestural interfaces easier to use, such as Bau et al.
OctoPocus and ShadowGuides continuously issue dynamic feedforward and gradual feedback during input.
While performing a gesture, users are provided with information about their current set of possible gestures  and the expected result of those gestures , together with feedback about how well the current gesture has been recognized.
Feedforward could also be made available at discrete points in time, instead of being updated continuously.
Dynamically updating feedforward is probably easiest to achieve in software.
Sequential feedforward in combination with feedback could further blur the difference between the two concepts since feedback might afterwards serve as feedforward for the user's next actions.
Gaver also discerns between affordances - as in Gibson's original definition  - and the perceptual information available about them , which corresponds to what Norman defined as perceived affordances .
Based on this distinction, Gaver introduces the concept of false and hidden affordances, where the apparent information about the affordance is incorrect or missing respectively.
A similar reasoning could be applied to feedforward and how an action is coupled to a system function, as shown in Figure 8.
Feedforward can be false when it conveys incorrect information about what system function the action performs.
When feedforward is missing, it hides how the action is related to the system function .
Although undesirable, false and hidden feedforward might be useful notions to consider in interaction design.
A simple example of a false feedforward in a graphical user interface is a button with an incorrect label .
The table in Figure 4 shows which aspects of feedforward are covered by different definitions and also analyzes how feedforward is used in a number of notable examples.
As pointed out before, feedforward can be provided using multiple modalities.
Unfortunately, designers mostly rely on visual information to convey feedforward, apart from a few exceptions, such as Djajadiningrat et al.
Bau and Mackay have introduced the level of detail as a useful criterium for classifying feedforward mechanisms.
Usually, feedforward is provided in a low to average amount of detail.
However, there might be situations in which feedforward can be provided with lots of details, for example to reassure the user when they have to trust the system .
Feedforward can be nested in a hierarchy.
There are a number of examples that use nested feedforward, such as Disney AppMATes and the Tangible Video Editor  .
Nested feedforward tends to rely on the object's shape to convey its general function , combined with lower-level types of feedforward information.
Disney's AppMATes is a children's toy which uses tangible toy cars which can be used on a tablet.
In this case, the shape of the toy car serves as high-level feedforward that explains the general purpose of the object.
When children place the toy car on the screen, the car's lights will be shown on the display.
This acts as additional feedforward information indicating that the car and display are linked, after which children can try to move the car on the display.
In case of the TVE, the shape of the different building blocks indicate their function.
Finally, feedforward can be either be static or updated over time .
An example of static feedforward is a fixed label in a tooltip.
Examples of sequential feedforward are the OctoPocus  and ShadowGuides  dynamic guides, the TVE and SpeakCup .
Gaver  proposed the idea of sequential affordances and nested affordances for complex actions.
We argue that feedforward can also be nested or sequential.
In his discussion of sequential affordances, Gaver also mentions that affordances can be conveyed through multiple modalities .
Similarly, we think that feedforward could also be provided using different modalities, as confirmed by Wensveen  and Djajadiningrat et al.
However, some modalities  will be better suited to exploratory actions as they cannot be perceived through what Gaver calls "relatively passive perception" .
As previously discussed, Wensveen's functional feedforward  conveys the general  function of a system , and can be seen as the root of a nested feedforward hierarchy.
It can be combined with feedforward that is provided for lowerlevel  functions.
SpeakCup is a digital voice recorder that is shaped like a small rubber disc with holes in its center.
When the holes are pressed in, forming a small cup, SpeakCup absorbs sound.
When the holes are pressed out, the stored sounds are released.
SpeakCup uses its shape to communicate to users what they can expect.
As this shape changes over time when the disc is pressed in or out, this is another example of sequential feedforward.
With this work, we reaffirm the importance of feedforward as a powerful tool for bridging Norman's Gulf of Execution.
We strongly believe that, like affordances, feedforward is not a concept that can be easily defined.
Although designers do use feedforward in many cases, they do so unknowingly and based on their experiences and skills.
We have reframed feedforward in terms of Hartson's four types of affordances:  we disambiguated feedforward from related design principles such as feedback and perceived affordances; and  we identified four new classes of feedforward: hidden, false, sequential and nested feedforward.
Our reframing of feedforward, together with the table in Figure 4 provides a means for designers to explore and recognize different opportunities for feedforward.
We would like to thank Stephan Wensveen for the interesting discussions we had on feedforward.
We also want to express our gratitude to H. Rex Hartson for answering our questions about his work and sharing his reasoning on feedforward versus affordances.
Many thanks to Johannes Sch oning and Steven Houben for their suggestions and feedback on early drafts of this paper.
We also thank Don Norman for his insightful suggestions.
Finally, we are indebted to the anonymous reviewers whose comments further improved this paper.
Bau, O., and Mackay, W. E. OctoPocus: a dynamic guide for learning gesture-based command sets.
In Proceedings of the 21st annual ACM symposium on User interface software and technology, ACM , 37-46.
Bellotti, V., Back, M., Edwards, W. K., Grinter, R. E., Henderson, A., and Lopes, C. Making sense of sensing systems: five questions for designers and researchers.
In Proceedings of the SIGCHI conference on Human factors in computing systems: Changing our world, changing ourselves, ACM , 415-422.
Bellotti, V., and Edwards, K. Intelligibility and accountability: human considerations in context-aware systems.
De Souza, C. The Semiotic Engineering of Human-Computer Interaction.
Dey, A. K. Understanding and using context.
Djajadiningrat, T., Overbeeke, K., and Wensveen, S. But how, donald, tell us how?
Djajadiningrat, T., Wensveen, S., Frens, J., and Overbeeke, K. Tangible products: redressing the balance between appearance and action.
Freeman, D., Benko, H., Morris, M. R., and Wigdor, D. Shadowguides: visualizations for in-situ learning of multi-touch and whole-hand gestures.
