These issues include the use of different applications , different computational platforms, multiple file formats, and differing standards in the display of information.
Users often resort to perform side-by-side comparisons for their data.
Alternatively, many users take steps that reduce the fidelity or richness of their data sets, such as overlapping saved screenshots or exporting to raster-image formats that do not store non-visual meta-data.
Although many of these limitations could be overcome with the production of new software, one cannot anticipate future file formats and application with which to integrate, so any new application that addresses one interoperability need is destined to become another interoperability problem.
Additionally, software development is expensive.
In this paper, we present an alternative to new software development that facilitates the rapid visual overlay of data displayed in different applications.
Named LivOlay, our system visually overlaps and geometrically registers multiple remote desktops on a shared display so that groups can collaboratively compare application visualizations running on these machines.
Because LivOlay displays the live desktops of remote machines, modifications to the applications running on these machines are immediately reflected on the shared display.
The interoperability of disparate data types and sources has been a long standing problem and a hindering factor for the efficacy and efficiency in visual exploration applications.
In this paper, we present a solution, called LivOlay, which enables the rapid visual overlay of live data rendered in different applications.
Our tool addresses datasets in which visual registration of the information is necessary in order to allow for thorough understanding and visual analysis.
We also discuss initial evaluation and user feedback of LivOlay.
When engaged in data exploration, it is common to draw information from multiple sources: city planners consult topographical and city maps of the same region, doctors examine x-ray and MRI images of a patient, and astronomers view images of the same region at both visual and infrared wavelengths.
In each of these cases, the data being considered have a common subject, but the sources, including the sensor instrumentation, associated encoding and meta-information of these visual datasets may vary widely.
In many instances, users would benefit from visually overlapping this information in order to allow for a direct comparison and a more complete understanding of the data; however, many applications either do not support overlapping datasets or do not support the multitude of file types that their users require.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Our exploration of this area of research began in collaboration with a local university astrophysics research centre.
In their weekly discussion meetings, it is common for the scientists to share and present astronomical data taken from multiple sources and relating to a single subject.
This group often had difficulty comparing datasets because of the many file formats, viewing applications, computer platforms, and custom scripts and code used by team members.
They often settle for positioning two laptops side by side to compare their contents.
There is no tool that would allow them to quickly geometrically register and visually overlap their datasets.
The following scenario, taken from a recent meeting, illustrates this problem:
Three astrophysicists  get together to analyze the outflows from young protostars in a star forming region, in anticipation of writing a proposal for telescope time.
A brings a 3-color composite extinction map taken at Calar Alto which shows dust, and a radio image taken with the SMA interferometer  of a very small portion of the region identifying possible outflow sources.
B pulls-up a wide-field image on his laptop of the same region and its surroundings taken in the infrared with the Sptizer telescope.
In addition, C opens a 12 CO radio data cube in the program DS9  with an overlay marking where all the currently known outflows and sources are located.
Unfortunately, there is no common program that allows them to overlap the images or align them, thus comparison of the data is a difficult task.
Current practices include printing the images on paper in order to mark-up and compare side-by-side, opening the images in multiple application windows on one or multiple laptops, or overlapping and quickly switching between image windows to look for subtle changes.
While useful, these solutions allow only for side-by-side comparisons or overlay using unregistered transparency .
They do not address datasets in which visual registration of the information is necessary in order to allow for thorough understanding.
In order to identify celestial objects, as in the astrophysicist meeting scenario, data from different instruments, such as radio and optical telescopes, need to be overlaid, with appropriate corrections applied to perform an appropriate registration.
Because the data comes from a myriad of sources and encoded in entirely different data types, there do not exist tools to overlay all of this data.
To overcome this, users will commonly export data to a common format, such as raster maps, and overlay them as layers in Adobe Photoshop.
The layers are then viewed by adjusting transparency, assigning data to a colour channel, or blinking between images, a common practice in astronomy .
These solutions address the problem of registration, but are labour intensive.
In addition, the connection between the visualization and underlying data is lost, making updates or user interaction extremely laborious.
Our design objective was to produce a lightweight tool for rapidly registering and overlaying visual data from multiple live sources.
Tools to display overlapping imagery and data do exist: Google Earth, for example, renders registered satellite and cartographic data, and the World-Wide Telescope project aims at mining the vast online observational astronomy data for visual analysis .
These tools, however, do not provide dynamic, on-the-fly user-controlled interactive registration and overlay from arbitrary sources, including sources that are either proprietary or are not online, as ours is able to.
A number of information visualisation systems allow comparison of data.
Snap-Together Visualization provides tools to build ad hoc coordinated views .
VisLink, provides a visual linking approach to allow interactive exploration of relationships .
Unlike LivOlay, both of these tools require access to underlying data, and are intended to examine only visualizations of statistical data.
Work in collaborative visualization, such as described by Johnson, focuses on providing coordinated views of a data source to multiple displays .
In contrast, LivOlay is intended to allow one or more users to overlay data from multiple sources on a single display.
Techniques do exist for simultaneously viewing data from multiple sources: multiple applications can be run side-by-side, or screen sharing software, such as VNC  and others described in research , can be used to show content from multiple systems on a single display.
This last goal may seem unintuitive; however, even in a cooperative setting, boundaries may exist as to what collaborators are willing to share.
While one may be willing to show visualizations or grant limited access during a meeting, it is essential for some users that this sharing not necessarily result in unmitigated access to underlying data.
In support of all of these goals, we developed a tool that allows users to connect their own laptops with a display wall, and share their screens as remote-desktops.
These remote-desktops can then be overlaid, with user-definable visual registration shown on the wall.
Registrations are computed continually in real time, maintaining interactivity.
This method achieves all of our goals, first and foremost because we are leveraging existing applications, running on users' own laptops.
Making use of these applications means that all data sources are supported, and because these applications are responsible for rendering the visualisations, which LivOlay then registers, no new software is required to add new sources to the system, and underlying data are protected from access.
Further, because we directly overlap the remote-desktops, the applications remain completely unaware of their use in the larger system.
Applications used to display information in LivOlay are not at all modified - they are run as usual on connected laptops, whose screens are then rendered on a shared display.
We built our tool using OpenGL and Java.
Our prototype runs on a large display wall, made up of six Mitsubishi Electric VS-50XLF20U Display Cubes.
Our software allows multiple notebook computers to connect over Ethernet using custom software built on the VNC protocol.
From VNC, our application reads only the current colour of each desktop pixel.
A side-by-side comparison can be achieved by placing the remote desktop images next to each other.
User-defined transformations can then be applied to these remote desktop images to produce a registered, overlapped visualization.
The system is able to update screen content and apply the transformations at interactive rates.
To quickly align and overlap desktop images, a user identifies pairs of common features from each visualisation to serve as registration points.
In the case of astrophysicist users, these points are often stars or other celestial features.
The control points define a transformation for visually registering the visualisations within the remote desktops.
LivOlay currently supports linear transformations, defined by up to 4 point pairs, illustrated in Figure 2: a single pair is sufficient for visualisations of the same size and shape .
A second pair is necessary for rotation and scaling, such as when overlaying 2D maps .
A third pair adds sheer, as might be needed when overlapping graphs with different scales in x and y axes , .
A fourth point defines a perspective transformation , .
Astrophysicists frequently make use of data collected from multiple types of instruments and sources, such as x-ray, infra-red, optical, and radio telescopes.
This data is often rendered in applications which do not provide overlays.
Exporting the images to a raster format would result in loss of valuable meta-information and interactivity.
LivOlay will allow easier collaboration, by enabling fast, ad hoc overlays of their data visualisations while meeting .
To evaluate the design and prototype of LivOlay, we carried out two observation and discussion sessions with the members of the astrophysics community.
The group indicated that the interaction methods were intuitive, and the user-controlled registration and transformation facilities appropriate.
They would like to use the tool during their meetings.
Although useful in its current implementations, their feedback indicated potential avenues for future work.
First is the need to investigate additional, non-linear transformations to support a wider range of comparison scenarios.
Second is to consider the position and orientation of the reference camera on the registered images.
Our current implementation keeps one reference image nontransformed, and the user can switch between reference images.
Although this guarantees an undistorted view of one desktop at a time, it may not always be ideal.
Third, our system presently relies on user-defined reference points in the images to be registered.
Although this is appropriate for many visualisations, some may not contain commonly visible reference points; mechanisms for registration that do not rely on image features are desirable.
Fourth, although our software is currently intended as a tool for multi-user collaboration, it would also be useful as a single-user tool for the registered overlay of application windows.
Finally, our tool provides real-time updates of the registered image as screen content changes.
This is a primary contribution of the work, but it comes with a significant limitation: display angle or viewpoint changes necessitate re-registration.
Synchronized input, automatic feature-based recalibration and tracking are future work.
Our user group identified a common source of problems: they often examine visualisations for which the underlying data is no longer available, such as when reading old papers.
GraphClick  is a software tool which allows the recovery of data via image processing of a graph.
Although useful, its applicability is limited to certain visualisations.
Our application does not provide a facility to recover data, but will allow for the overlay of old visualisations.
In discussions with our users and past experience, it became clear that it is sometimes the case that participants in a discussion might be prepared to share visualisations, but not actual underlying data.
This might occur with confidential information, such as patient records, or highly valued data, such as rare-instrument output or marketing research.
Because our system combines visualisations only at the pixel level, it is possible for users to perform visual comparative analyses of data without fear of copying.
