Showing a live software demonstration during a talk can be engaging, but it is often not easy: presenters may struggle with  unexpected software crashes and encounter issues such as mismatched screen resolutions or faulty network connectivity.
Furthermore, it can be difficult to recall the steps to show while talking and operating the system all at the same time.
An alternative is to present with pre-recorded screencast videos.
It is, however, challenging to precisely match the narration to the video when using existing video players.
We introduce DemoWiz, a video presentation system that provides an increased awareness of upcoming actions through glanceable visualizations.
DemoWiz supports better control of timing by overlaying visual cues and enabling lightweight editing.
A user study shows that our design significantly improves the presenters' perceived ease of narration and timing compared to a system without visualizations that was similar to a standard playback control.
Furthermore, nine  participants preferred DemoWiz over the standard playback control with the last expressing no preference.
In addition, the stress of public speaking, especially during a high-stakes presentation, makes it difficult for presenters to deliver effective messages in a timely manner without forgetting to cover a set of core values of the system.
An alternative is to present with prerecorded screencast videos that capture the correct flow and information.
Even though technical problems are less likely to occur with a video, it is challenging for presenters to talk over a video with appropriate timing because they have to mainly rely on their memories for the sequence and timing of interactions.
Such a "canned" demo can often result in a less understandable or engaging presentation when a video is not tightly prepared to attract the audience's attention to anticipate the results .
The presenter view in PowerPoint or Keynote attempts to help presenters during slide show presentations by showing notes along with an upcoming slide.
A teleprompter, commonly used for news programs or political speeches, prompts presenters with an electronic visual text of a speech or script.
With this, speakers can appear to be speaking spontaneously as they look at the audience while reading the script.
Inspired by these tools, we built DemoWiz , a system that assists presenters in giving software demonstrations with a screencast demo video during a live presentation.
DemoWiz augments a screencast video with visualizations, enabling presenters to anticipate the video content rather than react to it; overlaying glyphs to guide presenters to the next action along with the time remaining before the action occurs.
DemoWiz supports the entire authoring process from capturing a screencast video; to rehearsing it and adjusting timings; to performing live presentation of the demo.
During the recording phase, DemoWiz captures the screen pixels and logs input events, including event types and locations with timestamps.
This event information is then processed and provided to presenters in the form of an adjustable timeline of events.
During the rehearsal phase, presenters can speed up or slow down specific segments while navigating through the video recording using the timeline.
In addition, they can add pause markers and short text notes.
During the presentation, similar to current presentation tools like PowerPoint and Keynote, DemoWiz shows two views-one for the presenter and the other for the audience.
The Presenter View is augmented with timed notes and a visualization of the captured events to help presenters synchronize their narration with the video.
Performing a software demonstration can be an effective way to communicate with the audience during a live presentation.
By illustrating actions within a working system, presenters can guide the audience through an interaction flow and show results in real time.
However, it is not always easy to perform an effective live demo.
Problems such as software crashes, network connectivity issues, and configuration changes  may break a demonstration.
Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
To explore the effectiveness of the DemoWiz system, we performed a user study, comparing it with a version similar to a conventional video player.
Our results show that, with DemoWiz, participants anticipated upcoming actions better and rated themselves as having narrated the video better.
Moreover, 9 out of 10 participants preferred DemoWiz to a system without visualizations.
The contributions of this work are:  An interactive video playback interface to help presenters control demo videos during a live presentation.
It is combined with visual augmentation of screencast videos to enable presenters to anticipate upcoming actions and to be better aware of timing for narration.
A lightweight workflow for presenters to record, rehearse and edit, and present demo videos.
To support automatic video segmentation, we employ a hybrid approach to combine screencast videos and input event logs.
Evaluation of the overall effectiveness of DemoWiz, incorporating visualizations into the presenter view of a video, across the workflow.
In addition to visually enhancing events, presenting operation history helps users review the workflow.
Approaches include annotating screenshot images with markers and arrows , showing a list of before and after thumbnails and video clips , and creating a union graph of operations for workflow comparison .
These projects demonstrate the benefits of recognizing and visualizing events.
Our work is related in that we use the stream of input events, but is focused on enhancing a speaker's experience in a live presentation by visualizing events in advance of the happening moments.
Another closely related area is the design of various tutorial formats that help viewers operate an interactive system.
Work includes embedding video snippets in application tooltips , mixed-media tutorials that combine operationbased video segments with text descriptions and screenshots , and application-in-tutorial design enhanced by community-shared workflows .
These designs show possible ways for viewers to explore application features interactively, but again, differ from our goal of real-time assistance for presenters.
There has been a considerable amount of research and many commercial tools devoted to revealing input events and operation sequences for software applications.
Researchers have shown that visualizing input events in real-time during operations can provide better learnability of applications .
Tools such as Mousepose1 and ScreenFlow2 capture mouse and keyboard events and apply special effects, such as drawing a circle around a mouse cursor.
Videos can be navigated at the content level beyond log events, such as visualizing subject movements in a storyboard design  and enabling direct manipulation of a target in 2D  or 3D .
These techniques help viewers understand content flow and playback videos, and have been applied to screencast videos .
It is also possible to automate video control based on user actions for scenarios such as operating software applications  and block assembling tasks .
Modern presentation tools have supported embedding video recordings and animation.
Recent research has proposed advanced designs for content creation and navigation beyond simple slideshow composition, including: tools that help presenters compose content in a large canvas  as a path  or a directed graph  derived from zoomable graphical interfaces ; structure slides using markup languages  or sketching ; and define animation programmatically .
There has also been work on analyzing slide content for search and reuse  and comparing revisions in a design process .
Our work shares similar goals of structuring a presentation based on event inputs that can be navigated and edited.
However, we focus more on presentation enhancements of video content specifically for software demonstrations rather than on the authoring experience of the presentation itself.
Research on presenting information that can be perceived at a glance  helps presenters recall the content during a presentation, such as a callout to show finer resolution of an overall view .
Closely related, Time Aura provides ambient cues of a pile of slides using colors and a timeline for pacing .
Recent research shows that people like to have better control of the presentation even though it requires more effort , and earlier studies suggest that designing an integrated presentation tool for complicated tasks could be challenging .
These findings inspired our design on revealing content of a demo video with information that can be perceived with minimum attention.
Among all the respondents, 35.6% indicated that they were very experienced at giving software demos to the audience during a live presentation; 46.6% had demoed at least once; 13.7% had not demoed but attended talks that showed a software demonstration.
We asked respondents who had demo experience  how they preferred to perform a demo.
In Table 1, we list the top 2-3 reasons for their preferences.
Giving a live demo can be more engaging with a working system and match the audience's interests, but presenters can encounter unexpected problems and forget to show important features within a given time constraint.
On the other hand, presenting with a demo video avoids such problems by extracting the most important parts, and can allow visual highlighting , but can be less engaging.
In addition, it is hard to narrate.
We were also interested in reactions as an audience member.
For respondents who had seen software demos , we asked how they preferred to see the demonstration performed.
We found a slightly different preference: a live demo , a mixed format of a live demo and videos , pre-recorded videos , and other .
However, the reasons were well aligned with presenters' concerns.
A live demo shows a working system and can be more engaging, but the audience might need to wait for system problems to be resolved or sometimes see presenters rambling.
A demo video can show the most important parts, sometimes assisted by visual highlighting, but it can be hard to tell which parts of a demo are real, and can be less engaging to the audience.
To understand both presenters' and audiences' preferences for performing and viewing system demonstrations, we conducted an online survey in a software company and a university research lab.
Our goal was to co llect people's feedback on giving and seeing software demonstrations during live presentations.
Presenters Advantages Disadvantages  More engaging   May encounter unexpected system problems   Show a working system   Easy to adjust a demo based on  May forget to show important features  audience's interests   Hard to control time   Avoid system problems   Less engaging   Work with a partially working  Hard to match their narration to system or a mockup  the video content   Can edit to remove mistakes or add highlights 
From the survey results, we understand that giving a live demo is often more preferable than showing demo videos.
However, we cannot, in general, address some of the main concerns with giving a live demo - that is, stability of the software system and variations in the presentation environment which can cause the demo to fail.
Audience Advantages Disadvantages  Show that it's a working system  May need to wait for problems  to be solved   More engaging   Presenters may end up rambling   Avoid problems   Hard to tell which parts are  Show the most important parts with real  visual highlights   Want to see how the actual system works   Work with a partially working system or a mockup   Less engaging 
More specifically, our goal is to make demo videos more engaging by assisting presenters in adjusting their narration to guide the audience through the material.
In this section, we describe our design goals to support more effective demo video presentations.
To engage the audience with the demonstration, it is important for presenters to guide the audience's attention to the right place at the right time.
To do so, presenters should be fully aware of upcoming actions - specifically what actions will happen, where they will occur on the screen, and when they will happen.
While it is our desire to help presenters understand and anticipate impending events, we should not overburden a presenter who is already narrating a specific set of talking points.
As a tradeoff between providing more information and minimizing cognitive load, any augmentation of the video needs to be offered in a glanceable fashion, i.e., information can be interpreted quickly and without the presenter's full attention.
DemoWiz overlays visual annotations of events on the screencast recording in a graphical way where the events happen.
For example, in Figure 1, the presenter clicks and drags the map view to the right.
DemoWiz uses the following simple, distinctive glyphs to differentiate event types as Figure 3 shows:  Mouse click: a red circle with a radius of 20-pixels,  Double-click: a green circle with a radius of 20-pixels,  Mouse drag: a thin, orange line with a dot at the start point and an arrowhead at the end point,  Mouse scroll: a thin, yellow line, 80 pixels long, with an arrowhead, and  Keystrokes: text in blue.
At any given time during the video playback, DemoWiz shows the current event and the upcoming event on the video.
We tried to show more than two events within a fixed time period in our initial prototypes.
However, we noticed several issues.
First, the view becomes too cluttered to understand at a glance, especially when the original video is visually complex.
Second, it is not easy to convey the order of the events.
Third, it is difficult to observe when multiple events are spatially close.
Therefore, we provide minimum but essential events for recall.
Different presentations may require more or less extensive explanations, and when first recording a demo video, it may not be possible to perform the demo at the same rate necessary for a live presentation .
In addition, it should be easy to review, practice, and modify the pace for a particular presentation.
For all these reasons, lightweight editing and rehearsal are necessary.
Using these principles as a guiding rubric for our design, we iterated on several versions of the DemoWiz system.
For presenters to narrate "live" over a video recording, we propose augmenting a typical workflow from capturing a screencast video; to rehearsing it and adjusting timings; and finally to live presentation of the demo video .
DemoWiz first captures a screencast video and input events during a software demonstration from a user-defined rectangular region.
Once the recording is done, DemoWiz analyzes the low-level event stream and transforms it into higher-level events such as mouse clicks, double-clicks, and drags.
In order to help guide the presenter's attention, DemoWiz overlays a motion arrow between the current and upcoming events on the demo video .
This is inspired by storyboard design used in filming where an arrow effectively shows the movement of a camera or an actor in a single shot .
We expand the idea of guiding attention for a specific purpose: the arrow in DemoWiz shows the movement from one action  to another action .
By overlaying this motion arrow, the visualization matches the flow of a presenter's attention when they observe the video content.
Since the distance between two consecutive event segments vary, we created three visual designs to make sure the arrows are visible to lead a presenter's attention:  For two events that are located far away , apply a straight arrow .
For events that are nearly at the same location , apply a round arrow that points to the current location .
Otherwise, apply a curved arrow .
DemoWiz provides a sense of timing for an upcoming action so that presenters can adjust their narration.
First, DemoWiz embeds a progress bar in the motion arrow to show relative time .
The green bar shows the proportional time that has been passed before reaching the next event .
When a motion arrow is filled up with green, it fades away and guides the presenter to the next action.
We were concerned that people may associate the length of an arrow to the length of time.
Therefore, we also incorporated a countdown visualization where circles will fade out in the last three seconds before the next action starts  to convey absolute timing.
Figure 6 presents examples of DemoWiz visualizations with four different systems.
The glyphs effectively show the start and end points of mouse drags and the locations of mouse clicks.
Motion arrows help direct the presenter's attention between events, such as start the end of the drag event to clicking a button , clicking between several options , or selecting a specific slide after scrolling down .
During rehearsal for their demonstration, presenters can modify the video timing and add reminder notes for their narration.
DemoWiz shows the type and length of each event in a sequence in a timeline .
Each segment is shown as a block whose width indicates its length in time.
To simplify the timeline and avoid fine-grained adjustment, lengths of event blocks are rounded to the second.
Presenters can modify the playback speed of a segment by dragging the boundaries of a segment on the timeline.
For example, presenters can speed up to shorten long text inputs, and slow down for fast mouse drag inputs that select multiple objects.
Sometimes a change in the playback speed may result in an awkward effect that is noticeable to the audience, especially when showing a UI transition.
Therefore, DemoWiz supports two special time control markers to enable breaks in the narration.
Presenters can add an adjustable pause segment, at which the system will pause at the last frame of the previous segment for the specified length of time.
If presenters prefer full control on pause length, a stop marker ensures the video stays paused at the last frame of the previous segment and will not proceed until presenters manually resume the playback of the video.
DemoWiz enables presenters to add a short text note  so that they could remind themselves of upcoming actions at a higher level.
The note can be positioned manually at any location on a video so that it does not block important video content, and will be shown for 3 seconds before the associated event.
For every edit that is associated with time changes , DemoWiz computes and updates the total presentation time as well as updating the progress bar and countdown to provide accurate timing.
As with a conventional video player, presenters can control the video, to pause and play at any time.
In addition, when a video is paused , presenters can hover the mouse over the demo video in the presenter view to point out an important area, as many presenters currently do in a live demo.
DemoWiz then simulates and synchronizes a mouse cursor in the audience view to help the audience follow the demonstration.
During recording, DemoWiz captures the screen within a specified region and logs low-level system input data with timestamps  from the operating system, including:  Mouse events  and their positions .
Once presenters finish their demonstrations, DemoWiz analyzes the low-level event stream and transforms it into high-level event metadata.
For mouse events, we pair each mouse down and up into mouse clicks, double-clicks, or drags.
We group any consecutive mouse wheel events within a time threshold of 2 seconds to one scroll event and any keypress events within the same threshold to one keystroke event .
For each high-level event, we log the start and end time .
Based on the start and end times of these high-level events, DemoWiz segments the screencast video recording into event segments.
Any gap between two consecutive input events is marked as an inactive segment, which may include mouse hovering, UI transitions of the demo system, or static frames with no visual changes.
DemoWiz adjusts the boundaries of these event segments to avoid any short visual effect that cannot be observed.
DemoWiz examines segments in a linear order to ensure each segment lasts at least tmin seconds long, which is set as one second based on our early testing.
For an event segment Si of time  that tend -tstart < tmin, DemoWiz expands 0.5 second forward and backward if Si-1 and Si+1 are inactive.
If the adjusted S'i-1 and S'i+1 are shorter than tmin, DemoWiz merges it to the shorter neighbor segment.
Currently, DemoWiz does not analyze these inactive segments, but techniques including computer vision and video analysis  can be applied for finer segmentation.
The capturing program is implemented in C#.
The recorded metadata  and screencast video  are read by the Presenter UI, which is implemented using standard Web technologies, including HTML5, CSS3, JavaScript, and jQuery.
To evaluate the DemoWiz design, we conducted a controlled experiment in which participants recorded and edited a demo video, and gave a presentation with the edited video.
Specifically, we wanted to see if presenters would evaluate their own performances higher with the support of our augmented visualizations and control of timing.
Since DemoWiz allows for rapid editing of the video, it would have been unfair to compare it with a conventional video player without supporting any editing during the rehearsal phase.
We therefore modified our system to serve as the baseline condition, providing participants with the same lightweight editing of the video in each condition.
However, during presentation, the baseline condition was similar to a conventional video player that shows only the video without event timeline and augmented visualizations.
It also did not support the stop markers and text notes, i.e., participants could only adjust playback speed of each segment and add variable length pauses.
During presentation, participants only saw the video with a traditional timeline.
They could, however, pause  and resume the video manually at any time during playback.
We conducted the study as a within-subjects design in a usability room.
After recording and editing a video using the same system, each presenter gave a presentation with both systems to an experimenter.
To control the effect of order and learning, we prepared two tasks that included similar interaction flows and counterbalanced the order of the two systems--DemoWiz and Baseline--but we fixed the order of tasks.
Even though presenting to a single audience member in a usability room is not the same as using the system with a large conference audience, it is important to control the tasks and presentation as closely as possible to understand the relative benefits of the system in comparison with a baseline condition.
For each condition, we observed and coded the timing of narration that matched the video content and noted the time in seconds when an event was described before, at, or after the action happened in the demo video.
We also marked obvious breaks between narrations, errors when the narration was not about the current or following events , and misses when an important action was not mentioned.
To avoid unconscious bias that might influence the coding of the videos, we neutrally named the recordings and coded them all in a batch.
We recruited 12 participants  from a software company.
However, we excluded the data from two participants ; one was due to a software bug during one condition and another was because the participant requested to restart a presentation in one condition.
The average age of the effective 10 participants was 37.3 ranging from 24 to 64 years of age.
We recruited participants who had experience at showing a software demonstration to an audience such as giving a presentation at a conference.
Four participants were native English speakers and the rest were fluent in English.
The expertise of participants included audio processing, computer graphics, human-computer interactions, machine learning, networking, and software engineering.
Each participant was compensated with lunch coupons worth $20.
Each participant used a desktop computer running Windows 7, Expression Encoder 4 for screen recording, and a web browser for the DemoWiz user interface.
A regular mouse and keyboard were provided, along with two 27-inch displays, one for editing  and showing the audience view , and the other for the presenter view on a stand-up table.
The resolution of both displays was 1920x1200 pixels.
The average captured screen area was 1311x857 pixels.
In the presenter view, the video resolution was within 1000x600 pixels; in the audience view, the screencast videos were resized to fill the entire display with at least 100-pixel wide border in black.
During the study, the experimenter stayed in the room, providing instructions and sitting behind the participants during the recording and editing phases.
Each session consisted of one training task and two experimental tasks.
For the training task, to introduce the common features for recording and editing the video, we designed a simple workflow of five steps to demonstrate editing of a slide using PowerPoint.
The experimenter briefly demonstrated an example and then introduced the recording program that captured the screen.
Participants were then asked to practice and record using the recording program.
For each task, we provided a specific scenario along with a list of subtasks.
The experimenter walked through this list with participants to ensure that they could easily find the features that needed to be demonstrated.
Participants were then asked to practice , record , and rehearse and edit .
To help simulate a conference setting where participants would not be able to present immediately after having recorded a demonstration, we inserted an intentional 1minute gap between rehearsal and presentation.
During this gap before giving the presentation, we asked participants to watch a conference showcase video.
Participants were then asked to stand up and gave a 2-3 minute presentation to the experimenter in a usability room.
After each task, participants filled out a questionnaire of 810 questions asking about their experience .
At the end of the session, an online questionnaire was provided for them to present overall preferences and leave comments.
Each session lasted about 1.5 hours.
Figure 7 shows the average subject responses  from presenters for both systems.
We analyzed these subjective responses using a Wilcoxon signed-rank test.
We also found marginally significant differences in participants' overall satisfaction with their presentations .
Participants also tend to agree that DemoWiz helped them interpret timing .
In addition, 9 out of the 10 participants preferred DemoWiz to the system without visualization and would choose to present with DemoWiz if they were asked to give a public software demo; the remaining participant indicated no preference for both questions.
The general feedback was also encouraging.
For example, P1 commented "Awesome system.
Participants answered that they were able to understand DemoWiz visualization of input events  and found it supportive for their presentations .
They also commented that the DemoWiz visualization supported the presentation in various aspects: "the visualization reminds of the order of the content" , "Really liked the ability to know what was coming up" , "It provides better insight of the progress of the video" , and "viz gave me an idea about timing or something I was going to forget to say" .
On the other hand, in the DemoWiz condition no errors were made, and there were only one long break and one miss from two different participants, respectively.
Participants' comment s also support the fact that DemoWiz helped presenters anticipate the upcoming events.
P7 explained, " felt better able to time my speech to coincide with visual events, rather than trailing after them.
Without the event visualizations, I felt like I was talking about what the audience had just seen, rather than having my words and visuals combine to a single message."
We coded the 20 recordings of participants' final presentations to observe the timing of narration of each action in correspondence with the video content .
With DemoWiz, participants tended to anticipate the upcoming events rather than talk afterwards, where the average timing was -0.1 seconds with DemoWiz  and 0.4 seconds with the Baseline condition .
We found a significant difference in the number of times that events were anticipated by the narration, cooccurred, or occurred after the fact  = 8.6, p = .01, see Figure 8.
In general, this supports our suspicion that DemoWiz would help in anticipating an event as opposed to talking about it after it occurred.
More important though, was how often a narrator spoke about an event within several seconds of when the event actually occurred.
By defining better timing as when a presenter's explanation came within 2 seconds of a shown event , there was marginal significance by condition .
In addition, with the Baseline condition, the timing of narration was less consistent and off more, varying from 6 seconds early or 10 seconds late with a variance of 3.9 seconds, in comparison to the DemoWiz condition with at most 3 seconds early to 3 seconds late and a variance of 1.9 seconds.
Five participants had an obvious error , had a long break ,
We collected comments on the workflow.
Participants found it easy to record  their demonstrations with DemoWiz.
For editing features, they found it easy to edit in general , including controlling the playback speed  and adding pauses and stops , but it was less easy to add text notes ; only two participants used this as reminders.
Although using different strategies, all of the participants adjusted the playback speed for matching their narration.
Some sped up whenever possible and added stop markers for transitions; some slowed down the repetitive actions  to demonstrate effects.
P6 said, "I really liked being able to add `stop' events so I could `fake' my demo better."
DemoWiz made it easy for participants to separate the capturing and presentation preparation as P5 explained, "Overall, recording was very easy.
In fact, as I got to the second task, I realized that I really don't need to think about the words as I record because later on I will be able to slow down and speed up time ..." On average, the length of demo videos was 2'09" before editing and 2'05" after editing, and the presentation was 2'38" long.
Each participant spent 7.5 minutes on average to edit.
For each demo of 44 segments on average, participants adjusted 3.15 segments for speedup and 4.25 segments for slowdown, and added 0.55 pause markers.
In the DemoWiz condition, 1.2 stop markers and 0.2 text notes were added.
DemoWiz is an attempt to make demo videos more engaging by helping presenters anticipate the upcoming events rather than reacting to them, leveraging a refined workflow with augmented visualizations.
Overall, participants liked the DemoWiz visualization, finding it supportive rather than distracting.
For examples, P4 said, "Event visualization was very powerful - definitely the way to go."
This corresponds with our goal of designing the visualization with a minimal cognitive load.
Presenters do not have to prepare a complete script for exact timing.
They also do not have to repeat recording many times to grab the best recording.
Some participants appreciated our design choice of providing only minimum but essential editing capabilities to make the process as light as possible.
P2 mentioned that "Ironically, I think it's better to have limited editing feature set -- this system was very easy to learn/use."
A few participants expressed the need for more editing features: P1 explained, " cutting events in parts so that I can slow down/speed up/remove portions of, e.g., a mouse trajectory"; P3 wanted to "flip segments around" and P8 thought "break up or merge blocks" would be helpful.
We found these interesting as the system enabled more possibilities, but there is a tradeoff between providing a powerful tool and lowering the burden in editing.
We believe that this is a design choice that needs to be balanced.
Our system does not support combining two or more video clips for a presentation.
Sometimes, presenters may also want to update part of the existing material to show new features of their developing systems.
For example, P4 explained that he would like to see "the ability to record multiple clips and insert them in a timeline."
This would be straightforward future work because the current DemoWiz framework is designed to be able to implement this.
Editing can still be limited to support fine timing control of narration.
P10 explained, "The length of narration changes each time I present, and it is difficult to perfectly align the timing."
Automatically navigating a video based on presenters' performances could be an interesting avenue of exploration, similar to scenarios of following a tutorial  or performing music .
However, we decided not to pursue this approach because it would present its own form of risk relying on unreliable speech recognition during a live presentation.
Also, considering the time constraints presenters usually have, we chose to provide full control for presenters rather than trying to intelligently update a video.
Although our current implementation is focused on software demonstrations, we argue that it is possible to expand our system design to more advanced inputs.
By defining event types that a system recognizes , it is possible to log the events and align them with the captured video for later use.
In addition, the enhanced presentation mode can be potentially applied to other domains where knowing the timing and the sequence of events is crucial, such as narrating over animated presentation slides with dynamic graphical objects.
DemoWiz is an important first step towards validating this general approach and we believe our work could inspire future research in these directions.
This paper introduces DemoWiz, a system with a refined workflow that helps presenters capture software demonstrations, edit and rehearse them, and re-perform them for an engaging live presentation.
DemoWiz visualizes input events and guides presenters to see what's coming up by overlaying visual annotations of events on the screencast recording where the events happen in a screencast video.
It also provides lightweight editing for presenters to adjust video playback speed, pause frames, and add text notes.
A user study showed that DemoWiz was effective in helping presenters capture timing and narrate over a demo video.
In our user study, we gathered presenters' opinions as to how engaging their presentation was, and we explored the relative timing of the narration to events in the video.
Ultimately, however, our goal is to help increase audience engagement.
Measuring audience engagement is an ongoing topic of research, and we would like to explore ways of quantifying the relative impact of the DemoWiz system, but that work was out of scope for this project.
Some participants commented that it would be helpful to highlight certain input events for the viewers to observe subtle changes.
For example, P10 wanted to enable, "visualize mouse events such as clicks and scrolls for the audience so they know what is going on."
The current DemoWiz framework makes it easy to achieve this goal by highlighting the audience view only when the event happens.
