Pen-based user interfaces are becoming ever more popular.
G e s t u r e s  are a valuable aspect of pen-based UIs, but they also have drawbacks.
The challenge in designing good gestures is to make them easy for people to learn and remember.
With the goal of better gesture design, we performed a pair of experiments to determine why users find gestures similar.
From these experiments, we have derived a computational model for predicting perceived gesture similarity that correlates 0.56 with observation.
We will incorporate the results of these experiments into a gesture design tool, which will aid the p e n - b a s e d UI designer in creating gesture sets that are easier to learn and more memorable.
Pen and paper is a versatile, powerful, and ubiquitous technology .
Pen-based user interfaces are becoming more widespread  and have great promise in power and versatility .
Gestures, or commands issued with a pen, are one desirable feature of pen-based UIs.
Because command and operand can be specified in one stroke, they are fast .
They also are commonly used and iconic, 1 which m a k e s t h e m e a s i e r to r e m e m b e r than textual commands .
Gestures are useful on displays ranging from the very small, where screen space is at a premium, to the very large, where controls can be more than arm's reach away .
A survey of PDA users  showed that users think gestures are powerful, efficient, and convenient.
They want more gestures in applications and the ability to define their own gestures.
However, the survey also revealed problems with gestures.
Specifically, users often find gestures difficult to remember, and they become frustrated when the computer misrecognizes gestures.
Users of other systems have also found gestures to be awkward .
By "iconic", we mean that the gesture shape suits or suggests its meaning.
To copy otherwise, to republish, to post on serve1~or to redistribute to lists, requires prior specificpermissionand/or a fee.
We believe gestures can be difficult to use because they are difficult to design.
We are developing a tool to assist penbased UI designers in creating and evaluating gestures for pen-based UIs .
The primary benefit of the tool will be to advise designers about how to improve their gesture set.
This advice will enable the designer to improve their gestures early in the design process before investing in expensive user studies.
The current work is an investigation into gesture similarity.
P e r c e i v e d similarity is useful for designers to know because it affects how easily users can learn and remember the gestures.
We contend that similar operations with a clear spatial mapping, such as scroll up and scroll down, should be assigned similar gestures.
Conversely, gestures for more abstract operations that are similar, such as cut and paste, may be easily confused if they are visually similar.
To d e t e r m i n e what features affect p e r c e i v e d gesture similarity, we ran a pair of experiments to measure the similarity of a variety of gestures.
The data collected in these experiments enabled us to derive an algorithm for computing how similar novel gestures are.
In conjunction with information about the impact of gesture similarity on their ease of learning and recall , this will allow our gesture design tool to provide better advice.
The remainder of the paper is organized as follows.
The first section discusses related work.
The next section describes the gesture similarity experiments.
A discussion of the results of both experiments follows.
Finally, we present future work and conclusions.
This section discusses relevant prior work.
The first subsection gives some background on p e n - b a s e d user interfaces, which is the context for this work.
The second discusses prior work on perceptual similarity of gesture-like shapes.
The last section introduces m u l t i - d i m e n s i o n a l scaling, a data analysis technique used in our experiments.
The device that popularized pen input was the Apple Newton MessagePad.
It was designed primarily for pen input.
It minimized the use of overlapping windows and encouraged the user to focus on one document at a time.
Its core applications were a notepad, to-do list, calendar/ scheduler, and address book.
Perceptual similarity P s y c h o l o g i s t s have investigated similarity of simple geometric shapes, which are less complex than our gestures.
Attneave studied how changes in geometric and perceptual properties of different kinds of simple figures influenced their perceived similarity .
Participants in one experiment reported how similar they perceived parallelograms of differing sizes and tilts to be.
Attneave found that similarity was correlated with the log of the area of the parallelograms and with their tilt.
Also, parallelograms that were mirror images of one another were perceived as similar.
It also supported a small number of gestures for editing text and drawings.
Our work deals with the same type of gesture used on the Newton: single-stroke and iconic.
The Newton's handwriting recognition was widely criticized when it was first introduced, but by the last model the recognition had greatly improved.
More recently, the 3Com PalmPilot has become a popular pen-based platform.
Its display is even smaller than the Newton's.
Its applications have very few on-screen controls, and the pulldown menu at the top of the screen is normally hidden.
Its core applications are the same as the Newton's.
The Pilot does not recognize normal English letters, but uses the Graffiti character set , which must be entered in a dedicated area of the screen.
It does not use gestures of the kind we focus on, but instead uses a keyboard accelerator facility.
The user may write a special "command" stroke to indicate that the next stroke is a command.
For example, in many applications "command" followed by the "d" stroke invokes the delete operation.
These applications have included spreadsheets, word processors, a disk manager, music editors, an equation editor, a GUI design tool, an air-traffic control UI, and note-taking applications .
Pens performed well for many of these applications.
In their standard office applications, Briggs and associates found that users liked using a pen for navigation and positional control, although not for text entry .
This is in spite of a lack of pen-specific interaction techniques.
Wolf and colleagues added pen input and gestures for editing operations to a drawing application, a spreadsheet program, a music editor, and an equation editor .
Users reported that gestures were easier to recall than keyboard commands, and edited spreadsheet documents 30% faster with the pen than with keyboard.
Zhao used a combination of gestures and menus to facilitate object creation in a structured drawing program .
It allowed users to draw the object creation gesture and select from the object type menu in either order.
This technique could allow rapid access to many commands while limiting the number of gestures that the user is required to learn.
L a n d a y d e v e l o p e d an i n t e r f a c e design tool based on sketching that was well-suited for pen input and gestures .
It used iconic gestures of the same type as the ones in our study for creating and editing the UI elements.
Chatty and Lecoanet discussed how pen input and gestures are useful for air-traffic control .
Their interface allowed controllers to navigate the airspace and change aircraft attributes such as speed and heading.
An evaluation of their system showed that although a few gestures had to be modified because of confusion, they were still useful.
Lopresti and Tomkins advocated treating electronic ink as a first class datatype .
They developed a prototype system that supported ink input and searching based on matching feature vectors.
This technique was used to search a library of gestures using the gesture as the key.
We concentrate on gestures in the spirit of copy editing  rather than marking menus , because we believe that traditional marks are more useful in some circumstances.
For example, they can specify operands at the same time as the operation, and they can be iconic.
Another study by Attneave indirectly measured perceived similarity by measuring how easily names of triangles and squares were remembered.
The squares varied in reflectance and area; the triangles varied in tilt and area.
The result of these experiments indicated that similarity of form caused more confusion than similarity of area.
Based on these experiments, Attneave concluded the following.
In general, the logarithm of quantitative metrics was found to correlate with similarity.
Also, if the range of differences in stimuli is small, these differences are linearly r e l a t e d to p e r c e i v e d s i m i l a r i t y , and w h e n m u l t i p l e dimensions of the stimuli change, their dimensions combine nearly linearly to give the change in perceived similarity.
When the range of differences is large, the relationship between stimuli value and similarity is not linear, and the stimuli do not combine linearly.
Lazarte and colleagues studied how rectangle height and width affected perceived similarity .
They found that reported similarity was related to rectangle width and height and they derived a model to fit the reported similarity data.
Also, they found that not only did different people use different similarity metrics, but that the same participant may have used different metrics for different stimuli.
Multi-dimensional scaling M u l t i - d i m e n s i o n a l scaling  is a t e c h n i q u e for reducing the number of dimensions of a data set so that patterns can be more easily seen by viewing a plot of the data, usually in two or three dimensions.
It takes as input one or more sets of pairwise proximity measurements of the stimuli.
It outputs coordinates and/or a plot of the stimuli in a predetermined number of dimensions  such that the pairwise inter-stimuli distances in the new space correlate with the input proximities of the stimuli.
There are several decisions to make in using MDS.
One is how to use data f r o m multiple participants.
A simple method is to average the pairwise proximities and analyze the resulting proximity matrix as if it came from a single participant.
However, there is evidence that this method does not give good results , and it also p r o h i b i t s analyzing the differences among participants.
Fortunately, we were able to use a version of MDS, INDSCAL , that takes as input a proximity matrix for each participant and takes individual differences into account.
When p is 2, this is Euclidean distance.
Another common p value is 1, in which case it is called city-block or Manhattan distance.
Infinity is also sometimes used for p, which makes the sum equal to the distance along the dimension that differs most.
There are sometimes psychological reasons to prefer cityblock or Euclidean , but generally researchers use the metric that fits their data best.
The final step in MDS analysis is assigning meaning to the axes.
Sometimes the experimenter may know the axes in advance.
P a r t i c i p a n t s w e r e first s h o w n an o v e r v i e w o f the experiment, which outlined the tasks they would perform.
Participants were then shown the tablet and the task was explained to them.
The program displayed all possible combinations of three gestures, called triads.
The order of the triads was r a n d o m i z e d i n d e p e n d e n t l y for each participant, as was the on-screen ordering of gestures within each triad.
Figure 2 is a representative screen shot of the triad program.
For each triad, participants selecte!
The p r o g r a m r e c o r d e d the selections of the users and computed the dissimilarity matrix.
The program was run using a practice gesture set of five gestures, shown in Figure 3, so that participants could b e c o m e f a m i l i a r with the p r o g r a m and the tablet.
Participants were asked to select the gesture in each triad that seemed most different to them.
After the practice, they performed the task again using the experimental gesture set of fourteen gestures .
To better understand the principles people use to judge gesture similarity, we performed an experiment to measure how people perceived similarity among gestures in a predefined set.
We hoped that the experiment would enable us to derive metrics for predicting the human-perceived similarity of gestures.
We ran this experiment twice with different data sets and different subjects in order to confirm our results.
The two trials are described below.
In the first experiment, we attempted to make a gesture set consisting of gestures that varied widely in terms of how people would perceive them.
The gesture set is shown in Figure 1.
We considered whether the participants should draw the gestures or not.
Drawing them would mimic actual usage more closely, but it would have lengthened the experiment.
In order to a c c o m m o d a t e more participants and more gestures, we decided not to have participants draw the gestures.
Instead, the test program animated the gestures to show participants the dynamic nature of the gestures.
We recruited twenty-one people from the general student population to participate in the experiment.
We only required that they be able to operate the computer and tablet.
Each participant was paid $10 .
ALSCAL uses more information than standard MDS, so it is reasonable to think that more dimensions would be valuable.
Unfortunately, we were unable to find an analysis of how many.
Cosine of initial angle Sine of initial angle Size of bounding box Angle of bounding box Distance between first and last points 6.
Cosine of angle between first and last points 7.
Sine of angle between first and last points 8.
Total angle traversed / total length 15.
Area of bounding box 19.
Total angle / total absolute angle 21.
Log Table 1 Possible predictors for similarity.
Features 1-11 are taken from Rubine's recognizer.
Bold features were found to be significant and so are used in the model.
This questionnaire was a web form that was filled out on a different computer than the one used for the experimental task .
The first goal was addressed using plots of gestures generated by MDS.
In these plots, the Euclidean intergesture d i s t a n c e s c o r r e s p o n d e d to the i n t e r - g e s t u r e dissimilarities reported by the participants.
By examining these plots, we were able to determine some geometric features that contributed to similarity.
To determine the number of dimensions to use, we did MDS in two through six dimensions and examined plots of stress and goodnessof-fit  versus dimension to find the "knee" in the curve 3.
Similarity data was analyzed with MDS as interval/ratio and as ordinal.
The ordinal model gave a better fit, so it was used for all subsequent analysis.
We used Euclidean distances since it provided a better fit to our data than the city-block metric did.
The second goal was achieved by running regression analysis to determine which of many measurable geometric features of a gesture correlated with the reported similarity.
Regression also produced weights indicating how much each feature contributed to the similarity.
To compute the s i m i l a r i t y of two gestures, their feature values are computed.
The feature values and weights together give the positions of the gestures in feature space.
The similarity of the gestures is given by the Euclidean distance between the two gestures in the feature space, where smaller distance means greater similarity.
The features used in our regression analysis came from a few sources.
Some features were taken from Rubine's gesture recognizer .
Others were inspired by plots from the MDS analysis.
The list of features that we thought might predict similarity is given in Table 1.
We wanted our model to be c o m p u t a b l e , so we did not include in the final regression analysis features whose values were only obtainable by subjective judgement.
4 It was observed in the MDS plots that short, wide gestures were perceived as being very similar to narrow, tall ones and that both types were perceived as different from square gestures.
Angle of bounding box represented the difference between thin and square gestures, but not the similarity of tall vertical and short horizontal ones.
We created the aspect feature to represent this relationship.
Table 2 shows which features strongly correlate with each dimension, based on a regression analysis.
Although the most important  dimensions are predicted by relatively few features, the other dimensions require many features.
A s e p a r a t e r e g r e s s i o n a n a l y s i s was done for each dimension, using the computed feature values as the independent variables.
From these regressions we derived a set of equations to predict the position of an arbitrary gesture in the feature space.
We were able to derive a model of gesture similarity that correlated 0.74  with the reported gesture similarities.
The multi-dimensional scaling indicated that the optimal number of dimensions was five .
For ease of comprehension, we plotted the gesture positions two dimensions at a time.
Examination of the plot of dimensions 1 and 2  quickly showed that dimension 1 was strongly correlated with how "curvy" the gestures were - - for example, g5 and g40 are curvy and g32 and g28 are straight.
The curviness metric was derived in an 3.
Examination of stress vs. dimension and r 2 vs. dimension is a standard MDS technique for determining dimensionality.
Figure 4 MDS plot of dimensions 1 and 2 for first similarity experiment.
Curviness of a gesture was computed by adding up all intersegment angles within the gesture whose absolute value was below a threshold .
The threshold was chosen so that the metric would agree with the author's curviness judgements of gestures in trial 1.
Correlated features  Curviness, Angle / distance 2 Total absolute angle, Log 3 Density 1, Cosine of initial angle 4 Cosine of angle between first and last points, Cosine of initial angle, Sine of initial angle, Distance between first and last points, Angle of bounding box 5 Aspeci, Sharpness, Cosine of initial angle, Total angle Table 2 Predictor features for similarity trial 1, listed in decreasing order of importance for each dimension.
The derived model predicts the reported gesture similarities with correlation 0.74 .
The MDS model upon which it is based fits the data only slightly better, so this is a good fit.
Another interesting aspect of trial 1 was the differences among participants.
As expected, the degree that different features affected similarity j u d g e m e n t s varied across participants.
This disparity is consistent with the finding in other perception experiments that different people judge similarity using different features .
What was surprising was that the participants seemed to be clumped into two distinct groups.
We separated the data for the two groups of participants and analyzed them separately.
However, the resulting MDS models were not as good as the original, combined model, so we did not pursue the analysis further.
It would be interesting to see if more participants reinforced this trend and illuminated a pattern.
Participants took an average of 26 minutes to complete the experimental task.
The total time for each participant was approximately 40 minutes.
The results of the first similarity trial were encouraging, but we wanted to test the predictive power of our model for new people and gestures.
We also were interested in exploring how systematically varying different types of features would affect perceived similarity.
To investigate how varying particular features would affect perceived similarity, three new gesture sets of nine gestures each were created.
The first was designed to explore the effect of total absolute angle and aspect .
The second was designed to explore length and area .
The third was designed to explore rotation-related features such as cosine and sine of initial angle .
In addition to examining the effects of particular features, we wanted to determine the relative importance of the features.
The most straightforward way to perform this test is to c o m b i n e all g e s t u r e s into one big set and h a v e participants look at all possible triads from the combined set.
Unfortunately, combining all of these gesture sets into one results in far too many triads, based on the time per triad taken for the first experiment.
To allow us to compare the three sets against one another without a prohibitively large gesture set, two gestures from each of the three gesture sets were chosen and added to a fourth set o f gestures .
All participants were shown all possible triads from all four gesture sets.
This trial was analyzed using the same techniques as the first trial, MDS and regression.
First, a combined analysis was done, using the data from all four gesture sets.
The goal of the combined analysis was the same as trial one: to determine what features were used for similarity judgements and to derive a model for predicting similarity.
Many pairwise dissimilarity measures were missing from the data, because not all possible triads of all gestures were presented to the participants.
However, this was not a problem because MDS can accommodate missing data.
In addition to the combined analysis, data from each of the first three sets was analyzed independently.
The focus of the independent analyses was to determine how the targeted features affected similarity judgements.
Lastly, the results of trial 1 were used to predict the p e r c e i v e d similarity of the gestures in trial 2.
Unfortunately, when the data was plotted, the meaning of the dimensions was not as obvious as in trial 1.
The derived model predicts the reported gesture similarities with correlation 0.71 .
Analysis of the first gesture set  gave a three dimensional MDS plot.
This gesture set was intended to show the effects of absolute angle and aspect.
Unfortunately, the absolute angles of gestures in this set covaried greatly with the values of several other features, so it was not possible to determine whether absolute angle was significant.
Strong covariance with other features was not a problem for aspect.
H o w e v e r , bounding box angle c o r r e l a t e d even m o r e strongly with dimension two  than aspect did.
Data from the second gesture set  were surprising.
It was intended to discover the effect of length and area, but although length and area correlate well with dimension four , they are both only weakly correlated with the first three dimensions .
Since INDSCAL dimensions are ranked in order of importance, it appears that neither length nor area are very significant contributors to similarity judgement.
The third gesture set  also provided interesting results.
One might expect similarity among gestures that are rotations of one another to be proportional to the amount of rotation, but this was not the case.
Instead, the gestures whose lines were horizontal and vertical were perceived as more similar to one another than to those gestures whose components were diagonal.
The perceived similarity of gestures whose components are aligned in the same directions is consistent with findings on texture in the vision community .
This set was analyzed in five dimensions.
U n l i k e trial one, the participants did not separate easily into two groups, but consisted instead of one clump with outliers trailing off.
We experimented with removing outliers from consideration, but they did not appreciably improve the MDS model.
To validate the models produced by the two trials, each model was used to predict the similarities between all pairs of gestures used in the other trial.
These predictions were compared with the reported similarities from the other trial.
Based on these correlations, the model derived from experiment 1 is a slightly better predictor of gesture similarity than the model from experiment 2.
Human perception of similarity is very complicated, even for simple shapes .
Shapes like pen gestures can be viewed as similar or dissimilar based on many different perceptual cues.
In the face of this difficulty, we are pleased at how well our model predicts similarity.
We were pleased to find that a small number of features explain the three most salient dimensions.
In experiment 1, we saw that dimensions one through three can be predicted b a s e d on o n l y two f e a t u r e s each.
S e v e r a l p o s s i b l e explanations exist for the larger number of features needed for dimensions four and five.
One is that the underlying perceptual model is complex.
Another is that the gesture set used in the experiment was not complex enough or did not vary in the right way to illuminate those dimensions.
It was surprising to us that neither length nor area were significant factors in e x p e r i m e n t 1, so the "60" series  in trial 2 was designed to investigate the effect of these two features.
Our results are consistent with Attneave's .
We found that the l o g a r i t h m of aspect had m o r e i n f l u e n c e on similarity than aspect itself.
Also, the range of distances among feature values of our" gestures was large and did not combine linearly .
Design and Analysis The primary challenge in designing both the similarity and memorability experiments was creating good stimuli .
For the first similarity experiment, we wanted the stimuli to span the perceptual feature space.
However, this was difficult because we did not know the structure of the perceptual feature space in advance.
We culled gestures from an informal survey of colleagues and from another experiment  in an attempt to create a "well-rounded" gesture set.
For the second similarity trial, we wanted gestures that varied with respect to particular features.
Our gesture design tool  was modified to display valdes for these features, but the process was still difficult.
In particular, some of the features we wanted to investigate covaried with other features, which made the results difficult to interpret.
We were concerned at the outset that developing a model for similarity would be complicated by differences among the participants.
However, in spite of the individual differences the model does have predictive power.
Although analyzing different groups of participants separately was not useful for our data, more data might make it feasible to create multiple models, each of which models a subset of users well.
In that case, a gesture design tool could use multiple similarity metrics and notify the designer about similar gestures along any metric.
The designer may want two gestures to be similar or dissimilar, depending on the semantics of the operations they are used for.
The two similarity experiments each resulted in a model for similarity, and they are different.
It is difficult to say which is better, but we think the model from trial one is sligh~tly preferable.
It predicts the data from the other trial slightly better than trial two predicts its data.
Also, it uses more features, and thus may capture more about the underlying psychological model.
We found MDS to be very useful, but also limited.
It was extremely helpful in the early stages of analyzing trial one, when we had little idea of what features m i g h t affect similarity.
It inspired us to invent several significant features, including curviness, aspect, and density.
Another potential benefit of MDS is the ability to analyze differences in participants, which are discussed above.
Although it was useful for discovering candidate predictors for similarity, our use of MDS was qualitative.
For the quantitative analysis, when we needed to create a predictive model, we used standard linear regression.
FUTURE WORK We h a v e run an e x p e r i m e n t to i n v e s t i g a t e g e o m e t r i c properties of gestures that influence learning time and memorability, and to explore how similarity relates to learnability and memorability.
The analysis is not complete, but preliminary results indicate that when similar gestures are used for similar operations, they are easier to remember.
In Human Factors in Computing Systems .
Saliency metric for subadditive dissimilarity judgments on rectangles.
Implications for a gesture design tool.
In Human Factors in Computing Systems .
1 of Advances in Human Factors~Ergonomics.
Information Processing Society of Japan and others, Elsevier Science, Jul.
Implicit structures for pen-based systems within a freeform interaction paradigm.
In Human Factors in Computing Systems .
International Journal of ManMachine Studies, 1990.
Center for the Study of L a n g u a g e and Information; Cambridge University Press, Stanford, Calif.: Cambridge ; New York, 1996.
In Proceedings of the ACM Symposium on User Interface and Software Technology .
12B of Advances in Human Factors~Ergonomics.
Lawrence Erlbaum Associates, Hillsdale, NJ, 1987.
20B of Advances in Human Factors/Ergonomics.
Information Processing Society of Japan and others, Elsevier Science, Jul.
Gestures are an important part of penbased UIs, and we believe that designers of pen-based UIs c o u l d g r e a t l y b e n e f i t f r o m a g e s t u r e d e s i g n tool that informed them o f gestures that may be difficult for the computer to recognize or for people to learn and remember.
For e x a m p l e , it w o u l d be interesting to measure memorability and similarity of other gestures to validate and/or refine our current models.
Also, in the two experiments described here, participants saw animated gestures but did not draw them.
It is possible that different similarity criteria would emerge if participants drew the candidate gestures before judging their similarity.
Gesture set designers may want their gestures to be similar or dissimilar depending on the semantics of the operations.
W i t h t h e s e f e a t u r e s , we h a v e d e r i v e d a computable, quantitative model for perceptual similarity of gestures that correlates 0.56 with reported similarity.
Using our model, we can predict how similar people will perceive gestures to be.
We expect similarity predictions to be a useful addition to our gesture design tool.
Our model and our experiences of experimental design and analysis should provide an excellent starting point for further investigation into gesture similarity, memorability, and learnability.
When integrated with our gesture design tool, our model will allow designers to create gestures that are more memorable and learnable by users.
American Journal of Psychology, 1950.
A theory of textural segmentation.
8 of Notes and Reports in Computer Science and Applied Mathematics.
Proceedings of the Conference on Human and Machine Vision, Aug. 1981.
In User Centered System Design: New Perspectives on Human-Computer Interaction .
In Human Factors in Computing Systems .
In Proceedings of the ACM Symposium on User Interface and Software Technology .
In Human Factors in Computing Systems .
