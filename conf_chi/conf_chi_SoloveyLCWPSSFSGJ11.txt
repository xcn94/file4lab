Multitasking has become an integral part of work environments, even though people are not well-equipped cognitively to handle numerous concurrent tasks effectively.
Systems that support such multitasking may produce better performance and less frustration.
However, without understanding the user's internal processes, it is difficult to determine optimal strategies for adapting interfaces, since all multitasking activity is not identical.
We describe two experiments leading toward a system that detects cognitive multitasking processes and uses this information as input to an adaptive interface.
Using functional near-infrared spectroscopy sensors, we differentiate four cognitive multitasking processes.
These states cannot readily be distinguished using behavioral measures such as response time, accuracy, keystrokes or screen contents.
We then present our human-robot system as a proof-of-concept that uses real-time cognitive state information as input and adapts in response.
This prototype system serves as a platform to study interfaces that enable better task switching, interruption management, and multitasking.
Multiple windows, multiple monitors and large displays make it possible for the interface to handle multitasking, and many researchers have investigated how best to support the user who is balancing multiple tasks.
Because multitasking can elicit several different cognitive states, the user's needs during multitasking may change over time.
However, it is difficult to determine the best way to support the user without understanding the internal cognitive processes occurring during task performance.
In this paper, we describe a preliminary study and two experiments using neural data in which we identified four mental processes that may occur during multitasking and have direct relevance to many HCI scenarios.
These processes are almost indistinguishable by examining overt behavior or task performance alone.
However, using our non-invasive brain-sensing system  with functional near-infrared spectroscopy , we can automatically distinguish these four states.
By detecting specific cognitive states that occur when multitasking, we can build user interfaces that better support task switching, interruption management and multitasking.
We show an example of this with a proof-of-concept adaptive human-robot system that can change behavior based on brain signals received.
This prototype system serves as a platform to provide the basis for designing and evaluating future brain-based adaptive user interfaces, with broader applications beyond human-robot team tasks.
Multitasking has become an integral part of work environments, even though people are not well-equipped to effectively handle more than one task at a time .
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
In the Delay scenario, the secondary task requires little attention, but the primary task goal is held in working memory.
In the Dual-Task scenario, both primary and secondary tasks require attentional resources to be allocated for each task switch, but goals are not held in working memory.
Branching has characteristics of both Delay and Dual-Task scenarios .
This paper makes the following contributions: We show that specific cognitive multitasking states, previously studied with fMRI, can be detected automatically with fNIRS which is more practical in HCI.
We moved from a simple letter-based task in previous work to actual HCI-related tasks that elicit similar states.
We show a working proofof-concept human-robot platform that supports adaptive behavior based on the cognitive states detected with fNIRS.
Although computers are capable of handling multiple processes simultaneously, people have a difficult time due to high mental workload from increased working memory demands and the overhead of switching context between multiple tasks.
Repeated task switching during an activity may lead to completion of the primary task with lower accuracy and longer duration, in addition to increased anxiety and perceived difficulty of the task .
The challenge is to devise an effective way to measure workload and attentionshifting in a dynamic environment, as well as to identify optimal support for multitasking.
When managing multiple tasks, interruptions are unavoidable.
To address this, researchers have developed systems that try to identify the cost associated with interruption based on different inputs, such as desktop activity, environment context , eye tracking , or other physiological measures such as heart rate variability and electromyogram  and handle interruptions accordingly.
They have found interruptions to be less disruptive during lower mental workload .
Other studies tried placing interruptions near the beginning, middle or end of a task , at task boundaries , or between repetitive tasks which were considered as more interruptible .
It was also shown that interruptions relevant to the main task tend to be less disruptive for the users than irrelevant interruptions .
Various interruption schemes may affect performance in different ways; however, there is no universally optimal interruption scheme.
Interrupting the user as soon as the need arises, for example, emphasizes task completeness over accuracy, while allowing the user to defer interruptions indefinitely does the opposite .
McFarlane  discusses four distinct methods for coordinating interruption--immediate, negotiated , mediated , and scheduled -- and found that no optimal method existed across users and tasks.
Thus, it is crucial that the style of interruption adapts to the task.
Systems have been developed that quantify the optimal time to interrupt a user by weighing the value against the cost of interruption .
In addition to determining the optimal time for switching tasks, researchers have tried to determine the best method for reminding users of pending background tasks.
Miyata and Norman  note that important alerts specifically designed for someone who is deeply engaged in another task would most likely be inappropriate and may even be disruptive in other situations.
Managing mental workload has long been an active topic in HCI research and high mental workload has been identified as a cause of potential errors .
Researchers have shown that different types of subtasks lead to different mental workload levels .
As a measure for mental workload, researchers have proposed pupil dilation  in combination with subjective ratings as this is non-invasive, and allows the user to perform the tasks as the data is processed in real time.
Other physiological measures, including skin conductance, respiration, facial muscle tension and blood volume pressure, have also been used to detect cognitive or emotional states to improve machine intelligence .
While adaptive user interfaces may be designed to reduce mental workload, any automation may also result in reduced situation awareness, increased user complacency and skill degradation, and these human performance areas should be evaluated in the system .
Real-time cognitive state information can inform the tradeoffs to create intelligent user interfaces.
Design of user interfaces that employ real-time cognitive state information has become an emerging topic in HCI recently .
Much of this work has used brain sensing as explicit input to the system to make selections or control the interface , although there have been examples of passive brain sensing to be used either as implicit input or for evaluation of user interfaces .
Our work focuses on using fNIRS sensors to detect signals users implicitly produce while interacting naturally with a system.
These sensors detect changes in oxygenated and deoxygenated blood in a region of the brain by using optical wires to emit near-infrared light .
The sensors are easy to use, have a short set-up time and are portable, all characteristics which make fNIRS suitable for use in realistic HCI settings .
However, because it is a novel technique for brain sensing, there have been few studies showing specific measurements with fNIRS and their appropriate use in HCI.
Multitasking behavior involves several high-level brain processes, which vary depending on the types of tasks and the interaction between the tasks.
These are the foundation for the studies described here.
Branching  is illustrated by the following scenario: A user is tackling a complex programming task but is interrupted by an incoming email from her boss that is time sensitive.
Thus, the user must "hold in mind goals while exploring and processing secondary goals" .
Branching processes are triggered frequently in multitasking environments and pose a challenge to users.
These tasks are referred to as dual-task because there are two tasks that require attentional resources .
The third multitasking paradigm is illustrated with the following scenario: A user is tackling a complex programming assignment and at the same time gets instant messages which the user notices, but ignores.
Here, the secondary task is ignored and therefore requires little attentional resources.
They refer to this as delay because the secondary task mainly delays response to the primary task .
In their experiment, Koechlin et al.
Their task involved processing rules based on letters appearing on the screen.
Each stimulus was either an uppercase or lowercase letter from the word "tablet."
The expected response from the user was different depending on the case of the letter, so switching between uppercase and lowercase letters would be similar to balancing two tasks.
When the case changes, is the first letter in the series a `T' or `t'?
If the letter is lowercase, respond as in Dual Task.
We then followed with two experiments that look at distinguishing the cognitive multitasking states in other scenarios besides the "tablet" task to investigate whether these are generic cognitive processes, and not simply tied to the particular task used in the earlier study.
Finally, we designed and built a proof-ofconcept platform that recognizes and classifies the fNIRS signal and uses it as input to drive an adaptive human-robot system.
Our preliminary experiment extends Koechlin et al.
We wanted to determine whether we could distinguish between branching, dual-task and delay situations.
These states were successfully distinguished using fMRI , but fMRI is not practical in HCI settings.
Our hypothesis was that the same could be achieved using fNIRS.
Since the sensors are placed on the forehead, they are particularly sensitive to changes in the anterior prefrontal cortex, where Koechlin et al.
Three participants wore fNIRS sensors as they performed the experimental tasks.
To trigger the three cognitive states, we used the same experimental paradigm used in .
To determine whether these tasks could be distinguished, we performed leave-one-out cross validation in Weka  to classify the fNIRS sensor data.
In MATLAB, the fNIRS signal was detrended by fitting a polynomial of degree 3 and then a low-pass elliptical filter was used to remove noise in the data.
Using support vector machines, we achieved reasonably high accuracy classifying the tasks across the three participants .
This was a small sample of users, and we hope to achieve higher accuracy, but found the results encouraging enough continue in this research direction.
From the promising results of the preliminary study, we investigated whether we could detect these three states in other tasks and domains that are more relevant to interactive user interfaces.
Our hypothesis was that the cognitive functions elicited in the "tablet" tasks were generic processes that occur during multitasking.
Numerous HCI scenarios involve multitasking, and we chose a humanrobot team scenario to further explore the detection of cognitive multitasking in user interfaces.
Human-robot team tasks inherently involve multitasking, as the user is both performing his or her part of the task, while monitoring the state of the robot.
The significance of these two experiments lies in the fact that all experimental conditions had the same stimuli and the same possible user responses, so the conditions could not be easily distinguished from one another by simply observing the participant.
Using fMRI, however, it became possible to distinguish the conditions based on the distinct mental processes  elicited by each task.
In addition, the cognitive states identified in these experiments have direct relevance to many HCI scenarios, particularly when a user is multitasking.
Automatically recognizing that the user is experiencing one of these states provides an opportunity to build adaptive systems that support multitasking.
For example, by recognizing that most interruptions are quickly ignored, as in the delay condition, the system could limit these types of interruptions or reduce their salience as appropriate.
Further, if a user is currently experiencing a branching situation, the interface could better support maintaining the context of the primary task, whereas during dual-task scenarios this would be unnecessary.
Finally, distinguishing between predictive and random scenarios could trigger the system to increase support when the user's tasks become unpredictable.
This paper builds from their experiments with the goal of designing interfaces that recognize these states and behave in appropriate ways to support multitasking.
Thus, the simple wordrelated task was replaced by a human-robot interaction  task that has similar properties.
We conducted two separate experiments which built from the human-robot team task described by Schermerhorn and Scheutz  and adjusted it to include tasks that would induce delay, dual-task and branching, similar to our preliminary study.
The tasks involved a human-robot team performing a complex task that could not be accomplished by the human nor the robot alone.
The robot and the human had to exchange information in order to accomplish the task.
The robot continually updated the human operator with status updates to which the human responded.
In the two separate studies, the participant worked with a robot to investigate rock types on the surface of Mars and had to perform two tasks.
The robot presented the participant with status updates, either about a newly found rock or a new location to which it moved.
Each rock classification update informed the user of the newly discovered rock's class, which was based on size and ranged from Class 1 to Class 5.
Each location update alerted the user of the robot's current location.
The spacecraft to which the robot was transmitting could detect the robot's location to the nearest kilometer and assumed the robot was moving in a straight line.
Thus, the location updates presented to the user ranged from 0 to 800 meters, in 200 meter increments.
The participant's primary task was to sort rocks, and the secondary task was to monitor the location of the robot.
Each time the participant received a status update from the robot , s/he had two possible responses: either respond with the left hand by typing "S" to signify same or the right hand by typing "N" to signify new.
After a rock classification, "S" instructed the robot to store the rock in the same bin, while "N" instructed the robot to store the rock in a new bin.
The first experiment contained three conditions, analogous to those in , each with its own rules for the user response : Delay: Do two successive rock classification messages follow in immediate consecutive order?
If so, put it in the same bin.
If not, select a new bin.
For all location updates, begin a new transmission.
Dual-Task: Do two successive messages of the same type follow in immediate consecutive order?
If so, select the same rock bin or maintain the same transmission.
If the update is of a different type , is the message either a Class 1 rock or a location of 0 meters?
If so, select the same rock bin or maintain the same transmission.
In all other cases, place the rock in a new bin or begin a new transmission.
Branching: For rock classification messages, respond as in Delay.
If the update is a location, respond as in Dual Task.
This study included 12 healthy volunteers , between the ages of 18 and 34.
Four additional volunteers had participated in the study, but are not included in this analysis because their performance in the tasks was below 70% in more than two trials per condition, indicating that they were not correctly performing the tasks.
In addition, data from another participant is not included due to technical problems with the fNIRS system.
All participants were right-handed, had English as their primary language, had no history of brain injury and had normal or corrected-tonormal vision.
Informed consent was obtained for all participants.
This experiment was approved by our institutional review board.
Like the sensor data, response time and accuracy measurements can be obtained automatically without interfering with the task so we investigated whether they would vary depending on the condition.
Statistical analysis was performed utilizing the InStat statistical package by GraphPad Inc. All variables were tested for normal distribution with the Kolmogorov-Smirnov test.
For normal distributions, the repeated measurements one-way analysis of variance  with the Tukey post-hoc test for multiple comparisons was used.
For non-Gaussian distributions, we used the Friedman  test.
The level of statistical significance was set at 0.05 .
Since dual task and branching behavioral results are similar, the factor was not significant overall, but is in pairwise comparisons.
We found statistical significance in response time between delay and dual , delay and branching , but not between dual and branching .
Similarly, we found statistical significance in accuracies between delay and dual , delay and branching , but not dual and branching .
Also, correlations between accuracy and response time for each task were not statistically significant.
We also looked at learning effects based on response time and learning effects based on accuracies as users progressed through the experiment.
We did not find a learning effect.
Statistical Analysis of Signal: We wanted to determine whether the hemodynamic response measured by fNIRS has a different signature between the three conditions.
For each of the two probes, we selected the fNIRS measurement channels with the greatest source-detector distances , as these channels are expected to probe deepest in the brain tissue, while the closer channels are more likely to pick up systemic effects and noise.
From each of these channels, we calculated both the change in oxygenated hemoglobin and deoxygenated hemoglobin using the modified BeerLambert law  after removing noise with a band pass filter.
The conditions were presented in counterbalanced pseudorandom order.
Each task was repeated until the participant achieved greater than 80% accuracy in the task.
After this accuracy was achieved for all three conditions, the fNIRS sensors were placed on the participant's forehead.
The participant was presented with an initial rest screen, which was used to collect a baseline measure of the brain activity at rest.
After that, the user had to complete ten 40-second trials for each of the three conditions, which were presented randomly.
Between each task, the user was presented with the instructions for the next task, followed by a rest screen.
We used a multichannel frequency domain OxiplexTS from ISS Inc.  for data acquisition.
Two probes were placed on the forehead to measure the two hemispheres of the anterior prefrontal cortex .
Each distance measures a different depth in the cortex.
Each source emits two light wavelengths  to detect and differentiate between oxygenated and deoxygenated hemoglobin.
The sampling rate was 6.25Hz.
To examine the differences between the three task conditions, we looked at behavioral data collected during the experiment as well as the fNIRS sensor data.
In both experiments, any trials where the participant achieved less than 70% accuracy in the task performance were removed in the analysis, since this would indicate that the subject was not actually performing the task correctly.
Behavioral Results: In the three conditions, the stimuli were essentially the same, as were the possible responses.
Thus, it would be difficult for an observer to detect any difference from the screen contents or the subject's behavior alone.
Combined oxygenated and deoxygenated hemoglobin by condition for Experiment 1.
Since the hemodynamic changes occur over a 5-7 second period, we simplified the signal for analysis by dividing the time series measurement for each trial into seven segments  and took the mean over these segments for the four channels.
In order to confirm that there were differences in brain activity during the three conditions, we did an ANOVA comparing condition means within subjects.
Since there were multiple sensors, factors for the distribution of sensors were included , as well as a factor for hemoglobin type  and the time point.
We used the Greenhouse-Geisser ANOVA values to correct for violations in sphericity.
We found a main effect of condition =4.353, p=0.029, in which total hemoglobin measures were overall higher in the branching condition than in the dual-task or delay condition .
There were no other significant effects in this analysis.
This study included 12 healthy volunteers , between the ages of 19 and 32.
Three additional volunteers had participated, but are not included in this analysis because their performance in the tasks was below 70% in more than two trials per condition, indicating that they were not correctly performing the tasks.
In addition, data from another participant was not included due to technical issues with the fNIRS system.
This experiment used the same procedure and equipment as in Experiment 1.
However, in this experiment, there were only two experimental conditions as described above and the participants completed eighteen trials of each condition, which were counterbalanced.
Behavioral Results: As in Experiment 1, we collected response time and accuracy throughout the study to determine whether the conditions elicited different measurements.
Statistical analysis was performed utilizing the InStat statistical package by GraphPad Inc. All variables were tested for normal distribution with the Kolmogorov-Smirnov test.
For normal distributions, a paired t-test was used.
For nonGaussian distributions, we used the Wilcoxon matchedpairs signed-ranks test.
Also, correlation between accuracy and response time for random branching was not statistically significant , but there was a statistically significant correlation in the predictive branching condition .
Statistical Analysis of Signal: Our goal was to determine whether the hemodynamic response measured by fNIRS has a different signature between the two conditions.
Our analysis was the same as in Experiment 1.
This effect indicates that, although there was no significant change in oxygenated hemoglobin, deoxygenated hemoglobin levels were higher in the random branching type than the predictive branching type for the first half of trials, but reversed for the second half .
Therefore, it should be possible to distinguish these two conditions using only the deoxygenated hemoglobin measure from fNIRS, which is in accordance with Huppert et al.
There were no other significant effects in this analysis.
To follow up on the first study, we conducted a second experiment to determine whether we could distinguish specific variations of the branching task.
This experiment had two conditions that were analogous to those in , in which the participant was always following the branching rules described in Experiment 1: Random Branching: Rock classification and location update messages were presented pseudorandomly.
Predictive Branching: Rock classification messages were presented every three stimuli.
Ideally, when using computer systems, the default scenario for a user would be similar to the predictive condition, and therefore the user would be able to plan ahead and handle incoming work appropriately.
If we could automatically identify that the user is experiencing random or unpredictable behavior, there may be appropriate adaptations that the system could make to better support the user, which we are exploring with the adaptive interface platform described below.
This experiment investigates whether we can automatically detect the different scenarios using fNIRS.
In the two experiments described above, we verified that there is a significant difference between the cognitive multitasking conditions in the fNIRS signal.
Because we can statistically differentiate them, we can apply machine learning techniques to automatically identify these cognitive multitasking states, in real time, in a user interface.
This information could then be used to drive the user interface to better support cognitive multitasking.
As a proof-of-concept, we developed a platform for studying brain-based adaptive user interfaces of this type.
The system has two main components: the Online fNIRS Analysis and Classification  system  and the Distributed Integrated Affect, Reflection, Cognition Architecture   for human-robot interaction .
The OFAC system receives raw fNIRS signals from Boxy acquisition software , classifies them in real time and sends the classification results to a specialized DIARC component.
In addition to the normal online mode where signals are classified and sent in real time, OFAC supports offline mode which simulates the analysis and classification of previously recorded data, and will be useful in experimenting with various adaptive strategies.
As OFAC receives data, it stores the signal in a database and preprocesses the signal , and performs classification using Weka .
The DIARC  is an integrated architecture for working with complex robots that can support various levels of robot autonomy and other adaptive robot behavior.
The architecture can interface with physical robots in an environment, but also has a simulation mode that allows for simulated interactions with a robot on a computer screen , along with several different environment configurations.
To receive input from the OFAC system, we have created a DIARC component to which OFAC sends cognitive multitasking state classification results via sockets.
DIARC can then use these messages to change the robot's goal structures, allowing the robot to adapt its autonomy and behavior.
In addition, we have provided a simulation mode, where cognitive state classifications can be entered manually by inputting classification confidence levels for each of the possible states.
Integrating the OFAC system with DIARC provides the robot with cognitive state information of the human, affording the robot to adapt its behavior to better support and collaborate with the human operator.
Driven by fNIRS cognitive multitasking input, DIARC can adapt various aspects of the human-robot interface, such as level of autonomy of the robot, the frequency, length and style of the robot's status updates, as well as the tone of the robot's voice.
As an initial step, we created a task scenario and simple adaptive behavior based on Experiment 1 described above to provide a technical demonstration that the platform functions as intended and can be further expanded to study adaptive multitasking user interfaces.
The system was used to complete a human-robot team task where the primary task was to classify rocks and the secondary task was to monitor robot location as in the two experiments above.
When a branching state was identified--indicating that the user was tending to multiple tasks and maintaining information about the primary task over time--the robot switched to autonomy mode allowing the user to focus on the primary task of classifying rocks.
In autonomy mode, the robot would move autonomously to new locations and find the best location for a new transmission.
When a nonbranching state was recognized, the robot returned to the default behavior, requiring the human to give instructions to the robot about whether it needed to start a new transmission.
Staying in autonomous mode throughout the entire task would not be ideal as the human needs to be aware of the robot's location and progress to provide corrective feedback , ensuring that the message is transmitted before time is up.
To validate that branching and non-branching could be classified in real time and that the robot could receive the signal and adapt its behavior, we did two demonstrations.
First, utilizing the offline mode of OFAC, we sent previously recorded fNIRS data through the system as if it were being collected on a user in real time.
We used the previously recorded data from Experiment 1.
The next demonstration of the platform was to show that it can perform in online mode while a user was wearing fNIRS sensors.
In both cases, we used the branching and delay tasks described in Experiment 1 to invoke known branching and non-branching states.
There was a training session where the branching and delay tasks from Experiment 1 were performed , allowing the robot to build a classification model based on the fNIRS sensor data during those tasks.
Each condition was completed 10 times in random order to provide training data.
The entire session took about 30 minutes.
We established that fNIRS data was transmitted from OFAC to DIARC in real time, with fNIRS and robot components running in full operational mode.
Robot goals and behaviors adapted based on the fNIRS data.
This proof-ofconcept confirms that our platform can form the basis of future study on brain-based adaptive user interfaces.
We intend to enhance the machine learning techniques to improve the accuracy of the system.
We will also analyze the fNIRS response more deeply in our future work, but our initial goal was show that there was a significant difference between the signals we detected for the different conditions.
This allows us to discriminate the conditions, and adapt a user interface when each state is detected.
In addition, we will expand adaptive behaviors that are supported to study the tradeoffs for making such adaptations.
This paper builds a foundation for brain-based adaptive user interfaces.
First, in our preliminary study, we brought research on cognitive activity during multitasking to a system that is practical for HCI by showing that fNIRS sensors could detect states previously studied with fMRI .
In our next two experiments, we further extended this research to HCI by showing that the states elicited in the "tablet" task may be generic processes that occur in more realistic HCI tasks, by using a human-robot scenario.
We integrated these findings with the brain-based adaptive interface platform we developed, in order to augment user interfaces with this cognitive multitasking state as input.
We demonstrated that the platform can form the basis for brain-based user-interfaces by implementing a simple adaptive scheme based on the experiments.
However, to design a successful adaptive user interface many factors must be considered and the automation scheme will be more complex than that illustrated here.
This framework provides guidelines but does not prescribe specific adaptive behavior for every system.
Instead each system must be carefully evaluated and iteratively designed to meet the needs of the users.
Our platform will enable us to conduct evaluations of various adaptive behaviors to determine the appropriate strategy for supporting multitasking by utilizing signals coming implicitly from the brain.
Human-robot team tasks provide appropriate scenarios for studying adaptive multitasking support, as they inherently involve multitasking: the user is performing a task, while also monitoring the state of the robot.
HRI team tasks thus may see improved performance with brain-based adaptive interfaces.
There has been much work on adaptive robots that change behavior based on the environment or situation.
We plan to develop robots that have a greater understanding of the user's cognitive state during multitasking, and can adapt their behavior to better support the user.
In addition, we believe that similar brain-based user interfaces may support a wide range of contexts that involve multitasking and interruptions, such as air traffic control, management of unmanned aerial vehicles , complex data visualization and analytics, and many others.
Noninvasive brain sensing provides an additional channel of input to the system without any explicit action by the user.
However, any adaptation must be done carefully, to ensure that the user does not feel that he or she has lost control.
The platform we have developed will allow us to explore adaptive behavior to find the best strategies for these scenarios.
We can now begin to develop complex systems that adapt based on fNIRS brain signals and experimentally evaluate them.
We thank the Tufts HCI Lab , Remco Chang, Desney Tan and Dan Morris.
Any opinions, findings, and conclusions or recommendations expressed here are those of the authors and do not necessarily reflect the views of the National Science Foundation.
Towards a Physiological Model of User Interruptability.
Instant Messaging: Effects of Relevance and Timing.
Examining the robustness of sensor-based statistical models of human interruptibility.
Designing a Passive Brain Computer Interface using Real Time Classification of Functional Near-Infrared Spectroscopy.
Feasibility and pragmatics of classifying working memory load with an electroencephalograph.
The WEKA data mining software: an update.
Brain Measurement for Usability Testing and Adaptive Interfaces: An Example of Uncovering Syntactic Workload with Functional Near Infrared Spectroscopy.
Knowing where and when to look in a time-critical multimodal dual task.
Predicting human interruptibility with sensors: a Wizard of Oz feasibility study.
A temporal comparison of BOLD, ASL, and NIRS hemodynamic responses to motor stimuli in adult humans.
Towards an index of opportunity: understanding changes in mental workload during task execution.
Investigating the effectiveness of mental workload as a predictor of opportune moments for interruption.
Task-evoked pupillary response to mental workload in humancomputer interaction.
Brain Computer Interfaces: Applying our Minds to Human-Computer Interaction, Springer, 2010, 89-104.
The role of the anterior prefrontal cortex in human cognition.
Dissociating the role of the medial and lateral anterior prefrontal cortex in human planning.
The influence of implicit and explicit biofeedback in first-person shooter games.
Using a low-cost electroencephalograph for task classification in HCI research UIST'06, ACM Press, 2006.
Physiological indicators for the evaluation of co-located collaborative play CSCW '04, 2004.
McFarlane, D. Comparison of four primary methods for coordinating the interruption of people in humancomputer interaction.
Miyata, Y. and Norman, D. The Control of Multiple Activities.
User Centered System Design: New Perspectives on HumanComputer Interaction, Lawrence Erlbaum Associates, Hillsdale, NJ, 1986.
Miyata, Y. and Norman, D. Psychological Issues in Support of Multiple Activities.
User Centered System Design: New Perspectives on Human-Computer Interaction, Lawrence Erlbaum Associates, Hillsdale, NJ, 1986, 265-284.
The attentional costs of interrupting task performance at various stages.
A model for types and levels of human interaction with automation.
Toward Machine Emotional Intelligence: Analysis of Affective Physiological State.
Coordinating the Interruption of People in Human-Computer Interaction.
Schermerhorn, P. and Scheutz, M. Dynamic robot autonomy: investigating the effects of robot decisionmaking in a human-robot team task.
First steps toward natural human-like HRI.
Using fNIRS Brain Sensing in Realistic HCI Settings: Experiments and Guidelines.
Starner, T., Schiele, B. and Pentland, A.
Visual Contextual Awareness in Wearable Computing.
A novel brain-computer interface using a multi-touch surface.
