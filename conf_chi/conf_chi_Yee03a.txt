The small size of handheld computers provides the convenience of mobility at the expense of reduced screen space for display and interaction.
Prior research  has identified the value of spatially aware displays, in which a position-tracked display provides a window on a larger virtual workspace.
This paper builds on that work by suggesting two-handed interaction techniques combining pen input with spatially aware displays.
Enabling simultaneous navigation and manipulation yields the ability to create and edit objects larger than the screen and to drag and drop in 3-D. Four prototypes of the Peephole Display hardware were built, and several Peephole-augmented applications were written, including a drawing program, map viewer, and calendar.
Multiple applications can be embedded into a personal information space anchored to the user's physical reference frame.
A usability study with 24 participants shows that the Peephole technique can be more effective than current methods for navigating information on handheld computers.
Relative scrolling methods such as buttons and wheels can be slow for navigating long documents, since users may have to press a button or roll a wheel many times to cover large distances.
Using a scroll bar or dragging to pan the view is disruptive because it forces users to interrupt the current pen interaction, divert their attention to the scrolling manoeuvre, and switch back.
On current devices, pen interactions cannot span distances beyond the screen unless the display automatically scrolls when the pen reaches the edge of the screen.
However, auto-scrolling behaviour is notoriously difficult to control.
The screen regions that trigger auto-scrolling are usually invisible, and often the view scrolls too quickly or slowly.
One way to provide access to more information is to track the position of the display so it can be physically moved around to see different parts of a large workspace.
This idea was proposed by Fitzmaurice  in 1993.
This work takes that idea and explores what happens when we combine it with pen input and other interaction ideas such as the Toolglass  and the zooming UI .
Though Fitzmaurice's prototypes displayed views on 3-D scenes, our starting point is a 2-D version of the spatially aware display.
The information is spread out on a flat virtual workspace larger than the display, and the display shows a movable window  on the space.
Recent years have shown an explosion of interest in handheld computing devices such as palm-size digital assistants and increasingly smart mobile phones.
Their small form factor has the advantages of portability, low power consumption, and instant-on responsiveness, but also limits the size of the display.
A key limitation of these devices is the user's inability to view and interact with a large amount of information at once.
Handheld computers employ various scrolling mechanisms to provide access to more information on their small displays, including buttons for moving up and down, a thumbwheel on the side of the device, or scroll bars on a touch-sensitive screen.
A standard technique for viewing maps and photographs on touch-screens is to drag a pen to grab and pan the image.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
To create the illusion of a fixed workspace, the handheld computer scrolls the display opposite to the direction of its movement just enough to cancel its physical displacement.
Figure 2 shows an example of this method being used to view a large image.
Panning typically involves both hands, but this method lets the user browse with one hand.
The images on the right were made by blending two photographs taken from the same viewpoint.
The position of the device is tracked and the display scrolls to produce the illusion of a movable view on a large street map floating in space.
Notice how Gravier St., visible in both views, maintains a fixed position with respect to the outside world.
In this way, we can augment the space around a user with information and user interface elements;  describes a similar concept.
The handheld computer becomes a portable gateway to the user's personal information console.
We'll now continue with a survey of the related work, then a description of the 2-D prototypes and applications, the 2-D usability study, the 3-D prototype and applications, and finally a discussion of future directions.
The difference in approach is that, while in  Fitzmaurice proposes 3-D, virtual-reality-style mediation of an office environment, the Peephole designs and studies are more rooted in the rich heritage of interaction techniques for the desktop.
Even when 3-D position information is used, the purpose is not to achieve depth perception .
Previous work has proposed many compelling interaction techniques based on physical manipulation of a smallscreen device, including contact, pressure, tilt, and motion.
Specifically with regard to navigation, Rekimoto  used tilt input for navigating menus, maps, and 3-D scenes, and Harrison et al.
Peephole Displays fall into the category of spatially aware displays, which differ from the aforementioned work in that they create a positional mapping between the virtual space and the real world, enabling the use of spatial memory for navigation.
Another approach to fitting information on a small screen is to provide zoom control.
Techniques for improving navigation on small screens include zooming UIs  and speed-dependent automatic zooming .
The advantages of two-handed interaction have been well studied .
In many asymmetric two-handed operations, the non-dominant hand provides a reference frame to situate the dominant hand's actions: for example, users can orient the work piece in the non-dominant hand while specifying operations with the dominant hand , or hold tools in the non-dominant hand for precise activation by the dominant hand .
This idea is extended here by using the non-dominant hand for navigating information spaces.
Two-handed Peephole interaction benefits from a unified kinaesthetic reference frame .
Fitzmaurice's Chameleon  and Ishii and Ullmer's activeLENS  are motion-tracked displays based on positional mapping, like this one.
The Chameleon was the original Wizard-of-Oz implementation of a spatially aware display, in which a handheld colour TV showed an image from a camera pointed at a graphics workstation; the workstation rendered a 3-D scene with the view controlled by the position of the TV.
The activeLENS is an armaturemounted full-size LCD screen, tracked in space by the joint angles on the arm.
The Chameleon provides a single button for input; the activeLENS does not read input other than its position.
Small and Ishii also experimented with tracking displays to control translation or zooming .
The Peephole Display is probably best described as a direct descendant of the Chameleon and the Toolglass .
In some ways, a Peephole Display is a physical realization of a Toolglass.
This paper extends the previous work in a few new directions by contributing:  the use of pen input on a movable display as a new form of two-handed interaction;  an emphasis on, and implementation of, more typical handheld computer applications and desktop-style metaphors;  a user study to determine the validity of these techniques for PDA-like applications;  a more portable spatially aware display, in which the display is generated directly by the handheld computer itself; and  a working implementation of multiple applications arranged around the user in a personal information space.
Between the submission and publication of this paper, work was published on two other spatially tracked displays with pen input.
The Boom Chameleon  is an armaturemounted flat-panel screen for viewing 3-D scenes, just like the activeLENS, but with the addition of pen and audio input for making annotations.
The Interaction Lens  is a handheld computer used as a lens for augmenting paper documents with digital ink annotations.
The variety of recent work on spatially aware displays suggests that there are many exciting possibilities to be explored in this area.
For this implementation, the innards of an optical mouse were affixed to the handheld computer so that its motion could be tracked on a flat surface.
Mouse technology is mature and cheap; this technique gives fast, reliable, and precise position data.
However, it adds the limitation that the handheld computer has to be put down on an available surface before Peephole interaction is possible.
This method employed the commercially available Mimio whiteboard-capture system.
The ultrasound transmitter from a Mimio marker was attached to the handheld computer.
Position was computed from distance measurements obtained by the ultrasound receivers.
This had the advantage that it allowed the handheld computer to move freely.
However, the position readings were too slow and noisy to be effective, and tracking only worked while the transmitter was held exactly in the plane of the receivers.
Selecting an item from a vertically scrolling list is a very common operation in mobile phone user interfaces.
This program provides an alternate way to perform that operation.
To simulate conditions on a mobile phone, the program is operated using one hand and only about half of the display is used .
The item nearest the middle of the view is highlighted; the user holds the display in the non-dominant hand and moves it along the list to highlight different items.
When the desired item is highlighted, the user selects it by pressing a button with the thumb of the non-dominant hand.
This program also allows selection from a long scrolling list, but under slightly different conditions, approximating those of a palm-sized computer.
The whole display is used, so that ten items are visible at once.
Unlike in the one-handed selector, moving the display does not affect the selection.
The user selects items by tapping on them with a pen in the dominant hand, while holding and moving the display in the non-dominant hand.
This method used two lengths of monofilament fishing line and a mechanical mouse.
In mechanical mice, the mouse ball contacts two plastic shafts, one horizontal and one vertical, and an optical encoder measures the rotation of each shaft.
As shown in Figure 3, the mouse was anchored to a platform, with two screws as reference points at the left and right ends of the platform.
Each length of fishing line ran from the handheld device to a reference point, then into the mouse, around one of the plastic shafts, back out of the mouse, and finally to a small weight that maintained tension on the line.
The x and y movement readings from the mouse were used to track the distance from the handheld device to each reference point and thereby triangulate the position of the device.
This method obtained fairly accurate position data while still permitting the device to move freely in space.
This program enables the user to view a large image on a handheld computer by physically moving the display around to see different parts of the image.
Such an application might be useful on the street for viewing a map, or for reading a large document like a Web page.
This is the program depicted in Figure 2.
This is a simple drawing program where the pen is used to draw in digital ink on a large canvas, and the display provides a movable Peephole on the canvas.
This allows the user to draw on a potentially unlimited surface using just a small handheld device.
At typical handwriting sizes, very little text fits on a palm-size display, so having a large canvas can aid note-taking.
Using the Doodle Pad, one can keep writing past the edge of the display without interruption, by bringing the display along while writing.
The four tasks were designed to test a common operation on handheld devices  and two typical uses for mobile computers - map viewing and note taking.
One-handed selection: Using only the non-dominant hand, find a name in an alphabetized list of 50 names, where 5 names are visible at a time.
Repeat this for 10 names, using the same list but prompted for a different name each time.
The Peephole one-handed selector was compared with a conventional interface operated by pressing physical "up", "down", and "select" buttons with the thumb.
Two-handed selection: Using both hands, find a name in an alphabetized list of 50 names, where 10 names are visible at a time.
Repeat this for 10 names, using the same list but prompted for a different name each time.
The Peephole two-handed selector was compared with a conventional interface operated by pressing physical "page up" and "page down" buttons with the thumb of the non-dominant hand and selecting items with the stylus in the dominant hand.
Map viewing: Given a fictional subway map, find two stations by name, and then plan a route between them.
With the same map, find two more stations by name and plan a second route.
The Peephole image viewer was compared with a conventional interface operated by using the pen to drag the image around the screen.
Drawing: Copy down a simple diagram consisting of labelled boxes and arrows.
The Peephole doodle pad was compared with a conventional interface that had a pencil tool and a panning tool, with two small onscreen buttons for switching tools.
To ensure that both interfaces provided the same screen area for drawing, the vertical space taken up by the tool buttons in the conventional interface was left unused in the Peephole interface.
The effectiveness of spatial memory becomes apparent when trying to draw figures bigger than the screen.
For example, when using the optical mouse implementation on a table surface, as in Figure 5, it is straightforward to draw a circle larger than the screen in a single continuous, natural stroke - an operation that would be impossible on existing devices.
The user simply draws with respect to the table instead of the screen.
Kinaesthetic memory and spatial memory make it easy to close the circle accurately.
In effect, putting down the handheld computer on a table augments the entire table surface to make it drawable.
I conducted a usability study to compare the effectiveness of Peephole techniques with more conventional interfaces for common tasks on mobile computers.
The study had 24 participants, all of whom were familiar with handheld computers, though not necessarily owners of such devices.
None had previously seen or used a Peephole Display.
Tests were performed using the two-tether implementation in a lab setting.
I decided that this implementation was adequate for user testing because it allowed freedom of movement in the air while still providing fairly accurate and fast position data.
Naturally, a deployed product would be quite different from this prototype; the goal was to determine the feasibility of the Peephole concept.
This study used a within-subjects design.
For each of four tasks, a conventional scrolling interface was compared to a Peephole interface.
Each participant did all tasks using both interfaces.
Participants were given a dummy data set with which to practice using each interface before proceeding with each timed task.
Each participant used the Peephole interface first in half the tasks and the conventional interface first in the other tasks.
For each task, half the participants used the Peephole interface first and half used the conventional interface first.
Two different data sets were used for each task, to reduce learning effects.
For each data set, half the participants saw it first and half saw it second; half used it with the Peephole interface and half used it with the conventional interface.
User error rates were negligible  for all the tasks, independent of data set or interface.
The data confirmed that there was no significant difference between the two data sets for each task .
Figure 7 presents a summary of the experimental data.
For each task, after trying both interfaces, users were asked which one they preferred.
The Peephole interface was preferred for the one-handed selection and map viewing tasks and strongly preferred for the drawing task.
For the map-viewing task, there was no significant difference in performance between the two interfaces, for either finding stations or planning routes .
Note however that the Peephole interface required only one hand to operate, while the conventional interface required both hands.
For the drawing task, Peephole drawing was about 32% faster than the conventional interface, and this difference was highly significant  = 8.27, p < 10-7.
Many participants made much smaller drawings with the conventional paint program than with the Peephole paint program.
In no case was the drawing produced with the conventional interface ever larger than that produced with the Peephole interface.
This suggests that participants felt less space-constrained when using the Peephole interface, even though the actual canvas sizes were the same - only the method of scrolling differed between the two interfaces.
Of the 24 participants, 17 were observed to use both hands together during the drawing task, panning and drawing concurrently to make long pen strokes.
All 17 attempted this technique without prompting, which suggests that this type of two-handed interaction is natural and effective.
The most frequent complaint about the Peephole interface was that the display was blurry while it was in motion.
In fact, all five participants who preferred the conventional map viewer explained that they preferred it because the blurry text in the Peephole viewer was too hard to read.
In the one-handed condition, this deficiency is overwhelmed by the constraints of the conventional one-handed interface: it takes 49 steps to traverse the entire list in the conventional one-handed selector, but only 4 steps  in the two-handed selector.
The Handspring Visor prototype has an LCD that responds quite slowly.
Personal experience and these user comments suggested that the Peephole techniques would work much better on a faster and brighter display.
It was very encouraging to obtain positive results despite the suboptimal screen and crude position-tracking hardware.
Based on user feedback and my own experiences with the 2-D prototypes, I developed a fourth Peephole prototype.
By this time, better hardware was available for both display and tracking: this prototype used a Sony CLIE with a 320-by-480-pixel colour screen and an Ascension Bird receiver.
This hardware had the advantages of better resolution and contrast, faster screen response, improved tracking precision, and the ability to track positions in 3-D.
Perhaps the most obvious mapping for motion along the depth axis is zooming.
This is an enhancement of the 2-D image viewer that zooms out when the screen is lifted and zooms in when it is lowered.
Each point in 3-D space corresponds to a particular zoom level and panning offset, giving continuous control over both panning and zooming.
With a single arcing gesture, the user can smoothly zoom out to see context and dive into a new region of interest.
The standard Palm DateBook application accommodates the small size of the display by offering multiple views at different scales.
A toolbar provides buttons for switching between the day view, the week view, and the month view.
Only the day view shows the descriptions of appointments and allows them to be edited, but it also gives the least context.
When looking for available time to schedule a meeting, for example, the month view can be more useful.
This is a semantic zoom operation, similar in feel to zooming UIs like Pad .
While a desktop ZUI can offer larger visual context, here we have the advantage that all navigation is controlled by the non-dominant hand, leaving the dominant hand free to interact.
Dragging an event to a different month is as direct as dragging it to a different day or time.
The Peephole Calendar views do not fade or zoom smoothly; a more complete implementation of Pad on a Peephole Display would be an obvious next step.
The Peephole Calendar tries to combine the strengths of all three views into a single modeless Peephole view.
It reads data from the standard Palm DateBook application and lays out the entire month on the workspace like a page of a wall calendar.
The box for each day shows all the appointments for that day, just like the standard full-screen day view.
The user can easily scan horizontally to view events in the coming week, scan vertically to look at a particular weekday, or browse through the entire month.
The display has three parts.
Most of the screen is occupied by a fully scrolling region that works just like a 2-D Peephole image viewer, except that it also allows direct interaction with the displayed appointments.
Along the top of this region is a bar showing the days of the week; this bar scrolls only in response to horizontal movement.
Along the left is a column showing the time of day; this bar responds only to vertical movement.
These bars, like locked headings in a spreadsheet, help to maintain context when the user is navigating around the workspace.
I wrote a simple object-based drawing program in order to experiment with object manipulation on a 3-D-tracked Peephole Display.
A toolbar on the left side of the display lets the user create, select, and move simple shapes.
The toolbar is fixed to the display, while the rest of the screen area is a Peephole view on the drawing canvas.
As the non-dominant hand moves the view to the region of interest, the tools stay nearby, like a Toolglass would.
Because the Sketchpad responds concurrently to device movement and pen input, the user can easily draw objects larger than the screen and can move objects beyond the edge of the screen in a single operation.
In Figure 11, the screen and pen are moved together to drag an object.
For switching between months, the Peephole Calendar provides a year view.
It adopts a model where there are two view planes, one for the overview and one for detail, with the overview  on the upper plane.
The third dimension is used for situating the clipboard in real space - it resides in a workspace of its own on a plane above the plane of the drawing canvas.
The operations for moving objects to and from the clipboard can then be a natural extension of drag-and-drop into 3-D, as shown in Figure 12.
To help the user stay oriented, the clipboard and canvas planes have different background colours.
Since the clipboard is a visible workspace, the user does not have to memorize what was placed there.
The user can place multiple objects on the clipboard, arrange them as desired, and then group them into a single object for reuse.
This works very much like a Toolglass clipboard, though in this case more clipboard space is available, and the original locations of objects can be preserved if desired.
A formal usability study has not yet been conducted on the 3-D applications, but some users have been informally surveyed.
During a recent public poster session, the prototype was left running the Zoom Viewer on the subway map in Figure 6.
Twelve curious visitors picked it up and had no trouble panning the view without instructions.
One immediately remarked, "It's like there's a map underneath it."
Another brought over a friend and explained, "You just move this in a kind of natural way."
Seven of the twelve found the zooming feature on their own; the rest understood it as soon as they were prompted to try vertical motion.
These observations suggest that the panning and zooming actions are easy to understand.
Three users tried two variants of the Zoom Viewer: one that zooms out when lifted, and one that zooms in when lifted.
All three preferred to zoom out by lifting the display.
The most common problem users experienced with the Zoom Viewer is that they would sometimes get lost in the workspace.
A distraction could cause them to let their hand drift beyond the edge of the map, leaving them with a blank screen and no indication of where to go.
This could be addressed by showing arrows pointing back to objects of interest when the display is moved into empty space.
Three users tried the Peephole Sketchpad.
After having used the Zoom Viewer, they already knew how to pan around the workspace.
All three inferred that they could pan while drawing and dragging objects.
One user, after seeing how to copy items by lifting them to the clipboard, immediately guessed that items could be pasted by pushing them down from the clipboard.
The others could successfully copy and paste items once 3-D drag-and-drop was described to them.
One commented, "This is a great idea."
To experiment with the concept of personal information spaces, I embedded two applications concurrently into a single virtual workspace: the Calendar and the Doodle Pad.
In this prototype, the user wears the tracking equipment so that the applications are embedded in the user's personal reference frame, just in front of the torso with the Calendar on the left and the Doodle Pad on the right.
The combined workspace supports linking between applications: for example, the user can draw a map to a party in the Doodle Pad, and then drag the drawing over to the Calendar to record the date and time of the event.
Selecting the event causes the associated drawing to be brought into the Doodle Pad and a big red arrow to appear at the right edge of the display, directing the user's attention over to the Doodle Pad.
The fundamental concept here is concurrent navigation and interaction.
When the non-dominant hand can take over navigation control, the dominant hand is free to work continuously over boundaries that would previously have forced an interruption.
The boundary at the edge of the screen, the structural boundary between months in the year, and the conceptual boundary between the work area and the clipboard are just examples of such boundaries.
Several interaction techniques have been described : 1. moving the display in a plane to view a workspace 2. moving the display while drawing on it  3. moving the display while dragging an item  4. lifting the display to zoom out, lowering it to zoom in 5. lifting the display to switch from detail to overview 6. lifting the display to switch to a clipboard view 7. lifting or lowering to drag an object to another plane Any single-button mouse interaction on a desktop computer, as it uses only the dominant hand, can be adapted to an analogous interaction on a 2-D tracked display with a pen in the dominant hand and navigation control in the non-dominant hand.
Techniques 1, 2, 3 are instances of such adaptation.
Additional mouse buttons can be emulated by providing modifier keys for the non-dominant hand.
A tracked display can also offer some information that a desktop does not: the position of the viewport indicates where the user is looking.
The Sketchpad exemplifies how this can be used to keep tools nearby.
Tracking in 3-D also yields added input without occupying more hands.
The Zoom Viewer, Calendar, and Sketchpad examine various uses for this input - techniques 4, 5, and 6 respectively.
Whereas 1, 2, 3 are "pure desktop" and 4, 5, 6 are "pure Peephole", so to speak, technique 7  is an example of taking a traditional desktop interaction technique and extending it with Peephole capabilities.
A significant drawback is the loss of peripheral awareness.
Peephole interfaces can compensate for this by giving notification of off-screen activity and directional indicators to aid navigation.
Using Peepholes is also more fatiguing for the non-dominant arm, so they are probably better suited to short-term interactions .
The Chameleon used its button as a "clutch" to allow the user to move the display while holding onto the workspace.
The current Peephole prototypes lack this, and it is evident that a clutch feature is vital for being able to work in a comfortable position.
Instead of shifting the entire workspace, however, the button could grab and reposition documents within the user's personal cloud of documents.
All of these ideas and more remain to be explored.
I thank my advisor, Marti Hearst, for her support and assistance with this paper; the participants in the study, who generously volunteered their time; Michele Markstein, Jen Mankoff, and the CHI reviewers, whose constructive suggestions greatly improved this paper; and John Canny for his advice.
The maps used in the study were subway maps from http://metropla.net/ with the station names replaced.
This work has combined spatially aware displays with pen input and suggested a family of interaction techniques based on this concept.
Two of the techniques have been usability-tested so far, and were shown to be successful in a study of 24 participants.
One of the prototypes augments the physical space around a user with an interactive information space.
However, the tracking hardware has a long way to go before it is truly robust and portable; inertial tracking is one future possibility.
I believe this work has only scratched the surface of the possibilities for interaction techniques and applications on pen-enabled spatially aware displays.
It should be clear that there is a wide range of techniques that can be brought over from the desktop and extended.
