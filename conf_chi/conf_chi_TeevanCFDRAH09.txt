Previously viewed Web pages are represented in many ways, including as thumbnails, titles in a user's history, captions within search results, URLs in the address bar, or colored hyperlinks.
These different representations are intended to support different tasks.
There are several drawbacks to the existing representations.
For one, while individual representations may be well suited to particular navigational tasks, people often navigate to the same Web page in many different contexts.
Users may not recognize the thumbnail they see now as the same page as the search snippet they saw before.
The success of a representation needs to be considered in the context of a person's entire Web interaction.
Additionally, those representations that effectively help people accomplish their task often require valuable screen real estate to do so .
This limits a user's ability to see many different Web pages in a search result list or browsing history in one view.
In this paper, we report on a study of 197 people 's interactions with compact Web page representations.
We analyze the success of each representation in supporting fast navigation to both new and previously viewed content and explore the importance of consistency of representation across different navigational task types.
We find that text snippets are effective for finding new Web pages that have never been seen before.
Thumbnails, in contrast, are good for supporting re-finding, but primarily when the page's thumbnail has been seen before.
This means that in order for a thumbnail to be useful for refinding, it needs to be seen initially in a context where it is not particularly useful.
A representation we call a visual snippet captures the best of these two representations: it supports finding new information comparable to text snippets, and re-finding in a comparable manner to thumbnails - even when it has not been seen before.
Visual snippets are designed to maintain the size and visually distinct advantages of thumbnails while containing the same essential elements as text snippets.
Following a review of relevant literature, we discuss how the visual snippets were designed and generated.
We then describe the study we conducted to test the effectiveness of visual snippets for both finding and re-finding tasks, compared with thumbnails and text snippets.
People regularly interact with different representations of Web pages.
A person looking for new information may initially find a Web page represented as a short snippet rendered by a search engine.
When he wants to return to the same page the next day, the page may instead be represented by a link in his browser history.
Previous research has explored how to best represent Web pages in support of specific task types, but, as we find in this paper, consistency in representation across tasks is also important.
We explore how different representations are used in a variety of contexts and present a compact representation that supports both the identification of new, relevant Web pages and the re-finding of previously viewed pages.
Search and re-finding tasks are among the most common activities on the internet.
A Pew Internet and American Life report showed that Web searches were second only to email , and studies of revisitation  have found that anywhere from 50%  to 80%  of all Web surfing behavior involves visiting previously visited Web pages.
People use search engines , bookmarks, browser history mechanisms, and their memory to find and return to Webbased information .
In order to accomplish search and re-finding tasks, a user must interact with different representations of Web pages.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
The ideal Web page representation for different tasks has been the target of much research.
As noted above, some representations are best suited for finding new information, while others are designed to optimize re-finding.
Representations designed for finding new information seek to surface a page's relevant content.
The most widespread search-based representations are summary text snippets that accompany Web search results.
Text snippets are capable of encoding significant amounts of information but suffer from two problems.
First, they take up a great deal of space; we estimate a three-line snippet uses around 80x800 pixels.
Second, text snippets do not capture visual information about Web pages and therefore lose spatial structure and visual features that may help determine relevance.
The second most common Web page representation for search is a scaled-down bitmap, or thumbnail, displaying a snapshot of a particular Web page as rendered in the browser.
Some Web search services such as RedZee  and searchme , as well as some browser extensions , display search results as collections of thumbnails or as mash-ups that present both thumbnails and snippets.
While visually compelling, in practice the thumbnails are either too large  or too small .
Their work provides insight into many of the factors that influence recognition when using thumbnails, Web page titles and URLs.
Relevant for our research, they find that for thumbnails above 208x208 pixels, users could recognize 80% of pages.
To achieve smaller representations for search, several research efforts have proposed the use of image representations of Web pages that call out relevant text.
For example, Woodruff et al.
Their Fishnet Web browser collapses Web pages via a fisheye viewport that compresses the text above and below the center of the screen, while surfacing relevant keywords  with pop-outs.
Other work by Lam and Baudisch  focused on enabling navigation within a particular Web page on a small device.
Their strategy took advantage of the document object model of the Web page to selectively collapse sections of the page.
Such representations often do so by surfacing metadata about the page.
For example, Cockburn and McKenzie  built thumbnails that show a person's interaction with the page by marking pages that are frequently visited.
The Data Mountain from Robertson et al.
They showed an improvement over standard bookmarking mechanisms for re-finding saved pages.
Similarly, PadPrints  used thumbnail representations to show past Web pages; they found that showing browser history helped users move through backtracking tasks more rapidly.
Previous studies of Web page representations have looked only at how the representation performs in a single context.
In this paper we explore how different representations perform across contexts and how seeing a given representation in one context may affect how that or a different representation of the same page is used in another.
In addition to studying well known representations like text snippets and thumbnails, we develop and test a representation intended to support both finding and recognition tasks while using as few pixels as possible.
In the next section we describe how we identified and used these components and in later sections we discuss how our representations may be further augmented to include taskspecific information.
Figure 1 shows several of the thumbnails the designer created.
On inspection, we observed a consistent pattern across the hand-generated thumbnails.
The majority of each designer thumbnail contained three elements: 1.
Some salient text from the page .
A salient image, cropped so as to leave some low contrast space on which to place the text .
A watermarked logo to brand the thumbnail .
Interestingly, these three components are similar to components typically captured by textual Web search result snippets.
The salient text in the designer's thumbnail can be seen as analogous to the page's title in a search result snippet, and in many cases the salient text actually was the same as the page's title.
And the thumbnail's logo provides branding information, in the same way that the URL in a search result often does.
The consistent pattern suggested it might be possible to automatically create high quality visual snippets.
Given these insights, we interviewed two graphic designers and one usability engineer to gather additional impressions regarding important features of a Web page for creating small-scale page representations.
All three confirmed the value of emphasizing a page's logo, title, and salient image.
Branding information and the page's title were viewed as central for distinguishing visually similar pages.
The logo was also cited as an indicator of the trustworthiness of the source, with the page's banner or URL being a suitable substitute.
A useful insight for automatically extracting these components from a page was that items "above the fold"  were highlighted as particularly significant.
In addition to confirming our observations of the designer thumbnails, interviewees also mentioned that preserving the color or layout of the page could be valuable.
For example, one interviewee said the diagrammatic composition of the different HTML elements would likely play an important role in revisitation tasks.
Although the visual snippets we studied here do not take advantage of page structure to compose essential elements, we present an extension that does so, particularly for mid-sized representations.
Previous research suggests that logo classification can be done with 85% accuracy based on features of the image alone .
Additional features, such as the image's location within a Web page, size, name, link structure, and surrounding text can improve the accuracy of logo detection .
For large Web sites, looking at many pages within the same site may be useful, as the logo is often consistent across pages.
In our experiments, we treat logo and salient image extractions as black boxes that we initially implemented in "Wizard of Oz" style.
Two authors viewed the Web pages used in our experiments and quickly identified a logo and a salient image for each by hand, focusing on above-the-fold content as suggested by our design analysis.
Hu and Bagga  found that manual image categorization can have a high error rate , so it is likely that the number of errors introduced through manual classification corresponds to what would be found through automatic classification, although the errors may be somewhat different in quality.
Later we present a fully automated implementation that successfully mimics the manual extraction in quality.
Following extraction, we automatically compile the component pieces into a visual snippet.
Figure 2 shows the template we used to automatically generate a visual snippet given a salient image, logo, and title.
Figure 3 shows three Web pages and the visual snippets we derived from them.
The visual snippet generation process involves four steps: 1.
Cropping and scaling the salient image.
The image is cropped manually along one dimension to an aspect ratio of 4x3 and scaled to 120x90.
If no salient image is identified, a snapshot of the page is used instead, appropriately scaled.
The logo is scaled to fit within a 120x45 rectangle while preserving its original aspect ratio.
The logo's scale is chosen so that it either fills half of the height or the full width of the visual snippet.
If no logo is available, it is omitted.
Strings of this length are possible in text snippets but are infeasible for smaller representations.
Because the leftmost 15-20 letters of a page's title  yield reasonable recognition of the page's site, we use the first 19 characters of the title.
If no title is available, it is omitted from the final snippet representation.
The three processed pieces are then composed as shown in Figure 2.
The logo is made semi-transparent and overlaid on top of the salient image, and the salient text is placed above both images on a white background for readability.
We place the logo in the lower left-hand corner of the visual snippet because that is where the URL appears in a typical text snippet.
We hypothesize such a placement is consistent with existing expectations.
Note that all component processing is done without consideration of how the pieces will compose.
It is likely that allowing for interactions will lead to better visual snippets.
For example, the salient text is currently placed above the image for readability and consistency, but it would be simple to automatically identify low contrast areas in the salient image on which to place the text instead, much as the designer did in his original thumbnail creations .
Similarly, it may be beneficial to crop the image so as to leave a low contrast area in the lower left hand corner for the logo.
Many extracted logos are not rendered on transparent backgrounds.
Because logos with transparent backgrounds appear to compose better, it may be valuable to try to identify the background and make it transparent.
The three representations explored in the study were: 1.
The title, a one line summary, and URL for a Web page were captured from a popular search engine.
The text display was generic and not tailored to a particular query .
Created as described in the previous section.
Note that visual snippets are less than a quarter of the size of text snippets.
For comparison, we also created thumbnails of the page that were the same size as the visual snippets.
Figure 4 shows some examples.
Note that text snippets are significantly larger  than the other representations, and this is true even in the absence of the additional white space required for effectively rendering a list of text results.
To explore how well visual snippets support search and revisitation tasks, we conducted a study to compare how participants used different representations types to find and re-find content.
Our goal was, first, to understand how different renderings of snippets support finding tasks; second, to explore how different renderings support re-
In Phase I of the study, participants were asked to perform 12 search tasks.
For each task they were given a task description and a set of 20 search results associated with the task.
Each participant completed four of the 12 tasks with each type of Web page representation so that we could perform a within-subjects comparison of representation.
Web search performance is associated with very large interperson variability; we hoped to minimize this by comparing performance between representations within a single user.
This time, however, they were not required to visit the page but instead were asked to re-find the target Web page based solely on the set of page representations associated with the task.
They could try as many times as needed; as soon as they clicked the correct representation, the task was considered complete.
Because all users saw all three representations, we could collect more reliable qualitative preference measures by asking participants to provide relative preferences.
The type of Web page representation for each task was counterbalanced between participants and the order of presentation was pseudo-randomized to avoid order effects.
In each search task, participants were asked to find some information that was guaranteed to be available on at least one of the Web pages in each result set.
The answers to the homepage finding tasks were on only one of the twenty results.
The answers to the medical and shopping tasks could be found on two to five of the results.
During the search phase, participants could click on a Web page representation to see the full Web page and click back to return to the result list.
When participants found a result containing what they determined to be an answer to the question, they were instructed to click on the answer within the target Web page.
The selected page was recorded for use in Phase II, and that task was considered complete.
We did not require participants to find a "correct" page but rather allowed them to decide for themselves when their information need was satisfied.
At the end of Phase I, participants filled out a survey including demographic information as well as impressions of their experience in performing the task.
In Phase II, we were interested in knowing whether the type of representation of search results in Phase I would affect the recall of those same pages the next day.
For example, if a participant used thumbnails during the search task, would that participant be better able to remember the correct pages when using thumbnails during the revisitation task?
We showed the same set of pages in Phase II as in Phase I.
However, participants saw only a single representation type  in Phase II; representation was a between-subjects variable.
By requiring each individual to interact with only a single representation during Phase II, we were able to assess the effect of the representation type on the recall of Web pages that participants had seen the day before as well as look at the effect of congruency of the representation.
Participants were recruited from across the entire employee population of a large software company.
Phase I was completed by 276 people; of those, 197 went on to complete Phase II.
Participants came from a range of job roles, including executive, design, engineering, and sales.
They ranged in age from 18 to 65 years old , and 86% were male.
All were heavy users of Web search, with most reporting that they searched the Web several times a day or more.
In addition to exploring how the different representations support search, Phase I also served as a priming phase for a follow up study of how people recognize previously viewed pages.
One day after participants completed Phase I, they were asked to complete a second phase of the experiment.
For the search phase we were interested in two quantitative measures of performance: task completion time and the number of page views for each task.
We performed two 3  x 4  within-subjects repeated measures ANOVAs , looking first at task completion time and next at number of page clicks.
We also explored several qualitative measures of representation quality, including preference judgments and free form comments.
Completion times averaged 166 seconds to complete the first task and decreased to 100 seconds to complete the last.
There was no effect on task time for Representation and no significant interaction.
As Figure 5 shows, while the average time to complete the task was smallest for text snippets, this was not significantly different from either visual snippets or page thumbnails.
This suggests our participants were able to find new information quickly, independent of how the pages were represented.
Participants judged ease of use on a seven-point Likert scale, with 1 being very hard and 7 being very easy; text snippets received a mean rating of 3.96, visual snippets 3.97, and thumbnails 3.24.
Because Likert scale responses are not normally distributed, standard t-test comparisons cannot be used.
Pairwise comparisons between ranks using the Mann-Whitney U test showed significant differences between text snippets and thumbnails  and between visual snippets and thumbnails  but no difference in ease of use between text and visual snippets.
Similarly, when participants were asked if they liked a particular representation on a seven-point scale , text received a mean rating of 4.51, visual snippets 4.28, and thumbnails 3.75.
Again, text and visual snippets were each liked significantly more than thumbnails  but did not differ significantly from each other.
We also explored the comments participants made about their experiences with the three different representations.
A number of people mentioned using branding information to find what they were looking for, referring specifically to the URL in the text snippet or the logo in the visual snippets as a source of that information.
As suggested by the designers during design analysis, these two components appear to have served similar functions.
For example, one participant said, "When I see a Web site's name in a visual snippet, I get the same information from the URL and I generally weight that heavily."
Only one participant mentioned using the page layout in the thumbnail representation to identify brand.
Visual representations of pages from unknown domains may have been less valuable, as suggested by a participant who reported, "The usefulness of thumbnailing pages that I've never been to is limited."
A number of subjects mentioned that the value of the different representations varied by task, with the visual snippets being particularly useful for shopping tasks.
This may be because people prefer to shop at trusted sites and are familiar with the shopping site logos highlighted in the visual snippets.
As one participant said, "The nice thing with the  was when I was looking for the cheap price I knew Amazon was usually the cheapest so I just had to look for the Amazon logo.
When looking for information the images were not helpful."
Even though there was little difference in selection time, it does appear that people explored the results in different ways depending on how the results were represented.
As was observed for completion time, as participants performed more searches, they also got a bit more efficient at searching: they looked at an average of about 4 pages initially, and this dropped to 3.3 pages by the last task.
More interestingly, participants clicked on the fewest number of results when searching using text snippets, and the largest number when using thumbnail representations, with visual snippets falling in between .
Posthoc pair-wise comparisons  show significant differences between all representations.
These comments were not surprising given that we know from previous research  that thumbnails of the size used in the study are too small to support recognition even at the site level.
Many subjects suggested combining visual and text representations either by creating a single composite or through the use of hover.
Phase II was largely a between-subjects design.
Participants interacted with the same representation type throughout the second phase.
Because they interacted with all three types during the initial phase, this meant that for one-third of the tasks in Phase II the representation type used was congruent with the representation type used in Phase I, and for twothirds of the tasks the representation type was different.
We performed a between-subjects 3  x 2  ANOVA.
There was no significant interaction.
Overall, we observed no significant difference in time to task completion for any representation.
However, visual snippets required fewer clicks to complete the task than thumbnails, and visual snippets were subjectively preferred over thumbnails.
We believe consideration of all of these observations is necessary to understand how the different representations were employed for search.
It is interesting to observe that participants clicked more often on thumbnail representations than text and visual snippets, while taking about the same amount of time to complete the task overall.
Timing differences can be difficult to assess in tasks like those studied, and the number of clicks may be a reasonable proxy for effort involved in the task, especially for systems like the Web with significant latency following clicks.
The pages in our test loaded almost instantaneously.
In systems with more latency for loading Web pages, the increased number of clicks for thumbnails could translate into longer overall task time due to waiting for page loads.
Text and visual snippets would presumably be less affected by this.
One way to understand the observed difference is that participants spent more time looking at the text and visual snippet representations and deciding what to click than they did with the thumbnail representations.
However, the different processing times allowed participants to find what they were looking for just as quickly because they used different click strategies.
Figure 6 displays the mean amount of time it took to re-find the correct result found during Phase I, broken down by representation type.
Visual snippets were the fastest for refinding, followed by thumbnails.
Text snippets were the slowest.
The trend suggests visual representations of previously viewed pages may support faster revisitation.
Follow up pair-wise comparisons showed that only the difference between text and visual snippets was significant.
We also looked at the effect of congruency on revisitation time.
When the representation type was congruent across both the search and revisitation phases, we saw a significant decrease in task completion time compared to when the representations were different .
Previous interactions with a given type of representation appear to improve performance for re-finding later; familiarity helps.
Deeper analysis of the data shows that this effect is stronger for thumbnails than for either visual or text snippets.
Figure 8 shows the difference in task completion time for each representation type broken down by congruency.
There was a significant difference for congruency for thumbnail representations =2.54; p<.01, but the differences were not significant for text and visual snippets.
During the second phase participants were asked to re-find the correct results that they had identified during the initial search phase the day before.
In general, the task completion times were considerably faster for revisitation than search, suggesting participants did indeed use their memory of the results from their initial search to help them revisit the correct result.
As described earlier, in our study we manually extracted the logo and salient image from each Web page in our collection and then automatically composed the pieces to create the visual snippet.
Given the success of visual snippets described above, we implemented fully automatic extractors.
The salient image was simply the largest image on the page, and logo was selected using machine learning over several features, including the image's name, aspect ratio, surrounding link structure, and location.
To confirm that the fully automated visual snippets are of similar quality to the partially automated visual snippets, we conducted a study in which we asked people to tell us which representation they preferred.
In the study, 128 participants viewed an average of six Web pages each.
The pages were selected from the set used in the initial study.
After five seconds, participants were presented with the two visual snippets and asked to select the representation that better matched the page they just saw.
Of the 723 comparisons, we found that people preferred the snippets used in our study 362 times, and the fully automated visual snippets 361 times.
There was no statistical difference between the two.
However, because the automatic generation was not tested in our experiment of representation use, there may be observable differences in how they are used compared with manual generation.
Given that it appears we have identified a successful way to generate visual snippets in a fully automated fashion, we can now explore the problems with the existing design and easily implement improvements.
Interacting with an actual Web page was not enough to recognize or use a thumbnail of the page for re-finding.
In contrast, text and visual snippets seem to have captured some of what the participants internalized about the pages during their initial interactions, making them better representations for revisiting previously seen pages.
The ability of the visual snippets to perform better on incongruent tasks is important because in many cases where Web page representations are useful , we cannot assume a user will have had prior exposure to the exact same representation.
In real-world situations, the expectation of congruency across tasks is likely to be hard to enforce.
Overall, we found that for finding tasks text snippets were easy to use, well liked, and required relatively few clicks to find the information target.
In contrast, for re-finding tasks the visual representations were the fastest.
Visual snippets appeared to capture the best of text and thumbnails; they were as easy to use and well liked as text snippets for finding and as fast as thumbnails for re-finding without requiring congruency.
Encouraged by these results, we implemented a fully automated visual snippet generator.
This allowed us to confirm that the extraction of important components from a Web page could indeed be done automatically, and to explore several avenues for improving the generation algorithm.
In this section, we first show that automatically generated visual snippets were as high quality as the ones created via manual component extraction.
Then we discuss some problems with the design as it stands and present improvements to the system that correct for these problems.
One problem is that while visual snippets convey an overall impression of the Web pages they represent, they can be quite visually distinct from their parent pages.
In our design analysis, several designers suggested that a correlation between the page layout and page color would be useful for revisitation.
We also hypothesize that representations that are similar to the target may help users better orient themselves within the target when they choose to visit it.
With this improved design, it is possible to highlight additional aspects of a page as the page is represented at different sizes.
For example, Figure 12 shows a Web page where the dominant image on the page, the logo, and an article title are identified as salient.
The component pieces can be scaled differently so that some salient pieces are emphasized when there is enough room, while the snippet still reduces to the original design at small sizes.
This design provides users with some orientation within the target Web page should they click through and to enables semantically meaningful thumbnails to be represented at different sizes.
Further, by identifying additional page elements, we can create visual snippets that fail gracefully when a salient image or logo is not identified.
These additional page elements could also enable us to create thumbnails that are consistent across navigational tasks at small sizes, but tailored to best support the task when there is room.
For example, we could create query specific representations by selecting the query text that appears on a page, as was done by Woodruff et al.
The improved visual snippet generator shares some aspects with the one proposed by Woodruff et al.
As a result, our representations are context independent.
The importance we observed of congruency across tasks suggests a consistent representation across many different uses may be valuable for users.
To create a visual snippet that is better connected visually to its parent page and that scales better to different sizes, rather than extracting the salient components from a page and using them to create a new representation by composing them, our improved visual snippet generator resizes the selected images and text and overlays them directly onto a scaled version of the Web page.
As illustrated in Figure 10, the key idea is to scale the selected images and text differently from the overall Web page.
The exact placement of the salient aspects corresponds to their original position on the page, offset as necessary to prevent them from overflowing the borders of the resized page.
An example of this improved visual snippet design can be seen in Figure 11.
The top of the figure shows the original Web page with the page's logo and salient image highlighted in yellow.
When the page is scaled to the size of the original visual snippets, as shown in the lower righthand corner of Figure 11, it looks very similar.
In this paper, we looked at how different representations of Web pages affected people's ability to recognize new relevant Web content and return to previously viewed Web pages.
We found that our novel visual snippets support search while being significantly smaller than text snippets, and are particularly valuable for revisitation.
We believe our findings can be used to significantly improve people's search and browse experiences.
Small representations like the visual snippets allow a greater number of results to be viewed at once.
This is particularly important on mobile devices, where screen real estate is limited, but also important for history functionality where a large number of pages must be viewed together.
Further, small visual snippets could be used to complement text snippets in search result pages.
With only a small reduction in the amount of text, a hybrid snippet could occupy the same amount of space as current text snippets.
We believe it may be possible to construct even smaller visual snippets that are consistent with the snippets we have explored using just the logo and image.
These microrepresentations could be used in a bookmark or history list the way favicons currently are.
One area alluded to in our discussion of the improved visual snippets that we plan to explore further is the transition between a Web page's representation and the full page.
Representations can serve an important role not just in identifying a target page, but also in orienting a person within the target.
This can be done by making the representation consistent with the target or by animating a transition between the representation and the target, both of which are supported by the improved visual snippets.
Understanding the value of these features is particularly interesting as complex animation on the Web becomes more technologically feasible.
