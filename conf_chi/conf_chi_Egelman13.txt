We performed a laboratory experiment to study the privacy tradeoff offered by Facebook Connect: disclosing Facebook profile data to third-party websites for the convenience of logging in without creating separate accounts.
We controlled for trustworthiness and amount of information each website requested, as well as the consent dialog layout.
We discovered that these factors had no observable effects, likely because participants did not read the dialogs.
Yet, 15% still refused to use Facebook Connect, citing privacy concerns.
A likely explanation for subjects ignoring the dialogs while also understanding the privacy tradeoff--our exit survey indicated that 88% broadly understood what data would be collected-- is that subjects were already familiar with the dialogs prior to the experiment.
We discuss how our results demonstrate informed consent, but also how habituation prevented subjects from understanding the nuances between individual websites' data collection policies.
Facebook Connect is likely the most used SSO system.
In 2010, Facebook claimed that each month 250 million people were using it to authenticate to third-party websites .
As of 2012, as many as eight million websites allow users to authenticate via Facebook .
Like other OAuth-based systems , Facebook Connect offers users a value proposition: the convenience of a single set of credentials in exchange for granting relying websites access to certain Facebook profile information.
When users attempt to authenticate using Facebook Connect, they are presented with consent dialogs that outline the information collected if they proceed.
A dialog may indicate that a website is requesting access to minimal data, such as the user's name and gender.
Alternately, websites may make requests for data beyond the defaults, such as a user's interests .
It is not clear whether the current consent dialogs make this tradeoff clear to users.
We are unaware of any researchers who have performed controlled experiments to quantify the proportion of users who accept the privacy/convenience tradeoff offered by Facebook Connect.
We are also unaware of previous research that has examined the extent to which informed consent is achieved, as well as how users' decisions might change as a function of both how much information is requested and the trustworthiness of the recipient.
We examined these questions by performing a laboratory experiment.
We contribute the following: * We perform a controlled experiment to quantify the proportion of users who are willing to use Facebook Connect to authenticate to various websites.
Thus, improvements are needed to highlight data collection practices that are likely to diverge from users' expectations.
In a seminal 2007 study, Flor encio and Herley showed that the average Internet user has around 25 passwordprotected accounts .
As the web continues to grow, the number of password-protected accounts that users maintain will increase.
While users may not use a unique password for each account, they must still remember which password was used for which account.
Single SignOn  systems solve this problem by allowing users to authenticate to multiple websites using a single set of credentials.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Despite the wide availability of SSO systems, websites  have been slow adopters until very recently.
The main incentive for users is the ability to use "one account to rule them all."
For instance, websites can use registration forms to collect personal information that may be unavailable from identity providers.
The OAuth protocol has addressed some of these incentives .
OAuth-based SSO systems allow a relying party to request profile information from the identity provider .
This provides relying parties with a strong incentive to participate, as they can now collect information about their users that they otherwise might not have been able to collect, even with lengthy registration forms.
The closest related work to our experiment was Sun et al.
Forty percent of their participants were hesitant to release personal information, with 26% going so far as to request fake OpenID accounts to complete the study.
In real life, this option would not be available: users unwilling to release their profile information would either have to create a new non-SSO account or discontinue the task.
Thus, it is not clear how users might behave when faced with this more realistic choice.
Likewise, it is unclear whether informed consent is being achieved: were participants truly unconcerned or did they simply not understand the terms of the agreement?
However, they observed that short summaries were not a panacea: many users still proceeded with installations and then regretted those decisions afterwards.
B ohme and K opsell found that software dialogs designed similarly to EULAs were more likely to be ignored .
Others have since tried to improve the design of EULAs .
Recent information disclosure research has examined applications on the Facebook platform, which use consent dialogs very similar to the ones used by Facebook Connect.
Besmer and Lipford examined misconceptions about how data gets shared with Facebook applications and concluded that users wish to disclose less .
While many users use community ratings to decide whether an application will use data appropriately, Chia et al.
Others have proposed tools to allow users to limit their disclosures.
Felt and Evans found that most Facebook applications functioned with a subset of the requested information and therefore proposed a proxy to limit disclosures .
Others have proposed recommender systems to help users make disclosures decisions .
However, all of this research has examined consent for disclosing information to applications.
We believe this is a different case--despite similar interfaces--from SSO authentication because the former violates Friedman et al.
Thus, we believe that the question of achieving informed consent with Facebook Connect remains heretofore unexplored.
As ubiquitous computing has become a reality and the perception of control over one's personal information has decreased, various researchers have proposed privacy guidelines for providing users with adequate notice about how their information may be used .
Chief among these principles is the notion of informed consent .
Disclosure: Are the costs and benefits of providing the information presented to the user?
Comprehension: Does the user understand the disclosure statement?
Voluntariness: Is the user coerced into disclosing?
Competence: Is the user of sound mind to make a decision about disclosure?
Agreement: Is the user given ample opportunity to make a decision?
Grossklags and Good demonstrated that informed consent was not being achieved with software end-user license agreements  .
When users attempt to log into a website using Facebook Connect, they are shown a consent dialog that indicates certain data from their Facebook profiles will be transferred to the website if they proceed .
Users then have the choice to proceed or cancel.
If they cancel, they can either use a different login method  or abandon their task altogether.
The initial motivation for our experiment was to examine whether informed consent was being achieved in this context.
The information above is in addition to any other information on their profiles that is publicly viewable.
For example, if a user has not changed her privacy settings, she may inadvertently allow a website to also view status updates, comments, or photo albums.
Websites also have the option of requesting additional information: the Facebook API specifies permissions so that websites can request nearly any piece of information present in a user's Facebook profile, regardless of whether or not that information is viewable by other human beings; the interpersonal privacy settings do not apply to information requested through Facebook Connect.
We hypothesized that the aforementioned method of presenting privacy information to users was inadequate, and that if their relevant profile information were shown verbatim, they would be less likely to use Facebook Connect.
We tested this theory by creating a GreaseMon-
The GreaseMonkey script randomly assigned each participant to one of the three between-subjects conditions at the beginning of the experiment and ensured that each participant remained in the same condition on subsequent websites throughout the experiment.
Finally, we also chose these three websites because in addition to allowing users to log in via Facebook Connect, they also offered the option of creating new accounts.
We felt that it was critically important to offer participants alternative ways of completing each task in order to minimize the Milgram effect; if participants felt compelled to use Facebook Connect, our experiment would have been testing their ability to follow instructions, rather than their willingness to compromise privacy for convenience.
We observed participants visit three different websites that all used Facebook Connect.
We chose these three websites to control for two different factors: the amount of profile information that each website requested and the extent to which participants might trust each website with access to their data.
We decided to design our tasks around retrieving information from news websites.
As such, we needed two websites that requested the same amount of information, along with a third website that requested a superset of this information.
Likewise, of the two websites that requested the lesser amount of data, one needed to be more trustworthy than the other.
Eventually, we settled on the following three websites: * CNN  * The Sun  * Reuters  We chose these websites because CNN and Reuters are known as relatively neutral U.S. news sources, whereas The Sun is a British tabloid.
CNN and The Sun both collect the "basic info" described previously, though The Sun also collects email addresses.
Reuters collects the "basic info," email addresses, locations, and birthdays.
Since The Sun collected email addresses, unlike CNN, and because we were concerned that Reuters did not collect enough additional information to make the contrast apparent, we used some deception.
We designed our GreaseMonkey script to deceive participants into believing that more information was being requested.
For example, the dialogs stated that all three websites collected email addresses, so that CNN and The Sun would appear to collect the same information .
We told participants that they would view each of the three websites in order to answer questions about the features that each offered.
We asked participants what features became available once they logged in to each website.
In reality, we did not care about participants' responses to these questions and instead we were only interested in whether or not they used Facebook Connect to log in or if they created new accounts on each website.
We hypothesized that most participants would view the Facebook Connect consent dialogs, but that based on the experimental conditions, a subset of participants would choose not to proceed in order to protect their personal information from disclosure.
We ran screen capture software on each computer to capture this data.
During August of 2012, we recruited participants from the Bay Area Craigslist, offering participants $35 to participate in a one-hour "social media" study.
Prior to scheduling, we directed participants to an online screening survey to ensure that they had Facebook accounts for at least six months and were at least eighteen years old.
In addition to questions to mask our screening requirements, we also determined whether or not they used the new "timeline" profile format or the previous format, since our scripts only worked on the newer format.
We scheduled participants who qualified to attend one of seven laboratory sessions.
We split 87 eligible participants into cohorts of up to eighteen.
Participants in each cohort arrived at our laboratory and selected seats in front of computers separated by partitions so that each participant could not view the screens of other participants.
In order to accommodate this additional information, we were forced to change the layout of the dialog into a bulleted list.
Because this change resulted in a dramatic increase in the amount of text shown on the screen, and because the change might be immediately obvious to participants familiar with Facebook Connect, we created an intermediate condition to control for this.
The list condition expanded the same information as the control condition into a bulleted list format .
Thus, our three between-group conditions were as follows:
After giving them time to read the instructions, we read the instructions aloud: 1.
In this study, you will be asked to visit three different news websites.
While on each of these websites, you will need to browse around in order to answer the questions on the task description sheet.
Please fill in your responses on the sheet to the best of your ability.
Some of the questions will require you to log in to the websites.
You can do this by either creating a new account on each of these websites or by using "Facebook Connect."
Facebook Connect allows you to log in to other websites using your Facebook account information.
The method you choose is completely up to you.
On some of the websites, you may be asked to view a confirmation email after logging in or creating a new account.
Please do this from within the web browser.
Once you complete a task sheet, raise your hand and the experimenter will give you the next task.
Once you have completed all three tasks, you will be asked to complete an online survey about your experiences.
We then handed participants their first task.
We randomized the order in which each participant visited each of the three websites.
As they completed a task, we handed them the next task until they completed all three.
Finally, they completed an exit survey.
Once complete, we compensated them and handed them a debriefing sheet.
When participants left, we stopped the video capture software and reset the settings on each computer so as to erase all cookies and browser history.
Despite attempts to minimize the Milgram effect by offering participants an alternative authentication mechanism--creating a new account on each website--a minority still felt compelled.
Thus, we were forced to remove these sixteen subjects.
Another six subjects never logged in to any of the three websites,2 which forced us to remove them as well, leaving our remaining sample size at 65.
Sixty-eight percent of our subjects were female, while 32% were male.
Regardless, we observed no significant differences based on whether or not participants used Facebook Connect with regard to any of these demographic factors.
Table 2 shows the high-level results for each website.
Since some participants did not attempt to log in to some of the websites, the sample sizes were not constant across the three websites.
Likewise, because the three betweensubjects conditions were assigned randomly when a consent dialog was first displayed, ten participants  were never assigned to a condition because they never attempted to use Facebook Connect on any of the websites, proceeding directly to creating new accounts.
Another two participants' condition assignments could not be determined from our screen capture videos because they accepted the dialogs before they had fully loaded.
Overall, we were surprised to discover that only one participant refused to proceed with Facebook Connect after viewing a consent dialog; the rest either proceeded with Facebook Connect regardless of what the dialogs said, or they refused to use Facebook Connect prior to seeing the dialogs.
Furthermore, this participant was in the control condition.
Thus, we observed no statistically significant differences between conditions based on how the data was presented to participants .
Therefore, we cannot accept H1 nor reject the null hypothesis.
One possible explanation for the lack of observable effect is that participants did not read the dialogs.
Without using an eye tracker, it is impossible to determine this with certainty.
However, we used our screen capture videos to measure the amount of time that had elapsed between the dialogs loading and participants clicking the button to proceed.
We performed our laboratory experiment to test the following alternate hypotheses about Facebook Connect: H1 : Participants who are shown verbatim examples of the data that websites request will be significantly more likely to abandon using Facebook Connect.
H2 : Participants will be significantly more likely to abandon using Facebook Connect on websites that request more data.
H3 : Participants will be significantly more likely to abandon using Facebook Connect on untrusted websites than trusted websites.
In the remainder of this section, we present our results in terms of the behaviors that we observed, participants' awareness of each website's data collection practices, the extent to which they trusted each website with their data, and whether participants engaged in other strategies to protect their personal information.
To help explain our experimental results, our exit survey included an open-ended question about why they chose whether or not to use Facebook Connect on each of the three websites.
Summary of the results indicating the login method participants used on each website: proceeding with Facebook Connect, seeing the Facebook Connect dialog and then choosing to create a separate account on the website, and creating a separate account on the website without ever seeing the Facebook Connect consent dialog.
Because we were worried about habituation effects on the subsequent dialogs after the first, we only tested this for the first dialog to which participants were exposed.
We observed no statistically significant differences between the three conditions: the median reading times were 7s in the control and list conditions, and 6.0s in the verbatim condition .
These results suggest that participants failed to notice the changes we made to the consent dialogs.
Therefore, in the remainder of this paper, we analyzed the three between-subjects conditions together.
One of the two reasons for having participants visit three websites was to control for the amount of Facebook profile information that participants believed each website was requesting.
Our hypothesis, H2 , was that participants would be less likely to proceed logging in with Facebook Connect on a website that requested more profile data than the others .
We had them visit the Reuters website for this purpose.
Despite observing a single participant opt out of using Facebook Connect after seeing the consent dialog on this website, we could not draw statistically significant comparisons with the other two websites.
Thus, H2 cannot be accepted.
In our exit survey, participants listed the types of data they believed each website was requesting via Facebook Connect.
Only three participants  indicated that they believed Reuters was collecting substantially more data than the other two websites.
This corroborates our theory that participants did not thoroughly read the consent dialogs in the laboratory and therefore did not notice the subtle differences between conditions.
While they may not have understood the nuances in data collection policies between the three websites, this does not mean that they were generally unaware of the privacy cost of using Facebook Connect.
In the exit survey, participants reported whether they had previously used Facebook Connect on a 5-point Likert scale , depicted in Figure 4.
Of the 54  participants who used Facebook Connect in our experiment at least once, only 26% claimed to have never used it prior to our experiment.
This suggests that many participants may have already understood the basic value proposition from prior knowledge and had become habituated to future dialogs.
We asked participants to list the types of data they believed each website would collect if they used Facebook Connect to log in and found that most participants understood that some amount of their profile data would be collected.
Because we thought it unreasonable for them to name the complete set of items listed in Table 1, we accepted answers that mentioned a subset of this information.
Examples of acceptable answers included:
Overall, we found that 88% of our 65 participants had a basic understanding of the privacy cost.
This comprehension rate did not observably change as a function of whether or not participants used Facebook Connect in our experiment.
In fact, of the 45 participants who claimed to have used Facebook Connect at least once prior to our experiment, 96% understood that they were disclosing profile information.
This further corroborates our theory that participants did not read the dialogs because they were already familiar with them.
Nineteen participants  believed that all of their profile data would be transferred to the websites: * "All of the personal information that we submit when registering for Facebook, all of the things we have liked and whatever other information they can gather from what we have posted in the past."
Surprisingly, this erroneous belief did not prevent participants from using Facebook Connect: there was no observable correlation between believing a website would receive all of a participant's Facebook profile data and whether that participant used Facebook Connect to log in to that website.
On CNN, nine of ten participants believed all of their Facebook data would be transferred yet used Facebook Connect anyway.
On both Reuters and The Sun, this proportion was eleven out of fourteen.
Thus, while participants did not pay attention to the details of the consent dialogs during the experiment, almost all of them understood that some amount of their Facebook profile data would be released to the requesting websites upon logging in with Facebook Connect.
The median response for both CNN and Reuters was "unsure," whereas it was "disagree" for The Sun.
Despite this varying level of trust, we observed no effect on participants' decisions to use Facebook Connect.
We examined whether our results could have been confounded by participants who already had accounts on one or more of the three websites.
While five participants claimed to have already had accounts on the CNN website, we observed no correlation with whether they chose to use Facebook Connect in our experiment.
None of our participants had accounts on either Reuters or The Sun's website.
We therefore conclude that neither participants' prior relationship with each website nor the extent to which they trusted each website with their profile data had an observable impact on their decisions to grant those websites access to their Facebook profile data.
Ultimately, we were curious why participants chose whether or not to use Facebook Connect on each website.
In our exit survey we explicitly asked this open-ended question about each of the three websites visited.
Of the participants who refused to use Facebook Connect, almost all of them explicitly mentioned privacy: 12 participants on CNN , 14 participants on The Sun , and 12 participants on Retuers .
Examples of these explanations included: * "I don't want CNN knowing my information."
But when I see the dialogue box that says something about giving permission to share content or share my information or share something, I ALWAYS cancel."
I don't think what I do on Facebook is the business of The Sun or any other site."
The corollary is that those who chose to proceed with using Facebook Connect, despite understanding the privacy implications, did so out of convenience: 34 participants on CNN , 36 participants on The Sun , and 38 participants on Reuters .
Examples of these explanations included: * "Easier because I already have a Facebook account."
The second reason why we had participants visit three different websites was so that we could control for whether or not participants trusted the websites with their data.
We chose The Sun to test this hypothesis, H3 , for two reasons.
First, since it is based in a foreign country, we reasoned that many participants may simply be less familiar with it than the other two U.S.-based websites.
Second, for participants familiar with The Sun, we reasoned that they may trust it less because it is a tabloid.
We validated this design decision in the exit survey by asking participants to use a 5-point Likert scale  to rate the extent to which they trust each website with their Facebook profile data.
After the Facebook login was invented, I never went back to creating a new account because you have to think of a creative username, which might be taken, and a password, and then confirm all that information with your email.
Facebook Connect is just one click of a button."
While participants who were more concerned with convenience than privacy were more likely to use Facebook Connect, this does not mean that they did not take additional steps to limit their information exposure.
In addition to specifying what profile information would be accessible to websites, the consent dialogs also allowed users to modify who could see posts made to their Facebook profiles originating from these websites .
The choices available to users were "everyone," "friends," "only me," "custom," and any user-defined lists of friends.
If users do not change their default privacy settings from within Facebook, the default is "everyone," which was the case for only six participants .
In fact, 34 participants  had the default set to "friends," thirteen  had this set to "custom," while a single participant had this set to "only me."
This indicates that 89% had previously modified their Facebook privacy settings, which corroborates Johnson et al.
But these are just the defaults that appeared when the consent dialog was first displayed: a majority of participants  changed these defaults to further restrict access.
Table 3 depicts the parties with whom websites' posts would be shared, for the participants who used Facebook Connect.
Of the 32 participants who changed their defaults during the experiment, every single one of them selected "only me."
While we cannot say anything about those who had "custom" as their default setting, our results indicate that for participants who accepted the privacy tradeoff involved with using Facebook Connect, they took steps to mitigate the flow of information to additional parties, which indicates informed consent.
But at the same time, our data suggests that participants were acting out of bounded rationality: most participants opted not to read the details of each website's data collection policy because they felt they already had an idea of what the policies said, and therefore participants did not understand the differences between the policies of varying websites.
We discuss our results within the context of Friedman et al.
We examined whether users understood the privacy cost of Facebook Connect by creating three between-subjects conditions to vary how the information was presented.
We found that when given additional details, participants were no less likely to use Facebook Connect.
Our exit survey showed that participants had a broad understanding of data collection policies, likely from prior exposures to the consent dialogs.
Thus, during the tasks they did not pay enough attention to the dialogs to notice nuances between them, likely because they were habituated to them.
This reflects a potential shortcoming in the informed consent process: participants may be failing to notice disclosures that diverge from their expectations.
We observed that 88% of our participants exhibited a basic understanding that their Facebook profile information would be transferred to the websites.
They may have gained this knowledge from previous exposures or through other sources, such as media stories or word of mouth.
Regardless of how they learned about Facebook Connect's value proposition, participants demonstrated comprehension of the default data collection policies ; our data suggests that informed consent failures occurred due to participants not noticing additional disclosures, rather than noticing but not understanding disclosures.
Facebook Connect offers users a privacy/convenience tradeoff: use Facebook credentials to log into third party websites  while disclosing personal information , or protect personal information  by creating separate accounts on each website .
Despite documented problems with similar dialogs for granting application permissions , our participants understood the privacy/convenience tradeoff when using Facebook Connect.
While we cannot directly compare our results with other studies that were performed at different times and under different conditions, a key difference between our results and previous research appears to be context.
When the dialogs are used for application permissions, the user has but one choice: she must accept the privacy cost to use the application.
In the context of SSO, the user makes a decision: accept the privacy/convenience tradeoff of Facebook Connect or maintain privacy and create a separate account.
Thus, when used for SSO, the dialogs succeed at the voluntariness principle where the same dialogs failed when used for application permissions.
However, a side-by-side comparison under controlled conditions is still needed.
While we did not specifically determine whether participants were competent enough to make the decisions needed to complete the tasks, we measured whether their observed behaviors matched their stated privacy preferences.
In the exit survey, we asked participants questions in order to classify them within the Westin Index of privacy preferences  .
We believe that the dialogs met the competence criterion because we observed a significant correlation between participants' Westin Index classifications and whether they chose to use Facebook Connect ; "privacy fundamentalists" were significantly more likely to opt out.
Thus, the dialogs allowed participants to act competently: those who had privacy concerns were able to avoid making disclosures.
Future studies are needed to determine the most effective techniques for overcoming habituation when users encounter "unexpected" privacy policies, as well as to establish how often these situations arise.
Thanks to Christopher Thompson, Rowilma del Castillo, Miho Tanaka, Stephanie Pe na, Ashley Lopez, and Thant Hein for help conducting the experiment; Adrienne Porter Felt, Maritza Johnson, Heather Lipford, and David Wagner for feedback.
This work was supported by the Intel Science and Technology Center for Secure Computing.
V. Bellotti and A. Sellen.
Design for privacy in ubiquitous computing environments.
In Proceedings of the third conference on European Conference on Computer-Supported Cooperative Work, pages 77-92, Norwell, MA, USA, 1993.
A. Besmer and H. R. Lipford.
Users' conceptions of social applications.
Social applications: exploring a more secure framework.
The impact of social navigation on privacy policy configuration.
R. B ohme and S. K opsell.
The agreement principle states that users should be given opportunity to reconsider their decisions.
Within the context of Facebook Connect, this corresponds to the ability to revoke websites' access to Facebook profile data.
While Facebook provides users this ability, explicitly testing whether or not they knew how to use it was beyond the scope of our experiment.
At the same time, two participants, unprompted, volunteered that they knew they could revoke their decisions later: "I can choose later to disconnect myself from the site."
The proportion of participants who understood this is a subject for future work.
We believe that during our experiment, informed consent was largely achieved: in general, participants who were comfortable making disclosures used the system, whereas those who were not completed the task using other means.
At the same time, our data point to a potential shortcoming of the Facebook Connect system: users are incorrectly viewing the consent dialogs as static warnings, mistakenly believing that they all communicate similar data collection policies.
It is unclear whether users of other OAuth-based systems also believe this.
Therefore, designers need to improve these dialogs so that users understand that the terms of a data collection policy may drastically change from one website to another.
We observed that participants made privacy decisions based on a coarse understanding of the types of data that websites might collect; in most cases, participants were either correct or cynically believed that data recipients were collecting more information than in reality.
However, this level of understanding may pose problems when users incorrectly believe that websites are collecting less data than they actually are.
Future designs should address this issue by examining user expectations and then doing a much better job of highlighting situations that are likely to diverge from these expectations.
For instance, when a website goes beyond collect-
Privacy protection for social networking platforms.
D. Florencio and C. Herley.
A large-scale study of web password habits.
B. Friedman, E. Felten, and L. I. Millett.
Informed consent online: A conceptual model and design principles.
B. Friedman, D. Howe, and E. Felten.
Informed consent in the mozilla browser: Implementing value sensitive design.
In Proceedings of the 35th Annual Hawaii International Conference on System Sciences , page 247, Washington, DC, USA, 2002.
Noticing notice: a large-scale experiment on the timing of software license agreements.
In CHI '07: Proceedings of the SIGCHI conference on Human factors in computing systems, pages 607-616, New York, NY, USA, 2007.
J. Grossklags and N. Good.
Empirical studies on software notices to inform policy makers and usability designers.
In Proceedings of the 11th International Conference on Financial cryptography and 1st International conference on Usable Security, FC'07/USEC'07, pages 341-355, Berlin, Heidelberg, 2007.
Each month 250 million people use facebook connect on the web.
M. Johnson, S. Egelman, and S. M. Bellovin.
Facebook and privacy: it's complicated.
M. Kay and M. Terry.
King, A. Lampinen, and A. Smolen.
Privacy: is there an app for that?
Privacy by design - principles of privacy-aware ubiquitous systems.
A conceptual model and a metaphor of everyday privacy in ubiquitous.
Technical report, University of California at Berkeley, Berkeley, CA, USA, 2002.
Is facebook connect mark zuckerberg's ace in the hole?
O. Schneider and A. Garnett.
Consentcanvas: automatic texturing for improved readability in end-user license agreements.
Roauth: recommendation based open authorization.
Beyond user-to-user access control for online social networks.
In Proceedings of the 10th International Conference on Information and Communications Security, ICICS '08, pages 174-189, Berlin, Heidelberg, 2008.
Social demographics: Who's using today's biggest networks.
A billion keys, but few locks: the crisis of web single sign-on.
What makes users refuse web single sign-on?
An online experiment of privacy authorization dialogues for social applications.
In CSCW '13: Proceedings of the 2013 ACM Conference on Computer Supported Cooperative Work.
E-Commerce & Privacy: What Net Users Want.
