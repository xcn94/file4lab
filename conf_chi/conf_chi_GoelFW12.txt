The lack of tactile feedback on touch screens makes typing difficult, a challenge exacerbated when situational impairments like walking vibration and divided attention arise in mobile settings.
We introduce WalkType, an adaptive text entry system that leverages the mobile device's built-in tri-axis accelerometer to compensate for extraneous movement while walking.
WalkType's classification model uses the displacement and acceleration of the device, and inference about the user's footsteps.
Additionally, WalkType models finger-touch location and finger distance traveled on the screen, features that increase overall accuracy regardless of movement.
The final model was built on typing data collected from 16 participants.
In a study comparing WalkType to a control condition, WalkType reduced uncorrected errors by 45.2% and increased typing speed by 12.9% for walking participants.
Visualizaton of key presses with WalkType  and without WalkType  collected while users were walking during model-building, showing touch points for "N", "R" and "S".
Correct key-press classifications are in green; errors are in red.
In our study, WalkType  corrected 90.1% of the errors.
Researchers have explored various techniques to accommodate some situational impairments, like walking versus stationary interaction  and, to a lesser extent, adaptive techniques to automatically meet such needs .
Despite these advances, techniques to improve interaction in the presence of situational impairments are relatively unexplored, particularly for text entry.
In this paper, we present WalkType , a system that uses a touch screen device's built-in accelerometer to increase text entry accuracy while the user is walking.
Taking inspiration from image stabilization techniques of cameras to remove motion blur , WalkType compensates for imprecise input by incorporating multiple features computed from the accelerometer data: displacement, acceleration, and inference about the user's movement.
Additionally, WalkType uses tap location and the finger travel distance during taps to improve the user's text entry accuracy, features that increase overall accuracy regardless of movement.
Previous work on adaptive text entry has largely focused on adjusting key-press probabilities based on language models .
To our knowledge, taking into account the user's motion through accelerometer or other sensor data has not been explored.
To design and build WalkType, we first collected touch screen typing data from 16 participants.
Based on this data, we built two key-press classification models that incorporate accelerometer information.
In simulations, these models improved classification accuracy over a control condition from 72.8% to 94.6% and 95.7%,
Touch screen devices have become the dominant platform for mobile computing; however, the lack of tactile feedback on these devices requires a high level of visual attention to select targets accurately.
Input is particularly challenging when the user is in motion , a state that can be thought of as causing situational impairments .
Situational impairments may be caused by a variety of factors including vibration, divided attention, diverted gaze, body motion, awkward postures, cold temperatures, clothing, rainwater, glare, uneven terrain, ambient noise, or encumbering baggage.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
While some improvement occurred for both walking and sitting, walking received an additional 4.8% increase in accuracy.
The final WalkType prototype is a composite of these two models and a third more basic model that together achieved an accuracy of 97.3%.
We evaluated the final WalkType system in a controlled study with 16 participants, 5 of whom had also participated in our model-building study.
Our findings show that WalkType improves typing performance for both sitting and walking, but that the benefits are greatest for walking.
WalkType improved text entry speed compared to a control condition from 28.3 to 31.1 words per minute .
Uncorrected error rate  also improved, particularly for walking, where average error rate dropped from 10.5% to 5.8% with WalkType.
Finally, WalkType was highly preferred by participants, who recognized its performance benefits despite there being no visual difference between WalkType and the control interface.
The main contribution of this paper is a demonstration that accelerometer data can be used to improve typing performance on mobile devices when the user is situationally-impaired due to walking.
This contribution comes in three parts:  an exploration of key-press classification models for improving mobile touch screen typing;  WalkType itself and its component models that incorporate accelerometer data; and  an evaluation of WalkType, showing that it significantly improves user typing performance over a standard touch screen keyboard, particularly while the user is walking.
To address the foregoing challenges, techniques have been proposed to bridge the gap between stationary and walking interaction.
For example, Brewster et al.
Taking an adaptive approach, Kane et al.
Yamabe and Takahashi  used accelerometer information to automatically adapt the size of fonts and images while walking.
Yatani and Truong  investigated how two-handed chorded keyboard input could improving using a stylus-based PDA while walking.
The importance of accounting for the context in which a mobile device is used has been stressed by numerous researchers .
Walking has been shown to affect both input and output with mobile devices.
Consequently, existing techniques for motor-impaired users may be useful in accommodating situational impairments on mobile devices.
Mobile devices can also impact the user's ability to read information.
For example, walking has been shown to have a negative effect on both text legibility  and reading comprehension .
A plethora of touch screen text entry techniques have been developed for both finger and stylus input.
Prior work  provides a full review.
Approaches to improve text entry performance with QWERTY keyboard layouts have been proposed, for example, using geometric pattern matching  and gestures .
Of particular relevance to our work are approaches that combine language model predictions with probabilities from a touch model  to improve overall input accuracy.
Language model predictions for the next letter to be typed have been used to resize keys, either visibly  or invisibly, that is, without showing the adaptation to the user .
That is, regardless of the changing predicted letter probabilities, a center  area on the visible key always returns that letter, ensuring that a "direct hit" on the key by a user's finger provides a predictable result.
We use this approach in WalkType.
As with WalkType, others have proposed techniques that use models of key-press distributions built on aggregate typing data collected from users.
Most commonly, bivariate Gaussian distributions have been used to model individual keys .
A small number of projects have introduced models that adapt to individual typing patterns.
A simulation study by Rudchenko et al.
Adapting the location of keys based on the centroid of the user's previous key presses has also been studied for larger devices , but no performance benefits have been found in user evaluations.
In general, these techniques have relatively high error rates and are meant for specialized contexts where touch screen keyboards may not be available.
TiltType  and TiltText , for example, use combinations of tilting and buttonpressing for entering letters.
Our system, in contrast, uses accelerometer data as an additional source of information to improve typing on a standard QWERTY layout.
The models were built based on typing data collected from 16 participants  who each volunteered for a 45-minute study session.
All participants self-rated as expert computer users and intermediate to expert touch screen smartphone users.
WalkType derives motivation from the image stabilization techniques broadly found in digital cameras.
There has been extensive research in countering user motion in image and video capture.
Researchers have worked to remove effects of camera shake for images .
Similar techniques have also been used by researchers to stabilize contents of a screen.
Behringer  addressed the problem of shaking displays in moving vehicles by dynamically shifting screen content.
Similarly, NoShake  utilizes the accelerometer of a smartphone to perform content stabilization by dynamically moving screen content.
Finally, of particular relevance to walking-based situational impairments, Crossan et al.
Although their approach is relevant to our work, Crossan et al.
WalkType uses multiple sources of information to classify a user's finger-touches as key-presses.
Among these sources is data from the device's built-in accelerometer, which is used to account for extraneous movement while the user is walking.
In this section, we outline WalkType and the process taken to build it, including a study to collect training data from 16 participants.
In the next section, we describe a controlled study of the final WalkType system.
Along with accelerometer data, WalkType uses tap locations and tap travel distance to better predict the intended key.
The Weka machine learning toolkit1 was used to generate two J4.8 Decision Tree models with pruning confidence set to Weka's default .
For classification, the first model used time-domain accelerometer data between taps and the second model used the pattern of accelerometer data generated from the three axes due to the phone's motion while walking.
The final WalkType system combined output from both of these models along with a simple Euclidian model.
Our analysis showed that this composite model performed better than individual models.
We built a custom data collection application, WalkType Collect, for the iPhone 3GS that records the device's movement using the on-device low-noise tri-axis accelerometer.
We wanted to elicit natural typing patterns and did not want participants to be overly concerned with the accuracy of their input.
Thus, we followed the approaches of Gunawardana et al.
To convey this feedback, a small cursor moved under the phrase as the user typed.
Figure 2 shows an example.
If the user realized that they were off by a character or two while typing, they could swipe from right to left anywhere on the screen to delete one tap at a time.
Participants were instructed to try to delete their tap when they knew they had made an obvious mistake or when they felt they were off by a character or two.
We requested participants not to go back through the whole phrase in order to correct a supposed error.
Participants were asked to enter 50 phrases in 2 postures, sitting and walking, while holding the device with both hands and typing with both thumbs.
The order of postures was counterbalanced and participants were randomly assigned to orders.
Short phrases of English text from MacKenzie and Soukoreff's phrase set  were used.
The lack of tap-location feedback meant that users made mistakes while entering text, which added noise to our data.
Thus, outliers were removed during post-processing by eliminating all taps that landed outside the Euclidean bounds of the intended key or its immediate neighbors.
Figure 3 shows filtered data for one participant for the "H" key.
About 2.5% taps were filtered out in this process.
When dealing with accelerometer data, it is often necessary to compensate for gravitational pull on the three axes.
We found this compensation unnecessary because phone orientation stays relatively constant while typing.
For the displacement magnitude and direction features in the z-axis, we first subtracted the mean acceleration from the filtered data and then double-integrated it using the cumulative sum.
The direction in which the phone moved in the z-axis was also calculated.
To do so, we compared the device's instantaneous acceleration with the moving mean acceleration of the device.
If the instantaneous acceleration was less than the mean, we inferred that the device was moving forward.
Otherwise, it was moving backward.
We conducted a 10-fold cross-validation on the WalkType Collect data to evaluate the Displacement and Acceleration Model.
The model improved classification accuracy on average from 72.8%  to 94.6%.
To evaluate the benefit of the accelerometer data, we also tested this model after removing all accelerometer features.
See Figure 4 for a comparison of all models, including the Displacement and Acceleration Model.
The logs from Collect contained tap-start and tap-end locations, amount of travel while tapping, the time interval between taps, the intended key, and temporal accelerometer data.
The touch-screen-based features  form the base set of classification features used in both models described in the next two subsections.
We chose to include tap travel and time elapsed in this set based on observations we made while developing Collect.
For tap travel, we observed that, at times, the tap-start and tap-end locations were not the same, yielding a potential feature to increase classification accuracy.
For time elapsed, we observed that typing speed appeared to impact the user's input accuracy: the tendency to type the wrong key was relatively low when typing slowly compared to more quickly.
We hypothesized that one of the major reasons for inaccuracy in typing while walking is the general movement of the phone and its displacement from a relatively stable location with respect to the user.
Based on this hypothesis, the Displacement and Acceleration Model improves tap accuracy by incorporating acceleration features in all three axes, and magnitude and direction of displacement in the z-axis.
To calculate these features, the data from the smartphone's on-device accelerometer was first passed through a low-pass filter to remove noise.
This model also includes the base set of features.
To calculate the acceleration features, the filtered accelerometer data was resampled to 10 samples between two consecutive taps.
We selected this sampling rate as it gave reasonable resolution and did not overly increase the number of attributes for the classifier.
In analyzing the Collect data, we observed that the phone oscillated in a largely repeatable pattern while a user was walking and typing.
Figure 5 shows one such instance of the pattern in the z-axis.
The Walktype Pattern Model leverages the on-device accelerometer to obtain this pattern in all three axes.
In addition to the base set of classification features, it incorporates four new features per axis.
We use different techniques as a user's interaction with a device while typing is very different while walking.
To make the model adaptive to different walking speeds, we calculated the dominant frequency  of the user's motion and its mean amplitude from all three axes.
This gives us a proxy for detecting changes in the user's speed and intensity of movement.
To calculate the instantaneous dominant frequency, we took the Fast Fourier Transform  of the accelerometer signal and found the frequency with the maximum amplitude.
This frequency and amplitude constitute the first two features.
For the third feature, the direction of the last mean crossing before the current tap gives a measure of the direction in which the device is moving.
Finally, to pinpoint where in the pattern a tap event occurs, we use the elapsed time since the accelerometer signal crossed the mean value of the signal, as demonstrated in Figure 5.
These features in the x-axis are particularly useful in detecting the user's footstep pattern.
We observed that when users' feet hit the ground, their taps tended to shift slightly towards the center of the keyboard.
We also observed that a shift to the left was more common when the left foot hit the ground, and a shift to the right was more common when the right foot hit .
When we do the analysis shown in Figure 5 on the x-axis data, we can detect which foot strikes the ground.
If the current x-axis data is less than the mean, then the user's left foot has landed, and vice-versa for the right foot.
Because the effect of the footstrike on the user's accuracy would attenuate over time, we also calculated the time since the last foot hit the ground.
This calculation was performed in exactly the same way as for the z-axis .
We provide the classifier with the tap location on the screen, the direction in which the phone is going in y- and z-axes, and the last foot that struck the ground.
We also provide three temporal components denoting time since the last change in direction in the three axes.
The Combined WalkType Model is a composite of the three sub-models: the Displacement and Acceleration Model, the Walking Pattern Model, and the Euclidean Model.
A majority voting approach is used, whereby for each fingertouch, the key selected by at least two of the three internal models is output to the text stream.
When all three models disagree, the Walking Pattern Model prevails, since it model performed the best in isolation on the WalkType Collect data.
Figure 7 shows a block diagram detailing the approach.
The Euclidian Model is included because, although classification accuracy was high for both of the accelerometer-based models, some keys become major sources of errors as they got masked by adjacent keys.
An example confusion matrix is shown in Figure 8.
Here a more frequently occurring key dominates adjacent keys, for example, "A" dominates "S".
To counter this problem we combined the two models along with the Euclidean model.
As mentioned earlier, the Euclidean model selects the key containing tap location.
Although simple and non-adaptive, this model increases the probability of less-frequently occurring keys like "W" being correctly classified.
Five of these participants also participated in the model-building study.
All participants had more than 10 years of experience with computers and self-rated as intermediate to expert computer users.
Fourteen participants were near-expert touch screen smartphone users with approximately 2-3 years' worth of use.
Two participants did not own touch screen smartphones and had little experience with them.
The Combined Walktype model also incorporates keytarget anchoring .
After incorporating the three models, there were still taps that, although clearly landing in a key's center, did not get classified correctly.
Their work demonstrated that anchoring some part of the key increases overall typing accuracy.
We thus define an anchor area in the middle of each visual key; a tap within that anchor area bypasses the classification models and instead returns the visual key.
We reserved the central 20% along the x-axis and 50% along the y-axis of each key as the anchor area.
Introducing anchors further increased the overall accuracy of the WalkType Combined model to 97.28% .
This final model was used in WalkType.
Referring back to Figure 4 shows the cumulative improvement in accuracy for each component within this final model.
In a verification step, we confirmed that the accelerometer features are, indeed, a critical component of WalkType.
Removing these features drops classification accuracy by 6.8%  on average across participants.
Participants used our custom experiment software on an Apple iPhone 3GS that has a 3.5-inch capacitive screen with 480 x 380 pixels.
The application was developed using Objective-C.
It recorded all of the users' screen interactions as well as movement data from the accelerometer.
Figure 9 shows a screenshot.
The presented phrase appears atop the screen, wrapping onto a second line if necessary.
Entered text, in dark blue for contrast, appears immediately below.
When the user types a key, keystroke feedback is displayed at the top of the keyboard exactly above the position where the user tapped.
Because WalkType uses finger-travel and elapsed time as features, the decision of which key was pressed occurs when the user lifts his or her finger.
Accordingly, we modified the key-press feedback to occur when the finger is lifted, as opposed to when the user touches the screen, as occurs for the built-in iPhone keyboard.
In the bottom-right corner of the text area, the current trial number is displayed, with a trial being equal to one phrase.
Finally, the backspace functionality for the keyboard was also modified: a swipe anywhere on the screen from right-to-left backspaced one character.
All simulations in the previous section were run offline with Weka.
The final step in the process of creating WalkType was to port the model to an iPhone 3G for online use and evaluation.
To do so, we first ported the classification models generated by Weka into the iPhone and then optimized and synchronized their operations to work in real-time.
The online version of WalkType first filters the accelerometer data, and then sends it to the Combined WalkType Model for classification.
Participants were asked to familiarize themselves with the application and to ask any clarifying questions.
This learning phase lasted approximately 5 minutes, until the user was comfortable with the system and had completed at least 5 phrases without assistance.
For the walking tasks, we followed an approach similar to Kane et al.
To simulate a routine and unconstrained environment, the pacesetter ensured that the walking speed was consistent at about 1.07 m/s , a pace that comfortably accommodates a wide range of age and abilities .
The walking tasks were performed in a relatively quiet corridor of a university building.
For each condition, participants completed 30 test phrases, 24 of which were randomly selected from the MacKenzie and Soukoreff phrase set .
Apart from these, every fifth phrase was a randomly selected pangram to cover all letters in the alphabet.
Participants were asked to hold the phone in both hands and type with their thumbs.
We asked participants to type quickly and accurately, and to fix errors unless those errors were noticed "far behind" their current point of entry.
Finally, participants were requested to complete each trial without failing to keep walking and were offered a rest period at the end of each trial.
To calculate WPM and uncorrected error rate, we used StreamAnalyzer .
Statistical analyses were done using SPSS 19.
We tested for effects of presentation order on the main measure of typing speed using a 3-way ANOVA with presentation order of the interfaces as a between-subjects factor and Interface and Posture as within-subjects factors.
No main effect of presentation order was found, indicating that overall counterbalancing was effective.
However, there was an asymmetric skill transfer: a significant interaction occurred between presentation order and Interface on typing speed .
The control condition benefited more when it followed WalkType than vice versa.
Since this asymmetric skill transfer only injures WalkType's performance relative to the control condition, we are confident that our comparisons are still trustworthy.
We present results from a 2-way repeated measures ANOVA with Interface and Posture as within-subjects factors.
For uncorrected error rate, we used the nonparametric Aligned Rank Transform  with Interface and Posture as within-subjects factors.
We used this nonparametric procedure because uncorrected error rate is highly skewed toward zero and violates normality.
All pairwise comparisons were protected against Type I error using a Bonferroni adjustment.
The study was a within-subjects 2x2 factorial design.
The factors and levels were: * Interface: WalkType and Control.
Both interfaces used the same experiment software but the underlying keypress classification models were different.
WalkType used the final combined model from the previous section, while Control was non-adaptive, using only the Euclidian model.
Speed results are shown in Figure 10.
Overall, WalkType improved typing speed regardless of whether the user was sitting or walking: on average 31.1 WPM  compared to 28.3 WPM  in the control condition.
No significant main effect of Posture was found.
Presentation of the interfaces was counterbalanced.
Within each interface, postures were also counterbalanced.
With 30 trials  in each condition, participants performed 2x2x30=120 trials each, for a total of 1920 trials in the study.
Overall, we collected 57,663 key presses from 16 participants.
The main measures were speed, calculated as words per minute , and uncorrected error rate, following Soukoreff and MacKenzie .
Uncorrected errors represent those errors left in the transcribed text.
Corrected errors, which are errors made during entry, are of less interest, as such errors slow WPM and are thus subsumed by it.
Also, to evaluate whether participants could perceive any difference between the two systems, at the end of the session we asked them to rate which one of the two systems they preferred and why.
To guard against any bias, participants were not initially made aware of which keyboard was Control and which was WalkType.
We had expected WalkType to improve performance more for walking than for sitting, which would be seen through an interaction of Interface x Posture on typing speed.
Pairwise comparisons showed that participants benefited more using WalkType while walking than while sitting.
For walking, WalkType improved typing speed by 12.9% compared to the control interface, which was a significant difference .
For sitting, in contrast, no significant difference was found between the two interfaces .
WalkType improved typing speed by 12.9% and reduced uncorrected error rates by 45.2% while participants were walking.
Although there were no visual differences between the control interface and WalkType, participants perceived the performance benefit of WalkType and overwhelmingly preferred it to the control condition.
The Combined WalkType Model uses a majority voting approach between the three models.
We also tried to combine these models into one single model with one decision tree, but the performance of the system decreased considerably because the number of features increased and became unwieldy.
The WalkType models were built using data collected both while participants were walking and while they were sitting.
While experimenting with different models, we observed that using only the training data from walking further increased classification accuracy for walking, but decreased accuracy for sitting.
Based on this finding, we combined the two datasets for the final WalkType model.
However, detecting whether a user is walking or sitting and dynamically switching between different models--one trained on walking data and one trained on sitting data-- would likely provide a further performance benefit.
Our analysis showed that the major source of incorrect classification was confusion between adjacent keys in the same row.
We created a confusion matrix on the basis of our classification results and found that 72.8% of incorrect classifications were of adjacent keys.
Further examination into whether misclassifications occurred more towards the left or right sides of the keyboard showed that misclassifications occurred about evenly in this regard.
The split of same-row errors was 48.4% to the right of the intended key and 51.6% to the left.
This predominance of same-row confusion shows that it was easier for users to reliably hit in the vertical direction compared to the horizontal direction.
That users could do this was somewhat unexpected.
While walking, most vibrations are along the yaxis, i.e., the phone moves backward and forward more relative to the user.
We anticipated, incorrectly, that this would lead to more inter-row misclassifications.
Most researchers examining effects of walking on user interfaces do not use a pacesetter as we did, but either ask participants to "walk normally" or employ a treadmill .
Some of the features we have incorporated, such as the dominant frequency of the user's walking pattern and its amplitude, may be useful in adapting to different walking speeds.
Additional testing is needed to determine how well WalkType performs with varying walking speeds and whether additional training data is needed to model that context.
Figure 11 shows mean error rates per condition.
Mirroring the speed results, participants exhibited a marked improvement in error rate while using WalkType.
A main effect was found for Interface on error rate, indicating that, overall, WalkType significantly reduced errors compared to the control condition .
Of perhaps more interest is how WalkType impacted errors compared to the control condition while walking.
A significant Interface x Posture interaction for error rate showed that the effectiveness of the interfaces differed by posture .
Pairwise comparisons revealed that WalkType was particularly effective at accommodating the situational impairments introduced by movement.
Compared to the control condition, error rates decreased from 10.5% to 5.8% with WalkType, which was a significant difference .
No significant difference in error rate was found between the two interfaces for sitting.
During the model-building phase, we collected typing data in a condition where users were given feedback only as to whether they had hit a key, but not whether they hit the correct key.
In comparison, in the final user study, participants saw which letters they had entered, which could have led them to more accurate typing behavior.
This leads to an interesting conjecture--that training the system on more realistic data, like we collected in our evaluation, could further improve performance.
Finally, our study concentrates on the scenario where users hold the phone in both hands and type with their thumbs.
It will also be interesting to explore how our models perform on data collected with users holding the phone in one hand and typing with the index finger of the other hand.
WalkType increases users' typing speeds from 28.3 WPM to 31.3 WPM, and also reduces the number of uncorrected errors from 10.5% to 5.8% while participants are walking.
While WalkType focused on touch screen text entry, its approach may be useful for mobile input in general.
We thank Gaetano Borriello and Jon Froehlich.
This work was supported in part by the National Science Foundation  under grant IIS-0811063.
Any opinions, findings, conclusions or recommendations expressed in this work are those of the authors and do not necessarily reflect those of the National Science Foundation.
The text entry improvements obtained by leveraging the accelerometer suggest a similar approach may be useful for mobile interaction more broadly.
Stabilizing input with techniques similar to those proposed in our work, and making the device aware of users' movement patterns and gait may, for example, be useful in accounting for vibrations when users are trying to press a button or move a slider control.
Additional sensors may also be useful in further improving WalkType's classification model.
We used only data from the accelerometer to infer device position and rotation.
The obvious extension is to evaluate whether the built-in gyroscope would be better suited for inferring rotation.
Personalization is also a promising area of future work for WalkType.
Our explorations of the WalkType training data indicate that personalized models, where the system is trained only on one user's data, may increase classification accuracy over models generated from data from all participants.
A prior simulation study  on mobile touch screen typing data also supports this conjecture.
From our model-building data we observed that users were regularly off by a character when they tried to tap the keys on the borders of the screen, like "A", "Q", SPACE, etc.
At times, participants' taps landed on the bezel of the device instead of on its keys.
Our signal processing filtered out the vibrations caused by tapping of the screen while walking.
We believe if we separate vibrations from walking and tapping, then there is potential to leverage the tapping vibrations to detect taps on the bezel and change the system's behavior accordingly, e.g., by entering the most likely intended letter.
Capturing the effects of context on human performance in mobile computing systems.
Stabilization of a Display in a Moving Environment.
Annual Federal Laboratory Symposium on Advanced Displays and Interactive Displays, 131-134.
Experimental analysis of touch-screen gesture designs in mobile environments.
Overcoming the lack of screen space on mobile computers.
Using mobile devices in a variety of environments can lead to situational impairment due to, among other sources, vibration and divided attention.
We have introduced WalkType, an adaptive system for mobile touch screen devices that leverages the on-device accelerometer to compensate for vibrations and extraneous movements caused by walking.
