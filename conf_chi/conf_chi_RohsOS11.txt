The model provides a good fit  with laboratory data, but it is not known if it generalizes to realworld AR tasks.
In the present outdoor study, subjects  did building-selection tasks in an urban area.
The differences in task characteristics to the laboratory study are drastic: targets are three-dimensional and they vary in shape, size, z-distance, and visual context.
Nevertheless, the model yielded an R2 of 0.80, and when using effective target width an R2 of 0.88 was achieved.
In HCI, camera-based interaction with mobile AR interfaces has been analyzed as an instance of target acquisition performance that consists of rapid precise movements towards a point target or a spatially extended target.
According to Fitts' law , the duration of such movements  is systematically dependent on the distance to the target  and the target's width  as follows: t = a + b log2  Wang et al.
Rohs and Oulasvirta  propose a modified Fitts' law model for target acquisition of external targets that fits data better than the standard model.
Mobile augmented reality  improves information navigation on handheld devices by overcoming the limitations of display size.
Particularly, magic lens pointing, or pointing through the movable camera-view of the device , is a promising kind of interaction, because it allows large-scale information presentation with private and up-to-date information on a personal display.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
However, these models, and all models of AR we know of, have been developed based on data acquired in rigorously controlled laboratory conditions where subjects are standing in front a surface  on which targets appear.
Moreover, sequential selections can take place between targets with different characteristics.
Because even seemingly small changes in task conditions can affect the performance of a Fitts' law task , the question of generalizability is best addressed empirically.
Therefore, to assess if the model of Eq.
2 generalizes to the abovementioned conditions, this paper presents an experiment using real-world targets.
In the study, subjects were taken to balconies, bridges, parking lots, and streets to do reciprocal selection of buildings .
As we will show later, the model of Rohs and Oulasvirta  generalizes surprisingly well to this real-world task, achieving an R2 of 0.80, but increasing to R2 of 0.88 when effective target width  is used.
We identified an "averaging behavior" that may explain this improvement.
But we extend this by defining the movement vector to lie on a line through the centers of the previous target and the next target as in Figure 2.
The two intersection points of this line of movement and the next target's polygonal outline define the angular width of the target.
Thus, in the realworld pointing case W of next target does not only depend on that target alone, but also on the movement vector from which the target is approached.
In the benchmark model , pointing consists of two phases.
The first phase is denoted as physical pointing: The target can be directly observed in the physical world.
At some point during the movement towards the target, the target falls below the display and can no longer be observed directly, but only through the magic lens.
With a screen width of S, the split point is located at a distance of S/2.
At this point, the second phase--virtual pointing--begins: The target can now only be observed through the display.
As soon as a target falls below the lens, the characteristics of the mediation by the camera-display-unit come into play, such as delay and display update rate.
For the outdoor situation with buildings and landmarks as targets, the model has to be slightly adapted.
The real sizes of the objects do not help in characterizing the situation, because objects can be located at a wide range of zdistances from the user.
A smaller object might thus cover a wider field of view than a larger object if it is located closer to the user.
The angular size of a target from the viewpoint of the user is more meaningful.
Hence, we measure D and W in angular degrees, as proposed in earlier work .
Another complication lies in the fact that target shapes can be arbitrary polygons  rather than squares as typical in Fitts' law studies.
We defined the centers of the real-world targets as the centroid of the polygon area.
Since the targets are arbitrary polygons, the target width is not constant, but depends on the direction from which the target is approached.
In the experiment, we utilized a non-conventional reciprocal pointing task, in which users have to move back and forth between two targets and the two targets have different properties .
An interesting aspect of the experiment was to find out how users adapt to this situation.
In particular because of widely differing widths, we wondered whether users would change their movement speed according to Fitts' law or whether they would apply some kind of averaging behavior.
We therefore measured the effective target width We, which is computed as the width of the target based on the scatter of selection points around the target center point .
We also applied the model to averaged target widths, i.e., for each target pair we computed the average width and used this as the input to the model.
The subject has to press the joystick button to make a selection.
Since we dealt with arbitrary outdoor scenes and changing lighting conditions, no attempt was made to automatically recognize the image in real-time.
This would have led to a noticeable processing delay with a detrimental effect on pointing performance .
Therefore, upon selection, the last visible frame is stored as a PGM image together with meta data.
Moreover, they were pointed at in the real world by the experimenter.
To select a target, the subjects had to move the crosshair  on top of the target on the display and press the phone's joystick button.
Each user selection resulted in capturing and storing an image on the device.
Images were uploaded to a PC and analyzed off-line with a Java tool.
We annotated the images, determining the distance between the target center and the point of selection, as well as whether the selection was successful.
This data was used to compute the scatter around the target for We and the error rate.
To calculate the angular target distances and widths, a highresolution image was taken with a DSLR camera at each site.
The image was taken from the standing position of the participants and covered all four targets of a site.
In addition, a calibration image of a brick wall from a known distance was taken, with the identical camera and lens configuration as with the high-resolution site images.
The calibration image enabled us to compute the parameters to convert pixel coordinates in the image to angular coordinates in the real scene.
Using this mapping, we computed the angles D between pairs of target center points.
We verified the angular distances using a large-scale local map.
To compute the target widths we entered the outlines of each target as polygons into the tool.
From the outlines and the target center points, the tool computed the intersection points of the line of approach and the next target , which were then converted into the angular width W for that target pair.
The route consisted of 7 sites .
It was short enough for the experiment to last about one hour including transitions.
Each site consisted of 4 targets, yielding 6 target pairs.
With 2 directions in each target pair this results in 84 directed target pairs.
Target borders were chosen to be clear and easily perceived, not blocked by other buildings or vegetation.
Car traffic directly in front of a target was avoided to minimize distraction.
Selection always started from the left target in the target pair .
Timekeeping started on the first selection and the next item had to be selected as quickly and accurately as possible.
Within each target pair, 24 selections were made .
Half of the male and half of the female participants walked the route in opposite direction.
Target pairs were run in different random order for each participant.
Standing position and orientation at each site were fixed.
The total number of selections per subject was 24 selections for practice; and 7 sites x 6 target pairs x 24 selections = 1008 for the actual experiment.
The experiment yielded 11952 data points .
The overall error rate  was low , the mean selection time was 885ms.
Preprocessing revealed that two targets  were problematic, because the participants had trouble distinguishing them from their backgrounds.
Consequently, the two targets were excluded from further analysis.
Including these targets leads to R2 = 0.71 for our model, and R2 = 0.42 for standard Fitts' law.
The results are shown in Figure 4 as predicted time against measured time.
Typically ID is shown on the x-axis.
With the extended model, ID cannot be used directly.
When using effective target widths We, a fit of 0.88 was achieved which is identical to that of the laboratory study .
This is remarkable, when considering that the real-world targets had much more complex shapes, were embedded in a rich visual context, and were selected from a wide range of z-distances.
Moreover, sequential selections took place between targets with different characteristics.
As future work we intend to investigate the effects of visual saliency as well as the effects of z-distance and perspective on real-world AR pointing tasks.
These challenges will require a metric for the visual saliency of a target relative to its background, and we expect that z-distance and in particular the effects of perspective distortion caused by the users position will have a strong influence on performance.
3 yields a better fit when compared to the standard Fitts' law, the fit  is still relatively low compared to lab studies in the literature.
We therefore analyzed whether the large variation in target sizes within a single target pair might have an influence.
To this end, we looked at the actual speed-accuracy tradeoff the participants chose within a target pair by computing the effective target width We = 4.133.
Here,  represents the standard deviation of the end-point positions, which here are angular deviations from the target center.
Using the effective widths, fit raises to R2 = 0.88 for our model and R2 = 0.72 for the standard model.
The difference between actual and effective target width seems to be particularly large if the targets within a condition differ strongly in width.
When selecting subsets of target pairs with restricted width ratio R2 increases.
However, also the number of D,W-pairs decreases, leading presumably to a better fit.
The results regarding effective target width let us suspect that participants performed an "averaging behavior" within the reciprocal task, i.e., adapting the task for the average of the width of a condition's two targets.
We therefore reevaluated the data using the average  target width.
This led to an extremely high fit of R2 = 0.96 for our model and R2 = 0.88 for the standard Fitts' law model.
Hence we conclude that the users indeed employed an averaging behavior.
The power of Fitts' law lies in its ability to simplify a complex phenomenon in a way that generalizes beyond immediate observations.
The question is, whether models of performance in rigidly controlled laboratory conditions generalize to real-world conditions that may have different characteristics .
An essential part of research in this field should consist of validation of models in the real world.
From this perspective, the results of the present study are highly promising.
The laboratory model was found to gen-
