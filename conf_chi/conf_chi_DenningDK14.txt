Augmented reality  devices are poised to enter the market.
It is unclear how the properties of these devices will affect individuals' privacy.
In this study, we investigate the privacy perspectives of individuals when they are bystanders around AR devices.
We conducted 12 field sessions in cafes and interviewed 31 bystanders regarding their reactions to a co-located AR device.
Participants were predominantly split between having indifferent and negative reactions to the device.
Participants who expressed that AR devices change the bystander experience attributed this difference to subtleness, ease of recording, and the technology's lack of prevalence.
Additionally, participants surfaced a variety of factors that make recording more or less acceptable, including what they are doing when the recording is being taken.
Participants expressed interest in being asked permission before being recorded and in recording-blocking devices.
We use the interview results to guide an exploration of design directions for privacymediating technologies.
A new form factor for recording hardware--glasses-style augmented reality  devices--is poised to become more common.
If commercialization attempts  succeed in creating a market for these types of devices, there could be a massive increase in the number of people using wearable cameras.
This class of device shares characteristics with both camera phones and CCTVs; however, the result is a unique amalgamation of properties.
For example, AR-style glasses--unlike camera phones-- are well-suited for periodic, continuous, and low-effort audiovisual recording.
In contrast to CCTVs, AR glasses are mobile and controlled by individuals.
While research has been conducted on the relationship between recording and privacy, most prior work focuses on the current dominant form factors.
There is a need for more research into how wearable and glasses-style devices differ from other classes of cameras.
Moreover, these cameras have not yet achieved significant market penetration.
As a result, we have the opportunity to study how perceptions and usage patterns change over the adoption of a new technology.
In this study we consider the perspectives of bystanders of AR glasses.
In particular, we consider their perceptions of how and why these devices might impact their privacy.
Bystanders are particularly relevant for study: they are the largest stakeholder group.
We have the opportunity to explore technology designs that can mitigate bystander concerns.
In this paper we report on our in-situ approach to investigating bystander perspectives on AR-style recording.
We wore a mock AR device in cafes around a city over the course of 12 field sessions.
During these sessions, we conducted semi-structured interviews with 31 individuals on their reactions to the co-located device.
Our analysis of interview data surfaces:  reasons why participants do or do not consider AR glasses to change the bystander experience; and  factors that contribute to participants not wanting to be recorded.
Additionally, we explore participant thoughts on permission and blocking technologies for recording.
We use the interview results to explore design axes for recording technologies that respect bystander privacy.
Audiovisual recording is pervasive in public spaces.
This recording takes place predominantly via two classes of devices: handheld devices such as camera phones, and infrastructure devices such as closed-circuit television .
These two recording paradigms can be characterized and contrasted via axes such as mobility, recording cues, typical recording duration, content ownership, and intended usage.
Copyrights for components of this work owned by others than the author must be honored.
Abstracting with credit is permitted.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Publication rights licensed to ACM.
Early research on media spaces--such as by Adams  or Bellotti and Sellen --explores the privacy issues that result from an environment instrumented with recording capabilities.
This research is particularly transferable to CCTVs, but also has some transferability to AR privacy issues for bystanders.
More recently, Nguyen et al.
They interpreted their results largely via Smith's Concern for Information Privacy model ; this model breaks privacy concerns into the dimensions of collection, improper access, unauthorized secondary use, and errors.
Their results have a heavy focus on infrastructure-style CCTV cameras rather than on individuals' mobile cameras.
The authors investigate underlying issues and interviewee justifications.
For example, participants viewed the installation to be less acceptable if the footage was streamed to a remote location.
These bystanders can optionally be contacted for follow-up interviews.
Participants placed repackaged motion sensor lights in locations around the home.
Light activation served to probe participants to record reactions to the hypothetical sensors in study diaries.
In particular, they present a video that portrays the technology in a positive light together with a video that portrays the technology in a negative light.
More topically, they have both worn AR devices for extended periods of time and in public.
They have anecdotally reported their experiences wearing AR devices.
For example, in 2012 Mann reported that he was assaulted by a staff member in a Paris McDonald's due to his use of EyeTap .
They also wished to investigate bystander reactions to a wearable camera.
However, the camera in question was one primarily positioned as an assistive device for users with memory or vision impairment.
The stated purpose potentially affects bystander reactions to the device.
The study collected data via paratyping .
Each field session was conducted using two researchers: a researcher wearing a mock AR device and a researcher conducting interviews.
The AR mockup consisted of a pair of media glasses--the Myvu Crystal Personal Media Viewer--and an attached, non-functioning camera ; see the Methodology Discussion for the reasoning behind our decision not to record.
Field sessions proceeded as follows: the interviewing researcher would enter the cafe, order food or drinks, and take a seat.
The researcher wearing the mockup device would then enter the cafe, order, and sit down to work.
Patrons that had obvious reactions to the AR device, were likely to have noticed the AR device, or were pertinent for theoretical sampling  were approached for an interview.
The interviews were semi-structured and based around the following questions: 1.
Did you notice the glasses that he's wearing?
What about them did you notice?
Have you heard about those kinds of glasses?
Did you know that those kinds of glasses have electronics and a display attached?
Did you know that you can record video with those kinds of glasses?
Paratyping  is a methodology for collecting insitu feedback from bystanders via situated experience prototyping.
With this technique, participants are recruited to act as proxies for the researchers.
Participants carry short surveys and distribute them to bystanders with whom they interact.
Why do you think someone would want to wear those kinds of glasses?
Do you think recording with those glasses is similar or different to recording with a cell phone?
How do you feel about being around someone who is wearing those kinds of glasses?
Would you want someone with those kinds of glasses to ask your permission before recording a video?
Would you be willing to wear something that would block someone from being able to record you?
The progression of increasing specificity in the questions was arranged to probe participants on the more general topics in a non-leading way.
The protocol served as a guide for the interview; questions were modified or discarded based on the flow of the conversation and any time constraints set by the participants.
Interviews were not recorded: the interviewing researcher took interview notes and both researchers made observation notes.
The researchers--one male and one female--took turns wearing the AR mockup and conducting interviews.
Our human subjects Institutional Review Board reviewed and approved the study protocol.
A total of 12 field sessions were held in 8 different cafes over the course of 31/2 months in spring and summer 2013, and ranged in duration from 20-90 minutes each.
The field sessions were performed at different times of day and on different days of the week, including weekends.
At the end of an observation session, individuals or groups were solicited for interviews.
If a group was approached, everyone in the group was included in the interview.
These 12 field sessions yielded 23 interview sessions with 31 participants.
The researchers approached 4 additional individuals who subsequently declined to be interviewed.
Our investigative methodology has both benefits and drawbacks.
We deploy  AR-style glasses into real environments and give participants a chance to observe them before they are interviewed.
During interviews, participant responses are grounded by the presence of the device in the environment.
Moreover, because we approach individuals "in the wild," we are potentially able to interview people who do not respond to research recruitment ads.
We found cafes to be suitable settings for a number of reasons: they are publicly accessible; they have a reasonable throughput of traffic; they are settings where researchers can position themselves for extended periods of time; and they are environments in which it is plausible to approach individuals for an interview.
Moreover, within a single city--and even within a neighborhood--the character of a cafe and its clientele can vary greatly.
Different cafes attract different demographics and subcultures.
At various times, cafes draw people engaged in a variety of activities: socializing, eating, reading, meeting, working alone, studying in groups, or playing games.
As mentioned, this investigative methodology has some drawbacks.
We chose not to record interviews.
This was done both to make the process less daunting to participants and to facilitate soliciting perspectives from individuals who might object to the idea of being recorded.
Although the interviewer took notes during and after the interview, the pace of the interview and the need to engage with participants inevitably means that these notes are not as complete as a full transcript.
The codes for the data analysis were developed via an iterative process.
After nearly half the interviews were collected, two of the researchers independently went through the interviews and created an initial set of codes.
Following this, the researchers met to discuss the similarities and differences in their initial set of codes and agreed on a codebook.
The researchers then used the codebook to code interview data segments via consensus.
When appropriate, nested codes and multiple codes were applied to a single segment of interview data.
As additional interviews were performed, the researchers reexamined existing codes and made modifications as necessary to the codebook, going back and recoding previously coded interviews.
This iterative process was repeated until all interviews were coded and the final codebook was created.
All interview responses were coded, regardless of whether or not the interview was truncated.
The next section  presents interview results and analysis; however, before we focus on subcomponents of the interviews, we convey a sense of the interviews as a whole.
We present below excerpts from three interview sessions.
The participants reflect different positions along the spectrum of reactions and different levels of familiarity with AR technologies.
The interviews also focus on different underlying themes.
J was definitely aware that these kinds of devices can record: "I would be surprised if their cameras aren't always on...It would make them easier to interact with, like the Kinect for the XBox One.
Plus, how else would you fuel the tinfoil hat conspiracy theorists?"
On the topic of how he felt about being recorded by such glasses, he said, "If I got drunk and puked on a friend, I wouldn't want that out there, but it shouldn't affect my ability to get elected to public office...There are things that we don't want in the public, but it won't be harmful, especially in the future...But, in the interim, people do lose their jobs over Facebook posts."
When asked if there are spaces where we shouldn't record, he replied, "The extreme example is the bathroom or the bedroom.
But it's only a matter of socialization.
Right now it's not civilized to record in the bathroom.
They didn't use to work out in the nude, until they realized that it was better.
Pariticipant V  and Participant W  were interviewed together.
V had heard of Google Glass, but neither she nor W knew that they could take photos and recordings.
W exclaimed, "Wow, like Spy Kids.
V said, "It's more obvious with a cell phone.
It's like, `I'm recording something.'
With the glasses, it's like, `Are you recording my conversation?'
She would find being around an AR device "a little unsettling--but not too unsettling."
W elaborated a bit more: "I'm a dancer, so if I saw a video camera coming down the street I'd probably jump in front of it.
But if they're just recording our conversation, it isn't that interesting."
Upon being asked about a potential interest in blocking technologies, V explained, "I'm a broke college student.
If it bothered me, I'd approach them.
If it got to be an issue--like for working in the theatre--if a lot of people started coming in with these devices I'd probably tell my boss to get one to stop all the recording.
Participant E  and Participant F  were interviewed together.
E described herself as having "limited knowledge" of AR devices, but then proceeded to express an appreciable understanding of the concept.
She was aware that the glasses could take pictures and recordings: "It seems creepy because they can take pictures surreptitiously.
You can go around and take pictures," again, she illustrated by using her hand, "hot girls , hot girls ."
While discussing how they would feel about being bystanders to such a device, F chimes in, "If I really researched privacy issues, I would be more bothered, since it's probably worse than we know--almost certainly worse than we know...I don't think the ethical questions have caught up with the technology."
E explained, "I teach young people--18 to 30--and they would probably get the device because it's the cool new thing.
It doesn't appeal to me.
I can't think of a reason to use them.
Technology portrays itself as creating community, but instead it destroys community."
F added, "People's attention spans have been brought down to sound bites."
In response to being asked, both E and F expressed an interest in having AR users ask their permission before taking recordings, but E said, "I don't think there's an actual etiquette for that...or any etiquette for devices in general."
In this section we present our analysis of interview data.
When specific analysis codes appear in the text they are indicated by a bold font.
This is a qualitative study that is primarily intended to explore relevant issues.
As a result, participant counts should be taken as a rough indicator of our population rather than an absolute measure.
At the beginning of each interview, we asked the participant whether or not they had noticed the second researcher's AR glasses.
Many of the participants  had not made any particular note of the glasses , despite the bias in our sampling methods .
As we proceeded with the interview, participants expressed a range of reactions regarding the idea of being a bystander to an AR recording device.
As part of our analysis, we coded these sentiments as AR Bystander: Positive, AR Bystander: Negative, or AR Bystander: Indifferent.
Participants were split in their reactions, but they primarily either reacted indifferently  or negatively  to AR recording; only one participant had a positive reaction.
Also notably, some of the participants  expressed more than one type of sentiment, highlighting the fact that people can have conflicting or complex reactions.
Several participants focused on the concept of appearing in public.
This viewpoint is reminiscent of Goffman's theory of the presentation of self in everyday life.
In this theory, he describes our interactions as times when we are performing: we are scrutinized by others, and dynamically adapt to their reactions.
At other times, we do not wish to be seen, and hide away "backstage" .
When participants offered reasons why recording with an AR device is acceptable or makes no substantive difference to their experience as a bystander, they primarily did so in the context of comparisons with existing technologies.
When we probed them, 10 participants indicated that they view AR recording as similar to cell phone recording .
Some participants volunteered comparisons to other existing camera technologies.
For example, 5 participants specifically commented on the preexisting prevalence of CCTV cameras .
A few participants made comparisons to other recording technologies, such as the GoPro wearable camera .
In general, participants rhetorically used these comparisons in one of two ways: to indicate that AR technologies make no difference in the legal landscape, or to indicate that AR technologies make no difference in their expectation of being recorded.
For example, Participant N  indicated that he cannot legally stop someone from taking his picture, regardless of device type.
Participant AC  is in the Screen Actors Guild; he indicated that no one is allowed to capture his image without written permission.
Multiple participants expressed that--between cell phones, CCTVs, and other cameras--they already expect to be recorded whenever they are in public.
Not all participants seemed pleased or indifferent about that fact; however, the introduction of AR technologies did not affect their expectations of being recorded.
Below are three participant quotes  that illustrate viewpoints along this spectrum:  Participant L : I'm fully aware that I'm being photographed all the time.
Look at the tracking activities of the police in Boston .
That was "fantastic," in the literal sense of the word, not necessarily the positive sense.
Participant B : People are aware that there are a lot of CCTVs around--there's not a street corner in Seattle that's not recorded.
It's a bit Big Brother, but we accept it as a society, and it's not like you're in a house.
Participant K : I am consciously sharing just by being present.
If I didn't want to be seen I would lock myself up and never go out.
When probed on the topic, 8 participants indicated that recording with an AR technology is different than recording with a cell phone .
Elaborations on these answers surfaced some reasons why participants regarded these technologies as creating a different experience for the bystander.
Over half  of the participants--including Participant V quoted in the Interview Excerpts section--raised the fact that AR glasses are potentially a more subtle form of recording than other form factors .
Participants indicated that bystanders consequently may not be aware that they are being recorded.
This concept of subtleness is somewhat intertwined with the fact that it is relatively easy to initiate a recording --an issue that was articulated by 5 participants.
Some participants  gave another reason why bystanders might not expect to be recorded by AR glasses: the technology's current lack of prevalence .
They indicated that the scarcity of AR devices meant that people would not expect glasses to be recording.
In some cases, as in the quote below, the participant explicitly indicated that this expectation would change as the technology becomes more common: Participant I : It's slightly more clandestine, but if it gets popular people would be clued in.
Throughout the course of the interviews, participants expressed a number of factors that affected their feelings towards being recorded.
For some participants, these factors described why they prefer not to be recorded.
Other participants mentioned factors that affect the circumstances in which it is or is not acceptable to be recorded.
While some of these issues have been surfaced in prior work , we show that they arise again: in a different time and place and with a different technology.
We present these factors below in approximate order of their prevalence in interview data.
Some of these places were unacceptable by virtue of Social Norms .
Other locations were described as off-limits owing to existing camera policies .
Participants V and W discuss this issue in their interview .
Participant L  is concerned about individuals recording, since they are not held to the same moral and ethical bounds as law enforcement.
Participants indicated that the acceptability of being recorded was somewhat dependent upon what they were doing at the time .
For example, one participant did not want an AR user to "shoulder surf" her at the ATM.
The majority of the references, however, were in the context of impression management.
Again in the context of Goffman , we might describe people's behavior as an interactive performance tailored to a particular audience.
When this performance is taken out of context, undesirable or unanticipated consequences can follow.
As a result, sharing images or videos online--or the context in which they are shared--affects bystander feelings regarding being recorded .
Participant J  gives one example of how bystander behavior and sharing can have negative consequences; most participant examples were similar.
Participant R , on the other hand, provides an example where his behavior is not the issue in question, but the sharing context still is: someone else could "superimpose" his recording over a porn film.
While this scenario may seem unlikely, it has parallels to media reuse for satirical or damaging purposes.
Participants articulated concerns about being recorded by AR technologies based on the idea that they--or others-- might be identified in the resulting images or videos .
Several participants provided further context regarding their concerns:  Participant A  is a foster parent and is concerned that her foster children might be identified in footage.
Participant Q  is concerned that he might be tagged in a video alongside a person of interest or a criminal element, resulting in "guilt by association."
Participant AE  is concerned that victims of domestic violence might be identified online, facilitating abusive ex-partners "coming after them."
A few of the participants indicated that they would object to being recorded only if it presented an interruption or an irritation --if the AR user was "up in their space"  or "disturbing" them .
Participants judged whether or not they minded being recorded based upon their evaluation of the AR user .
A contextual evaluation is illustrated by the following quote, paraphrased from interview transcripts: Participant M : I look over at him, I size him up, and if he doesn't look like a pervert--if he just looks like Joe Schmuck--it's not a problem.
Participants also indicated that the gender of the person wearing the glasses affected their perception of the device.
One of our interview questions probed whether or not participants would want someone to ask them before recording them with AR glasses.
The follow-up question asked participants if they would be interested in a device that could block others from recording them.
These questions were intended to:  surface relevant underlying issues; and  explore whether or not a technological mechanism supporting notification, consent , or blocking  would be of interest to participants.
Most of the participants  expressed that they would prefer for someone to ask their permission before recording them with AR glasses .
7 of them would prefer not be asked or expressed indifference .
7 of the responses were uncodable due to ambiguity, truncated interview, or omission .
Responses were frequently accompanied with caveats.
For example, some participants expressed that they would wish to be asked, but that it is not practical for the AR user to do so .
We discuss them in the following subsections and ground them with research references.
Figure 2 presents a set of axes by which to characterize or explore the design space of privacy-mediating technologies; these axes provide a framework with which to consider the following discussions.
Illustrative references to the axes are included using an italic font.
12 of the participants expressed an interest in a device that would allow them to block others from recording them .
6 of the participants were not interested in such a device .
13 participants' responses were uncodable due to interview truncation, omission, or ambiguity .
Participants variously expressed that their interest was dependent upon:  The cost of the device in question;  Whether or not they would have to wear the device ;  Device size;  Effort involved in using the device; and  The prevalence of AR recording devices .
Some participants expressed an interest not particularly for the purpose of blocking AR recording, but for the ability to use them on recording technologies in general: Participant O : ABSOLUTELY.
As noted by participants, one of the key ways that AR technologies are different from other technologies is the subtleness of the recording experience for bystanders.
Additionally, participants expressed an interest in being asked permission or being able to block recordings.
We explore mechanisms for notification, blocking, and permission below.
Subtleness may be partially offset by visual or aural cues to bystanders that a recording is taking place.
Unfortunately, this method runs the risk of being bypassed by malware  or by non-compliant devices.
Alternatively, devices could be designed such that their cameras may be physically blocked by switches or shutters.
The possibility of push-pull interactions leads to an array of potential notification and permission mechanisms.
For example, an AR device could push notifications to nearby cell phones that a recording is taking place .
Such a notification could include information about where the recording might be posted.
The AR device could solicit privacy preferences from bystanders' devices .
Alternatively, bystander cell phones could choose to broadcast their owners' privacy preferences .
The system could also support sending automated notifications to bystanders if relevant photos or videos are posted .
One way to support these interactions would be to rely upon messages exchanged while the devices are colocated .
Alternatively, the system could cryptographically support sending notifications after the fact while still supporting all parties' anonymity .
At the other end of the spectrum, privacy preferences could be technically enforced rather than suggested .
For example, a system could guarantee that all bystanders have the ability to take down a recording at any time in the future .
Similarly, some individuals--including some of our participants-- may have interest in a technology which actively blocks cameras' ability to record them, with or without the operator's cooperation .
A discussion of recording preferences and blocking naturally segues to ethical, philosophical, and legal discussions about the ownership of space, the rights of an AR user, and the ownership of content.
Many spaces where recording devices are used are privately owned.
As such, the owners or event managers might wish to enforce their own policies .
On the other hand, such a mechanism has the ability to limit individuals' ability to capture and express material.
An individual might want to--or have the moral or legal right to--record for a variety of purposes, including: the creation of digital memories for informational or emotional purposes, selfprotection, journalism, or social justice.
Another question arises once a recording is created: who has ownership over the data?
Although there are exceptions, the current model in social media networks is that the content is owned and managed by the uploader.
This can create tensions between the media owner and any subjects in the content.
Subjects can manually or automatically ask the owner to untag, restrict access to, or remove the content ; however, this does not necessarily circumvent social conflict.
Further afield are models for collaborative management of media content .
While it may be more difficult to form automated decisions based on a social context than on physical location, it is also a more meaningful distinction.
Devices could attempt to gather such context based on co-located individuals, online listings, physical artifacts in the environment, or even the user's calendar entries.
For example, calendar invites or event locations could include recording policies.
Even further afield, AR devices which have "prior knowledge" about a given event space's recording policies could broadcast that knowledge to surrounding devices.
Several participants expressed discomfort with the idea of being recorded on the basis that it facilitates identification.
In some cases, participants gave reasons why identification could lead to negative consequences, including bodily harm.
Below we explore some potential ways to mitigate this concern.
Individuals might choose to wear opt-out markers  if they do not wish to be recorded.
Conversely, they could wear opt-in markers if they do not mind being recorded .
However, outside of specific, structured environments, this strategy is most likely unrealistic.
Counterintuitively, if AR devices could rely upon facial recognition to identify everyone in an image, they could then use that information to blur or obfuscate individuals who have previously expressed or registered that they do not want to be recorded .
It should be noted, however, that this avenue puts the responsibility of registering on the bystander.
Moreover, this approach potentially leaks as much private information as it protects.
At the other end of the spectrum, facial recognition of acquaintances could be utilized to anonymize everyone who is not an acquaintance, thereby protecting bystanders.
The above approaches could be used to suggest to AR users that they avoid sharing media with sensitive identifications .
These approaches could also enforce recording deletion or obfuscation .
As previously discussed, preventing or altering recordings raises questions of the AR user's rights to aesthetic and accurate memories--not to mention the implications regarding legal evidence .
Further afield, bystanders or social media platforms could run independent "watchdog" software .
These agents could review media where the bystander might appear based on metadata such as time and place .
Previous research has found that the acceptability of recording varies by location, and this study is no exception.
Participants indicated that spaces such as homes, locker rooms, and theatres require special treatment.
Location and space have definite social and societal meaning, and we do not dispute that there is value in supporting space-based restrictions on recording.
We suggest, however, that designers and technologists consider the broader view of place, rather than space.
We use the word "place" to encompass the social characteristics of a space as situated in time and space .
The interviews took place in cafes in Seattle: a city with multiple universities and a concentration of technology companies.
We expect that general bystander perspectives regarding recording will shift by city, region, and country.
Moreover, while cafes are a rich source for study, they do not capture the full scope of human behaviors.
This methodology could be extended to a variety of location types with pertinent theoretical properties, such as: power dynamics ; specific population types ; disheveled appearances ; or casual atmosphere .
In our study, we investigate how individuals perceive ARstyle recording in comparison to other classes of recording devices.
Participants were split as to whether or not AR devices create a substantively new bystander experience; those who found it different cited subtleness, ease of recording, and the current lack of prevalence as the relevant factors.
The scarcity of AR devices is not an inherent property of the technology; however, it can contribute to whether or not an individual expects to be recorded.
It remains to be seen whether these factors continue to be perceived as relevant as the novelty of the technology fades.
People frequently:  are unable to adequately assess their reactions to a technology before they encounter it--an obstacle which we attempt to lessen with our interview methodology ;  change their perceptions with repeated exposure to the technology; or  change their views as they become active users of the technology .
Data gathered now may or may not reflect how individuals will perceive AR recording in the future; either way, it can be used to characterize the adoption of an emerging technology.
Participants expressed interest in the possibility of being asked permission and being able to block recording devices; however, they expressed concerns regarding feasibility and convenience.
These factors suggest that privacy-mediating technologies are a space that merit further research.
We discuss a range of such technologies in our Design Considerations section.
Furthermore, we characterize the systems by supplying axes for design directions .
The investigation of such technologies is timely: the nascence of AR technologies can potentially be used to bootstrap the inclusion of privacy-mediating measures.
The utility of such measures and the utility of characterizing axes extend beyond AR devices to new classes of emerging technologies.
While there has been much controversy in the media surrounding these technologies, little is known about how the general populace perceives such devices.
We sought to help address this knowledge gap with an insitu qualitative study: we wore a glasses-style AR mockup in cafes and conducted semi-structured interviews with cafe patrons.
Subsequent analysis yielded a variety of information: for example, participants described AR recording as different from other types of recording due to its subtleness and the current scarcity of AR devices.
Participants also surfaced factors that make recording less acceptable.
For instance, their reactions to recording can be affected by their perception of the AR user and whether or not they can be identified in the recording.
Many participants expressed interest in being asked permission or being able to block recording devices; however, they were concerned about the logistics of such capabilities.
We use our interview results to guide a discussion on design considerations for privacy-mediating technologies.
Additionally, we contextualize the technical directions with a number of potential design axes .
The fact that AR technologies are nascent affords opportunities to the research community.
Since these devices are not yet common, we can study how perceptions and usage develop throughout their adoption.
Moreover, we have the opportunity to explore privacy-mediating mechanisms; the user experience for AR devices has not yet become standardized.
Our hope is that findings from this and similar studies will help emerging technologies such as AR devices respect the priorities of all stakeholders.
We thank the participants and the study locations for their time.
We thank David Molnar for the loan of his equipment.
We thank Eun Kyoung Choe, Karen Fisher, Jaeyeon Jung, Julie Kientz, Adam Lerner, David Molnar, Alex Moshchuk, Oriana Riva, Franziska Roesner, Helen Wang, and Information School students for their input.
We thank the Pervasive Computing Intel Science and Technology Center.
Prototypes and Paratypes: Designing Mobile and Ubiquitous Computing Applications.
Adams, A. Multimedia Information Changes the Whole Privacy Ballgame.
Computers, Freedom and Privacy 2000.
Barhm, M.S., Qwasmi, N., Qureshi, F.Z., and el-Khatib, K. Negotiating Privacy Preferences in Video Surveillance Systems.
Modern Approaches in Applied Intelligence 2011.
Bell, M. and Lovich, V. US Patent: 8254902 Apparatus and Methods for Enforcement of Policies Upon a Wireless Device.
Bellotti, V. and Sellen, A.
Design for Privacy in Ubiquitous Computing Environments.
Moving Beyond Untagging: Photo Privacy in a Tagged World.
Technical Challenges in Location-Aware Video Surveillance Privacy.
In Protecting Privacy in Video Surveillance, 2009.
Brocker, M. and Checkoway, S. iSeeYou: Disabling the MacBook Webcam Indicator LED.
Department of Computer Science, John Hopkins University.
Total Recall: Are Privacy Changes Inevitable?
Investigating Receptiveness to Sensing and Inference in the Home Using Sensor Proxies.
The Watcher and the Watched: Social Judgments about Privacy in a Public Place.
Goffman, E. The Presentation of Self.
Halderman, J.A., Waters, B. and Felten, E. W. Privacy Management for Portable Recording Devices.
Harrison, S. and Dourish, P. Re-Place-ing Space: The Roles of Place and Space in Collaborative Systems.
Henne, B. Szongott, C. and Smith, M. SnapMe if You Can: Privacy Threats of Other Peoples' Geo-Tagged Media and What We Can Do About It.
Kahneman, D., Krueger, A.B., Schkade, D.A., Schwarz, N., and Stone, A.A. A Survey Method for Characterizing Daily Life Experience: The Day Reconstruction Method.
Mancini, C., Rogers, Y., Bandara, A.K., Coe, T., Jedrzejczyk, L., Joinson, A.N., Price, B.A., Thomas, K., and Nuseibeh, B. Contravision: Exploring Users' Reactions to Futuristic Technology.
Mann, S. and Ferenbok, J.
New Media and the Power Politics of Sousveillance in a Surveillance-Dominated World.
Manweiler, J., Scudellari, R., Cancio, Z., and Cox, L.P. We Saw Each Other on the Subway: Secure, Anonymous Proximity-Based Missed Connections.
Massimi, M., Truong, K. N., Dearman, D., and Hayes, G. R. Understanding Recording Technologies in Everyday Life.
Situating the Concern for Information Privacy Through an Empirical Study of Responses to Video Recording.
Nguyen, D. H., Marcu, G., Hayes, G. R., Truong, K. N., Scott, J., Langheinrich, M., and Roduner, C. Encountering SenseCam: Personal Recording Technologies in Everyday Life.
Palen, L., Salzman, M., and Youngs, E. Going Wireless: Behavior & Practice of New Mobile Phone Users.
In Protecting Privacy in Video Surveillance, 2009.
Schiff, J., Meingast, M., Mulligan, D.K., Sastry, S., and Goldberg, K. Respectful Cameras: Detecting Visual Markers in Real-Time to Address Privacy Concerns.
In Protecting Privacy in Video Surveillance, 2009.
Information Privacy: Measuring Individuals' Concerns about Organizational Practices.
CoPE: Enabling Collaborative Privacy Management in Online Social Networks.
Augmented Reality Through Wearable Computing, 1997.
