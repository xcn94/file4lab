In office environments, for example, social conventions dictate when it is appropriate for one person to interrupt another.
Social conventions also allow the development of an a priori expectation of whether or not an interruption is appropriate .
For example, a person seeking a colleague's attention is normally able to glance through an open office door, consider a variety of cues, and quickly estimate the colleague's current interruptibility.
This estimation of another's interruptibility, however, is not perfect.
On one hand, estimating that a person is more interruptible than they actually are can lead to inappropriately-timed interruptions.
On the other hand, estimating that a person is less interruptible than they are can lead to missed communication opportunities.
For example, Hudson et al.
The use of computer-mediated communication and awareness technology further complicates matters by fundamentally altering what information is available to people.
For example, a person calling another's mobile phone typically has no information about the current situation of the person they are calling, resulting in calls at times that are inconvenient, disruptive, or even dangerous for the receiver .
This lack of information about a person's current context can have other costs as well.
For example, Herbsleb et al.
This phenomena is known as the actor-observer effect, wherein people will often attribute their own behavior to external causes yet attribute the behavior of others to internal causes , in part because they know more about their own situation .
This paper examines discrepancies between a person's reports of their own interruptibility and estimates of that person's interruptibility by other people.
People have developed a variety of conventions for negotiating face-to-face interruptions.
The physical distribution of teams, however, together with the use of computer-mediated communication and awareness systems, fundamentally alters what information is available to a person considering an interruption of a remote collaborator.
This paper presents a detailed comparison between selfreports of interruptibility, collected from participants over extended periods in their actual work environment, and estimates of this interruptibility, provided by a second set of participants based on audio and video recordings.
Our results identify activities and environmental cues that affect participants' ability to correctly estimate interruptibility.
We show, for example, that a closed office door had a significant effect on observers' estimation of interruptibility, but did not have an effect on participants' reports of their own interruptibility.
We discuss our findings and their importance for successful design of computer-mediated communication and awareness systems.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
A better understanding of such biases could inform the design of computer-mediated communication and awareness systems by providing insight into how people are likely to use different pieces of contextual information.
We therefore examine two research questions: * Which contextual cues affect the error in human estimation of another person's interruptibility?
In this paper, however, we examine the contexts in which human estimates are unreliable.
Our findings show, for example, that the state of an office door is significantly correlated with errors in estimation of interruptibility and that it is likely that people incorrectly treat a closed door as a strong indicator of non-interruptibility.
Our findings suggest that people are also prone to overrating the importance of social engagement .
The reader should note that, while our analysis allows us to determine a cue's effect on estimation bias and point to the source of this bias, it does not determine that a cue was directly and consciously used by participants.
This paper makes at least two contributions to the study of human-computer interaction and computer-supported cooperative work.
First, we examine a variety of contextual cues to determine which are associated with errors in human estimation of interruptibility.
Second, we raise several questions regarding the tradeoff between abstractions and the direct presentation of sensed information in computer-mediated communication and awareness systems based on ubiquitous and context-aware computing.
Though some related questions have been raised in work on media spaces, the nature of ubiquitous and context-aware computing enables new approaches to these problems.
The next section reviews related work.
We then present our method, collecting audio and video recordings in the normal working environments of office workers, occasionally asking the office workers to report their own interruptibility, then showing the collected recordings to other people and asking them to estimate the interruptibility of the office workers.
This is followed by a discussion of our measures, including a set of contextual variables that we code to indicate what activities are occurring in the collected recordings.
Our results section then provides evidence of contextual variables that have a significant effect on estimation error and probes the causes for the bias associated with each of those contextual variables.
This is followed by a discussion of our results and a short conclusion.
Significant work on computer-mediated communication and awareness systems has been motivated by a desire to encourage the low-overhead communication that naturally occurs when people are located in close physical proximity.
For example, Kraut et al.
The high-level goal of many systems has therefore been to encourage informal, serendipitous communication and thus mitigate the negative effects of physical distance between people.
Media spaces were initially explored as switched audio/video connections between four offices and some common areas in two physically remote research labs .
The VideoWindow system used a continuous audio/video link to encourage informal interaction between people visiting two lounges on different floors in a research organization .
Adler and Henderson reported their experiences with a "direct office share", a continuous audio/video link between two offices .
Cruiser explored pair-wise connections between people working at their desktop, including a cruise functionality analogous to walking down a hallway of open doors .
Additional explorations of this rich media approach include, for example, the CAVECAT , RAVE , and Montage  systems.
Later systems shifted away from providing a rich media experience toward exploring the tradeoffs inherent in the sharing of different types of information.
Portholes showed that much of the benefit of a media space could be obtained using occasional still photos instead of continuous audio/video feeds .
These still photos represented less of a threat to personal privacy and were also less distracting to the people who used it.
Hudson and Smith further examined the tradeoff between protecting personal privacy yet still conveying information that is meaningful in an awareness system .
The emergence of ubiquitous and context-aware computing has raised some of these same issues in new forums.
Instant Messaging programs often use computer activity to indicate that a person is present at their computer.
Furthermore, a variety of additional and more complex information can also be sensed and made available to remote users.
Similar to work in awareness systems, Lilsys and MyVine explored some of the tradeoffs between providing a variety of contextual cues, their disruption to users, and the potential threat to personal privacy.
The use of interruptibility as an abstraction based on sensed context represents one approach to this tradeoff.
Work by Dabbish and Kraut confirms that this is an interesting point in the design space, as they show that joint performance in a controlled task is highest when using an abstracted notion of availability  .
Similarly, results by Avrahami et al.
In the context of related work, this paper provides insight into how people are likely to misinterpret contextual cues while assessing another person's interruptibility in the course of using a computer-mediated communication and awareness system.
Sensor-based statistical models of human interruptibility  may be useful in providing cues and abstractions for use in computer-mediated communication and awareness systems, but the underlying contextual cues are still important.
For example, systems may be expected to provide an indication of why a model thinks a person is interruptible.
Because this type of information is so important to ubiquitous and context-aware computer-mediated communication and aware systems, a better understanding is needed of the biases that result from people's interpretation of contextual cues.
The results presented in this paper are an important step towards reaching this understanding.
Two groups of participants provided ratings of interruptibility for a large number of real situations.
The first group, which we will refer to as Reporters, provided self-reports of their own interruptibility while doing their normal work in their normal office environments.
The second group, which we will refer to as Estimators, viewed audio and video recordings of the Reporters and provided estimates of the interruptibility of the Reporters.
Noting that some additional details are available in , we present the most relevant aspects of the method here.
Participants in the Reporters group provided reports of their own interruptibility while engaged in their normal work in their normal environments.
Audio and video recordings were collected using a computer with an audio/video capture-card connected to a small camera and microphone.
A grayscale camera with a wide-angle lens was mounted in the office such that both the primary working area and the door were visible.
Figure 1 shows several images captured from the recordings.
Video was captured at approximately 6 frames-per second, at a resolution of 320x240.
Audio was captured at 11 KHz, with 8-bit samples.
To collect measures of how these participants perceive their own interruptibility, self-reports were collected using an experience sampling technique  .
At random intervals , the recording machine that was collecting the audio and video recordings played a pre-recorded audio prompt asking the participant to "Please rate your current interruptibility."
Participants responded on a five-point scale, with a response of 1 corresponding to "Highly Interruptible"  and a response of 5 corresponding to "Highly Non-Interruptible" .
A sign was posted on the recording machine to remind the participant which value corresponded to which end of the scale.
Participants were able to respond verbally or by holding up fingers on one hand to the camera.
This approach was used, as opposed to using software running on a person's desktop computer, to maximize compliance by ensuring a participant can respond even if they are away from their desk.
Each participant provided self-reports over a period ranging between 3 and 4 weeks.
Participants in the Estimator group provided estimates of Reporter interruptibility based on short audio and video clips of the Reporters.
Our goal was to simulate a situation similar to that of a visitor stopping by another's office , considering the cues available to them, and deciding whether an interruption is appropriate.
Since Reporters were recorded in their private offices, doing real work, we were required to limit the risk of private and sensitive information being exposed.
Consequently, each Estimator was first shown still images of the Reporters and asked if they recognized them.
Estimators were then shown recordings only of Reporters whom they did not recognize.
A between-subject design was used, with each participant providing interruptibility estimates for 60 clips randomly selected  from the audio and video recordings collected in the offices of Reporters.
Estimates were provided after each clip.
Clips showed a period of either 15 or 30 seconds immediately preceding a prompt for a Reporter's self-report.
The length of the first clip  was randomly assigned, and clips alternated in length hereon.
This manipulation was included to determine whether longer clips provided additional useful information to the participants.
We should note that in face-to-face situations, people typically have only a few seconds to make an estimate of another's interruptibility.
However, it is not unreasonable to assume that using 15 or 30 seconds may only improve estimates and not hinder them.
Each session started with the experimenter introducing the graphical interface shown in Figure 2.
This interface was used by Estimators to provide interruptibility estimates on the same five-point scale used by the Reporters.
Participants were informed that they are allowed to watch each clip more than once, and were encouraged to make their estimates as accurately as possible, without concern for speed.
Instructions were followed by a training session in which the participant became familiar with the task by providing estimates for six randomly-selected clips.
Six paid coders used custom software to code the collected audio and video for occurrences of a large set of potentially relevant contextual cues, including activities and environmental cues.
This was based on the theory that environmental indications of task engagement or social engagement will relate to how the Reporters and the Estimators assess the interruptibility of a situation.
The set was chosen to include cues that could be reliably identified and coded from the recordings.
This custom software presents recordings in 15 second segments and a coder indicates whether each activity or environmental cue occurred during each segment .
The Boolean contextual variables coded are: Reporter activities: * Whether the reporter is present.
Guest activities: * Whether any guests are present.
Environmental Cues: * Whether the door is open, is closed .
Agreement among coders was evaluated by re-coding a randomly selected 5% of the recordings, finding 93.4% agreement at a granularity of whether or not each activity occurred within each 15 second interval.
Since a number of the contextual variables are highly correlated with one another, and in order to avoid problems resulting from co-linearity, we made a number of necessary adjustments to our full set of contextual variables; We created a new Boolean variable, Social Engagement, defined to be true if any of the following variables is true: Any Talk, Reporter Talk, Guest Talk, Guest Present, Guest Sitting, Guest Standing, and Guest Touch.
These other variables were then excluded from further analyses.
Similarly, the Keyboard, Mouse, and Monitor variables were combined to create a new variable named Computer.
Finally, we removed Door Is Open in favor of Door Is Closed, removed Reporter Sitting in favor of Reporter Standing, and removed Table in favor of Desk.
These adjustments yielded the 12 contextual variables used in our remaining analyses.
A positive Estimation Error on the other hand indicates an Over-Estimation of the reporter's interruptibility, or interpreting a situation as being more interruptible than it was reported.
It is worth noting that, while the overall accuracy of Estimators is likely to decrease with the use of a fine-grain scale , in this work we are interested in identifying systematic biases in estimation of interruptibility  rather than in overall Estimator accuracy.
Each Estimated interruptibility was assigned, in addition to the corresponding Reported interruptibility, the following control measures: Trial Number , Duration , ReporterID , and MultipleClipWatch .
Given indications of interruptibility for a situation from both self-reports  and human estimates , our measure of estimation error is the difference score: Estimation Error = Reported - Estimated This error ranges from -4  to 4 .
Four participants were recruited for the Reporters group, each of whom works in a high-level staff position within a major university, with responsibilities for the day-to-day administration of a large university department and/or graduate program.
The participants had private offices with closable doors, but their responsibilities required them to interact with many different people and they generally did not have full control over their time.
These four participants provided a total of 672 self-reports over the course of more than 600 hours of recordings.
Of these, 587 were appropriate for use in this study.
For the Estimators group, we recruited forty participants using a website that advertises experiments within the university.
A large majority of Estimators were students at our university or at a neighboring university.
Each participant was paid for a session scheduled to last one hour; sessions were not timed but none lasted longer than the scheduled hour.
As 40 estimators each provided 60 estimates, each of the 587 self-reports had at least four estimates provided for it, including at least two based on 15 seconds clips and at least two based on 30 seconds clips.
Trial Number, and MultipleClipWatch  were modeled as fixed effects.
ReporterID  and Participant Number were modeled as random effects2.
This analysis showed that Estimated interruptibility is significantly correlated with Reported interruptibility .
We also found a small significant effect of Trial Number on Estimated Interruptibility , although the parameter estimate  shows that the size of this effect was very small.
Still, we see that as the experiment continued, Estimators tended to rate Reporters as more interruptible.
One possible explanation is that Estimators tired of the task.
Another intriguing possibility is that Estimators began to feel acquainted with the Reporters and felt more comfortable declaring them to be interruptible.
Next, we examined the overall effect of Role  on interruptibility .
We used a Mixed Model analysis in which Interruptibility was the dependent measure and Role was modeled as a fixed effect.
For both types of participants, Participant Number was modeled as a random effect.
This analysis showed a significant main effect of Role on Interruptibility  with participants in the Reporter role reporting that they were more non-interruptible on average  than perceived by Estimators 3.
A closer look at Estimators' data revealed two participants whose estimations were far lower than others and had greater error.
In fact, one of these two Estimators never provided an estimate greater than 3 - the middle value on our five-point scale.
A Mahalanobis outlier analysis showed the two Estimators to be outliers.
We excluded these two outliers from the data and repeated the analysis described above.
Role still had a significant effect on Interruptibility  with the average interruptibility of Estimators increasing slightly to .
While the behavior of the two outliers might be interesting in itself, their estimates  were excluded from the remaining analyses.
Before describing our results in detail, we first describe the plan of analysis that will follow.
We start by presenting two basic and important results.
We show that, while a significant relationship exists between Reported and Estimated interruptibility, the two are significantly different from one another.
These results confirmed the existence of a bias in estimation of interruptibility, and led to a two-part detailed analysis of the contextual variables.
In this analysis, we show contextual variables that have a significant effect on Under-Estimation  and measures that have a significant effect on Over-Estimation .
In the final step of the analysis, we use the effect of each contextual cue  on either Reported or Estimated interruptibility to categorize the source of the cue's effect on bias in estimation.
In all the analyses described below, Reported interruptibility, Estimated interruptibility, and Estimation Error were modeled as continuous.
We started our analysis by testing whether a correlation exists between self-reports and estimations of interruptibility.
We conducted a Mixed Model analysis1 using the data from our Estimators, with Estimated interruptibility as the dependent variable.
Reported interruptibility, Clip Length ,
Individual differences had to be accounted for statistically because each participant, whether Reporter or Estimator, provided a number of interruptibility ratings.
This was done by including the participant number as a random effect in the model.
One could argue that ReporterID should be modeled as a fixed rather than a random effect.
Repeating our analyses with ReporterID treated as a fixed effect yielded nearidentical results .
Because the independent variables were not completely orthogonal, we used Least Squared Means  to control for the values of the other independent variables.
The means reported throughout this article are LS Means.
Analysis Summary:  = A significant effect on Under-Estimation Error,  = A significant effect on Over-Estimation Error, R = Has a significant effect on Reported Interruptibility, E = Has a significant effect on Estimated Interruptibility.
Bias types: 1 = Failing to consider a cue that is significant, 2 = Considering a cue that is not significant, 3 = Overrating the strength of a cue, 4 = Underrating the strength of a cue, 5 = Misinterpreting the direction of a cue.
The analyses described so far show that participants are able to make estimates that significantly correlate with selfreports of interruptibility, but also that there is a significant difference between the two.
In order to examine the effect of context variables on errors in estimation, we performed separate analyses of Underand Over-Estimation errors, each examining a subset of the data .
The first examines which contextual variables correlate with Estimators assessing situations as being less interruptible than reported .
The second examines what contextual variables correlate with Estimators assessing situations as being more interruptible than reported .
This method allows us to identify and address cases where the same contextual variable introduces both under- and over-estimation .
The analyses of Under- and Over-Estimation were done in an identical fashion.
We performed a Mixed Model analysis where Estimation Error  was the dependent measure and the following measures were modeled as fixed effects: Reported interruptibility, Clip Length , Trial Number, MultipleClipWatch , and the 12 contextual variables .
ReporterID  and Estimator Number were treated as random effects.
Finally, in order to determine the cause for a cue's effect on Estimation Error, we examined whether each cue had a significant effect on Reported and on Estimated interruptibility.
For example, a contextual variable that does not have an effect on Reported interruptibility but has significant effect on Estimated interruptibility could be characterized as an estimation bias of the form "Considering a cue that is not significant."
Our 12 contextual variables were modeled as fixed effects.
Next, we used the Estimators' data to conduct a Mixed Model analysis with Estimated interruptibility as the dependent measure.
Clip Length , Trial Number, MultipleClipWatch , and the 12 contextual variables were modeled as fixed effects.
ReporterID  and Estimator participant number were modeled as random effects.
The results of our analyses are summarized in Figure 5.
Given the space available, we present detailed results for only the variables found to have an effect on Estimation Error.
We provide only a short account of other results.
In both cases, being socially engaged resulted in a situation being considered less interruptible.
We may thus conclude that this is a case of "Overrating the strength of a cue."
That is, while social engagement played a significant role in both Reported and Estimated interruptibility, Estimators associate too much importance with this variable, resulting in both under- and over-estimation.
This finding is consistent with the use of a phone representing a reliable indication that a person is not interruptible.
Phone did not have a significant effect on Under-Estimation.
Thus, the cause for the effect of Phone on Estimation Error can again be categorized as "Overrating the strength of a cue."
This finding could be used, for example, in the design of a system by indicating only that a person is on the phone, but not indicating that a person is not on the phone.
Thus, we can classify the effect of Door Is Closed as a result of "Considering a cue that is not significant."
This is consistent with prior work's discussion of the common misconception that door status is a reliable indicator of interruptibility .
Standing did not have a significant effect on Under-Estimation.
Looking at each group of participants, we found that a reporter standing had a significant effect for both Reporters  and Estimators  as an indication that a situation was more interruptible than when the reporter was sitting.
Since standing was often part of entering or leaving a conversation or the office, this finding might be consistent with prior work on the link between physical transitions and better times for interruptions .
However, this cue's significant effect on Estimation Error indicates that the cause for the bias is "Overrating the strength of a cue."
This variable is thus an example of "Considering a cue that is not significant."
We found that Computer had a significant effect on OverEstimation, with Estimators being more likely to interpret a situation as more interruptible than reported when the Reporter was using the computer than when not .
Computer did not have a significant effect on Under-Estimation.
Finally, File Cabinet had a significant effect on UnderEstimation Error, with a smaller error when a Reporter was interacting with their file cabinet than when not .
This effect may be due to some interaction with another variable.
Given the limited amount of information available , it is difficult to draw conclusions regarding the impact of this variable on Under-Estimation.
Other contextual variables, such as Writing, Desk, Food, and the reporter's Presence played a significant role in either Reported or Estimated interruptibility, but not in Estimation Error.
As expected, Reported Interruptibility had a significant effect on Estimation Error .
We did not see an effect by any of the other control measures .
In other words, Estimators were likely to misinterpret a closed door and estimate the situation as less interruptible than was reported.
In the previous section we presented results from an indepth analysis of causes for biases in human estimation of interruptibility, comparing self-reports and estimations based on audio and video clips selected from over 600 hours of recordings collected in actual work environments.
Our results identified a number of contextual cues that affected estimation errors and point to their causes.
While this is an important limitation if our results are to be interpreted in the context of face-to-face interruptions, we note that the information available to Estimators in this study was similar to information available to users of media space systems, and far richer than information available in most awareness systems.
Our results are therefore directly applicable in these contexts, suggesting important considerations for the design of new computer-mediated communication and awareness systems.
While we chose not to vary the degree of familiarity between reporters and estimators in this work, further research on the effect of familiarity on estimation bias is needed.
In early audio and video media spaces, large amounts of information about a remote person and their context were shared.
This information, however, came at some cost.
Personal privacy has been raised as an issue in even the earliest media space work.
These rich information streams were also distracting to users.
The transition from analog audio and video streams to digital streams allowed systems to process the information, instead of simply mirroring it.
This led to systems that shared fewer, but more important bits of information.
But this processing has typically been limited to sharing information about presence.
Occasional still photos from a low-resolution camera were found useful primarily for determining if a person is present and perhaps whether any additional people are present.
Techniques like Hudson and Smith's "shadow view" added more temporal information to the stream , but the information conveyed was still primarily related to a person's presence.
Our results suggest that providing too much information may not only be a concern for privacy, but may also lead to errors in estimations of interruptibility.
Just as the transition from analog to digital streams allowed new approaches, the emergence of ubiquitous and context-aware computing provides another opportunity to examine what information is shared in computer-mediated communication and awareness systems.
Because sensing and recognition systems are now capable of inferring a variety of activities, communication and awareness systems need not be based on a direct presentation of a remote person's activities.
Our results suggest that sharing certain contextual cues will likely result in misinterpretations of a person's interruptibility.
A new system, informed by our results, could avoid exposing cues that should not be considered in an estimate of interruptibility at a particular time, while enhancing  others.
A related question is how systems might manage the fact that only one aspect of a piece of context is prone to misinterpretation.
Our results show that being on the phone is a good indication that a person is not interruptible and that it correctly plays a significant role in people's estimates of another person's interruptibility.
This paper presented an analysis of the systematic effect of different contextual cues on human estimation of another person's interruptibility, suggesting that careful thought must be given to selection and presentation of contextual cues.
The emergence of ubiquitous and context-aware computing now allows new approaches for recognizing and sharing a variety of information about a person's context to be used.
Understanding how people are likely to interpret such contextual information is important to designing effective and successful computer-supported communication and awareness systems.
We would like to thank Yaakov Kareev, Darren Gergle, Laura Dabbish, and Joonhwan Lee for valuable insights on this work.
This material is based upon work supported by the Defense Advanced Research Projects Agency  under Contract No.
