Multimodal interfaces with little or no text have been shown to be useful for users with low literacy.
However, this research has not differentiated between the needs of the fully illiterate and semiliterate - those who have basic literacy but cannot read and write fluently.
Text offers a fast and unambiguous mode of interaction for literate users and the exposure to text may allow for incidental improvement of reading skills.
We conducted two studies that explore how semiliterate users with very little education might benefit from a combination of text and audio as compared to illiterate and literate users.
Results show that semiliterate users reduced their use of audio support even during the first hour of use and over several hours this reduction was accompanied by a gain in visual word recognition; illiterate users showed no similar improvement.
Semiliterate users should thus be treated differently from illiterate users in interface design.
An estimated 785 million adults around the world are illiterate .
More than one third of this population lives in India, where the literacy rate is 65% according to the 2001 Indian census .
As access to online information and software tools is increasingly required for individuals to fully participate in society, we need to consider how these systems might better support different levels of literacy.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Previous research, however, has largely not distinguished between illiterate individuals and the vast number of semiliterate individuals, those who have some familiarity with letters and words but may in fact have difficulty reading even a simple text passage; by one estimate, 75-80% of the literate population in India may be only semiliterate .
As an illustrative context, Medhi et al.
The search engine has been shown to be useful for low literacy users in general, but the target population has from 0 to 6 years of education, encompassing a range of literacy skills.
Grouping together all low literacy users runs the risk of overlooking potential benefits of text for semiliterate individuals in terms of both performance with the interface and broader impact on reading skill acquisition.
Everyday exposure to text provides important incidental learning opportunities , which are important for reading skill reinforcement and the maintenance of rudimentary skills.
This is the theory behind including same language subtitles in local-language television programs, a technique which has been shown to improve script decoding in Gujarat, India .
From an interaction perspective, text offers a fast and precise mode of communication.
Augmenting a text-based interface with another modality such as audio or images could provide non-textual support for low literacy users when needed but could ease semiliterate users into interacting more with the text as they gain experience.
Although some studies have shown that text-free interfaces are preferred by low literacy users in comparison to fully text-based interfaces , there is some indication, albeit in a study with just one user, that text can help a person with low literacy to disambiguate images over just a few sessions with the interface .
As well, users with strong literacy skills are more likely to prefer an interface with at least some text over none .
However, there have been no formal evaluations to isolate the preference and performance differences of fully illiterate users from semiliterate users.
It is unclear whether previous findings on minimal or no text interfaces apply directly to semiliterate users, or whether semiliterate users, even with very little education, can benefit from text in the interface.
To address this question, we conducted two controlled experiments using an experimental interface and search task provided in Kannada, the predominant language in the state of Karnataka, India.
In the first study, 12 semiliterate participants  showed performance improvements that were coupled with reduced use of audio support.
The second study measured longer-term learning with the interface and changes in visual word recognition, and compared the performance and preferences of 12 participants with different levels of literacy .
All user groups improved their task performance, while both the semiliterate participants and those literate in other languages reduced their reliance on audio support and significantly improved their ability to recognize written words over the course of the study.
The primary contribution of this paper is empirical evidence to show that, in contrast to the needs of fully illiterate users, a text-based user interface augmented with audio can be beneficial for semiliterate users.
For these users, an improvement in performance on a simple search task was coupled with an improvement in visual word recognition, even though this improvement was incidental to the main task goal; this benefit was also seen with users literate in languages other than the target language.
From a designer's point of view, these findings suggest that illiterate and semiliterate audiences may need to be considered as very different user populations.
The addition of audio annotations to an existing text-based interface can significantly support semiliterate users and should be easier than creating a new, text-free one.
These prototypes have been evaluated to varying degrees; we discuss the more generalizable findings.
An evaluation with low literacy users  showed that the text-free versions were preferred and increased task accuracy.
In contrast to our study, their text-based interface was purely textual and was not augmented with audio.
More recently, in a study comparing participants' understanding of health information represented as text, drawings, photographs, videos or animation, all with and without audio, the conditions with audio resulted in higher understanding and task accuracy than conditions without audio .
Some participants also reported the text condition to be confusing.
While this highlights the importance of audio for low literacy users, the authors acknowledge that some of the accuracy benefit may have been due to participants mimicking the audio rather than understanding the material.
In the design of a financial management system for rural micro-credit groups in India, Parikh et al.
The final design included numbers to leverage numeracy skills, icons, audio, and text in the local language.
Audio augmentation was found to be useful for disambiguating items.
Although the impact of different levels of literacy was not the focus of their research, the findings provide preliminary support for our work: most participants were able to use the final design, except for those with the lowest levels of literacy.
Rural literate users who tested a text-only version of the interface after using it with both audio and text preferred the version with audio.
Finally, Shakeel and Best  designed a community bulletin board catering to a range of literacy levels by combining audio, images and text.
An evaluation compared the preferences of low literacy users to users who had passed a basic literacy test.
Only 2 out of 5 of the low literacy users wanted at least some text, in comparison to all 5 of the users with stronger literacy skills.
The evaluation was not designed to measure performance or to assess longer-term, broader impact  of working in the different versions of the interface.
The long history of research into reading includes many theories, sometimes conflicting, on how beginner readers learn to read and how best to teach these skills .
While designing a system to teach users how to read was not the primary goal of our research, a general understanding of prevailing theories can help to interpret our results.
The stages through which beginner readers progress are varyingly defined by different researchers , but a commonality among these theories is that beginning readers first use visual cues , before progressing to the use of alphabetic or phonemic cues .
During the first stage, characteristics such as the shape of the first letter can act as visual cues for remembering a word.
The surrounding context can also be used to facilitate recognition, for example, the consistent location of a word on a package of food.
During the alphabetic or phonemic cue stage, readers can map sounds to some symbols and use that as a less arbitrary cue to retrieval .
More complex strategies are used by skilled readers, such as reading new words by drawing analogies from known words.
Over 35 million people speak Kannada , the predominant language of the state of Karnataka, India.
Kannada is an alphasyllabary, in contrast to the alphabetic orthography of English .
This means that each print unit, or akshara, represents a syllable but may contain features that indicate subsyllabic information, such as the vowel sound.
There is a one-to-one mapping between aksharas and phonological syllables.
One difference between English and Kannada is that the development of phonological awareness  is faster in English .
The reading skill acquisition research summarized above was done with English, but the general phases should still apply with Kannada.
This would be manifest as a decreased reliance on audio as they gained experience with the interface and hence familiarity with the text.
Using the experimental system shown in Figure 2, the task was to search for words among a list of 40 Kannada words.
These words were chosen from a set of abstract words provided in the MRC Psycholinguistic database,1 such as "government", "general" and "nature".
Abstract words are more difficult than concrete words to represent in graphical format, hence text is particularly useful for disambiguation in these cases.
At the beginning of each trial , the system played an audio recording of the word the participant needed to find.
If the participant felt comfortable reading the words, he/she could visually scan the list and select the correct word by tapping on it with the pen.
Otherwise, tapping with the pen on an audio button paired with each word on the list would cause the system to read that word aloud.
Participants could exclusively use visual search, audio search, or a combination of the two.
Incidental learning plays an important role in language acquisition, and may even be better for long-term vocabulary growth than explicit learning .
Through its multimodal nature, subtitling offers an opportunity for incidental learning and has been shown to be beneficial for novice learners of a second language .
Multimedia software, though not necessarily multimodal, has also been explored in this context .
However, in the context of illiteracy, incidental learning through multiple modalities has not received as much attention.
One exception is a large-scale, long-term study by Kothari et al.
Over a six month period the show was broadcast for a total of 8 hours, but viewers could also request hard copies of the song lyrics by mail.
Pre-test and post-test reading assessments were administered to 358 viewers and results showed an improvement in the ability to read syllables and short words.
In the case of same language subtitling, the main "task" was to watch the music videos; the learning of script characters was incidental.
One goal of our research is to investigate if this phenomenon can also occur during interaction with a software user interface.
Screenshot of experimental system showing text and audio pairs; control buttons allow the participant to continue to the next trial upon completion of the current one, and to replay the audio prompt for the current trial.
English text labels are for illustration only, and were not shown on screen.
We required a pen tap to start audio clips because we wanted participants to explicitly decide whether or not to use the audio; another option would be to have it play when the pen hovered over the audio icon but we felt this would have led to too many inadvertent audio playback activations.
Playback of an audio clip was interrupted if the user made a selection  or tapped another audio clip.
After the correct word was selected, the set of 40 words shown to the participant was reordered randomly to isolate visual pattern recognition from spatial learning.
A task block consisted of 10 trials and participants completed 10 task blocks in a row, for a total of 100 trials per participant.
The particular set of 10 words to be tested in each task block was randomly pre-selected from the same list of 40 words at the beginning of the study for each participant, and the order of their appearance in trials was randomizd for each task block.
More than half of them spoke at least one other language, including Tamil, Telugu and Hindi.
There were 9 females and 5 males, with an average age of 30  and average of 2.3 years of schooling .
None of them had any computer experience.
Participants were each given a gift worth approximately 60 rupees  for their time.
Sessions were conducted in a location of the participant's choice, including our research lab, a local NGO office, and the home of one of our research assistants.
Note that from an experimental control perspective, it would have been preferable to have conducted all sessions in the same locale; however, the ground realities in conducting research in the developing world necessitated some compromises in order to accommodate the schedule and travel constraints of participants.
The experiment ran on a Toshiba Tecra M4 Tablet PC with a 14" display at 1400x1050 resolution.
Participants used the pen to interact with the Tablet PC in "slate mode", with the keyboard inaccessible.
We chose the pen over the mouse or touchpad because it is typically easier for novice users to manipulate.
The system recorded all performance data.
At the beginning of the session, participants were asked to read a short sentence in Kannada aloud, to filter out those potential participants who did not have any difficulty reading.
After answering several background questions, participants were introduced to the experimental system and completed a short practice block of 5 trials.
This was followed by the 10 test blocks of 10 trials each.
Participants were given the opportunity to take a short break between blocks if desired.
We ran a one-way repeated measures ANOVA  for each of the three measures.
A Greenhouse-Geisser adjustment for non-spherical data was applied to all analyses.
Two participants were excluded from the analysis because they did not need the audio at all during at least 2 of the first 5 task blocks , thus we report on data from only the 12 participants who clearly required the audio.
All three of our main hypotheses were supported: there were significant learning effects for each dependent measure.
Participants used less audio as they became more familiar with the task.
There were 40 words in the interface and these were randomly reordered for each trial, so a linear search using only the audio to find a word would result on average in 200 audio invocations per task block .
Task completion times and error rates also decreased.
We considered three main dependent variables: 1.
Time to complete all 10 selections in a task block.
Number of incorrect words selected in a task block; note that because participants could not proceed to the next trial until they had correctly completed the current trial, this number could potentially be higher than the total number of trials.
Number of times the participant clicked on an audio button in a task block.
The goal of the second study was twofold:  to determine whether the improvement seen in Study 1 was at least partially related to improvement in longer-term word recognition , rather than only based on general task familiarity or short-term memory, and  to understand how different levels of literacy among participants impacts interaction.
Participants picked up the experimental task quickly, even though none of them had previously used a computer.
Feedback on the combination of text and audio was also positive: when asked afterward if they would prefer to use an interface with sound only, sound and text, or text only, 9 of the 12 participants chose the combination of sound and text; the remaining 3 participants chose the sound only option.
The 3 participants who used the least audio still felt it was important to have because it gave them confidence and allowed them to confirm that they had found the right word before selecting it.
6 other participants reported their strategy changed over time and they started using cues such as word length to help identify words.
All participants had self-identified as being semiliterate and we did not further distinguish participants based on literacy level.
However, the rate of learning and comfort with the text and/or audio should be impacted by different levels of literacy.
Figure 3 shows a graph of average audio use per participant during blocks 1-5 versus blocks 6-10.
Points on the diagonal represent instances where participants used the same number of audio invocations in both halves of the study, while points below the diagonal indicate instances where audio invocations dropped in the second half of the study.
The pattern suggests that those participants who started off in the middle of the group in terms of audio use reduced their reliance on audio the most during the second half of the study.
Those participants who relied on it extensively did not show as marked an improvement.
We more systematically explore this pattern in Study 2.
Participants performed 5 task blocks on each of 4 consecutive days, for a total of 50 trials per day, and 200 trials over the entire study per participant.
At the beginning of the first day, as with Study 1, we asked participants to read a sentence aloud in Kannada , followed by a set of background questions.
At the end of each day we administered a reading test  and asked participants to describe the strategy they had used to complete the task that day.
On the final day we also conducted a short interview to collect feedback about the combination of text and audio, the search strategies that participants used, and their overall preferences.
Study sessions were at most one hour long, with the middle two sessions as short as 30 minutes.
In addition to measuring task completion time, error rate and audio invocations as in Study 1, we administered a reading test at the end of each session.
It consisted of 20 words from the experimental application .
Participants were asked to identify and read aloud as many words as they could from the list.
Study 1 was not designed to identify the specific causes for the reduction in audio use over time.
This reduction and corresponding improvement in task completion time could have been due to several factors, including an improved ability to visually decode words, reliance on short-term memory versus longer-term learning, and a general increase in familiarity with the experimental task and setup.
Twelve participants  completed this phase of the study.
The average age of each of the groups was from 26 to 28 years .
Literacy groups were defined as follows: 1.
Illiterate: The 4 participants in this group self-reported as not being able to read at all and on our initial reading assessment, none of them could read a single syllable.
One of them had one year of schooling while the remaining 3 had no formal education.
Only 1 of them had ever used a computer.
Semiliterate: These 4 participants self-reported as being somewhat fluent readers in Kannada and not fluent in other languages.
All could read some syllables and words with great difficulty on the initial reading assessment.
They had from 1 to 6 years of education .
None of them had used a computer.
Literate in another language : These 4 participants all had at least one university degree and all self-reported as being literate in English and at least somewhat literate in one or more other languages .
Two of them spoke but could not read or write Kannada; the others did not speak Kannada beyond a few words.
This group was included to see how literacy in another language might impact learning of a new language, as opposed to those who were only semiliterate.
Overall, the Illiterate group recognized the fewest words, on average only 0.9 words per day, while the Semiliterate and Literate groups achieved higher average scores of 3.7 and 6.2 words, respectively.
Participants were able to identify and read more words as the study progressed .
Semiliterate and Literate users improved on reading test score but Illiterate users did not.
Both the Semiliterate and Literate groups improved significantly over the course of the study, but no significant improvement was seen for the Illiterate group.
By Day 3 for the Semiliterate group there was a significant increase in reading test score over the first day .
The Literate group improved even faster, scoring significantly higher by Day 2 .
Participants were more likely to recognize target words than distractor words.
To understand if participants were more likely to recognize certain words over others, we examined the recognition frequencies for individual words in the test.
There was no clear indication that some types of words were recognized more often than others .
As might be expected, however, participants were much more likely to recognize words that appeared as targets in the search task over words that appeared as distractors .
This also differed by Group: only 1 participant in each of the Illiterate and Semiliterate groups recognized any of the distractor words, whereas all 4 Literate participants recognized at least 1 of these words on Day 4.
Upon completion of the study, participants were given a gift worth approximately 150 rupees .
The Literate participants were recruited from our research lab, while the Illiterate and Semiliterate participants were recruited through word of mouth from a network of housekeeping staff and from a nearby construction site.
Recruitment was especially difficult because of the four day commitment.
The construction site participants only had free time late in the evening once they completed their work.
The housekeepers often had several jobs during the day and were also pressed for time to participate between jobs.
Sessions were conducted either at our research lab or at the home of one of the research assistants based on which location was more convenient for the participants.
We expected that the Literate group would behave similarly to the Semiliterate group because of knowledge transfer from other languages.
Our main hypotheses were: 1.
Audio use: Audio use for Semiliterate and Literate participants will decrease with practice .
Audio use for Illiterate participants will not decrease with practice .
Reading test score: Reading test scores for Semiliterate and Literate groups will improve with practice.
Preference: Illiterate participants will prefer audio only .
Semiliterate and Literate participants will prefer a combination of audio and text .
For each of the dependent variables we ran a 2-way mixed factorial ANOVA with Day as a within-subjects variable and blocking on Group  as a betweensubjects variable.
Bonferroni adjustments were applied for all pairwise comparisons.
This is shown in Figure 5.
While all participants improved in terms of task completion time, the Semiliterate and Literate participants improved faster than the Illiterate participants.
Pairwise comparisons showed that Illiterate participants only significantly improved between Day 1 and Day 4 , whereas both Semiliterate and Literate participants showed improvement already by Day 2 .
Semiliterate participants continued to improve between Day 2 and Day 3 .
A trend suggested that error rates may have decreased over the course of the study , but no other significant main or interaction effects were found on error rate.
On average, the number of errors dropped from 16.3 errors on Day 1 to 5.1 errors on Day 4.
The overall audio invocations measure encapsulates a range of audio usage, so we performed a secondary analysis to isolate specific types of usage.
Since this analysis is a breakdown of the overall audio data it should be interpreted more cautiously; however, it does provide a first step in understanding different types of usage.
We first examined audio invocations on distractor words, those that were not the search target for a given trial.
Semiliterate and Literate participants used less audio than Illiterate participants .
Audio invocations on the target search word for a given trial showed a different pattern from nontarget words .
On the first day, participants needed the most audio support compared to the other three days , but by the last day audio use had dropped considerably, and was lower than each of the preceding days .
The Illiterate group relied more on the audio support than either the Semiliterate or Literate groups .
No significant interaction effect was found.
During earlier sessions, participants were more likely to repeatedly play the same audio clip more than once during a trial.
This may have been due to a general learning effect as participants became more familiar with the words, but may also have been a result of participants adopting more efficient  search strategies.
Participants could also replay the audio task prompt , and the number of times they did so dropped as they gained more experience with the task.
Finally, participants were more likely to play the audio clips for longer words.
There was a significant positive correlation between the length of a word and the number of audio invocations on that word .
This suggests that the shorter words were easier to visually recognize, thus not requiring as much audio support.
You need a reason to learn the script, like in English there are lots of things to learn.
Now I know some characters and it will make it easier" .
This comment also reflects the lack of incidental language learning opportunities, an important element of language learning as discussed in the Background section.
Participant 1 in the Illiterate group provides a compelling example that audio-augmented text can be useful even for some individuals with no formal education.
He was 23 years old and, although illiterate, still had relatively high exposure to computers: he had previously played first person shooters and car racing games in internet cafes at least a few times a month, for a cost of 15 rupees  per hour.
He was the only participant in the Illiterate group who showed substantial reduction in audio use and he more than doubled his score on the word recognition test from Day 1 to Day 4.
On Day 3 he reported that his search strategy had changed because he was beginning to recognize the words.
When asked if he felt he had gained anything from participating in the study he felt that if he could participate over a month he would be able to read and write the words.
He clearly benefited from the interaction in a way that would not have been possible with a text-free user interface.
We observed several search strategies to complete the task.
The most basic was an exhaustive search  of the audio clips, with no indication that the participant was making any use of the visual cues.
This strategy was always used by 3 of the Illiterate participants.
The remaining participants reported using strategies with different levels of sophistication: word length, starting/ending syllables, relating the visual pattern to a memory cue , identifying letters, and over time identifying script modifiers.
A representative quote for the Semiliterate group can be seen in one participant's description of her learning process: "The first day I did not know how to recognize the words, but later on I found out about long words and short words and I would find the words with few " .
When given the option of future Kannada interfaces with sound only, sound and text, or text only, 3 out of 4 Illiterate participants wanted sound only.
The only Illiterate participant who preferred sound and text was also the only one in that group who showed a marked decrease in audio use over the four days .
In contrast, 7 out of the 8 remaining participants preferred a combination of sound and text.
Only 1 Literate participant reported that she would prefer a combination of sound and images without text.
Both the Illiterate participant who showed reading improvement and several of the Semiliterate participants felt that they would see more benefit if they were able to continue the study for longer.
Both the Literate and Semiliterate participants quickly showed improvement on the reading test after only 2 and 3 days of use, respectively.
However, we found no significant improvement for Illiterate participants over the length of the study.
In terms of task completion time, Literate and Semiliterate participants improved more quickly than Illiterate participants.
The Illiterate group also made the most use of audio.
Finally, as expected based on Study 1, there was an overall decrease in audio use over the four days.
Illiterate and semiliterate users have differing needs and respond differently to text in the interface.
Our results show that text augmented with audio has benefits for semiliterate users: reliance on audio support decreases over time and this corresponds to longer-term evidence of an ability to visually recognize words, even when the visual learning was incidental to the main task.
These results are encouraging because they suggest that an augmented text interface provides an incidental learning opportunity and therefore reinforcement of reading skills in semiliterate individuals.
Semiliterate individuals can also take advantage of the performance benefits of text over audio  and can benefit from the unambiguous visual representation it offers .
To further support the benefit of working in a text interface augmented with audio, reflection by participants on their search strategies matched the literature on the stages of reading skill acquisition.
The reported use of visual cues such as word length, followed by learning of syllables, then finally sub-syllabic information  clearly demonstrate the stages of reading skill acquisition and suggest that working in audio-augmented text interfaces can result in the side benefit of incidental language learning.
Although there are differences in implementation, context and exposure, our findings confirm those of Kothari et al.
Based on both the performance and preference results from our studies, user interface designers should consider the use of audio-augmented text interfaces for semiliterate individuals.
For designers, augmenting an existing textbased interface with audio should require much less effort than creating a new text-free version of the interface.
When designing minimal-text interfaces there are several visual alternatives to text, such as drawings, photographs and animated images, and it is unclear which option is best .
Text-to-speech screen reader systems such as JAWS  already provide speech-based interaction with existing applications for blind and low vision users.
In contrast, the problem of augmenting the interface with audio for sighted users should be more straightforward because the designer does not need to provide non-visual navigation methods.
We have shown that augmented text interfaces can be beneficial for semiliterate users but we did not find a similar benefit for fully illiterate participants: 3 of the 4 illiterate participants in Study 2 appeared to entirely ignore the text and to focus solely on the audio.
Although illiterate individuals may also benefit from redundant text and audio in the interface over a longer time period, our results do not dispute previous work by Medhi et al.
These findings highlight the importance of considering the exact makeup of the target population before choosing a text-free versus an augmented, text-based user interface.
Since both illiterate and semiliterate target populations have low levels of education, interaction complexity needs to be considered in addition to the choice of whether or not to use text.
Finally, individual differences in skills and background, even for users with no formal education  should also be considered.
One option, for example, is to allow for text to be shown or hidden on demand.
In our experimental system we used a one-to-one mapping from text to audio.
Another option is to include tooltip-like audio which would provide a more descriptive alternative to the text.
If maximizing the opportunity for reading skill acquisition is a main design goal, then a karaoke-style approach to simultaneously highlight syllables as words are read aloud  would provide more benefit.
The research presented here offers a first step towards understanding how to design interfaces for semiliterate users and how this differs from illiterate users.
One limitation, however, is that we did not compare the combination of text and audio to either a text-only or an audio-only condition.
For our target users a text-only condition would be an extremely difficult if not impossible option, likely resulting in user frustration and high error rates.
On the other hand, an audio-only version could have functioned as a control for general learning effects such as confidence and the development of efficient non-visual search strategies .
Performance of the illiterate participants in Study 2 should offer at least some insight into potential performance with an audio only condition: on the first day illiterate and semiliterate participants were roughly equal in terms of task completion time, but by the fourth day semiliterate participants were approximately twice as fast as illiterate participants.
This suggests that an audio-only version would be significantly slower than a text and audio version for semiliterate participants over long-term use.
Recruiting and running studies with low literacy individuals in a developing world context presents unique challenges .
Our illiterate and semiliterate participants worked extremely long hours and had very little free time for extra activities, so it was a challenge to recruit 8 participants to attend sessions for four subsequent days.
Additionally, we did not tell participants ahead of time that they would be receiving a gift at the end, because we did not want this to be the motivating factor for their participation.
As a result of these practical constraints we only had four participants in each literacy group in Study 2.
It will be important for future work to build on and reinforce our findings via studies with larger numbers of participants.
We have shown through two controlled experiments that as semiliterate users become more familiar with a text-based interface augmented with audio, they become less reliant on the audio, a change that likely contributes to the corresponding performance improvement we observed.
The second study further showed that semiliterate individuals and those literate in other languages improved on a paperbased word recognition test administered at the end of each study session, as quickly as the second day of use.
For fully illiterate users, however, our findings add further support to the growing body of evidence indicating that little or no text should appear in the interface .
The goal of this research was not to teach users how to read.
Rather, we were interested in understanding how users with different levels of literacy would choose to use the text and audio representations in the context of completing a timed task.
The next step will be to replicate these results in a field study, with an application such as Medhi et al.
Further work also remains on how to most effectively augment a text-based interface with audio and, if desired, how to more explicitly support users in transitioning from audio to text.
Individual differences likely play an important role, in which case options such as showing or hiding text on demand may be appropriate.
