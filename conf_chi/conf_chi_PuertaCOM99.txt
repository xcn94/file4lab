Any connection between the operations made through an interface builder and the requirements of the target users and their tasks must be maintained in the head of the developer without assistance from the interface-building tool.
Separately, the user-interface community has come to accept that one of the best methodologies for user-interface construction is that of user-centered design .
The basis of this methodology is straightforward: The design of a user interface should be guided principally by the nature of the task that the user needs to accomplish.
This differs from so-called engineering-centered approaches where interface design decisions are made according to the requirements of the application being built.
The benefits of user-centered design have been clearly demonstrated over the years .
It is therefore curious that the clearly effective graphical interface builders do not support the similarly effective user-centered approach.
This opens the question of how could interface builders be augmented, enhanced, or modified in order to enable a user-centered approach but without changing the operations in such a way that the original benefits of the tools disappear.
Interface builders are popular tools for designing and developing graphical user interfaces.
These tools, however, are engineering-centered; they operate mainly on windows and widgets.
A typical interface builder does not offer any specific support for user-centered interface design, a methodology recognized as critical for effective user interface design.
We present MOBILE  an interface building tool that fully supports user-centered design and that guides the interface building process by using user-task models and a knowledge base of interface design guidelines.
The approach in MOBILE has the important added benefit of being useful in both top-down and bottom-up interface design strategies.
For a good number of years, interface-building tools have gained wide acceptance among developers of graphical user interfaces .
Interface builders allow developers to layout and organize, via direct manipulation, the various elements of a graphical user interface .
Typically, these tools include code generators that produce the basic hooks for application developers to write the code to communicate with the user interface.
All major commercial software-development environments currently available include interface-building tools.
Although efficient at what they do, interface builders restrict their scope to manipulation of those elements that make up a GUI, such as windows and widgets.
They support, in essence, an engineering process.
The approach taken by our group incorporates elements of user-centered design and of model-based interface development into the functionality of an interface builder.
From user-centered design we take the idea of building user-task representations as a guide for interface development.
From model-based interface development  we take the ability to create, edit and refine user-task models.
These models are computational units that can be exploited by an interface builder.
Finally, from interface builders we take their basic functionality and try to augment it in very specific ways  to enable a user-centered process.
The result is a tool called MOBILE , which enables user-centered interface building.
The tool also provides decision-support guidance thanks to knowledge base of interface design guidelines.
Users of MOBILE can benefit whether they use a top-down approach , or a bottom-up one .
The rest of the paper is organized as follows.
We first provide some contextual information about model-based interface development.
Then, we describe MOBILE and its main functional characteristics.
We illustrate the use of the tool via a sample target interface.
We proceed by detailing the decision-support capabilities of MOBILE and by describing its use in a bottom-up approach.
We conclude by relating our evaluation experiences, the work related to our approach, and the possible directions of future research.
Attributes can be specified for any task as well as procedural information .
Conditions that affect the execution of a task/subtask can also be specified in the model.
Domain objects  involved in the completion of a task can also be defined and associated with any task.
In general, a user-task model is less complex than a workflow diagram and it can retain a certain informal level to it without losing its usefulness.
In MOBI-D, user-task models are elicited from domain experts and then refined by interface developers .
Once created, it is available to any of the other tools in the environment.
Model-based interface development  is a technology that embraces the idea of designing and developing user interfaces by creating interface models.
An interface model is a computational representation of all the relevant aspects of a user interface.
The components of an interface model include submodels such as user-task models, domain models, user models, presentation models and dialog models.
Model-based interface development systems are suites of software tools that allow developers to create and edit interface models.
Many model-based systems aim at generating significant parts of a user interface given a partial interface model.
Some others aim at interactively guiding developers in building user interfaces using interface models .
Over the past three years, our group has been developing MOBI-D  .
MOBI-D is a model-based interface development environment that enables designers and developers to interactively create user interfaces by defining interface models.
The environment integrates a variety of tools including modelediting tools, user-task elicitation tools, and the interface building tool presented here.
A full description of the model-based interface technology and development methodology supported by MOBI-D has been presented elsewhere  and it is beyond the scope of this paper.
Some of the other individual tools integrated into MOBI-D have also been described in previous publications .
For our purposes, however, we simply need to note that a component of the interface models constructed in MOBI-D is a user-task model.
This component is the essential element for the interfacebuilding tool presented in this paper.
For illustration purposes of some of the shortcomings of conventional interface builders, let us consider the partial interface shown in Figures 1 through 3, which has been designed using the MOBI-D tools.
These figures show screen snapshots from a military logistics application.
This application allows users to perform typical tasks associated with requesting and monitoring supplies in a theater of operations.
These tasks include among others:  creating and modifying plans for requisitions of materials,  reviewing potential suppliers for location, available stocks, and delivery times,  requesting supplies and tracking shipments, and reviewing all current stocks of materials The application supports users of different ranks.
The dialog and presentation should adapt to the rank of the user and to the specific task that the user must perform.
In the screen snapshots we can observe the following situations: Figure 1 is the initial screen  for a user of rank Major.
Typically, a user of this application needs to see the authorized stock levels  for the current operation and needs access to a map of the region.
The Major can inspect the ASLs via the 3-D viewer shown on the left.
She can change the data in the viewer to that of a different location by clicking on the particular location on the map shown on the right.
Each row of bars in the 3-D viewer  corresponds to a different class of materials .
The user can quickly see in this viewer if any class has a deficiency in ASLs in which case, he is authorized to modify it and does so via the push button shown above the 3-D viewer.
We determined from domain experts and from the construction of a user-task model for this interface that this screen fulfills the first activity that a user must perform  and that the data presented was exactly  what is needed to complete the overview.
Figure 2 shows the initial screen for a user of rank Sergeant.
The central role of a Sergeant in this scenario is to carry out the requisition plans constructed by the major.
The Sergeant observes when supplies are running low and orders new shipments that conform to the levels set by the Major.
Because a Sergeant deals only with one specific class of materials , the interface uses a 2-D viewer for the ASLs.
In addition, since a Sergeant is not authorized to modify ASLs, the pushbutton for access to the ASL modification screens is disabled.
The user-task information is again derived from the accompanying usertask model.
Figure 3 shows a shipment inspection screen for a user of rank Sergeant.
Once more, the complete information needed to perform the inspection task is included in this screen as dictated by the user-task model.
Interestingly, under certain conditions  this screen must be the initial screen for a Sergeant user .
In such a situation, the decision context of the Sergeant changes from one of monitoring  to one of repair .
Clearly, a conventional interface builder can be used to layout and arrange the elements of any of the screens discussed above.
However, such a tool would offer no help with managing any of the user-task requirements.
Issues such as how data should be split among the screens, what widgets correspond to what type of user, and how the dialog changes according to the task and user characteristics are well beyond the support of a typical interface builder.
In practice, it may be that such user-task information is kept in paper documents, or is viewable through a separate tool, or  it is just in the head of the designer.
The result is bound to be a number of mismatches between the designed screens and the usertask specifications.
In addition, revisions of the screens or of the specifications can produce even more pronounced mismatches, or at the very least a cumbersome coordination process.
We aim for a much higher level of coordination and support for user-task specifications in the interface building process.
This is the central goal of MOBILE.
Figure 5 shows the main functional elements of MOBILE during the design of the screen shown in Figure 1.
The task/presentation manager is shown to the left as a splitscreen view.
The palette of widgets  is a toolbar where each icon represents an available widget.
The canvas area  is the drop target for selected widgets where interface elements are arranged under the direction of the interface designer.
The right-bottom pane of the task/presentation manager is the user-task model inspector.
Here the interface designer can review the hierarchy of tasks and subtasks.
Limited operations are possible in this pane.
The designer can add a new task , delete tasks, or regroup them in a different order.
More elaborate operations on the user task model  require moving to a separate model-editing tool in MOBI-D.
This separation is by design and was determined by our evaluation of MOBILE .
Immediately above the task inspector is also the end-user selector pull-down list.
Changing the user selected in this list results on the task inspector being updated with the user-task model for the specific user type selected.
The left-bottom pane of the task/presentation manager is the presentation inspector.
Here the interface designer can review the elements of the interface and their relationship to the user-task elements.
The top elements in the presentation trees are windows .
MOBILE  is an interactive software tool for user-centered interface building.
Figure 4 shows the main architectural components of MOBILE.
A task/presentation manager communicates with an interface model to obtain and update information related to user-task models and presentation elements of the target interface.
The main functional elements of MOBILE: The task/presentation manager on the left, the palette of widgets on the top right, and a windows canvas area.
The next step is to particular window by the designer.
Each task can have any assign tasks from the user-task model to specific windows.
The leaf elements of the presentation This is accomplished by simple drag-and-drop operations.
Immediately above the presentation inspector there is a button to create new windows in the presentation tree.
Following task assignment, the designer selects specific The palette of widgets is a toolbar populated with icons each symbolizing an available widget.
The widgets can vary from standard ones, such as checkboxes and text fields, to complex ones, such as the 3-D viewer shown in Figure 1.
These widgets are not created and maintained by us.
They are strictly third-party elements.
For example, the 3-D viewer is an ActiveX control supplied by a company called DataViews .
In general, the MOBILE palette can access standard Windows95 widgets and any other widget wrapped as either a Java Bean or an ActiveX control.
The canvas areas in MOBILE are identical to those of conventional interface builders.
A typical sequence of designer operations in MOBILE is as follows.
The designer starts the tool and selects a target end user via the user selector.
This updates the user-task inspector with the user-task model corresponding to the selected end user.
The presentation inspector appears initially empty .
The designer creates one or more new windows that are inserted windows within the presentation tree.
For each window, the designer accepts or modifies the subtasks that are grouped into that window .
This may require merging or splitting windows if changes are desired.
Ultimately, the designer reaches a satisfactory arrangement of tasks into windows.
At that point, the designer then selects each leaf subtask  and uses the palette of widgets to select a widget to complete that particular subtask.
Additionally, the designer can select an interaction technique to perform the task.
In our example, the sequence looks like this .
The designer selects user1  and the corresponding user-task model is displayed.
After creating a new window, the designer drags the task review operation onto the new window.
This window is automatically relabeled review operation window.
All subtasks of review operation are placed under the review operation window.
Note some interesting decisions from the design of the screen in Figure 1.
The user-task model in the task inspector of Figure 5 shows four subtasks for the task review operation.
The subtask update ASLs has some subtasks of its own .
However, no such subtasks appear for the update ASLs subtask in the presentation inspector of Figure 5.
The designer has noted that the update subtask is optional .
Because of its optional nature, the designer decides not to clutter the screen with potentially useless elements and to relegate any subtasks of update ASLs to a different screen.
The designer simply provides a navigation button for the end user whom will use it, if necessary, to access the update functionality.
Second, the screen in Figure 2 shows that the button for update ASLs is disabled for a user of type Sergeant.
We already discussed that users of this rank are not allowed to perform updates.
In the task inspector window this results in the update ASLs subtask not appearing as part of the user-task model when the designer selects a user of this rank.
Without any changes by the designer, the consequence would be that the screen of Figure 2 would contain no button at all for the Update of ASLs.
Instead, the designer decided to add the update ASLs task to the user-task model of Sergeant and in place of left-mouseclick  insert disabled.
This decision was made for purely aesthetic reasons in this case as it avoided creating a wide blank area within the screen.
This type of close coordination between use-task requirements and interface building is the main benefit of MOBILE.
Designers can evaluate at all times their interface building decisions based on the specifications of the user task.
They can also effectively manage the links between the various types of users, the user-task specifications for each user, and the widgets and interaction techniques that correspond to each task and subtask.
Furthermore, assignment of user-tasks into windows is a direct manipulation operation.
None of these important functions are available in conventional interface builders.
MOBILE selects a subtask for which a widget must be assigned, MOBILE can exploit the user-task knowledge to assist in the assignment process.
Based on the attributes of tasks and their related domain objects, MOBILE can consult a knowledge base of interface design guidelines to determine what are the most appropriate widgets to use for a given task.
The knowledge base is essentially a decision tree.
The inference mechanism looks at attributes of objects, such as data types and value ranges, in order to traverse the tree to find optimal widgets.
As a simple example, if a data/domain object to be accessed via the interface is of type Boolean, then the inference mechanism will recommend a checkbox as a suitable widget.
The widgets identified in this manner may also be grouped into discrete categories reflecting their relative suitability .
When a designer working in MOBILE sets a preference to work in guided mode, the tool reflects its decision-support capabilities via the palette of widgets.
As the designer selects a subtask for assignment of a widget, MOBILE disables all widgets in the palette that make no sense according to the knowledge base of interface design guidelines.
In addition, MOBILE will highlight the widgets that are considered of high suitability.
In this manner the attention of the user is directed towards the optimal widgets and irrelevant choices are removed from consideration.
In addition to widget assignment, MOBILE also exploits the user-task models to provide a user-task- and domainspecific interface building experience to the designer.
For example, in conventional interface builders when the designer selects a push button from a palette of widgets and places the widget on a window canvas, the widget appears with either a generic label  or no label at all.
In MOBILE, every widget assigned appears already tailored to the specific task and domains.
In the case of Figure 1, the button for updating ASLs first appears on the window with that label as the information is carried directly from the user-task model.
This capability serves to further solidify the user-centered design experience for the user of MOBILE.
In addition to the basic functionality offered by MOBILE, a knowledge-based decision support system complements the assistance given by the tool to interface designers.
As we discussed earlier, a user-task model encompasses knowledge about the attributes and nature of user tasks as well as about the domain objects involved in the completion of a given task.
The use of MOBILE described so far follows a strict topdown approach.
First a user-task model must be built, then MOBILE can be used to lay out a corresponding interface.
It can be easily argued that this limits the freedom of interface designers.
Some designers like to immediately jump into an interface builder and informally construct possible designs for a user interface.
Having to work out a user model beforehand may be an undesirable burden for these designers.
A bottom-up approach with MOBILE would entail the same kind of free-form interface layout that is available with a conventional interface builder.
However, once the designer starts settling with a particular set of layouts, the designer can annotate each window  with a newly created user task and then can arrange the tasks into a skeleton user-task model.
In this mode, MOBILE acts as a design rationale tool.
The initial user-task model can always be refined into a complete one that would be useful in any revision and update of the interface.
We also don't make any changes to the palette if the user is selecting tasks/subtasks in the user-task inspector .
We only modify the palette when the user selects a subtask in the presentation inspector.
In the earlier version, it caused confusion for users to be inspecting user tasks in the user-task inspector for possible regrouping  and having the palette change with each selection .
The implementation of MOBILE shown here has evolved through several evaluations that also included an early mock-up and two preceding prototypes.
Along the way, we learned what are the functions that designers really want in a tool like MOBILE, and how the on-screen items should be arranged for better efficiency in the interaction.
Our initial mock-up did not include a task/presentation manager.
Instead it counted on the existence of a user-task model-editing tool in MOBI-D.
MOBILE simply provided canvas areas for windows, each with an attached palette of widgets populated specifically for that window and its associated task.
Users were quick to point out that it was cumbersome to continually switch from MOBILE to the user-task model editor.
Furthermore, the model editor included lots of functions that were not relevant at interface-building time.
The one-palette-per-screen approach also seemed to consume too much screen real estate.
Our first prototype was entirely task-based .
The user-task inspector included only the functionality for editing usertask models that users felt was relevant .
A single palette was attached to the inspector.
The palette changed its widgets according to which task was selected in the user-task model inspector.
Designers remarked that it was important for them to be able to see the organization of the presentation elements .
The second prototype included a task/presentation manager similar to the current one, and a dynamic palette that changed its widgets with each task/subtask selection in the manager.
The main difficulty in this version was that designers did not want the palette changing continuously.
This forced them to visually inspect the palette for every task to see what widgets appeared and in what order.
In the current prototype, we fixed the elements of the palette of widgets.
Their location on the palette is always the same.
There are three areas directly related to our work: interface builders, user-centered design, and model-based interface development.
There are excellent comprehensive surveys of existing interface builders and other software tools .
We will refer to those surveys but will remark again that we are not aware of any interface builder that exploits interface models to support its operations.
Similarly, much has been written about user-centered design .
However, no specific implementations have arisen from this field to address the shortcomings of interface builders.
The work closest related to ours is that of other modelbased interface development systems.
UIDE  was one of the first systems to introduce the notion of using interface models to drive interface development.
ADEPT  used effectively for the first time user-task models in their approach to generate user interfaces.
UIDE  and Mecano , among others, exploited the idea of being able to generate automatically the elements of an interface layout from the attributes of the data/domain objects to be displayed on the interface.
A number of other systems have also improved or modified to a certain extent the techniques of user-task modeling and interface generation.
The key difference between earlier systems and MOBI-D is that the former placed an emphasis on the automated generation of an interface given a partial interface model.
For example, generating a concrete interface in ADEPT from a user-task model.
Because of the automated approach, these systems did not attempt to incorporate interactive tools, such as an interface builder, directly into their interface modeling approaches.
Therefore, efforts such as MOBILE have not been attempted in the past by those systems.
We have presented a software tool, called MOBILE, which enables user-centered design approaches for interface builders.
The tool combines the recognized benefits of user-centered design with the efficient functionality of interface builders.
We have, in addition, created knowledge-based techniques for decision support that further augment the capabilities of the tool over conventional interface builders.
MOBILE can serve as an initial step also in demonstrating the value of model-based interface development technologies.
We expect to further enhance MOBILE by providing additional decision-support functions, such as layout critics.
Our current experience with the tool is of course limited.
We do not know yet how it will respond in designs that include large and complex user-task models.
Nor do we have an extensive knowledge base of interface design guidelines that will cover a majority of widget assignment situations.
However, we feel the MOBILE approach significantly helps in advancing user-centered design principles in practical user interface building, a definite worthwhile goal.
Foley, J., et al., UIDE-An Intelligent User Interface Design Environment, in Intelligent User Interfaces, J. Sullivan and S. Tyler, Editors.
Johnson, P., Wilson, S., and Johnson, H., Scenarios, Task Analysis, and the ADEPT Design Environment, in Scenario Based Design, J. Carrol, Editor.
