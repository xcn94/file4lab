We present a novel approach to graspable interfaces using Touchbugs, actuated physical objects for interacting with interactive surface computing applications.
Touchbugs are active tangibles that are able to move across surfaces by employing vibrating motors and can communicate with camera-based multi-touch surfaces using infrared LEDs.
Touchbug's embedded inertial sensors and computational capabilities open a new interaction space by providing autonomous capabilities for tangibles that allow goal directed behavior.
Tangible user interfaces  combine the dynamic qualities typical of digital information representations with physical affordances, i.e.
TUIs, in combination with multi-touch tables, provide passive haptic feedback for hand gestures and are augmented by a physical model for visual feedback.
This allows people to interact with the input devices in the same way they interact with everyday objects, applying real world skills without the need for training or instructions.
The benefits of these user interfaces include the simultaneous reduction of cognitive load placed on users  and simplification of the interaction itself.
In contexts that are likely to include cognitive overload, time pressure, or stress, this may improve performance and even encourage improvisation and exploration .
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
To date, approaches to connect actuated tangible user interfaces with interactive surfaces either require complex modification to, or augmentation of, the interactive surface hardware  or use constrained and relatively cumbersome tangible artefacts .
For example, Madgets are tangibles containing small magnets that are actuated using an array of electromagnets  .
In this paper we present Touchbugs, an open source hardware and software framework for a novel actuated tangible technology .
Touchbugs are small tangibles that use directed bristles and vibration motors for actuation .
Their infrared LEDs allow multiple Touchbugs to both be spatially tracked  on optical multitouch tables and to communicate information about their internal state to the table.
We present the design of Touchbugs and investigate the accuracy of the actuation in a number of experiments.
Furthermore, we show how the embedded sensors can be used to stabilize the tangibles movement in an autonomous feedback loop.
Our aim was to develop a framework of autonomous, selfcontained and controllable actuated tangibles.
Our requirements for Touchbugs were:  that they are capable of smooth, continuous and controllable movement ;  that Touchbugs can sense their own movement and maintain internal state information independent of any external system;  that the electronics are robust and compact and can be readily enclosed by cases of different shapes and sizes; and  that the integration of Touchbugs with optical multi-touch tables does not require hardware modifications or augmentations to the table.
A Touchbug consists of a 40x40mm printed-circuit-board , as shown in Figure 2, comprising a microcontroller, two vibrating motors, LEDs and several sensors.
The PCB is located on two rows of bristles mounted at an angle of approximately 5 to the vertical .
A motor is mounted above each set of bristles, and the vibration generated by these motors causes a high frequency oscillating flexion of the bristles that results in a forward motion .
Custom bodies can be readily fabricated to enclose the PCB and the small and compact form factor of the PCB allows a wide variety of appearances and sizes.
The Touchbugs shown in Figure 1 are 60x50x20mm; weigh 24g; and have a maximum  velocity of 250mm/s.
An optical multi-touch surface can detect and process the signal from a Touchbug's infrared emitters and thus receive information from them.
As illustrated in Figure 3 both amplitude modulation and frequency modulation are employed to communicate information.
The amplitude corresponds to the intensity of the infrared diode, and the frequency is the reciprocal of the amount of time between the signal peaks.
Each LED transmits a distinct signal, which is detected by the camera of the interactive surface as a touch event.
The fixed distance between these pseudo-touch events , combined with unique signal frequencies for each LED, allows the detection and identification of multiple Touchbugs .
Parts of the implementation rely on Touchbridge .
We experimented with various different kinds of materials, but discovered that fine and soft bristles worked best.
Our final design utilized bristles from consumer off-the-shelf draught excluders that were trimmed to lengths from 717mm and attached to the underside of the PCB.
Touchbugs can be steered using differential control of the two motors mounted on the top-side of the PCB above the bristles.
Due to factors such as irregular surfaces and slight differences in the lengths of bristles, the Touchbug is unlikely to move by default in a straight line, consequently a feedback control loop is required to stabilize the motion.
While the process of control could be managed by the tabletop , experiments showed that due to latency in the communication between a Touchbug and the table the required control loop could not be maintained.
Instead we manage the control of a Touchbug on the tangible itself.
A Touchbug senses its deviation from its initial orientation using the gyroscope.
The gyroscope measures the angular velocity of the device around three perpendicular axes.
However, the measured angular velocity is subject to noise resulting from the vibration of the motors.
Results from two different experiments.
The two leftmost graphs show the absolute deviation from a straight path for 5 different motor settings and 2 different lengths of bristles .
The two rightmost graphs show the diameter for circular motion .
Figure 5, this noise is normally distributed be tween  50/s.
As can been seen in Figure 5, when the tangible is rotating, the measurements significantly exceed this noise-level, although this can be a problem for extremely slow turn rates.
We implemented a basic approach to direction control, in which a counter steering motion is induced if the angular velocity exceeds a certain threshold.
This deviation is easily estimated by integrating the rotation measurements over time.
Both the threshold from which to start compensating for drift as well as the coefficient that controls the strength of the counter steer, were estimated empirically to work best with medium speed motion.
To steer the Touchbug to a specific target, first the angle between the direction of the Touchbug and the direction to the target is calculated using simple trigonometry.
However, calculating this angle, rotating the Touchbug accordingly and starting a forward motion is bound to fail, as any rotating motion will also displace the device.
Therefore a more sophisticated control mechanism is required.
Given the estimated angle it is straight-forward to derive whether the device has to turn left or right to face the target.
After initializing the turning motion, the angle between the current direction and the direction to the target is continuously estimated.
Once this angle is below a certain threshold the forward motion is initiated.
This procedure results in a smooth and natural, slightly curving path from the source position to the target.
A Touchbug has two phototransistors, one next to each set of bristles on the underside of the PCB .
These point towards the interactive surface of the table and are sensitive to both visible and near infrared light.
As the phototransistors are affected by ambient and infrared light - and due to the variability in ambient light levels - we restricted ourselves to displaying three light intensities on the surface which the Touchbugs can reliably detect and distinguish: black, grey and white.
Displaying these colors is the mechanism by which the table can control the Touchbug.
When a light level is detected, the Touchbug sets the strength  of its corresponding motor accordingly.
Using white, black and grey semicircular patterns displayed directly under the Touchbugs, the table is able to start, stop and steer multiple tangibles at the same time.
Different configurations of pattern result in different motions as illustrated in Figure 6.
To assess Touchbug's movement abilities, we conducted two experiments.
The first explored the accuracy of the automatic path correction based on the gyroscope measurements for different motor strength settings and bristle lengths.
The tangibles were placed on a multi-touch table  and instructed to cross the available surface by following a straight-line path .
The results are shown in Figure 4.
Graphs  and  show the absolute deviation from the straight-line path measured after the device travelled for 500mm across the table.
Long bristles  show less deviation from the path and also a smaller standard deviation compared to short bristles .
Overall we have not found significant differences in the precision of the automatic path correction for different motor settings.
The second experiment investigated how the motor strength influences the turn-rate of the device.
The Touchbug was placed on the multi-touch table and instructed to turn in a circle .
The diameter of the resulting circle was measured and the results are reported in Figure 4.
Both the short bristles  and the long bristles  show a very similar relationship between diameter and motor strength setting.
When increasing motor strength the diameter initially decreases, after which a sharp jump in circle diameter was observed.
We believe this is due to the friction of the bristles on the surface.
Up until a medium motor strength setting the friction of the inner, nonvibrating bristle exceeds the drag produced by the forward motion by the vibrating bristle, resulting in a sharp rotation.
On higher motor settings the inner bristle begins to slide across the table resulting in a sharp increase in turn diameter.
In this note we presented Touchbugs, a novel actuated tangible user interfaces framework which can communicate with interactive surfaces.
We have characterized Touchbug's actuation and demonstrated its potential as an affordable yet uniquely expressive interaction device for optical multi-touch tables.
Touchbugs have a number of clear limitations.
The tangibles cannot rotate around their center, or move backwards and therefore can get stuck in the corners of a table.
Another drawback is the optical tracking of the devices.
The infrared diodes have a high intensity; nevertheless the tracking accuracy suffers when the lighting conditions change significantly.
The number of Touchbugs that can be used simultaneously is constrained by the number of touch points that the multi-touch surface API can support.
Although in theory there are no technical limitations on how many tangibles can be used, to date we have only used five simultaneously.
Improvements in table hardware such as increasing the frame rate of the camera, along with more efficient algorithms would reduce latency and increase the bandwidth of the Touchbug-to-table optical communication.
Due to the data set which is transmitted through the accelerometer and the gyroscope a wide range of additional features is in fact available.
These sensors allow the recognition of simple motions  or gestures such as shaking, which could be used as a direct input or captured for later analysis .
Furthermore, we implemented the possibility to couple digital content to the Touchbug - such as 3D objects displayed on the table.
When the user rotates the device in his hand, the digital object rotates according to the tangible.
The device can also detect if it is laid on its back or if a user is holding it .
In this case, the vibrating motors can be used as an output to provide variable haptic feedback or to attract the attention of the user.
