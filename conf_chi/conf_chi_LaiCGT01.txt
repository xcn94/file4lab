Car manufacturers and computer companies alike view the time workers spend in a car as an opportunity to deliver email and other individualized messages.
The in-vehicle information systems market is projected to exceed $5 billion by the year 2003 .
The U.S. National Highway Traffic Safety Administration estimates that currently 44% of drivers have phones in their vehicles, 7% have email access and 3% can receive faxes .
Given the difficulties and the high cost of delivering large amounts of dynamic data with pre-recorded speech, it is most likely that these applications will use synthesized speech for the reading of the email messages or profile specific news stories.
Synthesized speech is speech produced by a computer.
It is often referred to as "rulebased" speech because the computer uses a series of rules to convert text to the sounds that are generated.
Compared to human speech, synthetic speech is generally not as well liked and takes longer for people to become accustomed to .
Using synthetic speech in the car, as discussed above, may be easier from a system implementation viewpoint.
However, we have wondered whether there are any costs to attention and driving performance compared to using recorded human speech.
This work was conducted jointly by IBM Research and the University of Michigan Transportation Research Institute .
Complete details will appear in an upcoming technical report.
In this study 24 participants drove a simulator while listening to three types of messages in both synthesized speech and recorded human speech.
The messages consisted of short navigation messages, medium length  email messages, and longer news stories .
After each message the participant was presented with a series of multiple choice questions to measure comprehension of the message.
Findings show that for the low driving workload conditions in the study,  driving performance was not affected by listening to messages.
This was true for both the synthesized speech and natural speech.
Comprehension of messages in synthetic speech was significantly lower than for recorded human speech for all message types.
The term "mobile worker" no longer describes a transient state for a person, but represents a category of corporate employees who work from a multitude of locations.
Employees are being encouraged to "work smarter" since it often does not seem possible to work harder.
As a result, system designers are stepping up to the challenge of giving users access to the same functionality in a mobile setting that they would have if seated in their offices.
However, research suggests that it is not the listening per se that disrupts driving  but rather the additional tasks such as putting in tapes or changing stations, that deteriorate driving performance .
Recent research  focuses on the effect of using cell phones while driving.
Most evidence indicates that using phones has the potential to distract drivers and even cause accidents.
A statistical analysis of traffic accidents suggests that drivers using cellular phones are four times more likely to be involved in a crash .
These findings hold for both hands-free cellular phone usage and traditional usage.
Research on driver response to in-vehicle auditory messages is still fairly limited.
While driving, they were presented with traffic messages containing 6 to 14 items.
Participants were asked to identify whether the message was relevant to a particular route and to recall as much of the message as possible.
Typically only four items were recalled regardless of message length, with the road and crossroad being most common.
They found that listening to a message increased speed variance.
Other driving performance measures such as lane variability and lane excursions were generally unaffected.
As drivers became more loaded, they tended to slow down.
Concurrent with our research, Lee, et al.
Findings show that participants experienced a 30% increase in response time to a periodically braking lead vehicle when using the email system.
The drivers generally reported that the speech-based interaction caused a greater cognitive load for them and they perceived it to be distracting.
The present study was motivated by findings in Lai, et al.
Such demand of cognitive resources could divert attention away and negatively impact performance from concurrent tasks, such as driving.
Our hypothesis was that an increase in cognitive workload would lead to a decrease in both comprehension of messages and driving performance.
In this study, cognitive workload increased with the use of synthetic speech, the increased complexity of the messages presented to the driver, and the increased difficulty of the driving course.
All of these factors were predicted to negatively impact comprehension and driving performance.
This study utilized a 2  by 3  by 3  within-subjects design.
All participants participated in all conditions.
Half of the navigation messages were preceded by an earcon and half were not.
The earcon consisted of a brief chime sound.
Participants were randomly assigned to one of two groups, with the restriction that each group had an equal number of men and women, and young and old.
Messages that were presented in human voice in one group were presented in synthetic voice in the other group.
Each message was only presented once.
The dependent variables in this study were accuracy of message comprehension, response time to questions, standard deviation of the vehicle's lateral position within the lane, and standard deviation of the steering wheel angle.
We also assessed participants' subjective rating of the perceived difficulty of the message.
A total of 24 licensed drivers were recruited from the Ann Arbor, Michigan area.
Half of the participants were between the ages of 21 and 28 and half were older .
These two age groups were selected since they represent two extreme segments of the driving population in terms of driving performance.
All participants were paid $35 for the participation.
Participants were invited to complete the study only if they had no hearing problems.
Only 37.5% of the participants owned cell phones .
Previous exposure to synthetic speech was rated on a six point scale .
Except for two young participants, which reported their exposure at a level 4, none of the participants had significant prior exposure to synthesized speech.
Most reported that they had heard it once or twice.
Any participant reporting a level of 5 or 6 would have been excused.
Participants drove the UMTRI driving simulator version 7.2.2 , a mediumfidelity driving simulator based on a network of Macintosh computers.
The simulator consists of a mockup of a car, a projection screen, a torque motor connected to the steering wheel, a sound system, a sub-bass sound system, a computer system to project images of an instrument panel, and other hardware.
The sound system provides various noises  to enhance the realism of the experience.
The sub-bass sound system provides vibration.
The projection screen, offering a horizontal field of view of 33 degrees and a vertical field of view of 23 degrees, is 6 m  in front of the driver, effectively at optical infinity.
Simulated two-lane roads had 3.6 meters  wide lanes.
Oncoming vehicles were positioned statically in the left lane to provide a more realistic feeling of a busy road.
A lead vehicle drove in front of the simulator vehicle at a fixed speed of 72.5 km/hr .
A sample of the view of the road is shown in Figure 1.
The simulator has both a functioning brake and gas pedal.
For this study neither was required since the car was used in cruise control and automatically accelerated from a stopped position to the preset cruise speed.
Participants were only required to use the steering wheel to control the position of the car within the lane.
If a lane deviation occurs, a loud bump and grinding noise is heard as the car moves onto the shoulder.
If the car crosses the lane into other cars there is no negative impact on the driver.
One is able to "drive through" any object.
The other two questions probed for comprehension about details contained in the message.
Sample email message: Colleagues, Safe driving at our site is everyone's responsibility.
In the past few months, Security has received a number of complaints about speeding cars in the parking areas.
Excessive speed, combined with decreased visibility and wet roadways during the winter months, increases the risk of accidents.
In addition, a number of employees have been parking in the roadway next to the grassy islands, and therefore obstructing the flow of traffic.
All employees are asked to observe the following guidelines: - Observe the posted speed limits; - Observe traffic signs and pavement markings; - Respect the two-hour limit on visitor parking; - Do not park in areas marked "No Parking" or "Fire Zone."
Every participant heard three types of messages of varying lengths in both synthetic and recorded human speech.
The three message types were navigation, email, or news.
All navigation messages were four seconds long and consisted of the direction of the turn, name of road, and distance until turn.
For example "turn right in 1.5 miles onto Radiance Drive."
These three pieces of information appeared in random order to reduce any training effect.
The participants were then presented with two questions, which asked for two of the three pieces of information.
Thus the purpose of listening to the messages was to attempt to understand them and not to direct the driving.
The road in the simulator had no intersections and did not require turning off onto other roads.
The email messages were around 100 words in length and discussed a variety of topics, many geared towards a corporate recipient.
The participants were asked four questions about each news message, one general and three specific comprehension questions.
See Table 1 for characteristics of the email and news messages.
The IBM TTS engine Via Voice Outloud, for embedded platforms, was used to record the synthetic messages at a rate of 180 words per minute .
A voice talent recorded the natural speech messages.
Participants had a fixed amount of time to answer the set of questions.
After that fixed period of time, the auto-pilot was turned off and the driver needed to resume control.
The participants were made aware of the time remaining for the set of questions by a progress bar at the bottom of the screen that moved towards 0 as they ran out of time.
Also, when the auto-pilot was turned off, there was a road sign by the side of the road that read "Auto-pilot is now disengaging".
The participants began by completing a biographical form and a consent form.
They then underwent both a hearing test and a visual acuity test.
All were well qualified to drive and could easily hear the messages.
After moving to the driving simulator the experimenter played a sample message and verified that the participant found the sound level comfortable.
Then the participant read a few sentences from the in-vehicle display, to verify that the participant would be able to read both the questions and multiple-choice answers about the spoken messages.
The experiment started with a 5-minute practice of driving the simulator on a road that consisted of a few straight sections and several curves.
The participant then drove on a similar road to collect baseline-driving data.
Thus comfortable with how to operate the driving simulator, the participant was given a series of practice messages in both the synthetic and human voices with the simulator running but parked.
After listening to each passage the participant was presented with several questions with multiple choice answers on the in-car display.
Thus questions and their possible answers were read by participants and not spoken with either TTS or human speech.
Questions were answered by the participant by speaking the selection  out loud.
Each question was presented one at a time, with the participant controlling advancement to the next question by means of a finger switch fitted to the right index finger.
A similar practice session was conducted with the participant driving in both straight sections and curves.
After the participants pulled away from the side of the road the car automatically accelerated to a preset cruise control speed of 72.5 km/hr .
Cruise control was selected for this study to eliminate the variability caused by speed reductions when the driver listened to the messages.
This simulates a very easy driving scenario.
In order for the participant to read and answer the questions, the car went into an "auto-pilot" mode after the message was played.
Comprehension accuracy was measured by scoring the number of multiple choice questions that were answered correctly.
Time on task was measured for each question and included the time from when the question was presented until the participant clicked the switch to move to the next question.
Driving performance measurements included standard deviation of the steering wheel angle, and standard deviation of the vehicle's lateral position in the lane.
The number of lane excursions was also measured.
In general as standard deviations of these measures increase, driving performance decreases.
In the first baseline, 10 participants were asked to answer all the questions used in the study without ever having heard the text.
The subjects were presented with a paper copy of the questions and instructed to answer them in the order presented based on: common sense, prior knowledge of the subject of matter, or hints and clues in the structure of the questions and answers.
As in the main experiment, they said the number of their choice for the answer out loud.
The mean comprehension level was 23% correct, which is close to random guessing .
Therefore, the difference in comprehension of different messages could not be attributed to clues in the questions themselves.
In the second baseline, the main experiment was replicated without driving.
Twelve young subjects, whom had not previously participated, were asked to respond to the messages while seated in the simulator room.
The apparatus for this baseline was the same as used for the main driving experiment, except for the factors associated with driving the simulator .
The purpose of this experiment was to measure the difficulty of messages without the effect of driving workload.
The second baseline study revealed differences in comprehension between the different messages.
Consistent with our hypotheses, participants rated the synthetic voice more difficult to understand than the human voice and were less accurate in remembering the content of the messages read by synthetic voice.
However, voice type had no effect on driving performance.
We also had several findings that were contrary to our expectations.
While we expected that comprehension accuracy would degrade as the messages got longer and more detailed, we found that email messages, our medium length message, had the lowest accuracy scores.
Also comprehension accuracy appeared to increase with a more difficult driving workload.
These findings and others are detailed in the sections below.
No participants committed any lane excursions, therefore no results are reported for that measure of driving performance.
After each message was played, participants were asked to rate how much of the message they felt they understood on a scale of 1 to 10, with 10 being `understood all of message.'
This was expected, given that news messages were longer and contained more detail.
However the participants' perception of performance and ease of the email messages was contrary to actual accuracy scores.
Accuracy scores by message type and voice type can be seen in Figure 2.
The results suggest that listening to synthetic speech requires more attention than listening to human speech.
The time needed to answer the comprehension questions was not affected by voice type.
Both measures of driving performance were also unaffected by voice type.
No differences were found between navigation messages preceded by an earcon and those not preceded by an earcon.
We speculate that this is due primarily to the fact that participants were seated in the simulator waiting for the next message to play.
In real driving situations there would be more distractions and the earcon would be needed to alert the driver to broaden his attentional focus.
However since there were no differences in the findings for the two types of navigation messages  we collapsed the results and present only one type of navigation message.
Pairwise comparisons revealed that all means were significantly different from each other.
Though news messages are longer than email messages, they may be easier to understand because most people already have developed a model for listening to news stories in the car by listening to the radio.
One participant commented, "Yeah, I hear news messages on the radio.
With the email, it seemed like important stuff that you had to think about.
You couldn't just passively listen to it."
In addition, because the content of the email messages was somewhat business-related, it may have been more unfamiliar to the participants than the content in the news messages.
One of the participants, when asked to explain why she thought news messages were easier to understand than email messages, remarked, "It was the subject matter that made the difference.
Some of them were funny...
I could relate to them...
If I understood the message, the voice didn't make a difference.
It was the message itself."
More complex messages required more time to answer the comprehension questions.
The type of message the participant heard appeared to affect driving performance.
Lateral position within the lane was not affected.
This could have been due to the smaller sampling of time.
A different explanation might stem from the order of messages.
Due to the experiment setup, the first parked condition always occurred before the first two driving conditions.
Straight and curved sections were not presented in a fixed order.
Some task training could have occurred after the parked position.
However the subjects would also be more fatigued as the study progressed.
Alternatively, these results may have been an artifact of the particular messages presented in the different driving workload conditions.
Because we balanced the order of TTS and human voice messages within each age and gender group, we had 3 participants in a given condition .
As a result of the small number and the additional programming requirement, we did not randomize messages across driving workload conditions.
Response time to answer questions did not increase linearly with driving workload.
A two-way interaction revealed that accuracy in comprehending email messages was greatest in the straight sections, but accuracy of comprehending news messages was greatest in the curved sections, F=8.45, p<.001 as seen in Table 2.
It was surprising to find that the most complex messages were understood best in the most difficult driving condition.
The driving performance results affirm that curved sections were more difficult to drive than straight sections.
There were greater deviations in lateral position within the lane and deviations in steering wheel angle for the curved sections compared to the straight sections, p<.001 for both dependent variables.
More interestingly, we found that an increase in driving workload was accompanied by increased accuracy in answering comprehension questions.
All pairwise comparisons were significantly different from one another, p<.001.
Mean values for accuracy comprehension by driving workload and message type.
A two-way interaction also revealed that comprehension of synthetic speech was most accurate in the straight sections but comprehension of human speech was most accurate in the curved sections, F=10.09, p<.001 as seen in Figure 3.
This finding supports our hypothesis that perceiving synthetic speech requires more cognitive resources than perceiving human speech.
The increased workload of driving the curved sections made it more difficult to perceive the synthetic speech, thus the lower accuracy in remembering synthetic voiced messages in those sections.
Though findings from this study did not show a significant change in driving performance while listening to messages produced with either synthesized or human speech, the authors caution that this result should not be generalized until higher levels of driving workload can be examined.
As one of the first studies in this field, we wanted to keep the initial parameters fairly basic.
Thus driving conditions were simple: cruise control, a lead vehicle that never changed speed or braked, and very predictable two-lane roads with minimal traffic and no intersections or unexpected events.
This is perhaps one of the easiest driving scenarios that drivers could find themselves in.
However, while easy, it is still reflective of driving conditions on open highways in cruise control.
Future work should involve measurements of the effect of listening to email messages with greater levels of complexity in the driving conditions, such as random unexpected events  and more traffic.
Comprehension of messages was lower with synthesized speech than for recorded human speech and this was true across all message types.
This finding confirms previous research in the area.
Subjective evaluations showed that perception of the increased difficulty of the synthetic speech messages was correlated with lower accuracy rates.
Participants reported feeling that synthetic speech was more difficult to understand than human speech.
One participant commented, "The computer voice seemed annoying and not easy to understand."
Perhaps one of the most interesting findings was that comprehension accuracy for synthesized speech did not degrade linearly with the length of the message, as it had in an earlier in-lab experiment .
When driving, the navigational messages were easiest to understand, followed by the news stories, with email messages coming in last even though the news stories were longer with a greater level of detail.
This may be because many of us have a well-established model for driving and listening to news on the radio.
News stories are general and usually do not affect or involve us directly.
Also news stories are written by professional reporters and if reading the entire article, may have more redundancy than email messages.
However, since these articles were modified to fit the word length restriction most, if not all, of the redundancy was removed.
With regard to the professional writer argument, this was not a benefit that aided comprehension in the in-lab experiment referenced earlier.
Mean accuracy scores displayed by gender and age group.
We believe that examining technology as a potential distraction for drivers is an important area in need of additional study.
Future work not only needs to address higher levels of driving workload, it also needs to address more complex levels of interaction with in-car speech systems.
While in our study participants merely listened to messages, in a real speech-based system they would need to interact with it.
This would involve both trying to remember the correct phrasing or command for the system as well as keeping the context of the interaction in mind.
These additional complexities would further tax the cognitive resources of the driver.
We expect that analyses of higher driving and interaction workloads will reveal a negative impact on driving performance.
Alm, H., Nilsson, L.  The Effects of a mobile telephone task on driver behavior in a car following situation.
Effect of a car radio on driving in traffic.
Driver Performance and Memory for Traffic Messages: Effects of the Number of Messages, Audio Quality, and Relevance Technical Report UMTRI-98-22, Ann Arbor, MI: The University of Michigan Transportation Research Institute.
