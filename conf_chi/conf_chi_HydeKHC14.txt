Interactive animated characters have the potential to engage and educate children, but there is little research on children's interactions with animated characters and real people.
We conducted an experiment with 69 children between the ages of 4 and 10 years to investigate how they might engage in conversation differently if their interactive partner appeared as a cartoon character or as a person.
A subset of the partic ipants interacted with characters that displayed exaggerated and damped facial motion.
The children completed two con versations with an adult confederate who appeared once as herself through video and once as a cartoon character.
We measured how much the children spoke and compared their gaze and gesture patterns.
We asked them to rate their con versations and indicate their preferred partner.
There was no difference in children's conversation behavior with the car toon character and the person on video, even among those who preferred the person and when the cartoon exhibited al tered motion.
These results suggest that children will interact with animated characters as they would another person.
People's in teractions are complex, with verbal and nonverbal cues that can often be very subtle and meaningful.
The benchmark of a successful conversational agent, as proposed by Cassell and Tartaro , is if an agent can interact with a people similarly to how people interact with one another.
Extensive research has focused on how additions of humanlike behaviors to agents create more successful human-agent interactions.
These studies have incrementally tested how adding various behaviors, such as smiles, emotional facial expressions, gaze, and mirroring, can influence human be havior .
Although researchers have shown that these behaviors improve human-agent interaction, they have not shown that these interactions are similar to human-human interaction.
These studies also focused on how to improve adult human interactions with agents; however, many ani mated characters are created for children.
Much of children's entertainment and educational program ming features interactive or pseudo-interactive animated characters.
As of 2003, approximately 70% of children un der two had watched television, and over 90% of childrn have done so by age six .
The characters often wear bright colors and have simple, exaggerated features.
The bright col ors are supposed to grab children's attention, and the simple, exaggerated features  are supposed to help children focus on particular parts of the screen .
These characters have also been given human-like behaviors  to make them seem more "alive" and interactive.
It is unclear whether these characters are actually more ap pealing or engaging than real people.
Is Steve from Blue's Clues a better host than Dora from Dora the Explorer?
What about Fred Rogers and Daniel Tiger from Mr. Rogers'/Daniel Tiger's Neighborhood?
Some previous research has compared how children speak differently to real and animated people.
The researchers identified possible differences in children's language patterns, but the researchers could not explain whether the differences were due to different language patterns in the real and an imated partners or appearance differences .
We ran an experiment to examine children's preferences, attention, and language when conversing with an adult partner who ap peared via videoconference as herself and as a cartoon char acter.
Over the past decade, the use of animated human charac ters has increased dramatically in education, entertainment, and therapy.
They assist customers on shopping websites, occupy virtual worlds on behalf of users in games such as The Sims and World of Warcraft, serve as teachers or virtual peers in educational software, and act as mock job interview ers who provide feedback to users.
Copyrights for components of this work owned by others than the author must be honored.
Abstracting with credit is permitted.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Copyright is held by the owner/author.
Publication rights licensed to ACM.
In our exper iment, character appearance was a within-subjects variable and motion was a between-subjects variable.
The characters displayed human behaviors, including facial expressions and mirroring.
We also manipulated facial motion magnitude by exaggerating and damping the characters' spatial motion.
Ex aggerated facial motion magnitude has been associated with easier emotion recognition and perceptions of increased emo tional intensity .
By exaggerating our characters' faces, we hoped to make them more expressive.
In contrast to previous research, we found that despite having strong preferences about confederate appearance, the children behaved similarly across conditions.
Our participants be haved and conversed with animated and real people in similar ways, suggesting that appearance does not affect children's speech and that animated characters could be suitable sub stitutes for real people in conversational applications.
More over, this research highlights the importance of using both self-report and behavioral measures when conducting experi ments about design.
Although young children pay attention to people who are physically present, there has been a question as to how chil dren view people who appear on screens.
As adults, we understand that people who are not physically present may still provide useful information to us.
For example, we lis ten and learn from newscasters about what traffic to avoid or how to prepare for the weather.
Children, on the other hand, do not necessarily listen and learn from people on tele vision, especially if there is no interaction.
Troseth and col leagues  conducted several studies in which two-year-old children watched people on monitors or in the same room give useful hints for a game.
Only the physically present people and the people on monitors who interacted with the children were able to get the children to use the hints.
These results emphasize the importance of interaction if young chil dren are to pay attention to animated characters.
Very little research has compared how children interact with animated characters and other people.
Oviatt  conducted a study with ten 6- to 10-year-old participants.
The researcher compared how children spoke with an animated character to an adult experimenter, and she found that children had fewer disfluencies in their speech with the characters than with the adult.
Although participants were encouraged to ask questions in both interactions, the tasks were not identical.
In the character condition, participants spoke with multiple animated animals to learn more about the different species.
When participants spoke to the experimenter, they played a game of Twenty Questions where the children asked the ques tions.
In another experiment comparing child-computer interaction to child-human interaction, Black and colleagues  com pared nine 4- to 7-year-olds' interactions with an animated human agent on a computer to those with an adult exper imenter in person.
The comparison tasks were more simi lar: there was a single animated human character who asked questions that were similar to the questions that the adult ex perimenter asked.
The researchers found that children were less verbose and spoke slower when speaking with the agent rather than the adult; however, the researchers also noted that their agent used fewer words and spoke slower than the adult partner.
This work supports the idea that children will em ulate the speaking style of their conversational partners, as suggested by other researchers .
Additionally, they reported that the children looked away from the adult more than from the animated human character.
To build upon these two previous studies, we wanted to examine more precisely how children's patterns of engagement would differ between a human and an animated character by having the children take part in two nearly identical interactions using the same apparatus.
We hypothesized that they would attend more to the character.
Children interact with animated characters on a frequent ba sis.
Often, these characters are on television shows or in edu cational games, in which case the interactions are staged and the characters cannot respond to unexpected behaviors.
Sim ulated interactions on television are important because they help engage children and improve learning .
Since the successful launch of Blue's Clues, children's educational television programs have followed a similar format of charac ters looking directly at the viewers, asking questions, pausing, and then "acknowledging" viewers' responses .
Although children will interact with animated characters, they do not always treat these characters as they would other people .
For example, a prior study found that children used more gestures and words when conversing with adults than with computer characters .
As intelligent agents be come more human-like, the hope is that children will interact with the agents as they do real people.
Children learn from a young age to pay attention to socially relevant information, including eye gaze, gestures, and emo tional displays .
Children's comprehen sion of facial expressions develops over time .
When children are between two and three years old, facial expressions are categorized as positive or negative.
The number of categories grows and the criteria for each cate gory narrow as the children develop.
Most 4- and 5-year-olds can recognize basic emotions on the face although their accu racy may not be very high.
By the time children are 9 and 10 years old, they are almost as accurate as adults .
Be cause exaggeration can make facial expressions easier to rec ognize , we hypothesized that exaggerating the facial motion of animated characters may improve child-character interactions.
For both tasks, the interactive partner was an adult confederate who appeared on-screen.
In one task, she was shown through video; in the other task, she was shown as a cartoon char acter.
The confederate's cartoon character was human and was customized to her appearance.
The confederate was blind to her appearance on the participant's screen.
Also, we cre ated questionnaires to determine the correspondence between subjective measures and participant behavior.
Through this combination of control measures, we examined the precise effects of character appearance and motion on children's ex periences.
Our results indicate that children are resilient to the appearance and motion of their conversation partners, re gardless of their personal preferences.
Therefore, it should be possible to design conversational agents that elicit natural behavior from children.
Once the face and appearance space have been learned from the training images, the individual's face can be tracked from new video in realtime.
Animating a character requires a mapping from the individual's AAM to the character's AAM.
When the individual moves his/her face, the 79 mesh vertices change position.
The change in position is mapped to the character's mesh, and then the char acter's appearance is warped to illustrate movement .
We purposefully created characters that resembled the confederates so that the remapped motion would be as accu rate as possible.
For further information on the creation and use of AAMs, please see .
Given that each vertex changes position during movement, we followed previous procedures  to multiply those changes in position by specific scale factors, thus exagger ating or damping the spatial movements across all features of the face.
We selected damped and exaggerated scale factors based on a previous perceptual study in which the adult threshold of facial motion level sensitivity was deter mined .
We selected equally perceptible levels of damp ing  and exaggeration .
For example images of exaggerated and damped character motion, see Figure 1.
We used 2D AAMs for this research.
Therefore, our charac ters always faced forward.
We added rigid points around the tops of the characters' heads and damped the face border and nose points by 50% to ensure that the character would not warp excessively if the confederate turned her head.
Body motion was not tracked, so the torsos of the characters moved rigidly with respect to a pivot located at their mouths.
The confederates practiced extensively with the characters prior to the experiment to ensure that they did not generate move ments that appeared unnatural or otherwise distracting when presented on the characters.
Our goal is to create believable interactive animated charac ters, with motion that mimics the pacing, style, and facial gestures of humans; to that end, we opted to have two con federates "puppet" the characters.
To ensure that the confed erates were blind to the study condition, they were animated using a markerless, computer vision method for face track ing: active appearance models  .
This method tracks a person's face in realtime, permitting it to be mapped onto a character's face without noticeable delay.
We designed a desktop-like audiovisual telecommunications sys tem so that research participants could interact with confed erates who both appeared as themselves through video and as animated characters while using natural eye contact and speech.
Our audiovisual telecommunications system is diagrammed in Figure 2.
It was designed to maximize natural interac tions: both people appear life size and can make eye contact as they would in person.
Two setups were positioned in sep arate rooms with a control room in between.
All video and audio data from each setup was relayed through the control room for video and audio processing before being presented to the other setup.
A speaker was also placed within the participant's setup, but headphones were used on the confederate's setup to avoid auditory feedback.
We used a beam splitter made of reflective material between the user and the camera so that the camera was hidden di rectly in front of the user, allowing for eye contact between users, often an impossibility in audiovisual telecommunica tions.
The monitor was placed above the beam splitter in or der to project visual information directly in front of the user.
A shotgun microphone was mounted below the beam splitter to capture audio.
A computer attached to each setup controlled the presentation of visual information.
When animating a character, the partic ipant's computer tracked the confederate, retargeted the mo tion to the animated character, and displayed the character on the participant's monitor.
If the system was displaying a video feed, the computer was used to add a small amount of delay to the presentation of the video in order to replicate the delay induced by tracking and animating the confederate character.
A sound mixer in the control room was used to add delay to the audio and ensure that the audio and video/animation re mained in sync.
Our measurements indicated that the delay inherent in our system is 100 ms for video and 166 ms for animation.
Because the confederate always saw video of the participant, the delay for the confederate was 100 ms; how ever, because the participant saw both video and animated conditions we kept the participant's delay at 166 ms. Previ ous research with a similar system validated that these delays have a negligible effect on conversation between adults .
In the ice cream task, the children were asked to help de sign a fourth sundae by selecting the ice cream flavor, a sauce, and a topping from a list.
After the child completed the first task, the experimenter read the second part of the story that described the other task.
Participants were randomly assigned a task order and confederate.
To obtain participant feedback, we used a modified smiley ometer with written labels.
Smileyometers have been used frequently with children as they are understandable and re liable; however, we included written labels because they are better for older children .
The traditional smileyometer includes a neutral midpoint; however we removed the mid point as prior work  found that four response options and no neutral midpoint obtained the most reliable responses from children.
Our participants were all familiar with the various types of smileys as they were used in the other experiments that participants completed on the same day.
Unfortunately, eliciting truthful responses from 4- to 5-year-olds can be very difficult as they are susceptible to satisficing, and they will of ten select the most positive response .
When presenting the rating scale, the experimenter verbally stated each option while pointing to the corresponding smiley.
The experimenter also verbally confirmed each of the participants' responses.
After each task, the experimenter verbally asked the children four questions and offered possible answers while showing the questions and a rating scale: 1.
How much did you like talking to  just now?
How much fun did you have talking to  just now?
How nice was  to you just now?
How much did you like talking to  about ?
In order to introduce the children to the task, we created sto rybooks for each of the confederates and possible task or ders.
Each storybook starred one of two confederates and de scribed how she enjoyed playing pretend, sometimes as a car toon character.
She particularly enjoyed pretending to own a bakery.
Depending on the order of tasks assigned to a particu lar participant, the storybook then described one of two tasks: designing a cake or an ice cream sundae.
After both tasks, the children answered an additional three questions.
Again, participants were verbally read the ques tions and possible responses as well as shown images of the responses.
Participants were given response options in a ran dom order: 1.
Did you like talking to  more when she looked like a real person or when she looked like a cartoon character?
If you could speak to  again, would you want to see her as a real person or as a cartoon character?
Did you like talking about ice cream or cake more?
The six items were se lected to represent the six facets of extroversion, as defined in the NEO-PI-R , a well-known and validated person ality measure for adults.
The items were selected from the M5-PS-35 , a measure created and validated to assess preschool children's personality.
Children between the ages of four and ten years were re cruited to take part in a series of short, unrelated experiments, including this study, that lasted a total of approximately 90 minutes.
In total, 69 children  participated successfully in this paradigm.
Five additional children were excluded from analyses due to technical or behavioral issues.
See Figure 3 for participant breakdown.
Participants were recruited using email lists and advertisements in local gath ering places, and they were compensated for their time.
The research was approved by our Institutional Review Board.
Before starting the first task, the confederate engaged the par ticipant in unstructured small talk, typically about the child's summer activities, age, and favorite school subjects, in or der to make the child comfortable with the confederate and the apparatus.
When the confederate believed that the child was comfortable, she began the first task.
While the child made selections of food, the experimenter assembled the final product.
When the child made his/her second selection, the confederate challenged the choice and offered her own sug gestion.
Upon completion of the first task, the experimenter closed the curtain so that the child could no longer see the confederate, showed the child the design, and completed the questionnaire with the child.
Then, the experimenter veri fied that the confederate was ready to begin the next task and raised the curtain.
For the second task, there was no small talk; the confederate asked the child if he or she was ready and then began the task.
The confederate challenged the child on his/her second selection just as she had done in the first con versation.
Again, the experimenter created the food design based on the child's selection, closed the curtain at the end of the task, showed the child the creation, and completed the questionnaire with the child.
Finally, they completed the last three questions comparing both tasks and characters.
Upon arrival at the experiment location, each child and his or her parent/guardian was met by one of the experimenter team.
Parents/guardians completed the extroversion questionnaire in a separate room.
Most parents remained in the separate room while their children completed the study; however, six teen parents accompanied their children to the study room.
They sat 12 feet to their children's left with the experimenter in between.
Parents could not see the telecommunications screen, but they could hear the conversation.
Parents of chil dren who completed the study successfully sat silently during the study.
The child was allowed to select one of many stick ers to help the experimenter decorate the apparatus, in order to let him or her warm up and become accustomed to the ap paratus and environment.
Then, the experimenter seated the child facing the apparatus with the curtain still down and read the storybook to prepare the child to play a game of pretend with the confederate either as a video or an animated charac ter.
Upon completion of the first half of the storybook, the ex perimenter asked if the child was ready and then whether the confederate was ready.
After hearing agreement from both, she raised the curtain so that the participant and confederate were able to see each other.
Independent variables were divided into experimental and participant variables.
Experimental variables included ap pearance and motion manipulations.
Participant variables in cluded participant age, gender, and extroversion score.
De pendent variables were split into conversation, gaze, gesture, and self-report measures.
We annotated the video recordings for child speech, gaze, and gesture using ELAN , open-source software for anno tating video and audio recordings.
Each annotation has a start time, end time, and label or transcription.
For each measure that involved annotated data, we had a primary annotator who annotated all of the data and a secondary annotator who an notated one third of each child's data.
To evaluate interrater reliability, we calculated the percentage of aligned annota tions and then calculated Cohen's Kappa  for the aligned annotations.
Percent alignment and  are given below.
Facial motion level was a between-subjects variable with three levels .
The experimental conditions were counterbalanced across participants.
Participant variables included gender, age group, and extro version score.
Participants were divided into three age groups  based on theories of cognitive development .
Par ents completed a short questionnaire to assess their child's level of extroversion.
The parents' responses were averaged across the six questionnaire items to create a single extrover sion score .
Conversation measures included conversation length, number of utterances, number of words, and confederate influence.
The primary annotator transcribed all participants' speech, and the secondary annotator marked the times when partic ipants spoke.
Pauses between utterances had to be at least 500 ms long.
The annotators had 82% alignment on their annotations; we did not calculate Cohen's  because the sec ondary annotator did not transcribe speech.
From the tran scriptions, we calculated the number of utterances and num ber of words that each participant used.
Conversation length was measured between when the experimenter asked the con federate if she was ready and when the curtain covered the screen.
Because the first conversation included unstructured small talk, the start of the first task occurred when the confed erate asked if the child was ready to begin the task.
For con federate influence, we looked at when participants changed their selection based on the confederate's challenge.
If the participant changed his/her original selection to the confeder ate's selection, we scored the confederate as influential.
If the participant stuck with his/her original selection, we scored the confederate as not influential.
Self-report measures included conversation score, appear ance preference, and topic preference.
Participants were asked four questions after each task and another three ques tions after completion of both tasks, as described in the Ques tionnaires section of this paper.
The first four questions asked participants to rate their conversations.
The last three ques tions asked participants to compare their conversations.
The ratings from the first four questions were combined to cre ate a conversation score with good reliability .
The two questions, asking participants to select between the cartoon and video confederate, were combined to create the measure of appearance preference with good re liability .
The last question was used as an indication of participants' topic preference.
We conducted several ANalyses Of VAriance  to investigate possible effects from the independent variables.
Due to a lack of variability in extroversion scores across par ticipants and the fact that no relationship was found between extroversion score and the dependent measures, we excluded extroversion score from further analyses.
We also excluded number of shakes and shrugs from our analyses, as the me dian number of times these gestures occurred during conver sation were 1 and 0, respectively.
The number of nods and the total number of gestures were kept in the analyses.
Although participants had strong preferences for appearance and topic, they did not alter their behavior to reflect these preferences.
Interestingly, confederate appearance only affected the num ber of words children used.
Gaze measures included the percentage of time participants spent looking at the screen, percent on-screen, and the av erage length of each on-screen gaze segment, average gaze length.
While percent on-screen gives a rough estimate of how much of the conversation participants watched the screen, the average gaze length gives an estimate of how long participants sustained their gaze at the screen.
Annotators marked when participants were looking on- and off-screen.
The annotators had 86% alignment of annotations, and they agreed on the annotation labels with perfect reliability .
To determine which control variables to include in our main analysis, we first conducted a repeated measures ANOVA with conversation topic and conversation order as withinsubjects variables and confederate as a between-subjects vari able.
Only conversation length was affected by these vari ables.
Be cause the conversations were semi-structured and there were no significant effects of confederate on the number of ut terances or words, the difference in conversation length was likely due to a difference in the confederates' rates of speech.
Conversation length was also affected by conversation order, F  = 14.51, p = .0003; however, conversation order and confederate did not create a significant interaction.
To understand the difference in conversation length between the first and second conversation, we look at the significant interaction of conversation order and topic, F  = 5.35, p = .0239.
Participants' second conversation was only longer than their first conversation if the second topic was ice cream sundae.
From our analysis of self-report measures, we know that participants preferred the sundae topic to cake.
Gesture measures included the total number of gestures and the number of nods, shakes, and shrugs each participant used.
Gestures were only considered if they were communicative.
These results suggest that participants spent more time thinking about their responses if the second conversation was on their preferred topic.
Partic ipants were familiar with the conversation structure and the confederate by the second conversation so they may have felt less pressure to make their selections quickly.
Because the control variables did not affect any of the behavioral mea sures except for conversation length, we did not include them in our main analysis.
We were most interested in how the experimental variables of confederate appearance and facial motion level would af fect the dependent measures.
Because many developmental changes occur between ages 4 and 10, we included the partic ipant variables of age group and gender in our main analysis.
We conducted a repeated measures ANOVA with age group, gender, and facial motion level as between-subjects variables and confederate appearance as the within-subjects variable.
To analyze the data on appearance and topic preferences, we conducted a three-way ANOVA with age group, gender, and facial motion level as between-subjects variables.
We found that male participants had significantly more utter ances than female participants, F  = 6.27, p = .0153.
On average, male participants used 25 more words than female partici pants.
Participants used signif icantly more words when speaking to the confederates by video than by cartoon character, F  = 5.50, p = .0222, but the difference was six words, on average .
We found no significant effects of our experimental or partic ipant variables on confederate influence.
We found a significant effect of gender on conversation score, with female participants rating the conversations higher than male participants, F  = 10.43, p = .0021.
The data illustrates that males and females converged on their conver sation scores as age group increased, and that the largest dif ference between scores occurred between the 4- to 5-year-old males and females.
We found no significant effects or interactions of age group, gender, and facial motion level on preferences.
We did notice strong preferences across participants.
We ran several Chisquared tests to investigate these preferences.
Participants who selected "both" instead of selecting a single topic or ap pearance were excluded from the analyses.
We observed that some children were surprised that the cartoon character could see and respond to them.
We also observed some children who were surprised by the confederate in the video condition, and some children who were not surprised by either condition.
Statistically, the children did not con verse, gaze, or gesture differently when speaking to the con federate through video and cartoon.
The one exception was that participants used a few more words when in the video condition.
Although our participants behaved similarly across conditions, they had a strong preference for the video condi tion.
We also altered the facial motion level of the cartoon char acter to see if it would influence participants' behavior.
We found that facial motion level affected girls differently than boys, such that they had longer periods of on-screen gaze when the cartoon character's motion was damped.
It is possi ble that the girls were more engaged with the task and there fore more attentive when the motion was damped because damped facial motion can be harder to understand .
No other effects of facial motion level were found.
We found several effects of gender on participant behavior.
Although female participants rated the tasks higher, male par ticipants spoke more, both in number of utterances and words.
The youngest girls also rated the tasks the highest, supporting the idea that they were the most engaged with the task.
Unlike prior studies  that compared children's behav iors when conversing with an animated character to a per son, our animated character was controlled in real time by the same person that participants spoke to through video.
Prior studies used intelligent agents or Wizard of Oz techniques to control their animated characters, and comparison conversa tions were face-to-face.
We limited confounds by designing our tasks to be as similar as possible.
Participants had two conversations with the same confederate, engaged in two sim ilar tasks , and used the same apparatus to converse.
The cartoon characters were even designed to have similar appearances to their respective confederates.
Because participants had strong preferences for confederate appearance, we conducted a post-hoc analysis to ascertain whether or not participants' preferences influenced their be havior.
We ran a repeated measures ANOVA with age group, gender, and participant preference as between-subjects vari ables and confederate appearance as a within-subjects vari able.
We found the same significant main effects of gender on number of utterances, number of words, and conversa tion score.
Participants who preferred the cartoon version of the confederate were less likely to be in fluenced by the confederate compared to the participants who had no preference or preferred the video version of the con federate, F  = 5.71, p = .0205.
We also found a significant interaction between confeder ate appearance and participant preference with conversation score, F  = 3.69, p = .0305 .
Par ticipants who preferred the confederate in video rated their conversations with the animated confederate significantly lower than their conversations with the confederate in video, F  = 7.41, p = .0084.
In contrast, participants who preferred the animated confederate did not score their conver sations significantly differently, F  = 2.22, p = .1409, but this may be a reflection of the low number of participants  who preferred the animated confederate.
Different types of tasks, such as ones that re quire more trust and disclosure, may also cause children to alter their behavior based on their preferences.
Future work should examine how longer and/or different types of tasks  could elicit different be haviors based on children's preferences.
We used adult female confederates and similar-looking an imated characters in our study.
Future work could explore the effects of confederate gender, age, and animated charac ter appearance.
Our charac ters were rendered in a more realistic-looking style than many popular cartoon characters, and children may prefer more fa miliar and simplistic rendering styles.
An examination of how children react to a character with different rendering styles would help answer this question.
Our cartoon characters were not perfectly realistic in their motion or in their appearances.
We used 2D AAMs and 2D characters, which limited how our confederates and the char acters could move.
Specifically, 2D AAMs cannot track faces properly when certain features are obfuscated, such as when an eye disappears from view due to a head turn.
Similarly, the characters were incapable of head rotation; therefore, they could not nod or shake their heads.
Due to these limitations, we requested that our confederates limit their head motion.
Although our confederates kept their heads mostly still, they still made some small nods and shakes, which are naturally occurring movements.
The lack of these small movements in the cartoon condition may have influenced participant prefer ence for the video condition.
In the future, different tracking and animation techniques could be tested to verify our find ings.
Our findings suggest that operators/animators could adjust a character/avatar's motion to increase a child's attention and to suit a child's facial processing ability.
In the future, we intend to investigate how we can customize character/avatar appear ance and motion to improve conversations with children who have facial processing deficits and social and communicative disorders, like those on the autism spectrum.
Because ani mated characters created for children are often child-like and non-human, we believe future work should investigate the use of different types of animated characters.
Along similar lines, animated characters are used for more than just short conversational tasks; therefore, exploring whether children might behave differently with real people and characters dur ing other types of tasks would be useful.
According to Cassell and Tartaro , embod ied conversational agents in social settings should strive to elicit behaviors from users that are indistinguishable from the behaviors users would exhibit when with other real people.
Our results indicate that, with child users, the goal of elicit ing natural behaviors should be possible without needing per fectly realistic-looking human characters and head motion.
We thank our participants and their families.
We are grate ful to Jill Lehman, Rachel Browne, Brooke Kelly, Ran dall Hall, Emily Jensen, Tomas Simon Kreuz, Peter Carr, Iain Matthews, Mo Mahler, Jimmy Krahe, Cole Heiner, and Melanie Danver.
This work was funded by Disney Research and award R03HD068816 from the Eunice Kennedy Shriver Institute of Child Health and Human Development of the Na tional Institutes of Health.
Boker, S. M., Cohn, J. F., Theobald, B.-J., Matthews, I., Brick, T. R., and Spies, J. R. Effects of damping head movement and facial expression in dyadic conversation using real-time facial expression tracking and synthesized avatars.
Children as respondents in survey research: Cognitive development and response quality 1.
We ran an experiment in which children conversed with an adult partner who appeared as herself and as a cartoon avatar via videoconference.
We found that despite having strong preferences for confederate appearance, the children behaved similarly between conditions.
