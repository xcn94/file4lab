In this paper the development process and validation of the LEMtool  are described.
The LEMtool consists of eight images that display a cartoon figure expressing four positive and four negative emotions using facial expressions and body postures.
The instrument can be used during interaction with a visual interface, such as a website, and allows participants to select elements of the interface that elicit a certain emotion.
The images of the cartoon figure were submitted to a validation study, in which participants rated the recognizability of the images as specific emotions.
All images were found to be recognizable above chance level.
In another study, the LEMtool was used to assess visual appeal judgements of a number of web pages.
The LEMtool ratings were supported by visual appeal ratings of web pages both for very brief  and for long  stimulus exposures.
Furthermore, the instrument provided insight into the elements of the web pages that elicited the emotional responses.
In the past three decades human-computer interaction  research has started to adopt a more holistic view of the experience of computer interaction, recognizing non-instrumental elements such as fun .
This field of investigation has been referred to as User eXperience , and is principally concerned with studying emotional responses to HCI .
In HCI, emotions can have a broad range of effects on, for instance, the shaping of the interaction, the communication about the interaction, as well as the evaluation of the object of interaction .
Consequently, measuring emotions in interaction with a broad range of interactive products  and interfaces  has been a primary concern of UX researchers.
The methods used for such investigations are often validated emotion measurement instruments from the field of experimental psychology .
A downside of these methods is that they are not always well suited for the highly interactive nature of digital media.
Most methods are applied post-hoc, providing a measurement of the overall experience.
Consider for instance websites, where users can quickly navigate between different pages through hyperlinks.
In such a case a post-hoc measurement would only provide insight into the cumulative experience of all the pages.
The range of emotional responses that people experience in relation to individual pages, or elements of individual pages, would be lost.
Therefore, the investigation of emotions in UX research would benefit from methods specifically geared towards highly interactive contexts, such as interaction with websites.
The development process and initial validation of such an instrument is reported in this paper.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Visual interfaces such as websites, mobile, and desktop operating systems, can elicit emotions in a number of ways.
Hassenzahl  proposes that an individual's experience with technology depends on the perceived pragmatic and hedonic qualities of the product.
Unresponsive controls for instance, can cause negative affective responses in the user .
Similarly, an overly complex and unclear ordering of visual elements of an interface can lead to heightened arousal and less positive evaluations of that interface .
Hedonic quality on the other hand can be a source of positive affect.
An oft studied element of hedonic quality, visual appeal, influences the user's experience early on in perception , in the form of a rapid affective judgement .
Furthermore, a good visual design has the potential to negate existing usability problems, resulting in more favorable evaluations of the interface .
The initial affective reaction to the visual appeal of an interface can have a priming effect , and influence later evaluations of that interface .
The impact of visual appeal is thus not limited to the initial perception.
Psychophysiological measurements are often used to obtain continuous measurements of emotions during interaction with an interface.
Similarly, Hazlett and Benedek  measured the desirability of certain software functions, using facial EMG as a measure of emotional valence.
An issue with using psychophysiological measurements to measure emotions that occur during interaction with a visual interface is that it is often difficult to find which element of the interface is responsible for the emotional reaction.
The autonomous nervous system may be activated by non-emotional events, such as increases in concentration, which could confound measurements of emotion .
Furthermore, measurements of changes in physiology are an indirect measurement of emotions, thus a delay between the measurement and the actual emotion is to be expected .
This is especially problematic when considering the highly interactive nature of most visual interfaces, for instance while rapidly going back and forth between two web pages, or opening and closing programs in an operating system.
The most common method used to ascertain someones affective state is self-report measurements .
This is partly due to the complexities of psychophysiological measurements.
Malhke and Minge , for instance, found ratings of valence and arousal using the Self Assessment Manikin   to corroborate physiological measurements during interaction with a mobile phone interface.
Deng and Poole  successfully used self-report measurements of valence and arousal to measure emotional responses to different web page designs.
A strength of emotional self-report is that it is easy to apply and interpret.
Downsides are that it is a subjective measure, sensitive to bias, as well as subject to priming effects of forced-choice questionnaires .
Unlike physiological measurements, which are continuous, emotional self-report is mostly used as a post-hoc measurement.
Feldman-Barrett  argues that the time that passes between the stimulus and the reported emotion may negatively influence the accuracy of the measurement.
The longer the time between the stimulus presentation and the self-report of emotion, the more the respondent will rely on memory to report his or her subjective feelings .
Furthermore, emotions are difficult to verbalize, thus responding to one's emotional state with verbal labels requires considerable cognitive involvement which may influence the response .
In an attempt to improve on verbal self-report methods, researchers have developed non-verbal self-report methods to measure the subjective feeling component of emotion.
One of the most well-known is SAM , which is based on an abstract cartoon figure that conveys emotional valence, arousal and dominance.
Each of these dimensions is represented by five different visualized states on a horizontal 9-point scale.
While the dominance dimension is often unused because it lacks discriminative power, SAM has proven successful in measuring the valence and arousal dimensions , which are considered the underlying dimensions of all emotions .
Desmet  took a different approach with the development of PrEmo , an instrument to measure emotional responses to products.
PrEmo consists of fourteen animations of a cartoon character that expresses specific emotions through facial, bodily, and vocal expressions.
After being exposed to a product, people indicate, for each animation, how strongly the depicted emotion was felt.
PrEmo is based on the notion that people can accurately identify discrete emotions from bodily signals such as facial expressions  and body language .
PrEmo has been applied in studies into automobile designs  and mobile phone designs .
The initial validation study showed that the PMRI images were recognized with an accuracy between 38 and 94 percent.
A considerably lower recognition accuracy was obtained for positive moods compared to negative ones.
PMRI is envisioned as a communication tool to share moods between users, as well as a general tool to measure moods.
In comparison to emotions, moods are more diffuse affective states that are relatively long in duration, are less intense, and often do not have specific elicitors .
Evaluation methods that are strongly related to non-verbal emotional self-report scales, are found in pain assessment scales for children .
For example the Faces Pain Scale-Revised  uses six facial expressions in a horizontal orientation with the endpoints representing "no pain" and "very much pain".
The instrument has been proven to be a highly reliable method of pain assessment for children .
Comparable in design to the Faces Pain Scale-Revised, but different in application area, is the Smileyometer.
This instrument also consists of a scale of five abstract facial expressions, and is used to measure children's experience with technology .
Though not specifically aimed at measuring emotions, these types of scales do provide valuable insights into how pictorial representations might be used instead of words in self-report measurements, especially measurements taken from children.
First, methods either use continuous scales of the underlying dimensions of emotion , scales of emotion related concepts  or scales for reporting experience with technology .
Second, the only method that measures specific emotions uses an animated cartoon figure , while the only method that uses still images of discrete affective states is geared towards measuring moods instead of emotions .
Finally, no method is specifically aimed at measuring emotions during interaction with visual interfaces.
Similarly to PrEmo , the idea behind the LEMtool was to measure a finer granularity of discrete emotions rather than general emotional states.
However, PrEmo uses animations, which take time to play in their entirety.
This would severely disrupt the interaction with a visual interface, making the use of animations unsuitable for deployment during interaction.
For these reasons it was decided that the development of a new set of visualizations was necessary.
As was outlined in the previous section there are a number of ways to measure emotions.
However, each of the methods described has its downsides.
For in-process measurements, psychophysiological signals can be used, but these measures can be difficult to apply and interpret .
Verbal self-report methods might be easier to interpret, but add the difficulty of having to translate words for different languages, as well as adding cognitive load .
Therefore, non-verbal self-report measures of emotion provide a viable alternative to verbal self-report measures.
The LEMtool consists of a cartoon figure that expresses eight discrete emotions using facial expressions and body postures.
The instrument consists of four positive and four negative emotions .
The emotions were selected from a study into the emotional impact of web pages, in which emotion terms from the circumplex model of affect  were divided into eight octants along the valence and arousal dimensions .
Emotion words that represented states with a neutral valence were not considered, as these words might denote non-emotional states .
In the selection of the eight emotion words from the remaining six octants, the possibilities for visualizing each emotion term was considered.
Findings from studies into facial expressions , as well as the emotions that were visualized in PrEmo  were taken into account here.
Furthermore, the concept of emotion families was considered .
This concept states that although there are numerous emotion terms, each term may belong to a group of related affective states.
For instance, dissatisfaction would belong to the same emotion family as anger and rage, but represent a less intense emotional state.
That is not to say these more intense emotions cannot be elicited during such interactions, just that respondents using the LEMtool are more likely to experience dissatisfaction with an interface than to be enraged by it.
The LEMtool images were created in collaboration with a professional cartoonist, who was provided with general guidelines about the composition of the facial expressions and body postures.
The LEMtool was designed as an interactive instrument deployed during interaction with a visual interface, allowing participants to indicate responses in-process.
The way the LEMtool is used during interaction with a web page, is depicted in Figure 2.
The procedure was explained to the entire group by the lecturer.
Participants were asked to select either one or more of the eight given emotion terms, or add a word of their own, that according to them, would best describe the emotion expressed by the LEMtool image.
This last option was added to reduce response bias as a result of the forced-choice format .
Finally the participants were instructed to indicate their gender, age and first language.
Participants were specifically told that they were not allowed to talk to each other.
The entire procedure took no more than five minutes.
Table 1 lists the percentages of participants who selected the target label for each LEMtool image.
Only selection of the target label was considered a correct response.
Responses containing selection of more than one label, or responses consisting of an added label were considered an incorrectly selected label.
Binomial tests were computed for the proportion of participants who selected each emotion label for a given target label.
Chance was set to 50% for each emotion.
This chance level was based on Ekman's  considerations on how some facial expressions might be most likely confused with similar expressions.
Note that the chosen chance level is more stringent than that typically suggested for forced-choice facial expression recognition tasks .
Table 1 shows that all of the LEMtool images were recognized as the emotions they were intended to display at above chance level .
This indicates that the LEMtool images were relatively accurately recognized as the emotions they were intended to display.
Based on these findings, it was decided not to make any changes to the images at this point.
The study was conducted using a purpose-built website.
The LEMtool images were 200 by 200 pixels in size and displayed in an orange circle .
Table 2 lists the average rating given to the target label for each LEMtool image.
For all images, a one-sample t-test was performed, comparing the average rating for each target label with the average rating of all other labels.
For all images the target label was rated as significantly higher  than all other labels.
This indicates little confusion between the emotions depicted in the LEMtool images.
Additionally, the low standard deviations in Table 2 indicate consensus among participants about the most appropriate label.
Table 3 lists the percentages of participants who selected the target label for each LEMtool image.
Only selection of the target label was considered a correct response.
Identical to the pilot study, chance level was set to 50%.
Binomial tests were computed for the proportion of participants who selected each emotion label for a given target label.
Table 3 shows that all of the LEMtool images were recognized as the emotions they were intended to display at above chance level .
Again, these results are highly comparable to previous research .
Participants were first presented with an introductory text detailing the goal of the study and outlining the general procedure.
In the first task, participants were presented with a list of the eight emotion terms and for each of the eight subsequently presented LEMtool images were asked to rate, on a five-point scale, the terms that they thought were most prominently present in the presented image.
The scale ranged from 1  to 5 .
Intermittent response options were not labeled.
The order of the eight emotion terms, as well as the order in which the images were presented, was randomized for each participant.
In the second task, participants were asked for each of the eight subsequently presented images, to select one of eight emotion terms that they felt best described the emotion expressed in the image.
The response option "none of these terms" was added to reduce response bias.
Findings from the validation study show that participants were relatively successful in decoding the emotions intended by the LEMtool images.
Similarly high recognition accuracy was obtained using a number of different response formats, limiting the possibility that findings are an artifact of the response format .
The fact that the recognition accuracy of the images is comparable to, and in some cases exceeds, that of existing instruments such as PrEmo  and PMRI  is encouraging, and shows the potential of using the LEMtool images to measure emotional responses.
As a first application of the LEMtool a study was designed to see if the instrument could be used successfully to indicate emotional responses to visual stimuli.
Therefore it is important for the LEMtool to be able to measure responses to the visual appeal of interfaces.
A study was conducted to assess whether the LEMtool could be used to measure emotional responses to the visual appeal of web pages.
As a first application of the LEMtool to measure visual appeal of web pages, the focus was on visual appeal as a general concept.
The accent of the case study was therefore on measuring the difference between high and low visual appeal web pages.
Both brief  and long  exposure times were used.
Additionally, the case study served as a first evaluation of the way the LEMtool was envisioned to be used, namely by having participants indicate positive and negative emotions on different areas of a number of web pages.
The remainder of the participants were approached by the researcher and asked to volunteer in the study.
Participants with color blindness were excluded.
Two independent web designers created a high and a low visual appeal version of the same web page.
The designers were only provided with guidelines aimed at keeping the type, organization, and presentation of information, as well as the content and perceived functionality of the web page, consistent.
No specific instructions were given to the designers regarding manipulations of visual appeal.
The manipulations of visual appeal relied on the expertise of the designers.
The 24 web pages covered three topics, namely: Einstein, a holiday island, and medical information about headaches .
Similar to  a ten-point rating scale  was used.
Each web page screenshot was displayed for 500 ms, in a resolution of 1024x768 pixels, without visible browser elements.
All texts were presented in Dutch.
A paired-samples t-test was performed, comparing the visual appeal ratings for high visual appeal and low visual appeal web pages.
Overall, high visual appeal web pages received a mean rating of 5.39  while low visual appeal web pages received a mean rating of 3.08 .
From this result it was concluded that the web pages did indeed differ on visual appeal, and were therefore suitable for use in the main study.
The study consisted of two separate phases.
In the 50 ms phase, stimuli were presented using E-Prime 2.0 displayed on a 17 inch Samsung SyncMaster 750s CRT monitor .
The monitor was set to a screen resolution of 1024x768 pixels at 60 Hz.
Brightness was set to 85 and contrast to 100 with color temperature set to 9300  K. Participants used a standard computer keyboard to indicate their responses.
In the free-viewing phase, stimuli were presented using a purpose built online environment running in Firefox 3.6.3, displayed on an HP Compaq LE1711 17 inch LCD monitor .
The monitors native resolution of 1280x1024 pixels at 60 Hz was used.
The monitor was set to a brightness level of 90 and contrast to 80 with color temperature set to 6500  K.
Participants were given a written explanation of the procedures.
After informed consent was obtained, participants took place behind the CRT monitor and followed the instructions on the screen.
Participants pressed the space bar to present the next web page, and used the keys 1-0 on the keyboard to indicate a response from 1  to 10 .
After participants gave a response the eight LEMtool images appeared.
Each image corresponded to a numbered key  on the keyboard.
By pressing a single key corresponding to a single LEMtool image, participants indicated the emotion that the web page elicited in them.
Participants could use the 0-key to indicate that the web page did not elicit any emotion.
Once the participants had rated all five test web pages, a selection of twelve web pages  was subsequently presented in random order to the participants.
The procedure was identical to that of the test pages.
After rating all web pages in the 50 ms phase, participants moved on to the free-viewing phase.
Instructions for the use of the LEMtool  were given in the online environment used to present the stimuli.
Participants were again presented with the same five test web pages displayed in random order.
Each web page would stay on the screen until participants pressed a key 1 to 0 representing a rating of 1  to 10 .
After giving a visual appeal rating, the LEMtool would appear in the top-right corner of the screen and participants had to select areas of the web page using the computer mouse, and attach a LEMtool image to that area.
Participants could give as many LEMtool indications as they liked, but were instructed to only rate elements that were related to the visual appeal of the web page.
They were told that reading texts on the web pages was not required.
Once participants had rated the five test web pages, the twelve stimulus web pages  were displayed in random order.
The exact same procedure as with the test web pages was followed.
The second phase was concluded after participants had rated all 12 web pages using the 10-point rating scale and LEMtool and had indicated their age, gender, and native language.
All texts in both phases were presented in Dutch.
Two high visual appeal web pages about Einstein  used in the case study.
The top two pages show a visualization for the LEMtool boredom emotion.
The grey areas were selected by participants indicating boredom.
The bottom two pages show a visualization for the LEMtool fascination emotion.
The dots indicate the centre of a selection area indicated by participants.
First a paired-samples t-test was calculated for the average visual appeal ratings given to high visual appeal and low visual appeal web pages with a 50 ms exposure time.
An identical analysis was conducted for the free-viewing phase, during which high visual appeal web pages were rated with a 5.93  and low visual appeal web pages with a 3.47 .
In addition, a significant correlation was found between ratings in the 50 ms and free-viewing conditions .
These results match findings by Lindgaard et al.
To determine whether the LEMtool would show a similar difference between high and low visual appeal web pages, for both the 50 ms and free-viewing phases, a cross-tabulation for visual appeal  and LEMtool image  was constructed.
A Chi-square test of independence was performed to assess significance.
Thus, for both brief and extended exposure times, the LEMtool differentiated between high and low visual appeal web pages.
To assess the relation between the visual appeal ratings and the LEMtool indications more in-depth, a one-way ANOVA with LEMtool indications  as the independent variable and visual appeal ratings as the dependent variable, was computed  = 113.68, p <.001.
A post-hoc Tukey's HSD revealed that certain LEMtool images were related to different visual appeal judgements .
These findings indicate that the LEMtool images covered a range of emotional responses related to visual appeal.
Moreover, the LEMtool images that display positive emotions were related to higher visual appeal ratings, while LEMtool images displaying negative emotions were related to lower visual appeal ratings.
Note that this is only an example of a method for treating LEMtool data.
A more comprehensive analysis of LEMtool indications for elements of all the web pages would be beyond the scope of this paper.
Table 5 shows the cross-tabulation for both pages.
What can be observed from both the visual data, as well as the table, is that, while both web pages are high visual appeal web pages, the composition of LEMtool emotions attached to each page differs.
The visualizations at the top of Figure 4 show that the "early years" page on the left elicited boredom in participants, more than the "Albert Einstein" page on the right did.
For both pages, boredom was mainly indicated for the central text area, but considerably more so for the early years page.
Furthermore, the visualizations at the bottom of Figure 4 show that the Albert Einstein page elicited more fascination in the participants than the early years page.
For both web pages, the images, as well as the main text elicited fascination, but this was more so for the Albert Einstein page.
Additionally, the header and quoted text in the right web page elicited fascination.
The differing LEMtool indications for the web pages in Figure 4 are supported by the visual appeal ratings for each page.
As indicated by the cross-tabulation  the LEMtool revealed a similar difference between both pages.
Moreover, as shown by the visualizations in Figure 4, the LEMtool provides additional insight into why these web pages differ on visual appeal.
This difference mainly stems from differing LEMtool indications for boredom, fascination and satisfaction .
The Albert Einstein page was rated as more satisfying, fascinating and less boring than the early years page.
Third, results from the free-viewing phase of the case study, in which participants used the LEMtool to select areas of web pages that elicited a certain emotion, illustrated how the LEMtool can provide additional insights.
Analysis of two high visual appeal web pages showed that the LEMtool could aid in revealing which elements of a web page are mainly responsible for the outcome of a certain visual appeal judgement.
The goal of the case study was to demonstrate that the LEMtool can be used to differentiate between high and low visual appeal web pages.
Furthermore, the case study served as a first evaluation of the way the LEMtool was envisioned to be used .
First of all, the case study demonstrated that participants were able to use the LEMtool to select specific areas of a web page and indicate their emotional response.
While a test session was required for participants to familiarize themselves with the way the LEMtool is used, all participants were capable of indicating their responses without issues.
Second, the case study supports findings by Lindgaard et al.
Moreover, this judgement remained consistent for visual appeal ratings after longer stimulus exposure.
The results from the case study showed that the LEMtool revealed a similar differentiation between high and low visual appeal web pages for both the 50 ms phase and the free-viewing phase.
Moreover, findings showed that the LEMtool images relate to a range of visual appeal judgements.
The LEMtool emotions Joy and Desire were related to high visual appeal judgements, Fascination and Satisfaction to moderately high judgements, Sadness and Boredom to moderately low judgements, and Disgust and Dissatisfaction to low visual appeal judgements.
The alternative explanation that these findings represent confusion between the images is unlikely, because little confusion was found between the LEMtool images in the validation study .
In this paper the development process and initial validation of the LEMtool were outlined.
A validation study revealed that the recognition accuracy of the images was comparable to, and in some cases exceeded, recognition ratings found in other research into non-verbal self-report of emotions .
In a case study on visual appeal judgements, results obtained with the LEMtool were supported by findings from visual appeal ratings.
Using an interactive version of the LEMtool, participants were able to select areas of web pages to indicate their emotional responses.
Results revealed that the LEMtool could provide additional insights into which elements of the web pages were most prominent in forming the visual appeal judgements.
A number of limitations of the current research deserve mentioning.
First, the validation study was carried out for one culture only.
While the current validation study offers a good starting point for validating the LEMtool images, additional studies are required to further assess the validity of the images across different cultures.
Second, while the use of screenshots in the case study allowed for better experimental control in studying the relation between visual appeal judgements and the LEMtool, emotions resulting from usability issues during interaction with a visual interface were not studied.
However, considering the vital role visual appeal plays in the perception of and interaction with visual interfaces , it can be argued that studying the LEMtool's capabilities to measure visual appeal judgements is crucial for the validation of the instrument.
Finally, one could argue that in the free-viewing phase of the case study participants not only rated the web pages on visual appeal, but were also influenced by texts and images.
However, the use of complete web pages instead of, for instance, abstract mock-ups without texts and images, makes the study more ecologically valid.
Moreover, visual appeal ratings between the 50 ms phase and the free-viewing phase of the study, were highly comparable.
Considering that it is unlikely that participants in the 50 ms phase reported on anything other than a first visual impression , it would seem that participants were actually able to focus on rating visual appeal in the free-viewing phase.
Taking these limitations into account, the investigation presented in this paper provides a good starting point for the further development of the LEMtool.
Our aim is to provide a useful tool for designers in different stages of the design process of a visual interface.
Early on in the design process, the LEMtool could be used to compare different prototype designs, in a similar fashion to the example in the case study.
This could provide valuable insights into different design decisions.
Furthermore, the LEMtool could provide insights during interactions with a visual interface.
Here, the changing emotional responses of users can be studied over time, and, based on the reported emotions, interventions can be made during different stages of the interaction.
For example, if a user indicates dissatisfaction at a certain point during a search task, such indications could be used to actively prompt users with information they might be looking for.
Finally, we hope to further develop the LEMtool as a general research tool for measuring emotional responses during interaction with a visual interface.
Huisman, G., and Van Hout, M. The development of a graphical emotion measurement instrument using caricatured expressions: the LEMtool.
Kim, J., Lee, J., and Choi, D. Designing emotionally evocative homepages: an empirical study of the quantitative relations between design factors and emotional dimensions.
Understanding, scoping and defining user experience: a survey approach.
Lindgaard, G., Dudek, C., Sen, D., Sumegi, L., and Noonan, P. An exploration of relations between visual appeal, trustworthiness and perceived usability of homepages.
Attention web designers: You have 50 milliseconds to make a good first impression!
Mahlke, S., and Minge, M. Consideration of multiple components of emotions in human-technology interaction.
In Affect and Emotion in Human-Computer Interaction, C. Peter and R. Beale, Eds., vol.
McCarthy, J., and Wright, P. Technology as Experience.
Norman, D. Emotional design: Why we love  everyday things.
Read, J. Validating the fun toolkit: an instrument for measuring childrens opinions of technology.
Reeves, B., and Nass, C. The Media Equation: How People Treat Computers, Television and New Media Like Real People and Places.
Robinson, M. D., and Clore, G. L. Belief and feeling: Evidence for an accessibility model of emotional self-report.
A circumplex model of affect.
A. Emotion, core affect, and psychological construction.
Scheirer, J., Fernandez, R., Klein, J., and Picard, R. W. Frustrating the user on purpose: a step toward building an affective computer.
