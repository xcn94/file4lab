Most work on the usability of touchscreen interaction for people with motor impairments has focused on lab studies with relatively few participants and small cross-sections of the population.
To develop a richer characterization of use, we turned to a previously untapped source of data: YouTube videos.
We collected and analyzed 187 noncommercial videos uploaded to YouTube that depicted a person with a physical disability interacting with a mainstream mobile touchscreen device.
We coded the videos along a range of dimensions to characterize the interaction, the challenges encountered, and the adaptations being adopted in daily use.
To complement the video data, we also invited the video uploaders to complete a survey on their ongoing use of touchscreen technology.
Our findings show that, while many people with motor impairments find these devices empowering, accessibility issues still exist.
In addition to providing implications for more accessible touchscreen design, we reflect on the application of usergenerated content to study user interface design.
Research on touchscreen interface design for users with physical disabilities has been largely limited to lab studies with relatively few participants , or to small interview studies .
Moreover, even less attention has been paid to subpopulations such as children.
To develop a richer characterization of how people with physical disabilities are adopting touchscreen devices, we turned to a previously untapped source of data: YouTube videos.
We collected and analyzed 187 non-commercial videos uploaded to YouTube that depicted a person with a physical disability interacting with a mobile touchscreen device.
In analyzing the videos, we asked questions such as: What are these touchscreen devices being used for on a daily basis?
How well do they work out of the box, or how poorly?
What adaptations are users making to improve accessibility?
We coded the videos along a range of subjective and objective dimensions designed to characterize the interaction and to identify any challenges or adaptations we witnessed.
To complement the videos themselves, we also invited the video uploaders to complete a survey on their opinions and use of touchscreen technology in their daily lives.
Our results show that, while many people with physical disabilities find touchscreen devices empowering, accessibility challenges still exist.
We observed a range of interaction styles and use cases, from interaction with one's foot or nose or with a prosthesis  to interacting while lying down or, particularly with children, using arm or leg slings for support.
Specific breakdowns were evident, such as challenges of multitouch interaction.
Mainstream mobile devices are becoming an important means of daily technology interaction for many people with disabilities.
Such devices are being used, for example, by users with visual impairments to navigate unfamiliar areas , by older adults with limited mobility as a communication channel to family and caregivers for greater independence , or by hearing-impaired users to communicate without expensive, specialized TTY  hardware .
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Based on this synthesis, we identify potential means of improving touchscreen accessibility for users with physical disabilities through a set of design implications.
The contributions of this work include, first, a characterization of interaction styles, use cases, challenges, and  homemade solutions that users with physical disabilities are adopting or encountering while using touchscreen mobile devices in daily life.
Second, we derive a set of design implications from this data-- implications based on a much broader sample of users than has been the case for prior work .
Finally, we build on the limited prior use of YouTube videos as a data source for HCI research, by extending this method to surveying content uploaders, and by demonstrating its effectiveness for studying user interface design and interaction in the wild.
We close by discussing the challenges, benefits, and limitations of this methodology, to aid future researchers in applying it in their own work.
Though not for direct touch interaction, HandiGlyph allows users to enter text on mobile devices .
Another touchscreen technique, meant for use with a pen, is Barrier Pointing, which improved target acquisition for people with motor impairments by utilizing the edge of the screen .
Also using hard edges to aid gestures on a touchscreen is EdgeWrite, a technique for stylus-based text entry .
Touch devices such as the iPhone do not have the built-in hard edges required for these latter techniques to transfer easily to finger pointing.
The challenges of more traditional computer setups have been well documented for people with motor impairments , as well as for older adults  and children , two other groups who have difficulty with mouse pointing.
Novel techniques have been proposed to ease mouse pointing.
Area cursors , for example, reduce the need for fine pointing and have been shown to be beneficial for older adults  and people with motor impairments .
Gravity wells provide force feedback when the user is over a target .
Steady Clicks reduces errors by briefly freezing the mouse at the button down location, but does not improve target acquisition time .
Methods that automatically adapt to an individual user's abilities have also been proposed, including solutions to reduce mouse speed , adapt user interface elements  , and predict useful accessible interaction techniques .
While this previous work has not focused on touchscreens, some of the solutions  could be adapted for them.
Technologies to improve accessibility for users with motor impairments range from hardware devices like eye trackers and sip-and-puff input to software solutions such as voice recognition.1 While several studies in the HCI literature have explored touchscreen accessibility for users who are blind or have visual impairments , a smaller number--discussed here--have examined accessibility for people with physical disabilities.
Our review focuses on studies of physical pointing and gestural interaction, since these are most applicable to our video dataset.
Studying basic touch interaction, Duff et al.
Follow-up work yielded a more nuanced understanding: participants with fine or gross motor control disabilities were slower than the non-disabled group, and those with gross motor control disabilities exhibited longer dwell times on touches .
Biswas and Langdon  found that touchscreens offered the fastest input compared to mouse, trackball and stylus for people with motor impairments, but 3 of 12 participants could not use the touchscreen at all.
All three studies highlight the need for further work on touchscreen accessibility for users with motor impairments.
Several projects have resulted in design implications or proposed techniques to support touchscreen interaction for users with motor impairments.
Many research projects have examined YouTube, including an exploration of social networking on the site , how people search for videos , and the appropriation of YouTube videos as a data source for the social sciences  and health .
As a resource to inform user interface design, however, online videos have received little attention.
To our knowledge, the most closely related work comes from Blythe and Cairns  and Paay et al.
Blythe and Cairns  conducted a content analysis of 100 YouTube videos returned from a search for "iPhone" after the iPhone release in 2007.
They categorized the videos into review, reportage, unboxing, demonstration, satire, advertisement, and commentaries, and conducted a qualitative analysis of comments from the single most popular video.
While their study provides insight into reception and discourse around the iPhone launch, it does not discuss many of the challenges that exist in using YouTube videos to inform broader design.
Our study is also deeper in that we focus on accessibility, with 480 searches .
More recently, Paay et al.
By the tenth page, relevant results were generally sparse.
Many very specific searches returned only a few new results or none at all.
Some similar terms, such as "Parkinson's" and "Parkinson's disease," were both included in our searches because the 10-page cut-off for the first  one sometimes led to the second  one finding new videos.
Finally, YouTube's "Suggestions" list and users' "channels" also provided a small number of relevant videos.
Their study did not focus on technology, but was meant to inform the design of systems to support the experience of cooking together remotely.
We further reflect on methodological differences between our work and these examples  in the discussion section.
Our primary analysis comprised of coding the videos along the 21 dimensions shown in Table 2.
To ensure the code set was reliable, we refined the codes in a four-phase process.
The first two phases involved three researchers independently coding two separate sets of 15 randomly selected videos along 15 dimensions, followed by discussion of disagreements and refinement of the coding dimensions.
In the third phase, two researchers independently coded 12% of the video set , and a third researcher computed inter-rater reliability on this "spot-check" set using Cohen's kappa.
We removed three dimensions due to low agreement: number of people offscreen, relationship between main subject and other people, and commercial vs. DIY adaptation.
Video characteristics: * Video Purpose * Video Emotion : negative or not * Context: e.g., home, office, vehicle * Number of other people onscreen * Interaction of cameraperson w/ subject: yes or no * Language  Device usage in video: * Number of application used * Category of application used * Type of device * Physical position of device: e.g., lying flat, standing upright * Physical position of user: e.g., sitting, lying down User characteristics: * Age group: e.g., small child , child , etc.
This study included three main phases:  video searching--finding user-generated videos of mobile touchscreen device use by individuals with motor impairments on YouTube;  video coding--developing a coding scheme that focuses on user interaction with the touchscreen devices and any challenges or opportunities that are evident, applying it to the videos, and analyzing the results for patterns; and  an online survey--soliciting responses from the YouTube video uploaders on the continued use of touchscreen devices in their daily lives.
Because there are many terms used to describe physical disabilities and motor impairments, a single search would not be sufficient.
Instead, we followed a systematic approach.
We generated a list of disability-related search terms  and a list of technology-related search terms , then exhaustively searched for every combination of terms from the two lists .
This resulted in 480 unique searches.
The terms were informed by an extensive exploration of YouTube's search capabilities and the descriptions we found people using for their videos.
For example, non-Apple brand terms such as "Android" yielded no useful results in these explorations, and thus were not explicitly included our final set.
When an item included more than one word, we searched for it in quotes.
For example, the terms accessibility and touch screen resulted in the combination: accessibility "touch screen".
Finally, one researcher coded all remaining videos using the refined coding scheme.
Following the coding, we qualitatively analyzed subsets of videos identified by the codes as being interesting in some way, such as showing a particular type of interaction.
These richer descriptions complement the coded data.
For each subset, one or two researchers identified themes and commonalities across videos.
Additionally, we recorded objective information about the video, such as length.
To complement the snapshot of use offered by the video analysis, we developed an online survey to elicit more detail on users' daily use, opinions, and experiences with the device shown in their video.
Through YouTube's messaging functionality, we contacted 90 unique YouTube users whose videos were in our dataset and who appeared to be individuals rather than larger entities .
The survey included 20 questions divided into:  demographics--age, gender, disability, etc.,  daily use of the device--activities, frequency, motivation, etc., and  adaptations of the device--special setup, difficult actions, etc.
Users who completed the survey  received a $10 Amazon online gift card.
Fifteen respondents completed the survey.
We characterize the survey participants in more detail in the Dataset section.
In total we found 187 videos that depicted users with physical impairments interacting with a mobile touchscreen device.
The videos were uploaded by 101 unique YouTube users.
In this section, we characterize the videos and survey respondents before presenting additional findings in the next section.
Overall, our data represents a broader range of use cases than past human-computer interaction work on the use of mobile devices by users with motor impairments .
The diversity of our dataset also highlights that YouTube can be a rich source of data for similar work.
At the extreme, one user was a physical therapist who had uploaded 25 videos of various clients .
The uploader of the video was not always the primary subject of the video, that is, the individual with a physical disability interacting with a touchscreen device.
For the remainder of this paper, we use the word "user" to refer to the primary subject.
Our codes resulted in the following demographic breakdown:  Gender.
We also recorded diagnosed medical conditions where possible.
Typically this information was available in the video title, description, or comments, or in some cases, on the uploader's YouTube profile page or external website .
Table 3 shows the frequencies of disabilities in the dataset.
Since users may have more than one co-occurring disability, the numbers sum to greater than 187.
In 21% of cases, we were unable to determine the exact disability, but watching the video made it clear that some type of motor impairment existed.
These data reflect the diversity of users in our study.
The videos included a variety of assistive technology devices, such as wheelchairs , arm and leg slings , chest harnesses , or assistive breathing equipment .
Other equipment included adaptive seating systems, stander systems, neck braces, and limb prostheses.
In about a third of videos , more than one assistive device was present; 24% of videos showed none.
The videos ranged in length, from only a few seconds to much longer, covering multiple episodes of interaction  = 78s; range = 6-680s; SD = 128s.
Most videos were all or partly in English .
We subjectively coded the environment or context in which the video was recorded, based on cues in the video itself.
The most common setting appeared to be the home ,
A wide variety of applications were in use in the videos.
Each video typically showed interaction with a single app .
The specific app was not always apparent, so we instead coded the app purpose.
The most common apps were either kids' apps , in 26% of videos, or entertainment apps , also in 26% of videos.
Other common apps were augmentative and alternative communication  apps  and other games .
Interaction with the fingers was by far the most common direct interaction method, appearing in 56% of all videos.
Also, one-handed interaction  was more common than two-handed interaction .
Frequency of direct interaction methods is shown in Table 4.
Although many users were able to successfully use finger-based interaction, we observed several types of difficulties.
In some cases, users' motor impairments interfered with their ability to perform the necessary touch or gesture that the app was expecting.
For example, users unable to fully control finger extension sometimes made contact with the device surface with their fingernail.
The capacitive touchscreens on iPads and iPhones do not recognize a tap by a fingernail because it is not conductive .
One mother commented on a video about her son: " has been doing a much better job of touching the screen with the pad of his finger, instead of his nail."
We also observed users holding their finger on the screen too long, which the device recognizes differently than a short tap.
Similarly, dragging or sliding motions presented challenges for some users with limited muscle control or tremor.
One small child with mixed developmental delays changed how he was holding his iPhone several times and used different fingers to enable him to drag his finger along the path an app required .
In other cases, the user was unable to reach all areas of the screen due to limited range of motion.
In many videos , a third party helped the user in some way to recover from these errors.
We coded interactions in which the palm or side of the hand was used to contact the screen as `hands'.
Most users who interacted in this way  were small children with limited mobility due to their disability and/or young age.
Although the size of the contact point is larger than for the  finger, any part of the skin can be recognized as contact by these devices.
An app can take this potential interaction style into account by using larger interactive widgets onscreen that do not require precise targeting.
One caregiver of a child with Wolf-Hirschhorn Syndrome alluded to a need to develop precise motor control: "You have to actually touch on the...object to make it move, ...so it works on...fine motor skills."
Uses of fists and knuckles were similar in our videos.
Fifteen participants responded to our survey .
Of these, two were not members of our target population and were removed from analysis .
We additionally received a response from a therapist who works with iPads and people with disabilities.
Of the 12 remaining respondents, 3 were the user from the video themselves, while the other 9 were caregivers or relatives answering for the main user.
We report the demographics of the users  rather than the person filling out the survey.
Respondents reported a range of disabilities, including myotubular myopathy, spinal muscular atrophy , cerebral palsy, quadriplegia, and traumatic brain injury.
Half  reported only one disability, while the other half had 2 or more.
For 8 users, the disability had been present since birth, for 2 before age 5, and for 1 since adulthood.
These respondents were relatively technologysavvy, as might be expected of those uploading YouTube videos.
Most  indicated they used the touchscreen device once or more a day, and the others noted less frequent use.
Most users who used fists or knuckles were babies or young children using a simple app that only involved touching the screen .
As with hands, fists and knuckles can be recognized equivalently well to fingers, as long as precise aim is not required by the app.
In 5 videos , direct touch with the nose was used as the primary interaction.
In one comment, a mother remarked on her daughter's use of the iPod Touch with her nose: "She can play almost any game out there!
It is really quite a great accessible tool that Apple has created."
The videos depicted a range of tasks, including typing, creating music, and playing games.
In all cases, the touchscreen devices were mounted to a wheelchair so that they could be easily reached by the user .
Two videos showed people interacting with the touch device using their feet.
One of these users, an adult, commented regarding the iPhone and iPad that: "I used to have other phones with the little buttons but since I use my feet, it's easier to do things on the screen" .
During the video he tended to use his big toe and second toe the most, typing and interacting with different apps.
Adapted mouth sticks were used in 7 videos .
In one case, the user had attached a commercial capacitive stylus to her mouth stick, while the other two examples were homemade .
The videos demonstrate a range of interactions with both iPhones and iPads: tapping, dragging and scrolling.
One user was quite pleased with the combination of mouth stick and iPad, noting that: "There's just a couple of limitations for me personally.
That's a couple of...2-finger, 3-finger gestures, but other than that...I can do so much."
Finally, a stylus was held in the hand in four videos .
Two users held the stylus like a regular pen with the iPad positioned at a slight vertical angle.
The third user interacted with the iPad mounted to the front of her power chair and used an extra long stylus that appeared to extend her reach to be able to tap on the iPad screen.
Four videos  included head stick interaction.
In all cases, the users were seated in wheelchairs, with the touchscreen device either mounted to the chair or on a nearby surface.
The intention of one of these videos was to communicate that a standard head stick does not work on the capacitive touchscreen of the iPhone, while the remaining videos demonstrated use of head sticks that had been custom-adapted to work with such a screen .
In one of the latter videos , the user achieved some success tapping app icons and the physical home button on the iPad, but encountered problems because it was difficult for him to tap quickly enough with the head stick.
The narrator expresses that: "One thing that would be nice about the iPad is if you could adjust the sensitivity or the delay time for clicking on it."
In 13% of videos, children with severely limited motor control used slings to stabilize their arms or legs and enable direct touch interaction .
Most often the device was set up vertically, allowing the user to approach it from the side.
While this setup allows for horizontal movement, the child cannot reach higher or lower; correspondingly, the apps used in these videos tended to be children's games that did not require precise touches.
One mom told her young daughter with SMA: "Stretch  out!
People in the videos used the touchscreen devices while they themselves were in a range of positions, including seated , lying down , and reclining, e.g., in an adjustable wheelchair .
All users who were fully lying down were babies or small children who may have had trouble sitting up either due to their age or their disability.
However, they were still able to interact with the touchscreen device if it was propped up vertically.
The range of interaction methods that we observed points to the diversity of this user group in terms of abilities and accessibility needs.
While we observed many successful interactions, challenges still exist.
We return to potential improvements in the Discussion section.
We were interested in how users had adapted the touchscreen device to accommodate their own abilities.
In addition to commercial adaptations such as using a stand for the device, we observed a smaller number of do-ityourself modifications .
We discuss these DIY adaptations in detail, as well as device positioning methods.
The videos showed devices oriented in a variety of positions.
Most often, the device was either lying flat on a surface , typically a table, a wheelchair tray, the floor, or the user's lap, or it was standing vertically , typically leaning against something or held by another user.
In 11 videos , the touchscreen device was hard-mounted to an arm or stand that was affixed to the user's wheelchair.
Handheld use was seen in only 15 videos , perhaps unsurprising given users' physical disabilities and the fact that the iPad, the most common device type in our videos, is not necessarily intended for handheld use.
Touchscreen device position was related to user position, and both were related to disability and interaction method, pointing to a concrete set of use cases that users with motor impairments find successful.
Plastic zip-top baggies used as screen protectors  were seen in 8 videos, 7 of which were uploaded by the same user, a physical therapist who used the iPad with multiple children.
One child licked the screen, demonstrating the need for such a protector.
The plastic bag does not interrupt the conductivity of the screen, so users can still interact successfully.
We also observed DIY physical barriers.
Previous work on stylus-based touchscreen interaction for people with motor impairments has demonstrated the value of hard physical edges in guiding users .
However, the bezels of modern touchscreen devices are flush with the screen, leaving no physical edges for stabilizing the touch point.
Interestingly, two YouTube users uploaded a total of four videos that showed homemade physical guides for the iPad .
These guides were designed to be paired with specific apps, and, as such, included openings to match the layout of buttons in the app.
While these examples support direct touch interaction for children, they could also be useful for intermediate devices such as head sticks.
One user, an adult female with a spinal cord injury resulting in quadriplegia, stated in her video, "My main concern was if I would be able to use it given the fact thatit's designed to be used with your hands."
After describing how she uses a special capacitive stylus attached to her mouth stick, she says, "It gives me the freedom and independence to...do a lot of things on my own, which is great."
The user we mentioned who uses the iPhone and iPad with his feet cited these technologies as enabling his own independence: "I'm running the company and basically being independent."
Positive sentiment was also expressed in many videos  by parents of children with severe physical impairments who are growing up using these devices.
The iPad especially was seen as an affordable tool that gives their children the ability to communicate and play, in some cases expressing that this was occurring for the first time and in ways not previously possible.
The uploader of one video wrote of her child in the video description: "He may not be able to talk yet, or walk, but this little guy...loves playing his piano and he loves musical apps on the iPad."
Another mom stated in the video description, "When  saw this  was so amazed never in my life did  think she could ever be as good as she is."
One of our survey participants indicated that her child has "no other way to communicate..." , and another wrote that the iPad enabled her daughter to "verbalize things others had to guess at previously."
Another indicated "the iPad gives  the ability for voice."
Dedicated AAC devices are often expensive and inflexible, so these parents used the iPad as an affordable, multi-purpose AAC device.
In contrast to these positive examples, six videos seemed to have been recorded for the purpose of demonstrating how a touchscreen device was not accessible for that user.
For example, one user, a teen male with cerebral palsy, made a video entitled "Why Touchscreens Scare Me."
In the video, he comments that touchscreens require interaction via hands, and he is unable to control his hands enough to even touch the device .
Another user, an adult male with a congenital amputation, uploaded 4 videos, all of which primarily showcase how it is difficult or impossible for him to use the iPad or iPhone.
Survey respondents told us they are using mainstream touchscreen devices for a variety of applications, such as books, music, entertainment, games, and education.
Interestingly, 6 users who responded to our survey had never heard of the iOS feature known as AssistiveTouch, which allows entry of multitouch gestures with one finger.
Only 3 indicated they used it "sometimes" or "often".
A strong theme in our survey responses was that touchscreen technology is perceived as being particularly advantageous or suited for people with physical impairments.
Seven of the 12 survey participants indicated that they had initially tried the device in their video because they had "heard it was useful for people with disabilities or with my disability."
One reason touchscreens may be helpful to users with motor impairments is that the amount of physical strength needed to interact is less than with physical objects.
One respondent mentioned: "I don't need the physical strength to press down each of the keys that I would on a physical piano" .
Our study found evidence that users with motor impairments are frequently using mobile touchscreen devices in their daily lives.
Many users were able to interact with direct touch, using their fingers or hands with varying degrees of success.
Users frequently customized the devices or their configurations to work better for their particular needs.
For example, we saw a range of physical device adaptations such as homemade guides and barriers, pointing devices, or screen protectors.
We also saw a range of use cases, from interaction with one's feet or nose to interacting while lying down or using arm or leg slings for support.
Rather than finding a touch-oriented interaction completely inaccessible, motor-impaired users in our videos and in our survey responses commented that these devices empower them to be more independent and do things they otherwise could not.
Still, there is significant room for improvement in accessibility, ranging from tailored interaction styles for those with limited mobility, to support for indirect interaction methods, to personalization of interaction that can adapt over time.
We discuss the design implications we believe emerge from this work in the following section.
Survey respondents indicated that the technology still needs to improve before it can meet all of their needs.
For example, all but one of the survey respondents customized the device in some way for their own use.
Only one  of the survey participants was able to use the device by holding it; 7 indicated they had to lay it flat on a table and use it that way, and 6 indicated they used a stand or mounting rack with the device.
One respondent stated: "Correct positioning of  hand and arm were key."
Confirming our observations from the videos, limited arm mobility, finger control, and muscle control created challenges for users to interact with a touchscreen device like an iPad without accidentally activating the screen, as one respondent mentioned: "This  lets me slide my hand around the touchscreen surface without activating it.
Then I can use my index finger and thumb for interacting with the screen."
However, one respondent indicated that she hasn't "found a really good set up for when I am using the iPad on my own" .
The survey respondents indicated that many of the basic functions of the touchscreen devices were quite challenging.
Nine people noted that using the device's hardware buttons is difficult, 6 people indicated typing or entering text was difficult, and 5 people indicated that both selecting text and onscreen items or browsing the web and other documents were difficult.
Survey participants indicated that all such difficulties were caused by a lack of fine or gross motor control of one's arms or fingers.
Several design suggestions came directly from user comments in videos and survey responses.
For example, one user  suggested supporting adaptations for the sensitivity of the device, because he had difficulty tapping as quickly as needed by the device.
A settings option or even a feature that could learn this over time would be helpful for users with motor impairments.
Alternative support for multitouch interaction for motor impaired users is also required.
One user  specifically mentioned being unable to perform 2finger and 3-finger gestures.
We did not see any instances of pinch-to-zoom or other multitouch gestures in the videos.
The built-in accessibility feature on iOS devices called AssistiveTouch could support these interactions.
However, this feature was not used in a single video and only 3 survey respondents had ever used it.
One survey respondent stated that "It's not too intuitive."
More work is needed to understand why this feature does not succeed and how we might design improved multitouch support.
We suggest support for constant touch habituation, in which long duration touches that do not change or move for a period of time would be ignored by the system.
Highlighting this need, one user's arm was continuously activating objects onscreen as she attempted to interact with the device, while another mentioned that he used an arm sleeve to mitigate the problem of accidental interactions.
The DIY physical guides we saw in some of the videos were inspiring.
Users had made them out of different materials to keep from hitting other buttons on the screen, but these materials were often not very sturdy .
Commercial products such as the TouchFire4 physical keyboard overlay for the iPad are available for touchscreen text entry; perhaps similar products would be useful if standardized for various apps.
Many of the videos in our dataset involved children with disabilities, some of whom had severely limited mobility and were unable to lift their head to focus on the screen.
In one video, a young child diagnosed with Krabbe disease was using a xylophone app without looking, moving her fingers slightly over the screen to make sounds and music.
The narrator says with clear pride, "You gonna play music?
This population presents an interesting design opportunity: how can we design apps that engage these children's minds but do not necessarily require fine motor control?
Soliciting survey responses from people who had uploaded videos worked well to complement the video data.
We were reasonably successful, with a 17% response rate.
Still, as with most survey-based research, self-selection and response bias due to the minority sample could have impacted our findings.
An additional challenge relevant to future work in this area was that, in many cases, a third person completed the survey on the user's behalf, either because the primary user was a child or because it was difficult for the primary user to do.
As such, there were instances where the responses ambiguously referred to "I".
Careful survey design is critical for mitigating this issue.
Using video data as the primary source of data meant that we had very little context with which to resolve uncertainty.
For many dimensions, we included an "unable to determine" code, to prevent overconfidence in the findings.
This work represents one slice of interaction styles, physical adaptations, and attitudes toward touchscreen devices.
Ideally, we would triangulate the data we obtained here with data from other methods, such as in-person interviews, diary studies, ethnographies, and so on.
We had also hoped to include a systematic analysis of text comments for each video as was done in prior work , but a majority of videos in our sample had few or no comments.
Finally, we aggregated the data based on videos rather than on individual users, an approach that could bias results toward users who had uploaded many videos.
Mitigating this issue, the median number of videos uploaded per user was 1, and the 25 videos uploaded by the most prolific user actually showed many different individuals.
We attempted to make clear cases where one or a few uploaders had a substantial effect on the counts .
Moreover, multiple videos by the same user were sometimes individually valuable in depicting different issues due to increased experience with the device.
We found user-generated YouTube videos combined with uploader surveys to be a rich source of data on interaction in the wild.
While our focus has been YouTube, our approach could be applied to other sources of usergenerated content, such as blogs or photo websites.
To guide future work, we summarize lessons learned.
A primary challenge was to develop an effective search strategy.
The goal of our work was to look through users' own lenses on their daily interactions with technology, and, as such, many videos that fit this profile were labeled with generic labels denoting daily activities, such as "Dane and his iPad".
We had initially attempted  to search with only a small number of keywords as other studies have done .
Thus, we adopted the systematic approach described in the paper, resulting in 480 search term combinations.
It was also difficult to find videos for every type of motor impairment that we explored.
For example, we found no hits for the search term "Parkinson's touchscreen" even though Parkinson's disease is a fairly common condition causing motor impairment.
Inability to find these videos could have been due to a combination of factors: poor labeling, disinterest in making videos by Parkinson's users, or an actual lack of use of touchscreen devices by them.
Our method also has a sampling bias, in that it only includes users and/or caregivers who are willing and able to record and upload videos to YouTube.
As such, there was little representation from users who cannot use a touchscreen at all.
The method is also limited to use cases and activities that users actually wish to record.
For example, users may not want to record themselves in bed with the device or using social networking apps due to privacy reasons.
We presented an analysis of 187 non-commercial videos uploaded to YouTube that depicted a person with a physical disability interacting with a mobile touchscreen device.
Our method included  coding the videos along a range of subjective and objective dimensions, and  inviting the YouTube users to complete a survey on their opinions and use of touchscreen technology in their daily lives.
Our study builds on previous work  to demonstrate the effectiveness of using publicly available, user-generated content to inform input and interaction design.
We found evidence that users with a range of physical disabilities are adopting touchscreen devices, but often in unexpected or customized configurations.
Based on this data, we presented design implications to improve touchscreen usability for people with physical impairments.
