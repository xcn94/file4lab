However, little research has provided helpful instructions on creating or selecting proper forms to visualize verbs.
In this paper, we present a study comparing the performance of four different visual modes  in communicating commonly used verbs in sentences for both young  and elderly adults .
We reveal the influence of context and various visual/lexical factors, with design suggestions, for users across a wide age span considering aging effects.
In this paper we study how verbs are visually conveyed in daily communication contexts for both young and old adults.
Four visual modes are compared: a single static image, a panel of four static images, an animation, and a video clip.
The results reveal age effects, as well as performance differences introduced by lexical verb properties and visual cues.
We also suggest guidelines for visual verb creation.
Karen and Dongxia  are neighbors in senior citizen housing.
They wish to teach each other English and Chinese, but cannot even engage in daily conversations.
Multilingual communication is more common with the rise of globalization.
Visual languages, which convey concepts and information using photos, signs, and other graphic designs, have greatly increased especially with the spread of World Wide Web.
As a supplement/extension to verbal languages, visual languages can assist both young and old people, those wanting to overcome language barriers, those learning a new language, and those with language disabilities.
In order to create visual languages for real-world settings, a designer must explore visual representations that effectively express concepts for people in all age groups.
Verbs, a lexical category indicating the presence of a state, existence or operation of an action, are an indispensable part of English speech .
The accuracy in deciphering the visual expressions for verbs determines the quality of the delivery of the entire sentence, so the creation of visual verb representations is a crucial issue.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Conversation structure  is similar for young and elderly adults.
However, as people age, many aspects in their communication pattern are affected.
Elderly people have longer word-recall time, deficit in noun naming , and declined verb retrieval ability regardless of other demographic differences .
Additionally, elderly people spend less time in general small talk but in story-telling to pass down traditions and history, and build social bonds with peers .
Popular categories of utterance also vary, due to change in social roles, life experience, and the setting of living and interaction .
For example, elderly people talk more about education  and less about household routines  compared to young people .
This suggests that visual language vocabularies should be constructed based on user interests and usage, and visual representation designs should consider age-related effects.
Compared to nouns , verbs are more challenging to visualize.
Most online visual dictionaries offer few verb categories, since verbs are used to indicate ongoing action or an existing state or condition, and static forms might fail to portray time.
Hence, dynamic modes such as animations and videos are introduced into visual language.
Current research on visual stimuli for verbs, including line drawings , photos , animations , and videos , emphasized actions and movements having to do with postures, gestures, and observable manipulation.
Six images per verb were presented to seven raters  to assess their ability to evoke specified concepts as well as whether the images contain the visual cues  examined in the studies.
We assigned the most preferred image to the single image mode , and the next three to the four images mode .
The animations , animated sequence of icons showing continuous movements or change of status came mostly from Lingraphica , a popular communication support device for our ultimate user population, people with aphasia.
Aphasic patients are well familiar with this icon vocabulary, and Lingraphicare has spent a large amount of human hours and money on designing, implementing, and testing those icons.
Thus we believe their icons to represent the best "state of the art" available for comparison.
There were three cases in which we had to create Lingraphicastyle animations:  no animation available, i.e.
For example, the new "pay" animation switched the object in the "give" animation to "$" symbol.
The videos  were filmed by us.
Other video resources like computer vision databases and YouTube  are either confined to specific actions such as running, or too inconsistent and noisy.
Video clips for each verb were shot based on a script selected by four reviewers out of five independently written scripts, using the following rules for filming and post-processing:  pure white background;  single leading actor;  extra hands or feet if interaction required;  no sound, text, or lip language;  minimized use of props;  clip length three seconds  one-half second;  special effects if necessary .
An additional baseline mode with verbs in the phrases left blank was added to verify perception based only on context.
Evaluation of the efficacy of those visual representations is usually limited to two stimuli, like icons and animations .
There is a lack of studies across all possible visual representations, especially with videos.
Our work differs from previous research in that we evaluate four different visual modes  illustrating 48 most frequently used verbs, not restricted to action or motion.
Compared to a previous study on individual visual verbs, our study was carried out with young and elderly groups on verbs in sentences from daily communication.
We also investigated visual cues and verbal properties for possible impact on interpretation.
Our findings suggest how to create, select, and modify effective visual verb representations for both young and old adults.
Our verb list consists of 48 most frequently used verbs 1 from the spoken materials in the British National Corpus  .
We acquired the top 60 verbs by sorting in frequency descending order.
With a linguist and a speechlanguage pathologist, we compressed the list by eliminating words less common in American English, removed "like" and "know" , and words with similar sense .
The final 48 verbs were assigned to the most frequently used sense, and categorized into nine domains  by lexical function and WordNet association .
Sixty-five phrases were generated by crawling sentences with target verbs from senior citizens' blogs in the Ageless Project , removing the ones in different senses, and simplifying complex clauses.
Each verb appears twice, and each phrase has up to three verbs to test.
The choice and modification of the sentences reflects the communication pattern and popular topics for both young and old adults.
All five modes were assigned by Latin Square to blocks of 13 sentences each in which verbs in different domains were allocated evenly.
The display order of the modes was shuffled, and the phrases within each block were sorted randomly.
Additionally, the nouns and adjectives were expressed by a single image picked from the web by the same means as those for verbs.
All visual representations were normalized to a height of 132 pixels.
The web-based interface  displayed the 65 phrases one after another.
Participants were asked to interpret each entire phrase.
A backend script kept track of all answers as well as response time.
Both videos and animations were played repeatedly.
Participants were requested to rank the four visual modes by  difficulty in interpreting a verb;  speed of coming up with a thought;  confidence in the response;  personal preference; and  how much the context helped interpretation.
For balanced design, there were 25 participants in each age group.
No participants had eyesight worse than 20/40.
To quantitatively analyze the results, we applied four metrics: correctness/irrelevance, WordNet score, and response diversity.
Correctness/irrelevance are defined as the number of the exact match and the number of irrelevant responses separately.
Exact match means the response is in the same form and sense as the intended verb.
For instance, the verb "pick" is in the sense of "select carefully from a group," and the response "pick, picking an apple" is considered as an irrelevant answer.
WordNet score assesses the responses in a six-point scale by their semantic distance to the target verbs.
Exact match gets point 6, synonyms point 5, and irrelevant ones point 1.
Response diversity shows the number of difference responses received for each verb under each visual mode, which tells how well the interpretation converges.
If the responses spread out in the semantic network, it means the visual representation failed to illustrate the intended verb.
In another case, if the responses gathered around a verb that is different from the target, it means the representation successfully conveyed a concept, though the wrong one.
Compared to a previous study done with the four modes on illustrating individual verbs, context showed significant impact on the accuracy of concept perception =40.438, p=0.0, 2 =0.301, and both young and old adults benefited from context similarly.
To sum up, there is a strong, nearly constant age effect for all modes, and there is a strong effect of visual mode for all ages.
Data on preference, ease of use, response speed, etc.
Young and old adults were affected in a similar way.
These effects were also reflected by visual modes' performance on verb domains.
To sum up, the indirect-symbol verb category which tends to be more abstract is hard to illustrate in general, however, video did not suffer from using indirect symbols.
Certain verb-related gestures enhance perception, and videos can utilize them the most as a dynamic representation mode.
Results indicate that there is a strong age effect on interpretation, and the four modes perform differently for different verb types, with video mode best for motion and contact verbs, as well as verbs generally not imageable.
We also formulated some basic guidelines for designing visual verbs.
In terms of future work, we wish first to run studies comparing our current visual modes to refined versions based on our design guidelines.
We will also test them with our target population, people with aphasia.
Later, we will add the visual verbs that we verified to our current assistive communication system applications.
There are other factors that can lead to confusion, such as misapprehension of objects in the representation, distraction by background, subject's imagination, and/or unfamiliarity.
Based on our results and analysis, we propose these guidelines for the design of visual verbs: * Multiple pictures/frames are better for conveying verbs.
According to our post-study survey, participants tended to choose their favorite representations to visualize verbs.
However if elderly participants are asked to create their own visual vocabulary, they choose images  because of availability and ease of creation.
Baecker, R., Small, I., and Mander, R. Bringing icons to life.
Blank, M, Gorelick, L, Shechtman, E, Irani, M, & Basri, R. Actions as space-time shapes.
Bowles, N. and Poon, L. Aging and retrieval of words in semantic memory.
Aging and Reminiscence Processes: Social and Clinical Implications.
Druks, J. and Masterson, J.
An Object and Action Naming Battery, Psychology Press, London, 2000.
Fellbaum, C. WordNet: An Electronic Lexical Database, chapter: A semantic network of English verbs.
Kilgarriff, A. BNC database and word frequency list: http://www.kilgarriff.co.uk/bnc-readme.html.
Verb naming in normal aging.
Rogers, Y. Pictorial communication of abstract verbs in relation to human-computerinteraction.
Stuart, S. Topic and vocabulary use patterns of elderly men and women of two age cohorts.
Doctoral Dissertation, University of Nebraska - Lincoln, 1991.
Vanrie, J. and Verfaillie, K. Perception of biological motion: A stimulus set of human point-light actions.
