We present a novel integration of a brain-computer interface  with a multi-touch surface.
BCIs based on the P300 paradigm often use a visual stimulus of a flashing character to elicit an event related potential in the brain's EEG signal.
Traditionally, P300-based BCI paradigms use a grid layout of visual targets, commonly an alphabet, and allow users to select targets using their thoughts.
In our new system a multi-touch table senses objects placed upon its surface and the system can highlight the objects on the table by flashing an area of light around them.
This allows us to construct a P300-based BCI that uses a user-assembled collection of objects as targets, rather than a pre-determined grid layout.
An experiment shows that our new paradigm works just as well as the traditional paradigms, thus highlighting the potential for BCIs to be integrated in a broader range of situations.
We use an EEG-based BCI that uses the P300 event related potential  which we describe in the next section.
BCIs can be used as a communication channel for people with severe motor impairments such as amyotrophic lateral sclerosis .
However, there is a growing interest in their use in more general HCI applications .
Two main strands of work within HCI have emerged: the understanding and improvement of the BCI control paradigms , and the embedding of BCI in new HCI situations.
Our work is firmly in the latter strand.
Previous P300-based BCIs have typically used a grid-based spelling task which we describe in the next section.
A grid of flashing characters or symbols is displayed on a monitor.
Our main contribution is that we demonstrate how we can use physical objects as the targets to which the user should attend.
We place objects freely on a multi-touch table where their shape is detected by a simple computer vision system.
We then "flash" the objects by surrounding them with an area of light.
In an experiment we show that users are easily able to indicate their interest in objects on the multi-touch table using the P300-based BCI.
In fact, using a within-subjects comparison, we show that their success rate is slightly better than on a standard spelling task.
A brain-computer interface  is a communication system where the user's commands "do not depend on the brain's normal output pathways of peripheral nerves and muscles" .
A BCI thus makes it possible to control a computer using only your thoughts.
BCI methods include invasive and non-invasive forms with a variety of sensing modalities .
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
We describe a P300-based spelling task so we can both introduce how P300-based BCIs operate, and use this task as a reference in our experiment.
The P300 brain waveform is an ERP which is an increase in voltage of about 10V peaking around 300ms after the stimulus.
It is triggered by an auditory, visual or somatosensory stimulus which is infrequent or particularly significant amongst other more routine stimuli.
Its use as a BCI was pioneered by Farwell & Donchin .
Typical P300-based BCI systems use a spelling task.
In such systems, a participant observes a grid of characters, see Figure 1.
They attend to one of the characters and are instructed to count the number of flashes of that character.
Each character in the grid then flashes several times in a random order.
In addition, the type of pattern used is an important research problem .Figure 1 shows the screen of the P300-based speller from Guger Technologies  which follows the paradigm described above .
Each flash lasts for 60ms, followed by a dark-time of 10ms.
In our experiment we used the g.tec g.MOBIlab+ 8 channel EEG system which is wireless and portable.
The reference was placed on the right ear-lobe and the ground on the forehead.
The g.tec system provides tools in MATLAB 2008b and Simulink to do an offline phase to train a P300 classifier and then an online phase as shown in Figure 1 and discussed above.
The P300 classifier is trained using linear discriminant analysis .
A full review of P300-based BCIs is beyond the scope of this paper, but the g.tec speller paradigm and the associated hardware and software are typical of such systems.
We describe the use of the software in more detail in the description of the experiment.
We are not aware of any work that attempts to integrate a P300-based BCI with physical objects.
An image processing pipeline was built using Java and the DirectShow Java wrapper , Figure 3 gives an overview.
At the start of the application, a background image was captured.
This raw, single channel camera image shows the underside of the table's surface along with its supports.
Items were placed on the table, and a new image was captured.
Background subtraction and cropping were applied.
The image was passed through a low-pass filter, and thresholded at a grey-level of 40 to create a noisy binary image.
To remove noise, the image was opened.
The image was then dilated 15 times to create a blob larger than the image of the object.
A connected components algorithm was applied to detect and label regions.
This process was shown to work for any number of reasonably sized non-overlapping objects.
It works with fine objects as evidenced by the use of a necklace in Figure 2.
In the experiments, we standardized on the use of 6 objects at a time.
To bring the number of blobs to 36 the software also generates 30 non-object blobs.
This was done because the P300 paradigm relies on the fact that the object being attended to flashes relatively infrequently.
We picked 36 because that is the g.tec BCI software's default and many studies have picked a similar number as a good tradeoff between accuracy and speed .
The non-object blobs can overlap with the object blobs and each other.
This could have caused the P300 to be elicited incorrectly, but because the order of flashes is random, this shouldn't lead to an overall misclassification.
Our results suggest that there were no such misclassifications in our experiment.
Our aim is to replace the normal grid of characters with physical objects.
Figure 2 shows the operation of the resulting system.
Objects are placed on a multi-touch table.
The multi-touch table recognizes the objects' outlines and runs image processing algorithms to generate areas of light  around those objects.
This is interfaced with the g.tec software so that a participant can select the objects.
The participant is seated 1m in front of the SSS screen .
The participant is instructed to look at the character A and count the flashes.
Each of the 36 characters on the screen is flashed 16 times in a random order.
This is repeated for characters B-F.
The recorded data is analyzed offline using the LDA to create an EEG classifier.
The offline analysis takes less than one minute.
The SSS screen is restarted using this classifier.
The participant is then asked to spell four words: CAT, DOG, DV8, and FLY by keeping a running mental count of target character flashes.
Each of the 36 characters is flashed 8 times in a random order.
Between each word there is a pause, and they are only told the word immediately before attempting to spell it.
They receive feedback after each character is spelt.
Different numbers of flashes were used for training  and the actual selection task  in both the SSS and MTS.
This is because previous tests showed that 16 flashes are needed in training to provide sufficient data to generate a classifier but that 8 flashes are enough to give sufficient discrimination from a set of trained classifiers.
This adds a little extra latency to the system, but the application was run on a machine with a quad-core Intel i920 processor with an Nvidia GeForce 275 graphics card and 6GB of DDR3 memory.
The use of a high-end machine meant that the CPU load was very low and the applications ran at 75Hz.
An end-to-end latency of less than 100ms in the display system is, in any case, implicitly compensated for in the offline training of the EEG classifier as long as jitter is kept very low.
We performed an experiment to assess the effectiveness of the P300-based BCI multi-touch system .
The main aim was to demonstrate the effectiveness of the new system.
We examined the success rate of selections and compared this to the success rate on the standard speller system .
Twenty participants took part: 11 male and 9 female .
Most were staff or students at University College London.
They were not compensated for taking part.
We used a within-subjects design, which allowed us to both compare success rates on MTS with the previous literature and also compare each participant's performance on the MTS and SSS.
The participant stands in front of the touch-table, see Figure 2.
Six objects are placed on the table.
The participant is instructed, by the experimenter gesturing towards and naming, to look at one of the objects and count the number of times the area of light under it flashes.
Each of the 36 blobs on the table is flashed 16 times in a random order.
This is repeated for the other 5 objects.
The recorded data is analyzed offline using the LDA to create an EEG classifier.
The MTS system is restarted using this classifier.
Six objects are placed on the table, and the experimenter names and gestures towards one.
Each of the 36 blobs is flashed 8 times in a random order.
This is repeated for two other objects.
Then the six objects are replaced by six more, and the process repeated another three times.
They receive feedback after each selection: the blob chosen by the classifier is highlighted.
Each participant was introduced to the equipment and given an information sheet.
After consenting to take part, the participant was fitted with the electrode cap and electrodes and the signal from each electrode was checked.
Filters in the g.tec software can cope with minor artifacts caused by eye and head movements.
Each participant performed a series of 12 selection tasks in both MTS and SSS.
Half the participants first used SSS, whilst the other half first used MTS.
Overall, the experiment lasted an hour per participant.
In both the SSS and MTS, each selection is a choice of 36 potential targets.
In both the SSS and MTS cases, the participant's success rate is a score out of 12.
No participant, in either condition, scored less than 9 out of 12 .
A two-tailed t-Test was carried out to compare the conditions , but no statistical difference was found.
Given that the mean success rates are higher, this is good evidence that the MTS performs well.
There was no impact of the order of the two conditions suggesting there was no learning effect.
We can also compare the overall success rates, to other recent studies.
A common way of examining the success rates is to split the classification accuracy into bands as shown in Table 1.
We compare our results with those of Edlinger et al.
There are several direct applications for this new technique such as allowing "locked-in" persons to interact with real objects rather than a screen.
For example, in a meeting, real objects could be indicated rather than having the person spell the names of objects.
Furthermore, the work hints at a future scenario where real environments could be augmented so that the physical objects could act as their own interfaces.
In a smart home, a projector or array of lights could highlight objects to be used with the BCI.
For more general users, the main contribution is that this is the first demonstration that does not use the standard speller or a simple graphic icon interface.
Thus, as was highlighted as an important need in , this work opens up the space of opportunities for BCI.
The results are very promising with 100% of our MTS sessions in the 80-100% success rate band, compared to 76.3% for their study.
The SSS also scores highly.
Further studies would be required to isolate whether this is just due to the participant sample or some aspect of our system.
However, we suspect that a key difference may be that we ran the experiment on a very fast multi-processor PC so that the 300ms delay in the brain response was precisely measured by the software.
In addition, Edlinger et al.
BCI offers new opportunities for HCI.
The design of targets and flash patterns for the P300-based BCI has been a topic of major concern in the study of BCIs.
It is only one type of BCI paradigm, but it shows a lot of promise as its bit-rate is one of the highest amongst BCIs .
This short paper demonstrates that it is possible to use a P300-based BCI to indicate interest in real objects.
There are several avenues for future research.
We could use more sophisticated computer vision techniques to recognize and label target objects in more general environments.
The size and shape of the cues are important and this would be an excellent topic for a follow-on study.
It is worth noting that the P300-based BCI works well compared to the reference speller task.
