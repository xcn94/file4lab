We report results of a study which examines consensus building in user interface design discussions in open source software communities.
Our methodology consisted of conducting interviews with designers and developers from the Drupal and Ubuntu communities  and analyzing a large corpus of interaction data collected from Drupal.
The interviews captured user perspectives on the challenges of reaching consensus, techniques employed for building consensus, and the consequences of not reaching consensus.
We analyzed the interaction data to determine how different elements of the content, process, and user relationships in the design discussions affect consensus.
The main result from this analysis shows that design discussions having participants with more experience and prior interaction are more likely to reach consensus.
Based on all of our results, we formulated design implications for promoting consensus in distributed discussions of user interface design issues.
By consensus, we mean that participants are willing to commit to a proposal despite any remaining objections .
Because consensus building is a common and critical task in user interface  design discussions in OSS, it is important to understand how often consensus is  reached, what techniques are utilized to foster consensus, and which elements of a design discussion affect consensus, among many other interesting questions.
However, these questions have not been directly addressed by prior work.
For example, one thread of prior research has analyzed elements of design discussions such as participation , argumentation , and tracking of design proposals , but has not targeted consensus building.
In a second thread, researchers have conducted lab experiments to test how different factors of group work such as size, task, and anonymity affect decision quality and reaching consensus .
However, in lab experiments, it is difficult to simulate how consensus unfolds in real world design discussions, especially those in a mature OSS community.
In this paper, we report results of a study which examines UI design discussions in OSS communities from the perspective of consensus building.
Part of our methodology consisted of conducting semi-structured interviews with designers and developers from the Drupal and Ubuntu OSS communities .
The interviews captured user perspectives on key challenges of reaching consensus in the design discussions, the techniques utilized for promoting consensus, and the consequences of not reaching consensus.
To complement the interviews, we analyzed a large corpus of interaction data collected from the Drupal community to test how different discussion elements relate to consensus.
Our data set included UI design discussions that did and did not reach consensus.
From the interviews and other sources, we derived three categories of potential factors; content, process, and user relationships and operationalized them into 23 metrics.
The metrics were calculated for each discussion in our data set and entered in a binary  logistic regression.
The main result from this analysis shows that discussions having participants with more experience and prior interaction history are more likely to reach consensus.
In open source software  communities, many design decisions that shape the product's user interface are made through distributed discussions .
For example, to initiate a community discussion of a usability issue, a member describes the issue and others join the discussion to propose and debate design alternatives.
These discussions typically unfold via mailing lists or Web forums linked to the OSS project.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Similarly, in , the authors studied how participation relates to code-related design decisions.
One finding was that in the more effective projects studied, the number of participants increases over time and shifts from administrators to other community members.
Our work builds upon these results by including variables related to participation and social influence, among many others, in our statistical analysis of consensus.
In group decision making, consensus refers to when all participants are willing to commit to a proposal despite the fact that objections may remain .
The process of building consensus requires a good faith effort to meet the diverse interests of all participants as the process is considered as important as the final outcome.
For example, this is often accomplished by encouraging those with dissenting views to propose or adapt existing ideas to meet their own interests without supplanting the interests of others .
In this paper, we study consensus building in the UI design discussions in one established OSS community.
Consensus building is an appropriate and important lens for viewing these types of discussions.
For example, since almost all community decisions relating to the product's interface are made through distributed discussions, the ability to reach consensus can have a large impact on the quality of the product and satisfaction with the decision making process.
There is a long history of research examining how various factors of a group such as size, task, and anonymity relate to decision making performance .
This line of inquiry has often compared technology-mediated and face-to-face  group work and relied primarily on the use of controlled studies.
For example, controlled studies have shown it is more difficult and takes more time to reach consensus when groups use synchronous or asynchronous communication technology than when working FTF .
Similarly, it is more difficult to reach consensus as group size increases  and, when consensus is required, group members experience less satisfaction when using communication technology than when working FTF .
While working FTF is ideal for reaching consensus, decision making in OSS communities often occurs in a distributed setting.
It is therefore important to understand how consensus is achieved in this context.
Our research fills this void by studying real world consensus decisions made in the UI design discussions in a mature OSS community.
Enabled by open access to peer production communities such as Wikipedia and OSS, researchers have begun to study similar elements of group decision making in real world data sets.
For example, Lam et al.
Similarly, Burke et al found that extensive and diverse contributions in Wikipedia can predict promotion decisions .
Analogous to these studies, our work tests how different factors relate to reaching consensus on UI design issues in a peer production community.
Interviews were also used to understand users' perspectives on the consensus building process.
Researchers have often utilized the open nature of design discussions in OSS to study different elements of the user interface and software design process.
However studies of consensus in these discussions are conspicuously missing.
For example, in our own prior work , we studied how users propose, track, and debate design alternatives during UI design discussions in OSS.
Twidale and Nichols  explored how usability issues are reported, discussed, and resolved in several OSS bug repositories with a goal of understanding how to improve the discussion interface.
Ko and Chilana  also analyzed discussions in OSS repositories but with the goal of understanding the structure of the discussions.
Similarly, the authors analyzed open bug reports to assess who contributes the reports, the frequency of resolution, and the patterns of comments between the bug reporters and the developers .
Though the results of these studies illuminate important elements of the design discussions in OSS, they say little about the consensus building process.
Our work fills this gap by providing a comprehensive analysis of UI design discussions in OSS from the perspective of consensus building.
Thematic coherence and argumentation in OSS design discussions were analyzed in .
This research aimed to better understand the nature of consensus building in distributed discussions of UI design issues and centered on answering the following questions:  How important is consensus building in these types of UI design discussions, what are the key challenges of reaching consensus, and what are the consequences of not reaching consensus from the user's perspective?
What techniques are currently utilized for promoting consensus and how effective are these techniques?
What factors affect consensus building?
These questions are not exhaustive, but are intended to offer initial understanding of consensus building in UI design discussions and identify opportunities for enhancing the discussion interface to promote consensus.
To answer these questions, a mixed methods approach was employed consisting of semi-structured interviews and analysis of a large corpus of interaction data.
We first asked a participant to describe one or two recent or memorable discussions s/he participated in.
In context of these discussions, we asked the participant to describe the consensus building process, what is hard about this process, the techniques utilized to foster consensus, the factors affecting consensus, and the consequences of not reaching consensus.
Twelve interviews were conducted prior to the data analysis and five were performed afterward.
For the latter interviews, a few questions were added to probe further about specific results of the analysis.
Interviews were coded to derive common themes using a Grounded Theory approach .
The results were used to gain insight into the consensus building process, identify features to include in our interaction analysis, and help interpret the results.
The interaction data was extracted from the discussion threads  in the issue management system of Drupal, an open source content management system initiated in 2001.
Drupal is a mature community with an established workflow and social organization.
At the time of data collection, for example, the software was being used in about 490,000 websites to manage content and about 440,000 people had registered to contribute to the project.
Changes to the user interface and system software of Drupal are requested, discussed, and implemented  through its issue management system.
Any community member can create an issue in the issue management system describing a design problem or feature request, which establishes a separate discussion.
Others may participate in the discussion by proposing design alternatives, critiquing the alternatives, implementing an alternative , reviewing a patch, clarifying the problem, or offering other insights.
To indicate the current progress of a discussion, participants can set its status to `active', `needs work', `needs review', `reviewed and tested by the community', `fixed', or `closed'.
There are four categories of discussions in the issue management system: bug reports, feature requests, tasks, and support requests.
According to drupal.org, bug reports aim to resolve functionality and usability problems while feature requests are for adding new functionality.
Tasks are non-functional things that `need to be done' while support requests are for technical support.
We only examined bug reports and feature requests as they contained the majority of the UI design discussions we wanted to study.
There were 285,008 discussions tagged as bug reports and feature requests in the issue management system at the time of data collection.
This set was filtered to include only the discussions tagged with "Usability" or "d7ux" , which left 577 UI design discussions.
We conducted 17 semi-structured interviews with designers and developers participating in either of two open source projects, Drupal and Ubuntu.
Eight designers were interviewed, five from Drupal and three from Ubuntu, with an average of 4.5 years of experience in the community .
Nine developers were interviewed, six from Drupal and three from Ubuntu, with an average of 5 years of community experience .
Each interview lasted about an hour and was conducted via phone  or IM , whichever a participant preferred, and remuneration was either a $25 or $30 gift card depending on the duration of the interview.
The usability issues ranged from significant redesigns to design details.
For instance, an issue titled "Initial D7UX admin overlay" aimed to revamp the interaction design of admin pages in Drupal by providing themed admin pages as an overlay on top of the actual website while another issue only requested changing the location of a shortcut on a toolbar .
We used the status to categorize discussions as consensus, non-consensus, or ongoing .
We considered discussions marked as closed as having reached consensus.
This typically means there was collective support for a decision such as implementing a specific proposal or concluding the issue was unnecessary or not a problem after all.
Differentiating non-consensus and ongoing discussions was more challenging.
We calculated the idle duration, the time from when the last comment was posted to the time of data collection and considered a discussion to be non-consensus if it's idle duration was more than 90% of the idle durations between comments in the consensus discussions.
The remaining discussions were considered ongoing.
This categorization yielded 284 consensus and 241 nonconsensus discussions.
The 52 ongoing discussions were discarded.
Finally, we filtered this data set to include only those discussions that were non-trivial.
By reading a large fraction of the discussions and experimenting with different thresholds, we found that a threshold of having at least seven comments filtered almost all of the non-trivial discussions.
After this filtering, we had 200 consensus threads and 141 non-consensus threads for our analysis.
Table 1 reports summary statistics for the consensus and non-consensus UI design discussions after this filtering.
In usability it would be easier, anyone can suggest a design: I think we should do it like that.
It tends to get a lot more people involved; it's also a lot more visible .
Often more people are participating, more people means it's harder to  consensus."
Having more people participate in a lengthier, subjective discussion is perceived to make consensus building more challenging.
Another factor that makes consensus building more challenging in UI design discussions is the difficulty of providing supporting evidence in the discussions.
For instance, conducting usability testing to assess the effectiveness of a design proposal needs a lot of time and effort while testing the effectiveness of a performance solution can usually be performed directly and is therefore perceived to be easier: "...I think the usability testing is a little harder to do often.
It takes a little more time, if you do an informal one it's not so bad, but you certainly can't do with just one person,  you have to get several, and it takes time to get evidence.
In some other areas in Drupal it's easier to get evidence.
You know, what percent  faster."
Participants stated that reaching consensus in the UI design discussions was critical for building a better product  and for strengthening the community .
On the other hand, the inability to reach consensus can result in an unimproved product, build resentment in the community, and demotivate community members to the point of leaving the discussion or the community altogether.
Consequences can be that people disappear for a couple of weeks or entirely because they get burned out on a too long discussion that didn't reach consensus... "  The inability to reach consensus also causes the loss of significant community effort.
For example, of the 577 UI design discussions we analyzed, 241  did not reach consensus.
These discussions contained 4968 messages and 460 patches, contributed by 1934 participants.
This outcome highlights the need for techniques for enhancing consensus building within the UI design discussions.
From the interviews, we identified different techniques that designers and developers use to promote consensus.
Our interviewees said that providing evidence in support of a design proposal can better convince opposing parties in a discussion and accelerate consensus building .
For instance, sharing the results of usability testing on a design proposal or showing how the proposal worked in a similar situation can convince other participants.
As DevD2 said participants in a discussion are more likely to comment on a proposal that has a patch attachment: "I present arguments in favor of it and then post a patch.
People are typically more inclined to go with a solution that has a patch than another solution that does not have a patch, unless they have a major reason for liking the other solution better."
Participants also noted endorsing experienced members of the community in the discussion , writing a summary of the discussion , communicating via synchronized channels , having an administrator make the final decision , spending time to understand others' perspectives , voting for different design proposals , and advertising a stalled discussion  as techniques for promoting consensus.
However, it is unclear how effective these techniques are given that 42% of the UI design discussions we analyzed did not reach consensus.
Despite recognizing the importance of consensus building participants identified key challenges that make consensus difficult to achieve.
For example, one challenge is bridging the different perspectives and needs of the community members engaged in a UI design discussion : "There are many different use cases for Drupal, what is optimal for one use case may be suboptimal for another, and there are strong differences of opinion within the Drupal community about which use cases, if any, should be given preference...
Some people build for small sites, some people work on large sites, some people are designers, others are developers  others are end users"  Another challenge is overcoming a strong sense of ownership over one's contributions .
For example, one reason that members contribute is because they can adapt the software to their own needs .
However, building consensus requires members to detach themselves from their own contributions and consider alternatives: "People have egos and they have a lack of human contact with the people that they are talking to and trying to discuss with and a lot of time because these ideas are our own creations and our own feelings it's very difficult to separate ourselves from our own egos."
To understand quantitatively which factors correlate with consensus, we analyzed the interaction data collected from the Drupal issue management system as described earlier.
Based on the interview results, consensus building literature , and prior analyses of online communities , we identified 23 metrics that may relate to consensus building.
The duration of a discussion was also included as allocating more time to a discussion may indicate stronger commitment to identifying an agreeable solution.
For User Relationships, we calculated the number of triads contributing to a discussion to estimate prior interaction history .
Triads were determined from the social graph created from the users, discussions, and relationships .
In a social graph, the nodes represent users and discussions while edges represent their relationships.
An edge between a user and discussion is established when a user contributes to that discussion.
An edge between two users is established when one user responds to the other.
An edge is weighted based on the length of the comment.
We also computed a page rank score  for each participant to estimate `influence' within the community.
The page rank score was also calculated from the social graph.
The duration of community participation was used to estimate the experience of participants as interviewees felt having more experienced members of the community participate in a design discussion promotes consensus.
Table 2 lists these metrics grouped into three categories: content, process, and user relationships.
Though not exhaustive, these metrics provide a useful starting point for understanding which factors affect consensus building in UI design discussions.
For example, for Content metrics, we counted the number of messages with screenshots attached as a proxy for the number of design alternatives proposed.
More alternatives may create more opportunities for consensus.
The number of question marks was counted as a proxy for attempts at building shared understanding .
From the interviews, we found that synchronous chats can promote consensus and therefore included how often "IRC" was mentioned in a discussion.
Similarly, occurrences of "usability testing", "code review", and "summary" were counted in each discussion.
The number of non-Drupal links was included to capture use of external evidence in the design arguments.
For the Process metrics, we counted patches, comments, and contributors as a proxy for the level of activity in each discussion.
To investigate how these metrics relate to consensus, we performed a binary logistic regression.
Binary logistic regression is a type of regression used to model the relationship between independent variables and a binary response variable.
For our analysis, the metrics from Table 2 served as the independent variables and were computed for each discussion in our data set while the dependent variable was whether the discussion reached consensus.
To avoid problems with collinearity in the regression analysis, we removed fourteen variables that demonstrated strong correlations .
These variables are marked in Table 2.
We performed binary logistic regression as implemented in SPSS and used step-down regression to identify our partial model.
We first entered all variables and removed each variable that did not show significance and repeated until a set of variables was reached that were all significant.
Three of the nine metrics included in the analysis showed significance : average number of participation weeks, number of triads, and mentions of IRC.
Table 3 summarizes the results.
To assess the goodness of fit of our model, we performed the Hosmer-Lemoshow test .
In this test, the model is valid if the p-value is greater than 0.05.
To aid interpretation of the results, we conducted five follow-up interviews as described in Methodology.
These interviews followed the original script, but probed further about the factors found to be significant.
Finally, experienced members can promote consensus by understanding the need for proposing solutions that accommodate competing alternatives.
Satisfying opposing views allows stalled discussions to move forward.
For instance, in a discussion about placement of a shortcut for collapsing the Drupal toolbar, X thinks that the icon for the shortcut should be placed on the left side of the menu to prevent accidental clicks on the "logout" icon while Y thinks it should remain on the right side because the space on the left is needed for branding.
They cannot come to an agreement until Z who has been in the community for six years comes in and proposes a new solution: "Thought: Move /help over to the right of "log out", move the shortcut collapsing back to the right, then you'd at least accidentally click a "safe" link."
Our regression analysis showed that having people in a discussion who have participated in Drupal longer promotes consensus.
Research studies confirm that including experienced people can positively influence group decision making performance .
Our interview results and review of the discussion threads illustrated how experience can facilitate consensus building.
First, we learned that members who have been in the community for a long time facilitate consensus by helping other members, especially new ones, understand the norms of communication and the process of participation in the community.
For example, comments and opinions posted by experienced members are valued more than those posted by other participants.
For instance, in a discussion about adding edit and delete operations to a page in Drupal, when two of the participants  proposed different solutions and were not able to come to an agreement, a community member with design experience was invited to review and decide between the proposals: "I am inclined to agree with X here, following the logic of menus and taxonomies this should make more sense..."
Our analysis showed that having more triads participate in a discussion increases the likelihood of consensus.
Triads represent three people who have previously interacted and produce closed social structures that promote trust .
Interview results and review of the discussions confirm trust as an important factor in consensus building.
First, we found that participants are more likely to read, learn from, and evaluate comments posted by members whom they trust.
This exchange of knowledge can create mutual understanding and consequently promotes consensus.
It's a little more likely to read carefully what they say and believe that they have something meaningful to say"  This finding reflects findings in other research studies that indicate a high degree of trust existing within dense parts of a social network facilitates the exchange of complex knowledge .
Second, prior interaction and increased trust promotes agreement among participants.
For instance, knowing that the person who wrote a patch usually conforms to coding standards can accelerate code review.
Then it saves all kinds of time."
For instance, in a discussion where the proposal was to add an edit link to all Drupal pages, one member  was able to build upon another's  patch and save time.
Y says: "So, yeeha, X's last changes contained some really good ones that allowed me to proceed further."
Based on the regression analysis, threads containing more mentions of "IRC" are more likely to reach consensus.
A group of two to five people usually participate in the synchronized discussions and are expected to report their conclusions back to the corresponding discussion for the benefit of all.
Failure to report may cause the other participants to loose context.
First, we found having discussions in IRC can accelerate agreement between opposing viewpoints.
As DevD6 said: "...then it becomes let's argue against this position as opposed to try to come to a position to argue against..." Finally, we learned that participants use synchronized communication to hasten collaborative design review, programming, and debugging sessions.
This finding corroborates observations reported in .
Our regression analysis showed that three of the factors tested are predictive of consensus in a UI design discussion: the experience of participants, number of triads, and mentions of synchronous communication.
Interestingly, none of the content metrics were significant.
One interpretation of this result is that who participates in a UI design discussion is more important than how many design alternatives are proposed or what arguments are made for the purpose of building consensus.
For example, this may be due to not having a facilitator in the discussion skilled at steering the group toward consensus .
Participation of experienced members may therefore compensate for the absence of trained facilitators, i.e., they have a better understanding of how to guide the discussion toward consensus.
Another possibility is that the content metrics used in our analysis were incomplete.
Future work should therefore examine additional metrics such as the use of different argument types  and rhetorical devices  to further test how content attributes may relate to consensus.
A number of factors perceived by our interviewees to relate to consensus did not show significance in the regression analysis.
For instance, interviewees mentioned contributing concrete evidence to an ongoing discussion such as usability tests of the design proposals and external links to interface examples positively affect consensus building.
One reason these factors did not correlate with consensus is that they were seldom performed.
For example, in our data set, mentions of usability appeared in only 0.06% of the consensus discussions and in 9% of the non-consensus discussions.
One way to foster the inclusion of concrete evidence is to establish specific community guidelines for discussing UI design issues.
Another method would be to configure a testing platform where participants can easily try a patch and provide feedback in the discussion without having to worry about applying the patch to their locally installed version of the product.
A second possible reason some of the factors did not show significance in the analysis is that we did not consider their context.
This may be due to not considering the helpfulness of the link targets.
Our work has several design implications for discussion interfaces w.r.t.
One implication is to enable discussion participants to quickly identify others with whom they have had prior interactions.
These community members could then be invited to join the discussion, thereby increasing the number of triads.
For example, for each discussion, the community software could maintain a list of members whose participation would form triads by analyzing the social graph  or history of participants' contributions .
Options could be offered for filtering the list, e.g., requiring a minimum number of prior interactions or specifying that only the interactions within specific types of design discussions be considered.
A related implication is to allow discussion participants to identify experienced members who may be willing to join the discussion.
Inviting appropriate people to join a discussion may not only aid consensus building, but may also assist community members in identifying discussions of interest.
For example, analogous to , the system could recommend experienced members appropriate for the discussion by considering the duration of their community membership, interest profiles, and recent activity within the community .
As before, options could be provided for modifying these search parameters.
Our analysis showed that participants value the comments contributed by experienced members or members with whom they have had prior interaction.
The discussion interface could therefore allow participants to filter comments within the current discussion contributed by others meeting these criteria or by including appropriate visual cues for these criteria within the comments.
Results of our interviews and inspection of discussions revealed that certain types of comments aid consensus building more than others.
For example, comments that strongly argue for or against design alternatives can build agreement, comments that summarize the discussion to date can help participants make sense of the thread, and comments that report the conclusions from synchronized discussions can help participants maintain context.
The discussion interface could therefore employ color codes or other visual cues to highlight these types of comments .
To classify comments, the author or other participants could be allowed to assign pre-defined community tags.
To reduce or eliminate the costs of tagging, an alternative would be to automatically infer the comment types, which could be modified by participants to correct any errors.
To further aid the consensus building process, recent key contributions to the discussion could also be highlighted.
For instance, comments that include key contributions such as the most recent design proposal, implementing or reviewing a recent patch, or changing the status of the discussion could be highlighted.
One limitation of this work is that our regression analysis did not include an exhaustive set of factors that may relate to consensus.
Additional metrics such as the language complexity of the messages, number of arguments for or against design proposals, the sentiment of those arguments, use of rhetorical devices, and advanced techniques for assessing expertise could be included in future analyses.
Second, our qualitative findings were derived from the responses of seventeen participants.
We look forward to collecting data from additional community members and analyzing how the responses relate to their different roles such as designer, developer, administrator, or end user.
Finally, our interaction data was collected from the UI design discussions in one open source software community.
Similar analyses should be performed for UI design discussions in other open source and distributed software projects to assess the generalizability of our results.
Consensus building is a critical component of UI design discussions in OSS as it promotes a better product and a stronger community.
In this paper, we studied consensus building in UI design discussions from an established OSS community using qualitative and quantitative methods.
Our results made three contributions.
One contribution was reporting user perspectives on the challenges of reaching consensus in UI design discussions, the techniques utilized for addressing the challenges, and the consequences of not reaching consensus.
A second contribution was analyzing how various metrics related to the content, process, and user relationships of the discussions correlate with reaching consensus.
The main result from this analysis shows that discussions having participants with more experience and prior interaction history are more likely to reach consensus.
Finally, we offered design implications for promoting consensus in distributed discussions of UI design issues.
One immediate direction for future work is to implement our design implications and test their utility and impact on the consensus building process.
A second direction is to analyze the logs of synchronized communications that occurred within the discussions studied to better understand the strategies used by participants and the effect of this medium on consensus.
