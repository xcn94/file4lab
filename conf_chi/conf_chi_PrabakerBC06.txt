Guidance in performing such tasks is obtained through application-specific help documents, on-line tutorials or FAQs, or through seeking help from experienced users.
Certain tasks are peculiar to particular work groups, with no single individual charged with documenting them.
Even where expert-authored documentation does exist, it is often not up-to-date, because it is difficult for documentation authors to keep pace with the bureaucratic, organizational, personnel, and software changes that are constant in most mid-to-large companies.
An alternative to documenting procedures is to automate them.
Complex, frequently performed tasks, such as installation of individual software packages on a single machine, are particularly well-suited to automation via scripts or wizards.
We note, however, that there are situations where documentation is more practical than automation.
For example, the task may not be performed sufficiently often to amortize the cost of producing an automation module.
Also, some tasks need monitoring by a human to evaluate complex conditions and make highvalue, non-automatable decisions, or to permit the human to learn a process which will need to be specialized in the future.
Thus, documentation will continue to play an important role, even as better and more sophisticated automation tools become available.
Communities of users for whom detailed task-specific documentation has substantial value include systems administrators, computer consultants, and software developers.
In this paper, we will focus on the last group, as representative of the types of users who need to quickly develop documentation to communicate workgroup-specific procedures.
Tasks for software developers include: setting up development environments, configuring workspaces, and aligning project parameters between team members.
Much existing documentation is informal and serves to communicate "how-to" knowledge among restricted working groups.
Using current practices, such documentation is both difficult to maintain and difficult to use properly.
In this paper, we propose a documentation system, called DocWizards, that uses programming by demonstration to support low-cost authoring and guided walkthrough techniques to improve document usability.
We report a comparative study between the use of DocWizards and traditional techniques for authoring and following documentation.
The study participants showed significant gains in efficiency and reduction in error rates when using DocWizards.
In addition, they expressed a clear preference for using the DocWizards tool, both for authoring and for following documentation.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Developers face a number of hurdles both in producing and in consuming how-to documentation, including a lack of adequate tools.
The tool most commonly used by developers for generating documentation is a standard word processor, such as Microsoft Word .
Using such non-specialized tools, creation of documentation is time consuming, and maintenance throughout the lifetime of a project difficult.
Indeed, because of the high costs of creating documentation, it is likely that many procedures are communicated through ephemeral and non-sharable methods such as phone conversations and instant messaging sessions.
Documentation, once produced, can also be difficult to follow accurately.
Users may struggle to locate GUI elements in the application interface based on the textual or graphical descriptions contained in the document.
In addition, users may have difficulty keeping track of their position in the documentation.
This is especially evident in digital documents where placeholders and other marking techniques are often absent.
Another problem is the difficulty posed by context-switching between an application and documentation displayed in a separate window.
As a result, users may lose their place in the document and even miss steps .
Finally, due to the lack of interactivity, users may have difficulty navigating through long and complex documents, particularly when there is a need to evaluate and traverse the correct branch in conditional statements .
We have developed a system, DocWizards, that enables document generation through the use of programming-bydemonstration  techniques.
Through automatic capture of user interactions with application GUIs, documentation can be created simply by demonstrating the procedure.
Once the procedure has been captured, semantic content can be added through operations such as inserting comments, grouping steps into semantically related subprocedures, and parameterizing steps to generalize inputs.
Additionally, by demonstrating different action sequences to be performed when the application is in different states, the author can create structure in the procedure, such as conditional statements.
Follow-me documentation is a form of guided walkthrough that helps users keep track of their place in the task.
It does this by highlighting the next step to be performed in the documentation and by visually identifying the relevant GUI elements in the target application.
Furthermore, conditional statements in the documentation are automatically evaluated and the user is directed along the correct conditional branch .
This paper details a study of these techniques for improving documentation practices.
The study addresses two main questions: "Can PBD techniques facilitate the process of creating how-to documentation?"
The rest of the paper is organized as follows: first, we survey related efforts in this field and outline the PBD, tutorial, and guided walkthrough technologies utilized by DocWizards.
Then, we describe the evaluation studies in which we compare use of DocWizards by developers against current practices for creating and using documentation.
Finally, we conclude with a discussion of the study's results and present ideas for further work in this area.
Our work is primarily related to three areas of research: programming by demonstration, tutorials, and guidedwalkthrough systems.
Programming by demonstration  is a well-established field; we refer the interested reader to the classic references .
Much of the work in PBD has focused on reducing the overhead of performing repetitive tasks, typically for restricted applications, such as HyperCard  or text editors .
PBD has also been used to create simple applications .
More closely related to our work is the use of PBD for gathering collective procedural knowledge from multiple demonstrations and distributing it as executable procedure models, as in the Sheepdog system .
Sheepdog, however, is not suitable for documentation generation because it relies on a complex statistical model of the task that cannot be converted into a human-readable format.
There are a number of systems that use recording techniques  to create tutorials.
For example, RWD's Info Pak Simulator creates tutorials and documentation from recordings of user interactions with an application interface.
The tutorials, however, only work in simulated environments, and not within live applications .
Current screen capture tools, such as Camtasia , also enable rapid documentation of interactions with application interfaces.
However, there are certain disadvantages of using these tools, which we believe have contributed to their infrequent use within software development communities.
These include: lack of editing capabilities causing low maintainability, difficulty in searching, screen real-estate issues, confusion caused by UI elements that change location , and difficulties with capturing and representing alternative pathways in the procedure .
Guided walkthrough systems have long used scaffolding or training-wheels to assist new users in learning a procedure or application.
Even less intrusive forms of scaffolding appears in systems that direct the user, but ultimately leave the user free to deviate at will .
Our work builds on these techniques.
Many of the existing systems that provide in-context application guidance separate the role of author and consumer .
Typically, system and application experts must create the content, which limits widespread adoption of the technology, and makes it difficult to maintain the documents.
In order to better understand the creation and use of internal, developer documentation, we conducted interviews with seven software developers within our organization who routinely collaborate with two or more developers on the same project.
We were able to distill these interviews into the following five findings:
To facilitate creation and utilization of documentation, we have created an instantiation of follow-me documentation called DocWizards.
The DocWizards interface is shown in Figure 1, and its major features will be described below.
For a more in-depth discussion of the system features and implementation we direct the interested reader to .
The developers we interviewed collaborated regularly with an average of six and no less than three other developers.
Those collaborators were often geographically dispersed.
We found that, on average, developers collaborated with others in three different locations, with only one developer working solely with on-site team members.
DocWizards supports the automatic, incremental creation of documentation by means of multiple demonstrations.
When used in "recording mode", DocWizards observes a user performing actions on the application's GUI, and captures the changes in the GUI resulting from those interactions.
DocWizards uses these observations to incrementally update a model of the task, which is displayed in human-readable form in the user interface.
We will use the terms script , p r o c e d u r e, and d o c u m e n t interchangeably to refer to this human-readable format.
When multiple demonstrations are provided, DocWizards identifies differences between the demonstrations and introduces structural changes, such as constructing if-thenelse statements, to explain them.
The DocWizards learning algorithm  identifies differences by comparing both the actions in the various demonstrations and the state of the on-screen widgets .
The structural changes introduced are immediately reflected in the DocWizards script , where they are distinguished from unchanged parts by use of italics in the text.
The script-like representation of the task supports limited editing operations, such as moving, copying, and deleting steps.
Additional recording features available to an author include support for inserting steps at a specified location, and for incrementally adding to the document by means of partial demonstrations.
Developers reported using multiple formats of instructional content that included standard, word processor-authored documentation and online team repositories, but also included more informal formats, such as instant messaging and email.
We also found that most documentation was not placed in a group-accessible location, but rather transferred directly from one developer to another.
Developers reported that, even when documentation existed, it was likely not maintained through the development cycle and quickly became outdated.
Most developers worked on projects that had undergone at least one major platform or development-tool shift.
These types of changes typically rendered the existing documentation obsolete.
As a result, many interviewees resort to searching for external documentation online, because it is typically more current.
All the developers interviewed or their colleagues authored documents that were meant for group or customer consumption.
The DocWizards system  guiding a user through previously-authored documentation which describes a procedure to be performed on the Eclipse development environment .
The DocWizards documentation highlights the next step  and draws a circle around the Eclipse GUI element associated with the next-step .
DocWizards provides means for an author to add semantic information to the document.
The author is able to edit the text of any step.
In addition, she can add comments to individual steps; these appear in the document just before the step.
The author can hierarchically group steps into semantically meaningful units, and provide a description fore ach group.
These groups are presented within a tree structure; each can be dynamically hidden or exposed by clicking with the mouse.
Finally, the author is able to parameterize particular steps.
Parameterization is the conversion of specific recorded information  into a request for a general parameter when the procedure is replayed.
DocWizards is designed to capture and replay events from the GUI of any application running on a specific platform.
The DocWizards implementation described in this paper is built on the SWT widget set, which is provided with the Eclipse Integrated Development Environment .
In general, any platform  can be instrumented; building the instrumentation layer has a fairly high up-front cost, but it enables DocWizards for all applications on that platform.
DocWizards provides guidance to the user by suggesting the next step to be performed throughout the course of the task.
This extends from previous work in "anticipation highlighting" used in the Eager system  and in Apple Guides .
The user is prompted both by highlighting the next step in the document text and the widgets associated with that step on the application GUI.
In Figure 1, the step "Supply item merlin.watson.ibm.com for Combo Box Host" is highlighted in the document, and the corresponding widget, the entry field called "Host " is circled.
In order to evaluate how the DocWizards approach compared with standard methods of developer-authored, internal documentation, we segmented the study into three phases: documentation authoring, quality assessment, and documentation utilization.
The documentation authoring phase compared the ability of developers to create documents using DocWizards' programming-by-demonstration approach and a traditional word processor.
We selected a word processor as the standard tool for creating documentation because our interviews showed that it is the most common tool used by developers for creating internal documentation; previous literature has validated this observation .
Since the documentation produced by DocWizards is used in a way that is fundamentally different from traditional documentation, we generated a printed version of the DocWizards documents that could be directly compared to those authored using a word processor.
Finally, in the documentation utilization phase of the study we compared the user experiences when employing the follow-me features of DocWizards versus traditional documentation.
Clarity: The document is clearly written in a way that supports comprehension.
Does the phrasing of the steps make performing each step intuitive?
Is the overall purpose of each subsection or step communicated?
How understandable is the document, in whole?
Is the terminology used throughout the document consistent?
Eight professional software developers in our organization participated in the authoring study.
All of the participants are members of project teams that collaborate on software development.
None of these developers had any previous experience using DocWizards to create documentation nor had they previously documented the particular procedure we specified.
Seven of the eight participants rated themselves as Eclipse experienced ; the other participant rated herself as a `beginner'.
All users except the Eclipse beginner had been using Eclipse regularly for at least one year.
All participants were experienced code developers .
Finally, six of the eight users had previous experience in authoring documentation as developers.
We created a sample task by slightly altering a real and representative Eclipse procedure, collected from a developer during the initial interviews.
The task consisted of performing the following steps within Eclipse: creating a CVS repository connection; checking-out a project, modifying and committing a CVS controlled file; and configuring the Eclipse preferences required to build the project.
The total task contained 87 distinct steps, and included a conditional statement that required the user to perform different actions based on the existence or absence of a file in the environment.
In addition, the task required that users properly parameterize certain steps that captured actual login and password strings.
We recorded a screen-grab video of the task being performed on the Eclipse UI with a voice-over, which provides step-by-step instruction.
During each session, participants were asked to view the procedure video in its entirety, after which they could ask questions and obtain clarifications.
They were then asked to document the procedure in the video with the tool they were given , supplying groupings and annotations when appropriate.
Since we employed a within-subjects methodology, we balanced the order of use of the two tools to account for procedure learning effects.
Users were asked to think out loud during the study.
We ended each authoring session when the participant claimed to have completed the documentation.
Each participant was involved in two individual study sessions, held at least one day apart.
The DocWizards session lasted one and a half hours and the word processor session lasted one hour .
During the DocWizards authoring session, participants were first given an introduction and demonstration of how to use DocWizards' authoring functionality.
We recorded the time-to-completion for each authoring session.
We also administered a post-session questionnaire to gain insight into participants' subjective impressions of each tool, and a post-study questionnaire to gauge participants' overall tool preference.
We recorded critical incidents that took place during each session, paying particular attention to any difficulties users were having with authoring using DocWizards.
Three software developers participated as judges to assess the quality of the documentation produced during the first phase of the study.
Previous research has shown that three judges are sufficient to locate most of the errors in a heuristic evaluation .
We employed the same number here, since our quality assessment procedure is similar to performing an evaluation with domain-specific heuristics.
The judges were all experienced with software documentation, with the Eclipse IDE, and with the procedure that was being documented in the study.
Each judge was presented with a paper evaluation packet containing a judging instruction sheet, eight word processor documents, eight DocWizards documents, and sixteen quality evaluation forms.
We printed the word processor documents in their existing form.
The DocWizards procedures were converted into an html representation and then printed.
The html representation contained the same level of detail as the script shown in Figure 1, but had reduced legibility  due to bugs in the html formatter.
Errors in the documents were marked on the printed sheets by the study proctors, to ensure that the judges noticed them.
The judges did not know the factors involved in the experiment design, including the fact that there were two sets documents, each generated by a different tool.
We selected the highest-scoring DocWizards and word processor documents, based on the evaluation in the quality assessment portion of the study.
The best DocWizards document scored slightly lower  than the best word processor document  in the aggregate score.
Since both documents contained a few minor errors and possible ambiguities, we manually corrected them, to ensure that differences in using the documents could be attributed to their presentation and not to their content.
The word processor document was printed out and stapled.
The DocWizards document was pre-loaded into the DocWizards application.
Each judge was presented with the evaluation packet and asked to review all the documents before assessing their quality.
They were asked to evaluate the quality of each document according to its clarity, structure, and accuracy.
Clarity and structure were assessed according to the criteria listed on the evaluation sheet .
Accuracy was evaluated based on the frequency and severity of errors in each document, as annotated by the study proctor.
The degree to which judges agreed with the main statements in Table 1  were recorded on a 5-point Likert-scale that ranged from "Strongly Disagree"  to "Strongly Agree" .
A total score for each document was created by adding the three individual scores; the total score therefore had a maximum value of 15 points.
The total scores produced by the three judges were combined to create an aggregate score, which had a possible total of 45 points.
The judges were given three days to finish the quality assessment and were allowed to work at their own pace.
Each subject participated in two separate study sessions, one using the DocWizards document, the other using the word processor document.
During the DocWizards session, subjects were first introduced to DocWizards and given instruction on how to use it to follow a procedure.
During each session, the participants were given the documentation, asked to begin when ready, and told to notify us when they felt they had completed the task.
We used a within-subjects methodology, so the order of DocWizards and paper documentation sessions was balanced between the participants.
In addition, we told participants that the second procedure was similar in character, but different than the first.
We found that this instruction was sufficient to encourage them to perform each step by referring to the currently presented documentation, rather than from memory.
Subjects were asked to think out loud while following the documentation.
We recorded time-to-completion for each documentationuse session.
In addition, we administered a post-session questionnaire to gain insight into participants' subjective impressions of each tool used, and a post-study questionnaire to gauge participants' overall tool preference.
We also recorded any critical incidents that took place during the study, including errors made and corrected.
We analyzed the data using two tests: the one-sided paired t-test , and the Wilcoxon signed rank test  .
These tests are appropriate for comparing two groups when each subject belongs to both groups.
The paired t-test assumes that, under the null hypothesis, the differences between the values measured for each pair are independent and identically normally distributed.
Therefore, it is more generally applicable than the t-test, and it is only slightly less powerful when the differences are, in fact, identically normally distributed.
In the documentation authoring study, we found that while documentation was authored more quickly using DocWizards  than using a word processor , this difference was not statistically significant .
However, analysis of the number of errors committed showed some important differences between the tools.
The DocWizards group produced documents containing a total of 20 non-critical errors , and 10 critical errors .
The word processor documents contained 19 non-critical errors and 20 critical errors.
While these differences in critical errors are not statistically significant at the 0.05 significance level , their borderline p-values suggest that DocWizards might enable participants to create more accurate documentation.
Users were very positive about using DocWizards as a documentation-authoring tool.
Seven of the eight participants "preferred" using DocWizards to a word processor and, of these, two "strongly preferred" it; the remaining user had "no preference".
Six participants said DocWizards was "easy" to learn.
Two users found it "difficult", and explained that they were confused by the use of separate record and playback modes within DocWizards.
Similarly, six subjects found DocWizards "easy" to use , with one finding it "difficult" and one claiming it was "neither easy nor difficult".
The quality assessment portion of the study showed that there was also no significant difference in the quality of the resulting procedures created with the two tools.
Table 2 contains the structure, clarity, and accuracy scores for DocWizards and Word, averaged over all documents and all judges.
Although the word processor group scored higher in all three quality metrics, testing at the 0.05 significance level failed to reject the hypothesis of no difference among the two groups in any of the three metrics , although the results for clarity are not conclusive.
The d o c u m e n t a t i o n utilization study shows faster completion of the task when using DocWizards than when using standard paper documentation.
In addition, we noticed that with DocWizards, subjects both committed fewer critical errors during the execution of the task and recovered from committed errors more often than when using paper documentation .
Participants seemed very enthusiastic about using DocWizards as a documentation tool.
Six subjects "preferred" using DocWizards to traditional paper documentation with half of those "strongly preferring" it; one participant "preferred" paper and one had "no preference".
It is interesting to note that the only subject who preferred paper documentation actually completed the task faster and with fewer errors when using DocWizards; he felt that while DocWizards worked well for the current procedure, it may not work for all types of procedures.
We also asked participants their perception of the difficulty of performing the task with the given documentation, and how confident they were that they had completed the task correctly.
Users found that DocWizards enabled them to complete the task more easily than paper documentation .
Similarly, all users were very confident of having performed the task correctly with DocWizards, but not with the paper documentation .
Through its use of programming-by-demonstration and guided walkthrough techniques, DocWizards facilitates the authoring and use of documentation.
It also provides benefits in reducing errors while authoring and following documentation.
Participants had a strong preference for using DocWizards to create and follow documentation over traditional methods.
Although our data shows that using DocWizards enabled only slightly faster creation of documentation, we feel that experience with using the tool would significantly tip the balance in favor of DocWizards.
Anecdotally, we observed expert DocWizards users, not participating in the study, completing the authoring task in less than 15 minutes, compared with 29:49 for DocWizard subjects and 34:39 for word processor subjects.
Therefore, we feel that with additional DocWizards experience, users would be able to perform an authoring task significantly faster than using a word processor.
Another positive result of the authoring study is that subjects committed half the number of critical errors with DocWizards as with the word processor.
This is mostly attributable to a substantial reduction in spelling and syntax errors due to DocWizards' automatic capture of widget text and type information.
Although not statistically significant, we did observe a difference between the two document sets in the structure and particularly the clarity metrics.
The judges' comments made it clear that structure often scored lower for DocWizards documents due to bugs in how DocWizards formatted the html output .
Clarity suffered somewhat in the DocWizards documents due to low human-readability of automatically captured widget names and types.
This problem can be readily corrected with an enhanced naming scheme.
Much of the time gain in using documentation seemed to stem from improved navigation when using DocWizards' guided walkthrough highlighting.
Most subjects were observed navigating purely through the on-application highlights, which relieved them from the need to map between descriptions of widgets in the document and their location on the application.
Furthermore, for many widget types, the on-application highlights were sufficient to specify the action to be performed, without the user needing to refer to the document; for example, circling a radio button or checkbox is sufficient to indicate that a selection is required.
Another interesting finding was the reduction in the number of errors that users committed while using DocWizards to complete a procedure.
Users were more likely to notice performing an incorrect action or skipping a crucial step than with traditional documentation.
We feel this benefit is largely a side-effect of the next-step highlighting.
Users of word processor-produced documents were not given any analogous feedback on improperly performed actions.
In essence, the next-step and on-application highlights provide the users some semantic awareness, which can inform them of syntactically valid, but erroneous inputs.
We noted an even split between two different styles of using annotation and editing features.
Some users  preferred to perform actions such as adding comments, parameterizing steps, and creating hierarchical groupings, immediately after recording the relevant steps.
Other users  delayed these annotations activities; these users seemed to prefer to stay in a specific mode  for long chunks of time instead of continuously switching between the two modes.
Interestingly, we noted several instances where a delayed annotator made vocal mention of needing to perform an annotation, delayed that action, and ultimately forgot to complete it upon reaching the end of the procedure.
We found that even novice users were able to use multiple demonstrations to create conditional statements within documentation.
This could be accomplished by demonstrating the small portion of the procedure that deviated from the original recording.
To create the conditional statement, users had to make the appropriate changes to their environment  as well as indicate the starting point of the new demonstration within the existing DocWizards script.
Differences in annotation styles indicate that there is benefit to supporting annotation and editing both during and after the recording process.
Special care should be taken to provide delayed annotators with mechanisms for reminding themselves to perform important annotations, such as parameterization.
Because DocWizards tracks the current step within the procedure and displays it unobtrusively, users had fewer difficulties following the instructions, and were able to recover from errors more effectively.
In a guided walkthrough system, this type of peripheral information is remarkably effective because it both reassures users that they are performing the task correctly and prevents them from advancing in the document when they perform a step incorrectly.
By updating the task documentation immediately after recording each action, DocWizards allows authors to observe and reflect upon their actions in real time.
This is crucial functionality because DocWizards allows the authors to demonstrate an alternative pathway for a specific portion of a task .
In order to effectively leverage this capability, users must be able to quickly locate the exact step they are supplementing and the context surrounding that step.
We also observed that this immediate feedback provided new users with early confidence in the system and allowed them to concentrate on demonstrating the task, reducing the need to repeatedly check the recorded documentation throughout the authoring session.
We have presented an evaluation of the DocWizards system, a documentation authoring and playback tool that employs programming-by-demonstration and guided walkthrough techniques.
In a study of software developers, we have shown that a user guide for a substantial task can be authored using DocWizards with production time comparable to that required by a traditional documentation tool.
With additional user training, we anticipate DocWizards authoring will be substantially faster.
The documentation produced with DocWizards had a lower error rate and comparable quality to that produced with the word processor.
Users completed the task substantially faster under the guidance of DocWizards than when following written documentation.
Additionally, the error rate when using DocWizards was lower.
Users expressed a clear preference for DocWizards both for authoring and for playback.
These results point to the utility of both programming-bydemonstration and guided walkthrough techniques in an "application how-to" documentation system.
DocWizards uses multiple forms of guidance that provide complementary, but distinct benefits to the user.
Next-step highlighting allows users to see their current position within the document, and also understand surrounding context .
While performing a series of steps during the word processor session , one user mentioned, "This part is hardest, because I have to remember which steps I've already done".
The on-application highlighting vastly improved a user's ability to locate relevant UI objects within the application; one user commented, "I'm not sure I would have known where the `Add CVS Repository ' was without the guide."
This type of navigation problem was evident when participants used the paper documentation; we often heard users say, "Where do I put that," or noticed them systematically searching the interface for a control.
In addition, the widget highlighting helped to disambiguate similarly named UI controls and reduced the burden of context-switching between the documentation and the application.
While our work with DocWizards is encouraging, there are still questions that further studies will need to address.
From personal experience, we believe that expert users of DocWizards would be substantially more efficient at producing documentation than the novice authors who participated in the user study.
Gains in efficiency should be achieved both from experience and from obtaining access to a variety of authoring features that, in the interests of simplicity, were not exposed during the study.
Additional studies are needed to characterize both the learning curve and the benefits of exposing the additional features.
An important question is whether PBD technology produces documentation that is more readily maintainable than using traditional techniques.
The central question is whether partial recording techniques can be readily used to update or replace sections of a procedure that have changed over time.
An additional lab study that looks at the ability of users to maintain a document during simulated procedure evolution should be combined with corresponding field studies.
In the playback study, subjects were instructed to perform the task correctly and efficiently.
Some commented that they were merely following the on-application highlighting, rather than trying to understand each step in its larger semantic context.
This indicates that use of DocWizards as a teaching tool, rather than a documentation/intelligent help agent, might require a different interaction paradigm.
On the other hand, our study indicates that our subtle-guidance approach may provide the appropriate scaffolding for users to more quickly understand a novel interface.
Since the user study was not designed to measure procedure retention or application understanding, additional work is needed to quantify the effectiveness of the DocWizards approach to knowledge transfer.
Lastly, future comparative studies are warranted to better understand possible benefits of using DocWizards over other sophisticated documentation types such as those produced by screen capture tools.
We would like to thank the following researchers at the IBM T.J. Watson Research Center for their helpful comments and advice: Daniel Oblinger, Tessa Lau, John Karat, Wendy Kellog, Susan Spraragen, and Tracee Wolf.
We are grateful to Mark Brodie, Aaron Brown, and Nalini Belaramani, for generously accepting to serve as judges.
Bergman, L.D., Castelli, V., Lau, T.A., and Oblinger, D. DocWizards: a system for authoring follow-me documentation wizards.
Prompting, feedback and error correction in the design of the scenario machine.
Watch what I do: programming by demonstration.
