Even though time to completion of a task is only one aspect of a promising application, it is an important factor for a large set of applications ranging from small games to reservation systems, from sub tasks of larger systems to support and search systems.
This is especially the case for applications designed as side tasks or that exploit people's precious and short amount of spare time, e.g., between two tasks or while waiting for a meeting or the bus.
These fundamentally rely on quick and hassle-free interactions.
In addition to games and entertainment, mobile phones are increasingly used to enhance productivity and throughput in various fields like security or ticket sale.
In this paper we focus on time/performance predictions for the evolving domain of mobile phone interactions building upon KLM.
This choice is motivated by the large number of publications in the CHI environment using KLM in a variety of emerging application domains.
Many projects in cognitive modelling such as ACT-R  rely on such data in ongoing research areas like in-vehicle interfaces.
We adopt and define a set of operators giving sound and study-based estimates of performance measures for each of them.
Developers of mobile applications, which possibly include identification tags and smart objects, can then describe tasks as a sequence of these operators and predict user interaction times without even needing to create prototypes.
Table 2 shows an annotated excerpt of a model resulting from the new mobile phone KLM developed in this paper.
As an additional application area, we propose crossplatform evaluation as ongoing work in our lab.
It is easy to enhance any type of prototype like a paper or interactive HTML/Flash prototype to generate a KLM of a given task sequence.
Our model estimates execution time of those tasks on, e.g., a mobile phone without the need to have a single line of code actually running on a phone.
The design of applications using mobile devices needs a different quality assessment than those known for desktop applications.
Of the many aspects that have to be taken into account, one important criterion is the average time users need to complete a task.
For interactions with the mouse, keyboard or touch screens, there exist models that predict interaction times like Fitts' law or the Keystroke-Level Model .
This paper shows parallels to these models for advanced interactions with mobile phones targeted at pervasive services, including near field communication as well as built-in cameras and sensors.
Applications can be evaluated with respect to user performance time without having a prototype running on the phone.
To accomplish that, we extend the known KLM by identifying basic interaction elements for mobile phones and give estimates for expert user performance derived from several user tests.
Experience has shown that it is essential to assess designs and applications early in the development phase.
The phone company NYNEX probably saved millions of dollars  because the Keystroke-Level Model  was used to find out that the interaction performance of a newly designed workstation would have been worse than the existing system.
This was possible without having to actually build and test the new system at all.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Modelling user tasks and processes in general attained much attention from researchers, not only in the last decades.
The pioneering work of Card, Moran and Newell introduced the GOMS  model in 1980 .
It is often cited as one of the most mature engineering models of human performance.
The GOMS elements enable designers to model expert user behaviour during a given task and therefore to analyse user complexity for interactive systems including cognitive information processing activities.
Of course, even with certain extensions developed later, this family of models can only account for a small subset of aspects that decide whether a product is successful or not.
However, many empirical studies have confirmed that it suffices to support justified choices between similar approaches to the same problem .
In its beginning, GOMS was targeted mainly at text editing tasks on office desktop computers.
For that purpose, the Keystroke-Level Model , a tailored instance of GOMS, was developed.
A task can be described using operators that model unit tasks like key presses, pointing, hand switches between mouse and keyboard, mental acts, system response times and others.
With a set of user studies the authors were able to give estimates for the duration of these actions and evaluate those estimates.
Several projects  successfully used and validated those values in various application areas.
Others slightly adjusted or added one or more operators for a specific application setting .
Variants of GOMS have been applied to many different application domains: phone operators , visual and auditory perception , a tool selection technique for tablet computers  , and several others mentioned below and in .
Pavlovych and Stuerzlinger , non-perfect users are considered using the cognitive load operator to model input verification.
Although we do not focus on text messages, our model supports this view using Micro Attention Shifts explained later.
The authors conclude that the models give only rough approximations to real user behaviour for text input.
However, the models can correctly predict which input methods are faster than others .
In addition to text input, Mori et al.
There is to our knowledge no published research yet that includes new mobile interaction techniques in its model.
A beginning is indicated in Luo and John  and its followup  where the authors show that the method can be soundly applied to handheld devices using stylus-based interfaces.
They also present a tool they developed to automatically generate KLM models from storyboard descriptions and state that they plan to apply such research to novel interfaces like speech or gestures.
After a short treatment of mobile phone interaction types we first briefly describe the set of new, adapted and adopted parameters of our model and then present the studies that led to updated time values.
Their results are summarised and an evaluation of the values is described.
We close the paper with a discussion of the results.
In this paper, we are building upon KLM, revisiting the timing specifications for existing operators and extending it with new operators necessary to describe interaction with mobile phones.
The number of possible types of mobile phone interaction have increased and achieved much attention from various sources in the last years.
However, most research on performance measures for phone users has yet been limited to the input of text for short messages: An initial work by Dunlop and Crossan , shows KLM operator sequences for three different text entry methods .
However, the authors adopted the original operator values used for desktop interaction which proved to be imprecise in this new environment.
This is improved in How and Kan  where the presented model is more fine-grained.
They define 13 operators that more directly map onto the phone keyboard interface according to the different input methods .
New times are gathered from video taped sessions with a small set of subjects and a message typing task.
Mobile phones have mainly been used to make phone calls, send text messages, and sometimes as calendar.
However, other uses are becoming more and more popular.
Taking pictures, surfing the web, storing data, and playing music as well as videos are some of them.
Additionally, researchers started to use it as universal remote control  and suggest further interactions with the world .
The user interacts with the mobile device and the mobile device interacts with the smart object.
This allows the implementation of systems envisioned, e.g., in  and allows bridges to be built between the physical and virtual worlds using devices that many people carry with them, c.f.
Although many people still think that mobile phone applications include games and entertainment only, phones are increasingly used to enhance productivity.
In Japan, for example, it is common to buy tickets for public transport with the phone.
Security personnel can use a tag reading mobile device to quickly log the places they have checked.
Up to now there is no user performance model available for physical mobile interactions.
They also show that timing is an issue for users.
However, no quantitative performance numbers have been measured and only individual opinions of subjects are given.
Some operators have to be added to describe interactions that do not exist in the standard desktop metaphor.
Others have to be examined closely to ensure that the original timing specifications are still applicable or to be able to derive new values.
Others again are not applicable to the phone setting at all.
Besides number entry and menu selection there are several ways physical mobile interactions can be implemented.
In  and , as well as in , projects are described using prototypical implementations of three basic physical selection techniques, Touching , Pointing , or object recognition , and Scanning .
Another interaction method we investigated is performing gestures.
The underlying technology is based on tracking the phone by an external camera, using the phone's camera , or reading built-in sensors .
We keep the revised KLM as general as possible to be able to offer operators to model most of these types of actions and give accurate estimates for some special cases.
Thus, a Macro Attention Shift operator models the time needed to shift the focus between the contents on the screen of the mobile device to an object  in the real world and vice versa.
The original KLM does not need to consider this case since it assumes that the whole interaction session takes place on one single screen.
Although this can also happen in the desktop setting, this has not been mentioned in the original KLM.
A possible explanation is the expert user assumption: users were not expected to need to look at the keyboard at all and therefore the time was incorporated into the Keystroke operator.
This is different on mobile phones since the mapping of the keys is considerably more complex.
Even experienced users tend to spend some time to confirm their input.
Thus, the Micro Attention Shift operator allows a much more fine grained control over user interaction.
It can also model uncertainty when, e.g., entering critical data like credit card numbers.
Even though KLM is targeted at expert users, immediate corrections of incorrectly pressed buttons  have explicitly been allowed and incorporated.
There are 4 factors influencing the value of K in our setting.
Distances between buttons are much smaller on a phone than on a standard keyboard which removes the need for head and larger eye movements and indicates a smaller value for K. However, buttons are in general harder to spot and to press and people use only one or two fingers to type .
Finally, all but the most experienced users check and validate their input at some points needing some Micro Attention Shifts.
The last three aspects suggest a higher value.
For text input, we concentrate on multi-tap which, based on figures presented from industry in a panel at MobileHCI 2006, is still used by about every second user.
In addition, multi-tap proves useful for comparisons with previous research.
Variants like T9, which can also be easily modelled by KLM, are often seen as too complex and do not work well for names or addresses.
Since interactions with mobile phones take place in the real world, people are likely to be distracted from their main task by approaching people, passing cars, conversations, etc.
This is accounted for by the Distraction operator.
In contrast to all other operators, distraction is modelled as a multiplicative factor modifying the times of other operators.
This general operator models the time needed to execute a certain complex action with the phone that cannot sensibly be subdivided into smaller tasks and modelled with a combination of other operators.
Possible actions include touching RFID tags, or focus to take a picture of a marker or other objects.
The time for this operator highly depends on the type of action and, similar to the response time operator R, this must be input to the model  notation.
We give values for some typical actions.
This is in general not applicable for mobile phone applications except in rare applications in which a cursor can be controlled using the joystick or special buttons.
Such interactions can be modelled using appropriate Keystrokes since they are not based on Fitts' Law as is the original interpretation of P. For larger screens or handheld devices using stylus input, we refer to Luo and John  who updated the values for Pointing for touch and stylus use.
In our context, this models the time needed to move the phone from one place to another possibly to perform some Action at that point .
This operation is similarly based on Fitts' Law as the original operator.
In the KLM for the desktop, it is generally assumed that users are already sitting in front of their keyboard, mouse and monitor, ready to initiate the next task.
The phone introduces a completely different setting since people have to carry out some preparations  before being able to use it in most circumstances.
The value depends on whether the interaction was initiated by the user or externally, e.g., by an incoming call.
In the original KLM, this modelled the movement of the hand from the keyboard to the mouse or back.
For mobile phone interactions, this is not relevant.
However, the action of moving the phone from a position where one can read the screen to one's ear or back is an analogous motion and similarly important.
Therefore, we use the Homing operator whenever the user changes from listening and speaking to reading the screen or vice versa.
In this setting H can be expected to be somewhat smaller but close to Pointing P.
It can be adopted as defined, and existing usage guidelines, e.g.
Since we use new operators, we give additional guidelines in a later section on the Mental Act operator.
However, these values were taken from much specialised applications.
For general settings, a higher average value can be assumed.
Larger values than the original value are reported in Manes et al.
Current cognitive architectures like ACT-R  confirm the original value.
We also found no evidence to justify a change.
We taped all these actions and extracted timing information from 11 people, aged 25-54 with an average of 34.6 years, 4 female, all used to standard mobile phone interaction.
Those values are highly diverse, however, since people have extremely different ways to store the phone .
A best-case study in which the phone was placed in front of the users on the table who initiate the action themselves or expect a call gives a median of I = 1.18 seconds.
Thus, if no assumptions can be made, we suggest an average value of I = 4.61 seconds.
For repeated or expected interaction the I = 1.18 seconds estimate should be used.
In the same study we measured times needed to switch from a phone position where the screen can be read to one close to the ear and back .
The times of all people under observation were very similar and we extracted a median of H = 0.95 seconds.
As expected this is only slightly smaller than the found value of Pointing P = 1.00 second described below.
To model the fact that people have to refocus on the phone's screen and continue their interrupted action, we strongly suggest that a Mental Act operator be placed after a Homing away from the ear as specified in the heuristics given in the section about the Mental Act operator.
To be able to use the model in practice and to predict the time required for certain complex tasks based on the model, the duration of a single application of an operator must be known.
In 7 studies we acquired data to estimate the times.
We recruited volunteers of various backgrounds  on a study by study basis  and did not see any differences caused by gender with, altogether, 41% female participants.
Before conducting each of the studies, questionnaires were given to the users to clarify their experience with mobile phones in general and more specifically the mobile phone interaction technique under observation.
We also aimed to adhere to the expert user assumption by running one or several training sessions with each user.
Participants had to repeat the same or similar tasks until they and we were confident that they will to make only minimal errors.
All but one studies were executed in various, every day, non-laboratory situations.
To measure execution times for Pointing and Action, we needed an application where such interactions occur quite often.
In some countries like Japan, visual markers and near field communication  are already very wide-spread technologies in the public .
This is not yet the case in Europe.
Therefore, in conjunction with other projects run in our lab , we prepared a movie poster acting as user interface for several interaction methods.
Users can select and use different services by, e.g., touching NFC tags or taking pictures of visual markers.
We asked users to follow the brief instructions on the poster and let them buy tickets for their favourite movies in a theatre close to them.
From the videotaped footage we were able to extract timing measurements regarding the movement  and alignment  of the phone to the NFC tag, and the approach  and focus  of the phone to take a picture of a marker.
The user study was carried out with 9 persons, aged 22-46, with an average of 28.6 years, 2 female.
From a set of 64 error free video taped actions, we deduced Pointing P = 1.00 second.
The 37 NFC interactions showed that aiming at the NFC tag itself did not need any separate action besides the phone movement and we define ANFC = 0.
The remaining 27 photographs of visual markers led to a value of Apicture = 1.23 seconds for correct positioning and focussing .
Note also that the time needed by the system to recognise the tag or interpret the marker and initiate the appropriate action is not included in the Pointing or Action operator but must be modelled by with the Response Time operator R.
Using a careful frame-by-frame manual analysis of the video tapes from the study presented in the last section, we counted the number and determined the duration of head and eye movements that indicate an attention switch from the phone to the poster and vice versa.
We extracted a total of 121 attention shifts.
The times of the shifts in one direction do not differ significantly at all from those in the other direction .
Thus, we propose a common value of SMacro = 0.36 seconds.
To measure gesture input, we used a Samsung SGH-E760 phone with built-in acceleration sensors and a few games and standard applications that can be controlled using simple gestures .
The times for each gesture was extracted from videos of 6 different types of gestures, each done by 10 people .
Since the possible gestures were quite similar in type and time, the measurements resulted in one value for all gestures and we set G = 0.80 seconds.
Mobile phones in general suggest a split into three regions: display, hot keys, and keypad .
Finding out when and to which section people looked proved to be infeasible with conventional video taping.
Therefore we used an eye gaze tracker from Eye Response Technologies that samples images with a sufficient rate of 60Hz.
The participants had to run three pre-set tasks that included writing a text message , changing the ring-tone , and setting the time of the alarm-clock .
Keystrokes were measured with a small J2ME program that logs timestamps of key presses and releases into a file on the mobile phone .
Each person entered two mobile phone numbers of their own choice.
All of them used the widespread one-hand thumb entry method.
During the study we observed that no errors were made.
The Nokia N90 phone features a standard 12 button keypad.
The average of the whole interaction times is 4.63 seconds and the time per keystroke was calculated to be K = 0.39 seconds.
For the five most experienced users we got a value of K = 0.33 seconds per keystroke.
Another interesting value we measured is the mere physical action of pressing and releasing a key.
It was measured by the key logger to be 0.13 seconds  and will be used to calculate Finger Movement time in the next section.
We measured standard keypad input separately from the hotkeys, although we did not take additional special hotkeys into account that can be found on several phone models on the side or top of the phone.
For the hotkeys of the N90 , K = 0.16 seconds were measured as a median.
The smaller value can be easily explained with the smaller distance between buttons and the larger average size as well as the more direct and known semantic mapping of the buttons.
The findings are close to those of other research.
The original KLM suggests values between 0.08 and 1.20 with 0.28 seconds for a user with average routine on a standard sized desktop QWERTY keyboard.
An average value for typing random characters is also mentioned.
This better resembles text input on mobile phones.
The suggested value of 0.50 seconds again comes quite close to our estimate.
All 10 people  were allowed to use their own mobile phone and we ran several sessions to ensure error free interaction.
We then automatically calculated the number and time of gaze position changes between the regions from the logged data.
Figure 4 shows data overlaid on some phones.
We counted more than 1500 shifts between the three regions and found the following values: display  hotkeys 0.12 seconds, display  keypad 0.14 seconds, and keypad  hotkeys 0.04 seconds.
If no distinction should or can be made between the single sections of the phone, we suggest using the median of all values of SMicro = 0.14 seconds.
These values are meant for individual button presses or number input only.
Several projects already verified and improved Keystroke-Level Modelling of more complex variants of text entry.
The results are quite diverse: Dunlop and Crossan  predict a value of 2.01 and 1.84 seconds on average for multi-tap and predictive text input, respectively.
How and Kan  specify 1.32 and 1.00 for the same techniques, assuming an average SMS length of 60 characters.
The comparatively very small values result from only modelling the pointing component with the help of Fitts' Law, neglecting the time needed to find and actually press the buttons as well as verification.
Pavlovych and Stuerzlinger  calculate values ranging from 2.04 to 1.58 seconds for different input methods and suggest how those times should be adjusted for different states of routine.
These results might indicate that KLM does not work too well in this respect.
However, James and Reischel show in  that although the predicted times can differ from actual performance times, relative relations between different designs prove to be correct and significant.
Because of the rich set of publications in that area, we have not conducted detailed studies for text entry.
Some values were taken from the study for the Distraction operator described later.
Some parameters cannot be measured in a single specific setting.
The system response time, for example, differs strongly depending on the phone model, the application running on it, and the action invoked.
Also, the influence of mental preparation and the appropriate placement of the Mental Act operator has always been a complex issue in KLM models.
Kieras  gives several suggestions and heuristics specifying where and in what quantity the operator should be placed that also apply to the model as used in this paper.
Another parameter that belongs to the same category is the new Distraction operator D. It has not been treated in previous research on task models but we found that it has a considerable impact on time performance and there is a whole set of applications especially in the area of mobile interactions that are influenced by distractive and disruptive factors.
From our observations during the tests for the Keystroke parameter we can report that most users verified less than every second number they typed.
This means that the average total time needed to enter a 11 digit number was actually composed of 11 physical key presses, on average 4 Micro Attention Shifts, and 10 Finger Movements.
Since we know the values of the other operators, we can calculate F to be 0.24 seconds for all but the 5 quickest users.
According to our experience, full experts tend to only check their typing once during writing.
Modelling that behaviour for the 5 quickest users results in the median value of F = 0.22.
To additionally verify those assumptions, we ran an extra 10 tests using a mobile phone with a blinded display eliminating the use of Micro Attention Shifts.
The upshot of this study was a median of F = 0.23 seconds.
These results from the 323 key strokes done in the tests make it a very stable parameter.
Figure 6 shows movement paths of three sample phone numbers types in the tests.
The value is also very close to what others like Silfverberg et al.
Our studies indicate that the time drops to F = 0.16 seconds on average.
Depending on the interaction, designers can choose which value fits better or use an average according to an assumed ratio of key uses.
As already discussed, information on system response times is supposed to be input to the model since these are highly diverse.
We can, however, support the assumption of Silfverberg, MacKenzie and Korhonen  that key presses in general have immediate feedback.
Menu browsing and selection was also running in negligible amounts of time on the phones we investigated.
Starting applications needed anything between 0 and 6 seconds.
For our setting, we only explicitly give values for the special cases when tags are detected  or pictures taken.
Our 10 tests with a Nokia 3220 with a built-in NFC reader showed that the processing of a tag takes on average RNFC = 2.58 seconds.
Using a Nokia N71, measurements for visual marker processing resulted in Rmarker = 2.22 seconds.
Interactions in the real world have to take into consideration various events that divert the concentration on the task at hand.
This includes approaching people, passing cars, traffic lights, conversations, etc.
Situations in which it is known that such distractions occur frequently  can be modelled with the Distraction operator.
People cope with such situations in different ways.
They use their peripheral view, make quick glances, or introduce pauses.
Initial tests showed that the behaviour also depends on the type of task.
Thus, distraction can not be easily modelled as certain specific actions.
Through our tests we found that it is more appropriate to model distraction as a multiplicative factor rather than an additive operator.
Although the type and consequences of distractions can be manifold, several studies of distraction and multi-tasking, e.g., by D. D. Salvucci , proved feasible in cognitive modelling.
We give a simplified and rough but nevertheless justified idea how a task is probably slowed down by common side activities.
We ran three experiments, each with the same 10 people, aged 24-33, with an average of 26.7 years, 3 female.
Subjects had to write a short message  on their own phone in 3 different settings: a silent room , standing on a busy street  and walking along and crossing that street .
To obviate the possibility of sequence effects, we varied the order in which the participants conducted those trials.
They also freely chose the contents of the message to write.
Typing speed of the participants varied considerably .
However, relative changes in the performance of each user are quite consistent.
Experiments 2 and 3 revealed in an analysis of variance that the expected increase in time demand for distracted tasks is relevant well beyond the 5% level .
The results suggest to add XSlight = 6% of the modelled time to the whole interaction if there is an anticipated slight distraction and XStrong = 21% for distractions that force persons to deviate from their task in a more rigorous or regular fashion.
As said earlier, we found no reason to change the value of M = 1.35 seconds from the original KLM.
However, since we added and slightly changed the interpretation of some operators, we update the heuristics from Kieras  to place M's: Use rule 0 to place M's and then cycle through rules 1 to 5 for each M to see whether it should be deleted.
Rule 0 Place M's in front of all K's, H's, SMacro's and G's.
Rule 1 If an operator following an M is anticipated in the operator before M, delete the M .
Rule 2 If a string of MKs belongs to a cognitive unit , then delete all M's but the first.
Rule 3 If a K is a redundant terminator , then delete the M in front of it.
Rule 4 Delete the M in front of a H which describes the movement from the reading to the listening position.
Rule 5 If unsure, emphasise more the number than the placement of the occurrences of the M operator.
The scenario was based on a ticket service for public transportation in Munich, Germany.
The tasks included the download of a service from a poster augmented with NFC tags.
The interaction device was a Nokia 3220 with built-in NFC reader.
People had to order a ticket to a pre-defined target for three persons and write a text message to a friend about the expected time of arrival.
In order to illustrate the applicability of the modelling approach, two different ways of accomplishing the main task were implemented: Using a form input on the phone's web browser, and using the NFC capabilities of the phone.
The participants were either routinely working with the used technology or trained before the study.
None of them had taken part in any of the earlier studies.
KLM predicts 122.77 seconds for the first variant of the scenario using direct input and browsing with a total of 110 operators.
The model of the NFC version of the scenario uses 198 operators and predicts 174.84 seconds.
Distractions were neither observed nor modelled.
Table 2 shows some excerpts of the latter model.
The prediction was calculated independently of and before the validation based on a detailed analysis of the scenario and the heuristics given in an earlier section.
We presented models of two different implementations of a real world scenario that also indicate that well grounded design decisions can be reached purely based on the model predictions.
Nevertheless, we strongly encourage other researchers to expand our initial set of studies and examine our results through additional measurements and scenarios.
The collection of introduced operators is necessary to apply KLM to interactions such as those described in this paper.
According to the experiences in our lab and after reviewing relevant publications, we conclude that this set also suffices to capture the interactions possible with mobile phones at the current state of the art.
Of course, time will inevitably bring different and additional types of interactions in the future for which new operators might have to be defined.
Others might need adjustments when new or radically more time consuming variants are introduced .
It can also happen that some interactions become considerably easier .
Nevertheless, after having conducted our tests, we are very positive that those changes are easy to integrate into the model and predictions can be made that lead to an early and valuable basis for design decisions.
Both alternatives of the scenario have been completed by 9 people .
The times needed for the first version ranged from 106 to 133 seconds with an average of 117 seconds .
The values are remarkably close to the predicted value of roughly 123 seconds.
The upshots of the second, NFC version of the scenario are similar in magnitude: The average duration of the task was 170 seconds  which is also very close to the KLM estimate of 175 seconds.
This means that the deviations of the KLM predictions to each data sample are in the small range of -15% to +8%.
The measured averages actually deviate only 5% and 3%, respectively.
Furthermore, the speed loss of 30% of the NFC implementation predicted by the KLM is confirmed by the study with a measured average decrease of 31%.
We introduced a Keystroke-Level Model  that can be applied to most interactions currently available for mobile phones including advanced interactions involving identification tags or gestures.
We described considerations and several user tests to get sound estimates of time values for the operators of that model.
We also presented detailed explanations and guidelines for the use of these operators to enable application designers and teams to quickly model such interactions and compare different designs ahead of any implementation efforts.
It is evident that average users handle complex interaction styles differently and with different speed.
It can also be hard to get into a routine for tasks that are new to a user even after several repetitions.
This may render the expert user assumption difficult to support.
The complexity of the interactions adds to this problem.
However, our experience and evaluation show that for a set of interaction methods known to its users through at least sporadic use, estimates given by the mobile phone KLM are very good indeed.
Especially when target users are young and `hip' people or professional workers, it is very likely that these learn and adapt quickly and reach a state of experience that can be modelled close enough to make sound predictions.
