ABSTRACT Usability specialists were better than non-specialists at performing heuristic evaluation, and "double experts" with specific expertise in the kind of interface being evaluated performed even better.
Major usability problems have a higher probability than minor problems of being found in a heuristic evaluation, but more minor problems are found in absolute numbers.
Usability heuristics relating to exits and user errors were more difficult to apply than the rest, and additional measures should be taken to find problems relating to these heuristics.
Usability problems that relate to missing interface elements that ought to be introduced were more difficult to find by heuristic evaluation in interfaces implemented as paper prototypes but were as easy as other problems to find in running systems.
The present article extends previous work on heuristic evaluation    by looking more closely at several factors that may influence the probability of finding usability problems.
A probabilistic approach is necessary in examining the success of a method that is heuristic and approximate.
The factors considered below are the expertise of the evaluators, the severity of the usability problems, the individual heuristics, and the activities needed to identify the problems.
INTRODUCTION Heuristic evaluation  is a method for finding usability problems in a user interface design by having a small set of evaluators examine the interface and judge its compliance with recognized usability principles .
Heuristic evaluation thus falls into the general category of usability inspection methods together with methods like pluralistic usability walkthroughs , claims analysis , and cognitive walkthroughs , with the main difference being that it is less formal than the other methods and intended as a "discount usability engineering"  method.
Independent research has found heuristic evaluation to be extremely cost-efficient , confirming its value in circumstances where limited time or budgetary resources are available.
The goal of heuristic evaluation is the finding of usability problems in an existing design .
Permlsslon to copy wkhout fee all or part of this material is granted prowded that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and Its date appear, and notice ISgiven that copying is by permission of the Association for Computing Machinery.
To copy otherwise, or to republlsh, requires a fee and/or specific permission.
Heuristic evaluation was originally developed as a usability engineering method for evaluators who had some knowledge of usability principles but were not necessarily usability experts as such .
Subsequent research has shown the method to be effective also when the evaluators are usability experts  .
Unfortunately, usability experts are sometimes hard and expensive to come by, especially if they also need to have expertise in a particular kind of application.
To investigate the effect of having evaluators with varying levels and kinds of expertise, a study was conducted where the same interface was subjected to heuristic evaluation by evaluators with no three groups of evaluators: "Novice" usability expertise, "regular" usability specialists, and "double" usability specialists who also had experience with the particular kind of interface being evaluated.
A "voice response" system is a computer information system accessed through a touch tone telephone.
The user's only input options are the twelve buttons found on a regular telephone .
The system's only output is through speech and sometimes sound effects.
This interaction mechanism provides literally hundreds of millions of terminals to any computer system and allows it to be accessed from almost anywhere in the world .
Because of the variety of evaluators employed in the present study, a printed dialogue was evaluated instead of a running system.
The evaluators were given a dialogue that had been recorded from a voice response system which will be referred to here as the BankingSystem.
The BankingSystem is a telephone operated interface to the user's bank accounts.
The user's task in the sample dialogue was to transfer $1,000 from the user's savings account to the user's checking account.
The dialogue between the BankingSystem  and the user  in Figure 1 is took place as the user tried to perform this task.
This dialogue has actually taken place, the underlying problem being that the user had not authorized the bank to accept transfers over the phone.
The user can be assumed to be provided with printed instructions stating that the system uses the # key to signify the end of the user's input .
As long as the user has not hit the # key, it is possible to correct input by pressing ** .
This option is not used in the dialogue in this example, however.
The printed instructions were not evaluated as part of the heuristic evaluation.
For the heuristic evaluation, the evaluators were asked to keep in mind those basic technical limitations of the system which were due to the access through a touch tone telephone and not to include criticism of the very use of 12-button input and speech output instead of, say, input though speech recognition or output through graphical dialogues with pulldown menus, etc.
Even the small sample dialogue in Figure 1 contains a rather large number of usability problems as listed below.
Readers who are only interested in the general results of the heuristic evaluation and not the individual usability problems can skip ahead to the section titled Results of the Heuristic Evaluation..
The list of usability problems is ordered according to a rough estimate of the relative seriousness of the problems.
Major usability problems are those that have serious potential for confusing users or causing them to use the system erroneously while minor problems may slow down the interaction or inconvenience users unnecessarily.
For each problem a brief phrase in italics indicates what well-established usability principle was broken by the dialogue with respect to that problem.
These phrases are taken from the list of nine usability heuristics used in earlier papers on heuristic evaluation  and are discussed in further detail in .
Users should not be required to convert an amount of money to cents since only a very mathematically inclined person will find it easy to think of $1,000 as 100,000 cents.
This problem can be completely avoided by simplifying the system to allow transfer of whole dollar amounts only.
Doing so will also speed up the interaction by eliminating two keystrokes.
For transfers between the user's own accounts, whole dollars will be completely adequate, For a bill-payment system, it might still be necessaty to have some mechanism for specifying cents.
In that case, a solution might be to have users enter first the dollars and then be prompted for the cents.
Since the system allows the user to interrupt prompts, a transfer of a whole dollar amount could still be achieved very fast if the user entered 1000## to signify $1,000.
The fact that there were no digits between the two # keystrokes would mean "and no cents."
The error message in statement 11 is not precise.
It is not clear what "this function" refers to, The problem could be transfers in general, transfers between the two specific accounts, or that the user did not have the $1,000 in the savings account.
The system should explicitly state that the user was not allowed to initiate any transfers, thus also avoiding the use of the computer-oriented term "function."
The expression "access" is also imprecise as well as being a rather computer-oriented term.
An access problem might have been due to system trouble as well as the missing authorization form to allow telephone-initiated transfers.
The error message in statement 11 is not constructive.
It does not provide any indication of how the user might solve the problem.
The error message in statement 11 appears much too late.
It is not reasonable to have the user enter large amounts of information only to learn that it was all in vain.
The error message should have appeared immediately after the user's initial choice of the function in statement 2. one evaluator noted that the current form of the dialogue seems to be designed as a front end to a traditional full screen mainframe system where users fill in an entire screen of data before hitting enter and transmitting all of the data to the computer at once.
Even if the bank's main computer system with the account database were indeed a traditional transaction-oriented mainframe, one should not let the properties of the backend computer impact the dialogue when a new interaction medium is introduced.
In many cases, the best solution would be to prevent the error from occurring in the first place by only listing those functions in the main menu which the user is authorized to use.
There is a much larger risk that the user will make errors when entering a ten digit account number than when entering a single digit menu selection.
A menu-based dialogue would probably speed up the dialogue since users would be required to do much less typing and would not need to look up their account numbers.
In statement 6, the current design does provide a shortcut by letting the checking account number be the default but this shortcut again involves some risk of errors.
Also note that a menu of account names might be difficult to construct if the customer had several accounts of the same type.
Assuming that most customers do limit themselves to one of each account, it would still be best to use the menu approach for those customers and stay with the current interface for the difficult customers only: Just because one cannot solve a problem for 100% of the users, one should not skimp out of solving it for, say, the 8070 for which a better solution can be found, .
Feedback on the user's choice of accounts and amounts appears much too late.
Normally a lack of feedback would be a "major" problem, but the present design does provide the ** editing facility as well as some feedback .
The options in the accept/cancel menu in statement 9 have been reversed compared to the natural order of the numbers zero and one.
Actually it would be possible to achieve some consistency with the rest of the dialogue by using the # key to accept and the * key to cancel, Note that some systems  have the reverse convention and use * to indicate the answer yes and #to indicate the answer no.
The assignment of meaning to these two keys is more or less arbitrary but should obviously be consistent within the system.
The choice between the two meanings of # and * should be made to achieve consistency with the majority of other similar systems in the user's environment.
The phrase "account number primary account" in statement 9 is awkward.
When referring to an account by name instead of number, the field label "number" should be suppressed.
The term "account" in prompts 3 and 5 should be changed to "account number" as the user is required to enter the number.
Problem 15, It would probably be better to read out the account numbers one digit at a time instead of using the pairwise grouping in statement 9 since users may well think of their account numbers as grouped differently.
The change in feedback method should only apply to the account numbers since it is better to report $1,000 as "one thousand dollars" than as "dollars one zero zero zero," .
Different words are used for the same concepc "enter" and "press."
It is probably better to use the less computer-oriented word "press."
The complete voice response system raises several usability issues in addition to the sixteen problems discussed above.
One of the most important issues is the voice quality which of course cannot be evaluated in a printed version of the dialogue.
Normally one would caution against using the almost identical prompts "Enter account to transfer from/to"  since users could easily confuse them.
But the speaker in a voice dialogue can place sufficient emphasis on the words "from" and "to" to make the difference between the prompts obvious,
It is very likely that the user will forget to press the # key after having entered menu selections or account numbers.
Since the number of digits is predetermined for all user input except for the amount of money, the system in fact does not need a general terminator.
The system should only require a # in situations where the input has an indeterminate number of digits and it should then explicitly state the need for this terminator in the prompt.
In these few cases, the system could furthermore use a timeout function to give the user a precise and constructive reminder after a certain period of time without any user input, since such a period would normally indicate that the user had finished entering input but had forgotten about the #.
The feedback in statement 9 with respect to the chosen accounts simply repeats the user's input but ought to restate it instead in simpler and more understandable terms.
Instead of listing a ten-digit account number, the feedback message should provide the system's interpretation of the user's input and state something like "from your savings account."
By using the name of the account , the system would increase the user's confidence that the correct account had indeed been specified.
The listing of the main menu in statement 1 should reverse the order of the selection number and the function description for each menu item.
The current ordering requires users to remember each number as the corresponding description is being spoken since they do not yet know whether they might want to select the function .
The most natural order of menu options in this type of system would be a simple numeric order, so the main menu in statement 1 should not skip dkectly from selection 1 to 3.
The BankingSystem in Figure 1 was subjected to heuristic evaluation by three groups of evaluators with varying levels of usability expertise.
The first group consisted of31 computer science students who had completed their first programming course but had no formal knowledge of user interface design principles.
The error message is not precise 4.
The error message is not constructive 5.
Replace term "primary account" with "checking account" 6.
Let users choose accounts from a menu 7.
Only require a # where it is necessary 8.
Give feedback in form of the name of the chosen account Average for the major problems Minor usability problems: 9.
Avoid the gap in menu numbers between 1 and 3 11.
Remove the field label "number" when no number is given 14.
Change the prompt "account" to "account number" 15.
Read numbers one digit at a time 16.
Note that they were "novices" with respect to usability but not with respect to computers as such.
The second group consisted of 19 "regular" usability specialists, i.e., people with experience in user interface design and evaluation but no special expertise in voice response systems.There is no official certification of usability specialists, but for the purpose of this study, usability specialists were defined as people with graduate degrees andfor several years of job experience in the usability area.
The third group consisted of 14 specialists in voice response usability.
These "double specialists" had expertise in user interface issues as well as voice ~esponse systems and were therefore expected to indicate the best level of heuristic evaluation performance one might hope for.
Table 1 presents the results of the three sets of evaluations and shows that heuristic evaluation was difficult for single evaluators.
The above list of usability problems was constructed on the basis of the complete set of evaluations, but no single evaluator found all the problems.
Problems 7, 9, 11, 12, 14, and 15 were not included in my own original list of problems but were added after I read the other evaluators' lists.
On the other hand, the really catastrophic problems 1, 2, and 3 were found by more than half of the evaluators even in the group without any experience.
Just fixing these three problems would improve the interface tremendously.
No group did really well, even though the "double specialists" with both usability expertise and voice response expertise were I hle to find well over half of the problems on the average.
The differences between the novices and the regular specialists and between the regular and double specialists are both statistically significant at the pc.001 level according to ttests.
The average performance of individual evaluators may not be acceptable for the use of heuristic evaluation in a usability engineering project, even in the case of the double specialists, but the picture changes when the performance of groups of multiple evaluators is considered, Figure 2 shows the average proportion of the usability problems that would be found by aggregating the sets of problems found by several evaluators.
These aggregates were formed in the same way as in previous studies of heuristic evaluation .
That is to say, for each group size, a large number of random groups were formed, and for each group, a given usability problem was considered found if at least one member of the group had found it.
As can be seen from Figure 2, groups of double and regular usability specialists perform much better than groups of novice evaluators without usability expertise.
For the regular usability specialists, the recommendation from previous work on heuristic evaluation  holds in that between three and five evaluators seem necessary to find a reasonably high proportion of the usability problems .
For the double specialists, however, it is sufficient to use between two and three evaluators to find most problems .
For the novice evaluators, a group size of fourteen is necessary to find more than 75% of the problems.
Using five novice evaluators, which is the upper range of the group size normally recommended for heuristic evaluation, results in the finding of 51% of the usability problems.
The underlying issue of providing understandable feedback would also apply to screen-based interfaces but the problem would be less serious in such a system because it would be easier for users to understand the ten-digit numbers in their printed form.
Problem 10  was found by 37% more voice response usability experts than regular usability experts.
Even though screen-based menus are also more usable when they are sequentially numbered, the numbering is less crucial in the case where the user can see the complete list of numbers simultaneously.
A screen-based menu might have a blank line where menu item 2 would normally have been, thus indicating to the user that the number was reserved for a future extension of the system, if that was the reason for omitting the number from the menu.
Often, screen menus for non-mouse systems would actually be based on mnemonic characters rather than numbers.
Problem 15  was found by 32% more voice response usability experts than regular usability experts.
This problem could only occur in an auditory dialogue and the regular usability specialists would have no prior experience with this exact problem.
A similar problem does occur in traditional screen dialogues with respect to the way one should present numbers such as telephone numbers or social security numbers that are normally grouped in a specific way in the user's mind.
These detailed results indicate that the double specialists found more problems, not because they were necessarily better usability specialists in general, but because they had specific experience with usability issues for the kind of user interface that was being evaluated.
As mentioned above, the double specialists found significantly more usability problems than did the regular usability specialists.
As can be seen from Table 1, the two groups of evaluators actually performed about equally well on many of the usability problems.
A large part of the difference in performance is due to the five usability problems for which the probability of being found was thirty percentage points or more higher when the evaluators were voice response usability specialists than when they were regular usability specialists.
As outlined below, these five problems were all either specifically related to the use of a telephone as the terminal or were related to the dXferences between audhory dialogues and screen dialogues.
Problem 9  was found by 60?i0 more voice response usability experts than regular usability experts.
Even though a similar design issue of whether to list menu selection labels to the left or to the right applies to screen-based menus, the choice would be less crucial for usability.
As a matter of fact, screen-based menus are probably better off having the label to the left of the description of the menu item  since such a design leads to a uniform, close spacing between the two elements in each line of the menu.
Problem 7  was found by 39% more voice response usability experts than regular usability experts.
This problem is much more relevant for telephone-based interfaces than for screen-based interfaces.
Actually, the advice to speed up screen-based dialogues by eliminating the need for an enter key wherever possible would probably lead to less usable screen interfaces because of the reduced consistency.
Problem 8  was found by 38%
In the discussion below of additional factors influencing the finding of usability problems through heuristic evaluation, the results from the "regular" specialists in the BankingSystem evaluation are used since they are the closest to the evaluators used in the other studies that are analyzed.
Table 2 summarizes six heuristic evaluations.
Teledata, Mantel, and the Savings and Transport systems are documented in  and the names from that paper are used as headings.
For the BankingSystem, the results are given with the "regular" usability specialists as evaluators.
The Integrating System was evaluated by "regular" usability specialists and is discussed in .
The table only represents those usability problems that were actually found when evaluating the respective interfaces.
It is possible that some additional usability problems remain that were not found by anybody, but it is obviously impossible to produce statistics for such problems.
Table 2 also shows three different ways of classifying the usability problems: by severity , by heuristic, and by location in the dialogue.
Table 3 then shows the results of an analysis of variance of the finding of the 211 usability problems by single evaluators, with the independent variables being severity, heuristic, and location as well as the system being evaluated and the implementation of its interface.
Two implementation categories were used: Teledata, Mantel, and the Banking System were evalu-
Applicable heuristic: Simple and natural dialogue  Speak the user's language  Minimize user memory load  Be consistent  Provide feedback  Provide clearly marked exits  Provide shortcuts  Good error messages  Prevent errors  Where is problem located: A single dialogue element 
The proportion of problems found is given both when the heuristic evaluation is performed by a single evaluator and when it is performed by aggregating the evaluations from three evaluators.
Bullets  indicate categories of usability uroblems that were not vresent in the interface in question.
The total number of usability problems is lis~ed in pa;e~theses for each catego~.
Even though Table 2 would seem to indicate that paper interfaces are easier to evaluate heuristically than running systems, one cannot necessarily draw that conclusion in general on the basis of the data presented in this paper, since different systems were evaluated in the two conditions.
Earlier work on heuristic evaluation   did speculate that heuristic evaluation might be easier for interfaces with a high degree of persistence that can be pondered at leisure, and it is certainly true that paper prototypes are more persistent than running interfaces, Table 3 shows that the system being evaluated had a fairly small effect in itself.
This would seem to indicate a cetiain robustness of the heuristic evaluation method, but this result could also be due to the limited range of systems analyzed here, More studies of the application of heuristic evaluation to a wider range of interface styles and application domains will be needed to fully understand which systems are easy to evaluate with heuristic evaluation.
For example, inconsistent placement of the same information in different screens or dialog boxes may slow down the user by less than a second  and may therefore not be observed in a user test unless an extremely careful analysis is performed on the basis of a large number of videotaped or logged interactions.
Such an inconsistency constitutes a usability problem nevertheless, and should be removed if possible.
Also note that sub-second slowdowns actually accumulate to causing major costs in the case of highly used systems such as, e.g., those used by telephone company operators.
The top part of Table 2 compares the proportion of the major and the minor usability problems.
Previous research on heuristic evaluation has pointed out that it identifies many more of the minor usability problems in an interface than other methods do .
Indeed, heuristic evaluation picks up minor usability problems that are often not even seen in actual user testing.
One could wonder to what extent such "problems" should really be accepted as constituting usability problems.
Note that the term "serious" was used to denote this category of usability problems in earlier work .
Given that the usability problems were found by heuristic evaluation and not by user testing, this classification can only reflect a considered judgment, since no measurement data exists to prove the true impact of each problem on the users.
For the TeIedata, Mantel, Savings, and Transport interfaces, the major/ minor classification was arrived at by two judges with a small number of disagreements resolved by consensus, and for the Banking System a single judge was used.
For the Integrating System, the mean severity classification from eleven judges was used.
The simple classification of usability problems into only two severity levels was chosen because of this need to rely on a judgment; it was mostly fairly easy to decide which severity categoxy to use for any given usability problem.
See  and  for further discussions of severity ratings.
It is apparent from Table 2 that heuristic evaluation tends to find a higher proportion of the major usability problems than of the minor, and Table 3 indicates that the difference is statistically significant  and one of the two largest effects identified in the table.
Intuitively, one might even have gone as far as to expect the evaluators performing the heuristic evaluations to focus only on the major usability problems to the exclusion of the minor ones, but the results indicate that this is not the case since they find many more minor than major problems in absolute numbers .
So the evaluators pay relatively more attention to the major problems without neglecting the minor ones.
Since the interfaces have many more minor than major problems, the minor problems will obviously dominate any given heuristic evaluation, even though the probability of being found is greater for the major problems.
Usability engineers therefore face the task of prioritizing the usability problems to make sure that more time is spent on fixing the major problems than on fixing the minor problems.
A contrast analysis of significance based on an analysis of variance for three evaluators confirms that usability problems classified under the "good error messages," "prevent errors," and "provide clearly marked exits" heuristics are more difficult to find than usability problems classified under one of the other six heuristics, with p=.0006.
Even though the specific usability heuristic used to classify the usability problems had some impact on the evaluators' ability to find the problems, it might also be the case that other systematic differences between the problems can help explain why some problems are easier to find than others.
Since heuristic evaluation is a process in which the evaluators search for usability problems, it seems reasonable to consider whether the circumstances under which the problems could be located have any influence.
The bottom part of Table 2 shows the result of considering four different possible locations of usability problems.
The first category of problems are those that are located in a siitgle dialogue element.
An example of this category of usability problem is Problem 2  in the telephone operated interface analyzed earlier in this article.
To find single-location problems by heuristic evaluation, the evaluator only needs to consider each interface element in isolation and judge that particular dialog box, error message, menu, etc.
The second category consists of usability problems that require the evaluator to compare two interface elements.
This will typically be consistency problems where each interface element is fine when seen in isolation but may lead to problems when used together.
An example from the BankingSystem is Problem 16 , The third category contains the usability problems that are related to the overall structure of the dialogue.
An example from the BankingSystem is Problem 7 .
Another example would be the need to unify the navigation system for a large menu structure.
These problems require the evaluator to get a grasp of the overall use of the system.
The final category of usability problems are those that cannot be seen in any current interface element but denote missing interface elements that ought to be there.
An example from the BankingSystem is Problem 4 , Note that the issue here is not that the current error message is poorly worded  but that the message ought to be supplemented with an additional element.
As can be seen from Table 3, the difference between the four location categories is not statistically significant.
However, the interaction effect between location category and interface is significant and has one of the two largest implementation effect sizes in the table.
Since heuristic evaluation is based on judging interfaces according to established usability principles, one might expect that problems violating certain heuristics would be easier to find than others.
Table 3 indicates a significant and fairly large effect for heuristic.
Even so, Table 2 shows that there are few systematic trends with respect to some heuristics being easier.
Considering all the 211 usability problems as a whole, Table 2 shows that usability problems have about the same probability of being found in a heuristic evaluation with the recommended three evaluators for most of the heuristics.
Seven of the nine heuristics score in the interval from 54-6890, with the "good error messages" and "prevent errors" heuristics being slightly more difficult than the others.
The only truly difficult heuristic is "provide clearly marked exits" .
The practical consequence from this result is that one might "look harder" for usability problems violating the "provide clearly marked exits" heuristic.
For example, one could run a user test with a specific focus on cases where the users got stuck.
This finding corresponds to an earlier, qualitative, analysis of the usability problems that were harder to find in a paper implementation than in a running system .
Because of this difference, one should look harder for missing dialogue elements when evaluating paper mockups.
A likely explanation of this phenomenon is that evaluators using a running system may tend to get stuck when needing a missing interface element , whereas evaluators of a paper "implementation" just turn to the next page and focus on the interface elements found there.
Usability specialists were much better than those without usability expertise at finding usability problems by heuristic evaluation.
Furthermore, usability specialists with expertise in the specific kind of interface being evaluated did much better than regular usability specialists without such expertise, especially with regard to certain usability problems that were unique to that kind of interface.
Major usability problems have a higher probability than minor problems of being found in a heuristic evaluation, but about twice as many minor problems are found in absolute numbers.
Problems with the lack of clearly marked exits are harder to find than problems violating the other heuristics, and additional efforts should therefore be taken to identify such usability problems.
Also, usability problems that relate to, a missing interface element are harder to find when an interface is evaluated in a paper prototype form.
The results in this article provide means for improving the contribution of heuristic evaluation to an overall usability engineering effort.
The expertise of the staff performing the evaluation has been seen to matter, and specific shortcomings of the methods have been identified such that other methods or additional efforts can be employed to alleviate them and find more of the usability problems that are hard to find by heuristic evaluation.
The author would like to thank Jan C. Clausen, Heather Desurvire, Dennis Egan, Anker Helms Jorgensen, ClareMarie Karat, Tom Landauer, Rolf Molich, and Robert W, Root for helpful comments on previous versions of the manuscript.
The four studies reported in  were conducted by the author and Rolf Molich who also participated in the classification of usability problems as major or minor and in relating the problems to the heuristics.
