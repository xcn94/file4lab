Tactile Brush is an algorithm that produces smooth, twodimensional tactile moving strokes with varying frequency, intensity, velocity and direction of motion.
The design of the algorithm is derived from the results of psychophysical investigations of two tactile illusions - apparent tactile motion and phantom sensations.
Combined together they allow for the design of high-density two-dimensional tactile displays using sparse vibrotactile arrays.
In a series of experiments and evaluations we demonstrate that Tactile Brush is robust and can reliably generate a wide variety of moving tactile sensations for a broad range of applications.
The challenge summarized by Sherrick is "... to discover a set of tactile patterns that, like speech sounds or letters ... are clearly discriminated, rapidly processed, and easily learned" .
This paper is concerned with the development of tactile displays capable of producing a two-dimensional moving tactile stroke, i.e., a high-order tactile percept.
Developing such displays is important because, first and foremost, moving tactile strokes are one of the most common and rich tactile experiences .
Gibson listed such common sensations as stroking, rubbing, caressing, the crawling of an insect, scratching, rolling and the brushing of a leaf .
Combined with video and audio, the tactile stroke display can greatly enhance user experiences in a broad variety of interactive scenarios, e.g., games, movies and music.
Second, tactile strokes naturally form semantic units.
Just as a brush stroke on paper, a tactile stoke "drawn" on the skin is sensed, recognized and remembered as a single unit of information .
By varying the speed, length, direction, location and intensity of tactile strokes, information can be communicated in a compact and efficient manner.
Therefore, a tactile stroke display can be used in innovative tactile communication systems for the blind, emergency workers, vehicles operators, athletes, and many others.
Finally, although there is a long history of interest in tactile strokes , we are not aware of previously successful attempts to develop general purpose, scalable and compact haptic solutions to generate moving tactile strokes.
We present here Tactile Brush, a control algorithm that uses a low-resolution grid of vibrating actuators to produce highresolution tactile strokes on skin.
Tactile Brush allows interface designers to incorporate and control moving tactile strokes in a broad variety of applications using any vibrotactile actuators: from inexpensive pager motors to militarygrade tactors.
The algorithm is scalable and robust.
It can be used on any body location, including the back, chest, thighs, hands, tongue, etc.
The design, implementation and evaluation of Tactile Brush algorithm is the first major contribution of this paper.
The design of Tactile Brush is derived from rigorous psychophysical modeling of tactile illusions.
The sense of touch provides rich information about the world around us.
It informs us about object properties, such as texture, softness and viscosity, and provides dynamic feedback on our interactions with physical environments around us.
Although tactile feedback can be a powerful modality in developing compelling, realistic and efficient human computer interfaces, current tactile technologies can produce only a small fraction of the infinite variety of tactile sensations.
Designing new technologies that enhance the vocabulary of tactile "expressions" is, therefore, an important research direction in haptics and HCI.
Research in developing tactile displays can be separated into two broad categories.
First is the design of actuation technologies and control techniques needed to produce a microstructure of tactile sensations, e.g., vibration , surface roughness , skin stretch , rotational profiles  and others.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
To overcome this, we systematically measure the illusions' control space, construct their models, and validate them in psychophysical experiments.
The resulting data and models not only inform the design of Tactile Brush, but provide tools to control tactile illusions that can be used beyond the scope of this work.
Investigations of tactile illusions constitute the second major contribution of this paper.
Finally, we report a preliminary discussion of applications.
While there are many potential uses for Tactile Brush, developing compelling visio-tactile-audio experiences was our primary goal.
We synchronize moving tactile strokes with dynamic game and movie contents to add tactile feelings to drops of water, the recoil of a gun, buzzing of insects and air movement from passing cars.
Although we implement the Tactile Brush system in combination with a chair, the algorithm can be utilized with tactile grids embedded into clothing, gloves, tools, sporting equipment and mobile computing devices.
We believe that Tactile Brush opens a broad field for future innovative applications.
The remainder of this paper is organized as follows: in the next section we summarize the state of the art for multi-point tactile displays and their control techniques.
We continue with an overview of vibrotactile illusions.
We propose models to control the behavior of these illusions and outline a set of psychophysical experiments to validate them.
We then combine these illusions in a general algorithm and evaluate its usability.
We conclude the paper with a brief overview of example applications.
The development of schemes for encoding meanings into tactile patterns that users could learn and recognize is another important application of multi-point tactile displays.
An early attempt was a Vibratese encoding schema developed in 1957 .
It was found that these schemes were quite efficient when multiple actuators were used, e.g., Tan et al.
Another class of multi-actuator tactile displays attempted to present spatial information using dense actuator arrays, such as creating static 3D shapes , indicating directions  and motion .
However, due to rapid adaptability of the human hand, static shape and pattern displays could only be used for active hand exploration and usually were not able to provide dynamic motion cues.
Most previous work on multi-point tactile displays was focused on displaying static tactile shapes or a-priory defined spatial-temporal patterns.
Significantly less progress has been reported in developing displays capable of producing smoothly moving tactile stimuli.
Previous research on such displays employed moving air- and water-jet stimuli, rolling wheels, sliding brushes and even moving probes glued to a user's skin .
Although important in studies of tactile perception, none of these designs are scalable enough to result in a feasible general-purpose solution that can be used in end-user applications.
Indeed, with the rapid proliferation of digital computing technology, there has been growing interest in using multiactuator tactile displays to enhance user experiences, improve quality and better the efficiency of interactions.
Popular embodiments of tactile arrays include vests , chairs , sleeves and arm bands , patches , as well as tools and mobile computing devices .
Because of such a diverse range of possible uses, scalability of tactile displays becomes an important issue: a tactile platform that scales across multiple embodiments will substantially benefit both research and application development.
Tactile Brush is developed with such scalability in mind.
We are proposing a flexible tactile platform that can be used to design a broad array of experiences for a wide range of applications, actuation technologies and embodiments.
Multi-point tactile displays, where stimuli are delivered by the simultaneous and coordinated use of multiple vibrating actuators, have a long history.
In particular, sensory substitution systems for blind and deaf individuals have been an important application area of such displays.
One of the earliest designs was Teletactor developed by Gault in 1927 .
It subdivided speech into five frequency bands and mapped them to five vibrators attached to the fingers and thumb of a user's hand.
It was intended for use as a communication aid for the deaf.
A number of similar systems, so-called tactile vocoders, were subsequently developed, including the Felix system and Tactaid VII .
With the development of reliable photo electronics a number of pictorial tactile communication systems that converted the output from an array of photo sensors into vibrations have been developed.
Examples of such systems include Optohapt, developed by Geldard in 1966, using nine vibrating actuators spread across the body ; Optacon, using a small 24x6 matrix of vibrating pins to present images from a miniature camera to the finger ; and TVSS  and Tactile Television , using as many as 400 vibrating solenoids embedded into the back of a chair to display tactile images captured directly with a camera.
More recently, electrical stimulation on the tongue has been used .
The design of Tactile Brush is based on exploiting vibrotactile illusions, perceptual phenomena that arise when two or more vibrotactile actuators are stimulated on the skin.
Although tactile illusions have been studied for more than 200 years, they are still not well understood.
Their differences are subtle, and they are often referred to by different names, leading to confusion.
In this section we present two wellknown vibrotactile illusions that form the basis for Tactile Brush: apparent haptic motion and phantom sensation.
Both illusions share a common thread: a perception of a change in the stimuli location when time relations are manipulated .
Apparent tactile motion is also known as phi-phenomena.
It has been studied since the early 1900s when it was observed that when two vibrotactile stimuli were placed on the skin in close proximity and their actuation times overlapped, the user would not perceive two actuators, but rather a single actuator moving between them .
Early studies of apparent tactile motion failed to produce robust movements: usually only partial movement was observed by participants .
As a result of this instability it was impossible to isolate control variables that would produce reliable tactile motion.
It was Neuhaus who, in 1930, demonstrated that the variables producing robust apparent tactile motion were  stimuli duration and  inter-stimulus onset asynchrony , i.e., time interval between onsets of subsequent actuations  .
A number of follow-up studies confirmed Neuhaus's observations and estimated "optimal" values of SOA as functions of stimuli duration .
It can be observed that by manipulating stimuli duration we can control the speed of illusionary movement.
Indeed, as the duration decreases, the speed of apparent motion increases.
This, however, requires adjusting SOA values to preserve the illusion.
Failing to do so results in stimuli being perceived simply as a discrete sequence of vibrations rather than continuous tactile motion.
An exciting property of apparent tactile motion is that it can produce a strong and clear sensation of continuous tactile motion with just a few actuators.
However, the major challenge in designing tactile displays based on this illusion is that there is still insufficient understanding of the parameter space where motion exists.
Indeed, the main motivation of previous studies  was to identify variables that control this illusion by demonstrating an instance of control values producing stable motion.
How these values would change for different signal frequencies or directions, and how far they can deviate without breaking the illusion of motion, are not known.
Designing robust tactile displays based on apparent tactile motion requires mapping the control parameter space where the motion exists.
We report the results of experiments that accomplish this in the next section.
The location of the phantom depends on the relative intensity of physical actuators , e.g., if their intensities are equal, the sensation will appear at a midpoint between them.
However, the intensity of the phantom is controlled by the actuators' absolute intensities, e.g., increasing both in equal proportion should increase the intensity of the phantom without changing its location.
The challenge here is to control both the location and intensity of the phantom independently by manipulating the intensities of real control actuators.
In 1970, Alles proposed linear and logarithmic relations between the intensities of phantom and physical actuators.
He suggested that the logarithmic relation maintains the constant phantom intensity over the entire range of locations ; however, no experimental validation was reported.
Recently, Seo and Choi showed that, while logarithmic relation was better for predicting the phantom intensity, linear relation was better for predicting the phantom location .
Therefore, currently there is no model that can accurately predict both the location and intensity of the phantom sensation.
The phantom illusion allows the placement of a virtual actuator anywhere between physical actuators, an important design element of the Tactile Brush algorithm.
In this paper we propose and validate a new model for predicting both the location and intensity of phantom sensation based on energy summation theory .
Phantom tactile sensation is also known as the funneling illusion and should not be confused with the phantom limb illusion discussed elsewhere.
In discovering the phantom sensation in 1957, Bekesy was inspired by the working mechanism of the auditory system .
He observed that a simultaneous stimulation of two vibrotactile actuators placed in close proximity would create an illusory vibrating actuator located between the real actuators .
Unlike apparent motion, the phantom illusion is static and no motion is perceived .
Both location and intensity of phantom sensations are controlled by the intensities of physical actuators simultaneously.
However, there is a subtle difference.
There are many similarities among tactile illusion theories.
However, there is no consensus on a single unifying theory.
Any such theory should also take into account other tactile illusions, such as saltation or "cutaneous rabbit" illusion , Tau and Kappa effects .
Thus, in the absence of such theory, in the present paper we consider all illusions to be unique and investigate and use them independently.
However, the exact relations between control parameters and perceived sensations are not well understood.
We cannot develop the algorithm without first determining these dependencies.
Therefore, a significant part of this section constitutes experimental investigations of illusions.
We design and execute two experimental studies to gain a deeper understanding of how we can control human perception of tactile illusions.
We must emphasize that these experiments are not related to actuators, hardware or the particulars of tactile apparatus design.
Instead, we investigate the underlying mechanisms of human tactile perception using a well established, classical apparatus of psychophysics that has been used to gain insight into human perception for more than 150 years .
The knowledge we obtain is then applied to the design of the Tactile Brush algorithm.
Implementing this approach presents a major challenge: we must be able to control apparent motion and phantom illusions with a high degree of precision.
Therefore, in this section we report two experimental studies that investigate the control of these tactile illusions.
In the first study we measure the space of control parameters that produces robust apparent motion.
In the second experiment we propose and validate a set of equations that control the location and intensity of phantom actuators.
The results of these experiments were used to design the Tactile Brush algorithm as we report at the end of this section.
To create such strokes we use apparent tactile motion illusion to produce continuous tactile motion between any two locations on the actuator grid.
For example, in Figure 2a we produce a moving tactile stroke by sequentially vibrating actuators along the horizontal row.
However, a difficulty arises when we attempt to generate a diagonal stroke as seen on Figure 2b.
Because there is no actuator between start and end points, the apparent motion fails to produce a single tactile stroke, i.e., the user feels a gap in the middle.
To solve this problem we generate a virtual actuator by using the phantom illusion .
We then proceed to generate a tactile stroke using apparent motion, where the phantom actuator is treated just like a normal physical actuator.
In other words, the Tactile Brush algorithm does not distinguish between virtual and physical actuators.
In fact, we can produce tactile strokes consisting of virtual actuators only, as shown on Figure 2d.
We used a 4x3 equally-spaced rectangular grid of C-2 tactors  with inter-tactor spacing of 63 mm .
The tactors were placed in a finely cut sheet of foam padding and glued to the back of a wooden chair .
The choice of the chair embodiment was driven by gaming and entertainment applications presented later in the paper.
The combined frequency response of tactors had slight variability across frequencies that was compensated for in the software.
Each actuator on the grid was individually controlled by a multichannel audio card with tactile waveforms generated in a Pure Data  sound design environment.
A custom control board amplified the current and voltage of individual waveforms and sent it to the actuators.
Custom application software controlled Pure Data patches over UDP protocol .
Stimulus onset asynchrony , i.e., time interval between subsequent actuator vibrations, is a critical control variable for apparent tactile motion illusion.
When SOA is too large, the continuity of motion breaks and the user feels a series of successive stimuli.
Alternatively, when SOA is too small, the stimuli collapse into a single vibration, and there is no perception of motion.
Between these extremes there is an optimal range of SOA where the stimuli are perceived as continuous directional motion.
This section reports on experiments measuring this optimal range of SOA.
The research question is as follows: What are the upper and lower thresholds of SOA beyond which smooth tactile motion cannot be perceived?
We utilized a one-interval two-alternative forced-choice  paradigm combined with one-up one-down adaptive procedures to determine SOA thresholds .
When measuring the upper threshold of SOA, the selected initial value was large enough that participants could clearly feel independent stimulation points.
Participants were asked if they could feel individual "discrete" actuators.
For every "yes" response the SOA value decreased until participants responded "no", i.e., they did not feel discrete actuators.
At this point the SOA was increased.
The change of decreasing to increasing SOA, and vice versa, is referred as a "reversal".
The experiment continued until reaching the termination condition .
When measuring the lower threshold of SOA, the selected initial value was small enough that participants felt a single vibration burst, i.e., they were not able to perceive the direction of motion.
Participants were asked if they felt actuators "merged" as one.
For every "yes" response the SOA value increased until participants responded "no", i.e.
At this point, the SOA was increased and the experiment continued until reaching the termination condition .
Each experiment series started with a SOA step-size of 16msec and, after the first two reversals, the step-size decreased to 4-msec.
The experiment terminated after six reversals at the small step-size.
An average SOA threshold was computed from the last six reversals.
A four-way repeated measures ANOVA was used to determine the significant effects of frequency, duration, pattern and thresholds.
In between there is a region of SOA values where participants perceived apparent tactile motion phenomena.
As the duration increases, the SOA threshold also increases, increasing the entire range of reliable apparent tactile motion, see Figure 4.
Frequency is also a significant factor =10.1; p<0.01: as the frequency of stimuli increases, the region of SOA values producing smooth tactile motion decreases.
Hence it is easier to generate apparent tactile motion with lower frequency vibrations.
Figure 4 shows average SOA thresholds as a function of duration.
As long as values of SOA are kept between these two lines, the tactile display generates continuous tactile motion across the skin.
We also computed an average of the upperand lower-SOA thresholds and fit a straight line through them.
This line equation defines the near optimal SOA control for robust apparent tactile motion.
With this equation, generating smooth tactile motion becomes a trivial problem: as long as the time interval between subsequent actuators is computed using this equation, the user perceives smooth tactile motion.
Tactile Brush algorithm uses this equation to "chain" multiple actuators in a carefully controlled vibration sequence to create tactile motion of arbitrary length.
The SOA thresholds were determined for five apparent motion patterns, shown in Figure 4.
They wore headphones playing pink noise and earmuffs to isolate environmental noise.
Each participant completed 60 test series divided into three sessions over three days in random order.
Phantom illusion is used in Tactile Brush to create a phantom actuator when no real actuator is present .
The goal is to create a phantom actuator that is indistinguishable from the real one.
This section proposes and validates a model that allows "placing" a virtual actuator in the desired location and with the desired intensity.
The research question is as follows: How do the intensity and location of phantom sensation relate to the intensities of the physical actuators that produce it?
This energy model departs significantly from the currently used linear and logarithmic models proposed by Alles .
We validate the energy model in experiments reported below and test the following hypothesis: The perceived intensity of phantom sensation computed with Eq.
1 and the perceived intensity of the reference physical actuator are the same, i.e., their ratio is not different from unity or 0 dB.
We use the classical method of limits , where we gradually increase or decrease the intensity of the phantom actuator until it matches the reference intensity generated with the real actuator.
Here, matching means that when two stimuli differ by less than a certain threshold value, there is a complete "lack" of stimuli discrimination by the user, i.e., stimuli intensities are perceived to be equal .
In the case of phantom illusion, as we change the intensity of physical actuators, not only the phantom intensity but also its location may change.
To control for location, we assume that the phantom location is defined only by the relation of the physical actuators' intensities and changing them in equal proportion would change the phantom intensity but not its location.
Thus, we can control intensities of physical actuators using a single control variable : Eq.
2 A1 = , A2 = k *, where a constant k defines the location of the virtual actuator.
By increasing or decreasing  we can increase or decrease phantom intensity without affecting its location.
In the case of opposing series, the initial phantom intensity was significantly higher than the reference intensity.
At this point the series was terminated and the average  from the last two trials was recorded.
The resulting 30 series were randomly presented in one experimental session that lasted for about 15 minutes.
The final matched phantom intensity was computed as the average of ascending and descending series.
Two physical actuators in the center of the first row of the tactile grid  were driven with 200 Hz, 110 msec stimuli.
Eleven participants  took part in the study.
We used a 3I-2AFC paradigm in which participants were first presented with a real left actuator, followed by a phantom actuator, and finally a real right actuator.
Participants were asked to match the intensity of the phantom with real reference stimuli having intensities equal to 22 dB SL.
Experimental series started with the intensity substantially lower than the reference intensities.
All participants reported that they felt three distinct actuators.
The average phantom intensity was calculated from measured  values using Eqs.
1 and 2, normalized by the intensity of the reference stimulus and plotted in Figure 5.
We observe that the ratio of phantom intensities calculated with our model and intensities of reference actuators falls almost exactly on the zero dB line: averaged across locations it was 0.20 dB, i.e., a 2% variability.
It was not significantly different from 0 dB  = 1.7, p = 0.09, thus supporting our hypothesis that the intensity of the phantom actuator can be predicted using our energy model.
The importance of this result is that it allows us to accurately generate virtual actuators of a desired intensity.
This plays a crucial role in the design of the Tactile Brush algorithm.
The in-depth psychophysical validation of Equation 4 is beyond the scope of the present paper, however a preliminary quantitative evaluation was necessary.
To this end we conducted a brief psychophysical study with three participants, comparing linear, logarithmic and energy models.
Participants compared two sequences where each sequence consisted of four phantom actuators generated by one of the models, randomly selected.
The models were used to calculate locations of phantom actuators to be equally spaced between the two physical actuators.
The participants were required to choose the sequence where actuators were perceived to be more equally spaced.
Our hypothesis was that phantom locations computed using the energy model would be perceived as equally spaced more often than locations computed with logarithmic and linear models.
The results showed that out of the 180 pair-wise comparison trials, participants chose the energy model 71% of the time, compared to 43% and 37% respectively for the linear and logarithmic models.
These preliminary findings suggest that the energy model allows for the best phantom location accuracy.
We define a rectangular grid of equally-spaced tactile actuators S = {si,j}, i = , j =  where the distance between actuators is l .
The goal is to compute a sequence  of physical actuators, their intensities, onset times , and actuation durations that will produce a continuous tactile stroke H:
In this section, we design a general algorithm that uses the apparent tactile motion and phantom sensation illusions to draw continuous moving tactile strokes on actuator grids.
The goal is to design a universal algorithm that treats tactile grids as a generic content-rendering platform.
In particular, the algorithm must be independent from the specific mechanical and electrical properties of the tactile actuators used.
The design of Tactile Brush was inspired by the evolution of computer graphics from special-purpose hardware solutions to today's universal content presentation platforms.
Virtual actuation points {i} are a set of locations that will be used to compute the tactile stroke H .
Similar to Bezier curve control points, virtual actuation points {i} define stroke H independent of the tactile hardware, i.e., some i would overlap with physical actuators but others would not.
In the current implementation, we compute {i} at the intersections of tactile stroke H and the tactile actuator grid .
This choice of {i} easily maps them on the physical actuator space, as demonstrated later.
Alternative mapping schemes are also possible.
We produce continuous tactile motion along the path of the stroke by using apparent tactile motion illusion.
Figure 6c provides a timing diagram for a stroke that consists of three virtual actuation points.
The goal of the study was to validate that the Tactile Brush algorithm could produce the sensation of continuous motion.
Each stroke was presented twelve times: six times it was generated with the Tactile Brush algorithm, and six times it was a sequence of discrete tactile pulses of the same duration.
Different frequencies, intensities and velocities were randomly assigned to each stroke.
In each trial, the participants were asked if they felt  a single continuous moving stroke,  two strokes or  multiple strokes.
Participants felt the stroke only once before responding.
A brief training session before the experiment familiarized participants with the setup and experimental procedure.
The results of the evaluation are presented in Figure 7.
They demonstrate that tactile strokes produced by the Tactile Brush algorithm were felt as single continuous strokes by most participants =23, p<0.001.
We also observed that in some cases, when participants felt two strokes, it was due to participants' posture - their backs were not touching all of the actuators on the grid.
This problem can be solved by designing chairs that encourage certain user postures or using sensors to measure the actuator contact and dynamically adjusting the intensity.
The final step of the algorithm is mapping i on the physical actuator grid.
When i overlaps physical actuators, then i = si,j.
Otherwise, we consider i to be a virtual actuator, and we find the closest pair of physical actuators that are capable of producing a virtual actuator at the i location.
The advantage of the proposed algorithm is that it is broadly scalable.
Since the design is based on fundamental properties of human tactile perception, the same techniques can be used on any body sites and with any vibrotactile actuator as long as the desired timings are within the actuator's capabilities.
Furthermore, depending on application requirements, the algorithm can be adapted to other grid topologies, such as a honeycomb or triangular mesh, which is an interesting future research direction.
The Tactile Brush algorithm currently has some limitations.
First, it can only draw straight lines.
We have implemented a version of the algorithm that can draw open and closed curves, such as a circle, but that remains a topic for future research.
Second, the start and end of a tactile stroke must be on the rectangular grid joining two adjacent actuators.
This makes implementation easier but reduces the flexibility of placing tactile strokes in desired locations.
Third, the algorithm currently pre-computes all of the temporal and intensity controls for each actuator before the stroke is displayed to a user.
This restriction creates certain challenges in realtime scenarios, such as computer games.
Developing on-thefly tactile stroke computing is another future research directions.
An in-depth discussion of Tactile Brush applications is beyond the scope of this paper.
Indeed, Tactile Brush can be used in a variety of applications including rides and attractions, gaming and sports, aids for blind individuals, driving and navigation aids, mobile computing and many others.
Each application would require specific embodiments, such as furniture, clothing, gloves and accessories, mobile devices, sporting equipment, game controllers and so on.
Designing the tactile apparatus and tactile stimuli for a specific application will constitute an exciting research challenge in itself.
However, we are not able to address this challenge within the confines of the current paper.
Instead, we do focus on developing basic, fundamental technology that enables all these possible applications.
However, we also believe that it is important to illustrate some possible applications of Tactile Brush and indicate how the technology can be applied.
Since our long-term goal is creating rich multidimensional tactile experiences for games,
The tactile feedback in this category informs the user about the surrounding environment, but not interactions with objects.
Examples include feeling weather , oxygen levels, gravity, radiation, textures on the ground, airstreams and so on.
In our demonstrations we found that, while it was effective, this type of tactile feedback required a certain amount of learning.
This form of tactile feedback is the most direct and obvious.
It simulates physical interactions between the user and game objects, other users and the environments.
This category includes, but is not limited to, objects passing by closely , shooting and feeling the recoil from a gun or missile launcher , getting hit, feeling collisions , feeling objects crawling and moving on the skin, explosions, electrocution and many others events.
In the games that we have developed, these types of interactions were the most common.
While they were popular and made the experience rich and enjoyable, a lot of care must be taken not to overwhelm the user.
Games were implemented using Unity3D game engine  and enhanced with stereoscopic 3D rendering mode.
In a character control game, the user navigated a robot through a variety of static and dynamic obstacles, such as laser rays and falling projectiles.
In a simulation game, the user was driving a car through a simulated urban environment.
The goal of designing these games was to investigate the application of tactile strokes in two popular game genres: driving simulators and role-playing games.
After reviewing a variety of existing computer games and extensive brainstorming, we identified four design strategies for combining gaming with directional tactile feedback.
We discuss them in the remainder of this section.
Most games are not based on reality and include many magic experiences and tools that can be expanded with tactile feedback.
Examples include laser body scans , an enhanced perception of free-fall or flying , shrinking and growing, zooming, glowing, converging and diverging, casting spells, going through a portal and so on.
This form of tactile feedback may be the most popular and easy to exploit because these mappings are artificial and the user can learn them quickly, without expecting to feel them as they do in real world experiences.
These four categories are by no means a complete list, but rather a starting point to explore the applications of complex tactile experiences enabled by Tactile Brush.
Similarly, neither of the two games discussed above are the end result of this project.
Instead, we provide them simply as initial examples of how the Tactile Brush technology can be used in future entertainment applications.
This category includes tactile feedback that informs the user of changes in the internal state of the virtual game character.
Examples include the level of health, amount of fuel or ammunition, feelings of tiredness or injury, etc.
For instance, in a character control game we have implemented feedback on the amount of fuel  as well as damage to the robot.
The Tactile Brush algorithm provides a solution for creating two-dimensional, high-resolution, continuous moving sensations on the surface of the skin.
Using Tactile Brush and a few off-the-shelf tactile actuators researchers and interfaces designers can begin creating complex and rich multidimensional tactile experiences.
In future research we will continue to expand the vocabulary of the Tactile Brush, design new tactile sensations and improve on existing ones.
We will further explore means of combining multidimensional haptics with visuals and sound in order to deliver deep, immersive and believable user experiences.
We hope that the Tactile Brush algorithm will help researchers and practitioners inter-
We thank Disney Research for supporting this work.
We are also thankful to Jan Stec for designing and developing the games used in the evaluation of Tactile Brush, Cheng Xu for helping us in conducting experiments and Mark Baskinger for designing the next generation of tactile apparatus.
Finally, we thank the anonymous reviewers and CHI Associate Chair for their comments, constructive criticism and invaluable help in improving this manuscript.
