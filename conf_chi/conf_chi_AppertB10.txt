Gesture-based interfaces provide expert users with an efficient form of interaction but they require a learning effort for novice users.
To address this problem, some on-line guiding techniques display all available gestures in response to partial input.
However, partial input recognition algorithms are scale dependent while most gesture recognizers support scale independence .
We propose an algorithm for estimating the scale of any partial input in the context of a gesture recognition system and illustrate how it can be used to improve users' experience with gesture-based systems.
These techniques provide effective assistance to novice users but their main limitation is their scale dependence: each template gesture has a fixed size.
As illustrated with OctoPocus in Fig.
1, the template does not provide optimal guidance when the user's stroke does not match the template's scale, although the final gesture may be correctly recognized by a scale independent algorithm.
In this latter case, the probability of scale mismatch between input and guiding paths is increased.
This scale independence problem motivates our main contribution: an algorithm that detects the scale of any incompleteinput relative to a gesture template.
We first motivate the need for scale independence by empirical observations.
We then detail the algorithm for scale recognition of incomplete input and present an evaluation of its accuracy.
We finish by illustrating how our algorithm can improve users' experience with systems based on gesture recognition.
Gesture-based interfaces allow users to draw an arbitrary shape to invoke a command, providing expert users with a direct and efficient form of interaction.
However, users have to learn the available gestures and their associated commands.
This problem motivated research on online help systems improving users' transition from novice to expert.
For example, Kurtenbach et al.
More recently, Bau and Mackay  proposed OctoPocus, a dynamic on-line guide.
If the user pauses during gesture input, the guide appears to show all possible gesture alternatives.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
They presented sets of gestures to participants and asked them to select the one that they perceived as the most different.
They tested whether scale was a discriminating feature for users by asking participants about gesture differences within triads of spiral gestures displayed at different scales.
Results suggest that the gesture area was not significantly contributing to similarity judgment.
This preliminary study, while very interesting, has some limitations.
On one hand, scale has been investigated as one feature among many others, on a rather limited set of gestures.
On the other hand, we are interested in the differences in scale of gestures drawn from memory, which is different than the visual perception of scale differences among three displayed shapes.
Each subsegment can then be represented by the turning angle it forms with a reference axis, e.g., the x-axis.
The distance between two shapes is simply computed as the distance between the two vectors of turning angles.
When considering partial input recognition, users provide only a prefix of the final gesture, making the sampling in equally spaced points irrelevant for comparing an input to a template.
Thus, we use a modified version of this algorithm in Step 1 of our own algorithm as described below.
Given an input stroke v and a set of templates { a, b, c, ... }, the three steps of our algorithms illustrated on Fig.
2 are: Step 1: Compute a scale independent representation  for input v and all templates a, b, c, ... A SIR can be seen as a coarse turning angle representation: it aggregates the subsegments that do not significantly vary in the angle they form with the x-axis .
The SIR is thus a series of segments defined by their length  and their angle .
Step 2: SIRs are convenient to look for the prefix that matches v in each template by simply comparing the successive segments.
If a segment vi from v is not similar to the corresponding segment in a template, vi is recorded as non matching.
When the non matching length of consecutive input segments exceeds 10% of the length of v , the compared template is discarded.
As a further investigation of gesture scale variations for command strokes, we took a closer look at the stroke area on the data from an experiment conducted in .
In this experiment, the shape stimulus is presented in the center of the screen, always at the same scale, and disappears as soon as the participant starts drawing.
3 reports the mean area and the standard deviation for each stroke stimulus over all collected answers to that stimulus.
We observe a substantial standard deviation for most of the stimuli, showing that recognition mechanisms for command strokes should be robust to scale variations.
Many gesture recognition algorithms allow the recognition of gestures independently from their scale, such as the $1 recognizer .
Rubine's recognizer  can also be made scale independent if the training examples inhibit the proper features.
Similarly, we are interested in adding control over scale independence to incomplete-input recognition.
To assess the accuracy of our algorithm, we tested it on a set of incomplete gestures we generated from the data we already used for Fig.
We used each gesture at three different stages of incompleteness  and recorded the set of candidate classes our algorithm output to check if this set contained the right gesture class.
This was not the case for only 187 incomplete gestures among 6318, which corresponds to a low recognition error rate of  3%.
4-a shows that recognition fails mostly for the spiral gesture which is very difficult to draw and thus exhibits too high a variability.
For recognized gestures, we computed the ratio between the size of the bounding box of the gesture as completed by our algorithm and the size of the bounding box of the actual user's complete input, which should ideally be equal to 1 .
Figure 4-b shows that this ratio was  1-1.5 in most of the cases .
The estimation is less accurate when only 25% of the total gesture is input, especially for gestures where the first 25% is a straight segment.
This is not surprising since the scale estimation provided by our algorithm ignores the last segment in the SIR.
Indeed, it is impossible to know if this last segment is complete or not and taking it into account would introduce too much uncertainty in the scale estimation.
Thus, until the SIR of an incomplete gesture contains only one segment, our algorithms simply outputs the template scale.
First, it allows to identify candidate gesture classes, resulting in less screen space consumption thanks to smaller crib-sheets.
Second, the visual support they provide can be made more coherent by adapting the template scales to the scale of the current partial input.
Informal user feedback on the augmented OctoPocus prompted us to implement a scale computation policy that depends on the stroke's nature.
On the one hand, dynamic scale adjustment at each input point is required for the guide to remain coherent when the user cuts corners in polyline sections as on Fig.
On the other hand, computing the scale at each point for curves results in too much visual distraction.
Actually a curved part such as the beginning of the question mark on Fig.
2 contains many small segments in its SIR so the scale estimation varies frequently  on the partial input.
For an optimal user experience, we suggest to first update the guide at its invocation and then update it only when the segment lengths in the SIR exceed an acceptable length.
We have presented an algorithm for detecting the scale of incomplete gesture input and showed how to apply it to improve users' experience with gesture-based interfaces by providing better visual and motor support.
We now plan to extend it so it can handle non uniform scaling  to implement a fully functional drawing editor able to handle a large number of shape families, e.g., from simple ellipses to different kinds of arrows.
The width and depth of each ditch are proportional to the template's plausibility given the current partial input: the more probable a template, the larger and the deeper its ditch.
To provide a smooth and continuous behavior, ditch depth is maximal in the center and progressively decreases towards the boundaries.
The users have more control than with a binary snapping mechanism, enabling them to deviate from the most probable trajectory to draw another gesture.
If P is out of any ditch, it is added to the current prefix without any treatment.
If P is inside the ditch, we turn P , distant from D to the template, into P , distant from d < D, so as to simulate the ditch resistance.
7- shows the computation of D and Fig.
7- the function mapping D to d. Fig.
6 shows an interesting side effect of magnetism: the stroke gets beautified as it is drawn.
Not only does this inform the user that he can draw more quickly since the trace looks good, but it also provides a pleasant aesthetic experience.
To our knowledge real-time beautification of arbitrary strokes has never been proposed before.
Diagram beautification  or the SST toolkit  provide beautification by turning the stroke into its ideal template only after the stroke is fully drawn.
Interactive beautification  provides a more real-time experience: it beautifies simple segments as soon as they are entered thanks to inferred geometric constraints based on other already existing segments.
It is more powerful in the sense that it supports drawings composed of several strokes, but it is not able to handle an arbitrary shape made of a single stroke.
