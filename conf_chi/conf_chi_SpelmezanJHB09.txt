While learning new motor skills, we often rely on feedback from a trainer.
Auditive feedback and demonstrations are used most frequently, but in many domains they are inappropriate or impractical.
We introduce tactile instructions as an alternative to assist in correcting wrong posture during physical activities, and present a set of full-body vibrotactile patterns.
An initial study informed the design of our tactile patterns, and determined appropriate locations for feedback on the body.
A second experiment showed that users perceived and correctly classified our tactile instruction patterns in a relaxed setting and during a cognitively and physically demanding task.
In a final experiment, snowboarders on the slope compared their perception of tactile instructions with audio instructions under real-world conditions.
Tactile instructions achieved overall high recognition accuracy similar to audio instructions.
Moreover, participants responded quicker to instructions delivered over the tactile channel than to instructions presented over the audio channel.
Our findings suggest that these full-body tactile feedback patterns can replace audio instructions during physical activities.
In many sports domains, such as skiing, snowboarding, or surfing, students receive feedback on their performance only after each exercise or run.
Instant feedback during these exercises is impractical due to the students' physical movement and their spatial separation from the trainer.
This situation is in stark contrast to sports like tennis or golf, where instructors can even physically guide a student's arm to demonstrate correct techniques, or to help adjust posture.
Wearable automatic training systems that assess performance and provide feedback during exercises might soon be common practice.
In fact, one hot topic in pervasive computing deals with technology intended for improving sports performance of athletes and for making sports more entertaining and engaging .
Moreover, recent studies indicate that frequent concurrent feedback can be beneficial for learning motor skills .
One prominent example is the sonic golf club , which uses sensors to measure swing motion.
Speed is mapped to sound that is played back through headphones in real-time.
This immediate feedback while putting allows beginners to hear how fast they swung their club and to adjust timing and tempo.
The tactile channel has often been used to substitute audio or visual information.
As illustrated in the shoulder-tapping system for the visually impaired , vibration triggered either at the left side of the body or at the right side indicated the direction to walk.
Compared to audio feedback, tactile feedback was preferred and yielded better performance.
Our goal is to extend this simple tapping approach towards a language of tactile motion instructions.
These instructions will be triggered across the body and indicate how to move or how to adjust posture during physical activities.
Personal trainers can use this approach to deliver detailed instructions to course participants in real-time.
A snowboarding instructor might decide to focus on a particular mistake that she noticed while observing one of her students de-
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
For example, the student might incorrectly shift his weight to the backward pointing right foot instead of his forward pointing left foot during turns.
This incorrect weight distribution makes it hard to pivot the board across the fall line.
To increase the student's awareness of correct weight distribution on the snowboard and to help correct posture during the ride, the instructor presses the left arrow button on his cell phone whenever she observes her student to lean towards the right foot.
Pressing the left button immediately activates actuators attached at the student's left thigh.
These actuators render a specific tactile pattern across the thigh.
The evoked sensation instructs the rider to shift his weight from the right foot towards the left foot.
Various domains can benefit from such tactile motion instructions.
Future wearable sports training systems will use sensors attached to the body or to the equipment to continuously monitor posture, detect common mistakes, and automatically trigger instructions for corrections.
Tactile warning signals can assist patients during rehabilitation  or alert people to potentially harmful movements during daily activities, such as when lifting heavy objects from the floor with legs straight and upper body bent downwards from the waist.
GPS enabled tactile devices can warn and teach children to look left and right before crossing the street.
Exertion interfaces  and game consoles, such as Nintendo's Wii Fit, can become more engaging and entertaining by instructing players how to coordinate body movements.
As a step towards creating a tactile language of motion instructions, we started with a qualitative study on the intuitive perception and interpretation of tactile cues delivered across the body, which were subsequently tested under cognitively and physically demanding tasks.
Stimulations delivered across the body were further used to accompany musical performances  or were delivered at the wrists to indicate the start of dance motions .
Sensory saltation  is one notable example of a spatiotemporal pattern that can be used to draw directional lines on the skin.
Saltation  is a robust illusion and evokes apparent motion.
In the original experiment, three different loci equally spaced apart on the forearm were stimulated sequentially with five brief pulses.
Instead of feeling isolated bursts at the location of stimulation, the taps appeared to be distributed uniformly between the first and the third locus of stimulation.
This effect is not limited to the forearm but can be evoked on various body parts, such as the back or the thighs.
Since its discovery, tactile sensory saltation has mainly been delivered at the back to convey guiding signals for navigation .
Van Erp  stated that tactile messages should be self-explaining and composed of well-known meaningful components without producing sensory overload.
Geldard  investigated the discriminability of tactile patterns presented to different parts across the body.
He reported that participants were more likely to confound patterns that shared the same actuators than patterns that used distinct actuators.
These examples can be used as starting point for designing tactile experiences.
However, the design space for full-body vibrotactile feedback is mostly unexplored and requires further investigation.
One notable exception are Tactons , which represent structured, abstract messages intended to convey information non-visually.
Concrete guidelines for designing multi-dimensional Tactons can be found in .
Sensory substitution for visually impaired is a prominent application in which vibrotactile feedback has received broad attention.
Geldard, for example, devised two languages for translating written text to tactile cues, which were encoded as different vibrotactile parameters delivered with actuators at the chest  or distributed across the body surface .
Vibrotactile feedback was further applied as warning signals or displayed directional information for navigation.
Similar to the shoulder-tapping system , vibration triggered under the left or right leg indicated a left or right turn while driving a car .
Other systems were targeted at pilots who continuously process a large amount of visual information.
To relieve the visual channel, tactile actuators inserted into a vest were used to signal the direction towards a target, and to increase spatial awareness during flights .
Tactile feedback has also used to make interaction more realistic.
To improve the user experience in virtual reality, vibration delivered to the arm have been used to signal collision with objects .
Tactile cues can even trigger automatic movements in the recipient.
We define tactile motion instructions as tactile feedback that communicates how to move the body.
An instruction can signal how to adjust posture, e.g., bend your legs when you incorrectly lift an object from the floor with straight knees.
Other messages can indicate how to coordinate body or limb movements during sports training, such as shift the weight to the left foot followed by rotate your upper body to the right.
Table 1 summarizes ten distinct movements that we focus on in this work.
This selection was originally inspired by incorrect postures while snowboarding .
Every movement has a corresponding countermovement, which were grouped to represent five different movement categories.
Our idea was to deliver tactile impulses at the appropriate location on the body that needs to be adjusted or that is involved in performing the movement.
For instance, a pulse delivered to the back can signal to straighten up whereas a pulse delivered to the right thigh can signal to move the right leg.
A series of signals across multiple tactors around the torso can indicate rotation , such as turning to the left or to the right .
Expanding on this idea, spatiotemporal patterns can be used to differentiate between related movements.
For example, saltation in upward direction at both thighs can signal stretch the legs whereas saltation in downward direction can indicate flex the legs .
Parameters for encoding information tactually include intensity, duration, temporal patterns, and spatial location .
Experiments dealing with absolute identification of these parameters were carried out under relaxed conditions and oftentimes with extensive training.
Spatial location and rhythm can be discriminated most reliably, whereas only about three levels of frequency, intensity, or duration can be absolutely identified by the tactile sense .
Other work showed that cognitive load can degrade both the performance in identifying the location of vibrotactile feedback delivered to the torso as well as the perception of directional patterns delivered to the back .
Moreover, Gallace reported that participants who were not involved in demanding cognitive tasks often failed to detect a change in tactile patterns presented sequentially on the body surface .
This detrimental effect of cognitive load on the perception of tactile cues has to be considered when designing full-body tactile patterns.
3 and R are one-element patterns.
We further introduce simultaneous patterns to represent patterns that activate multiple actuators at the same time.
We will use the symbol  to denote consecutively triggered patterns and + for simultaneously triggered patterns.
The rabbit pattern R consecutively pulses three motors located in line to render directional information on the skin.
We used a standard burst duration  of 3 100 ms and an inter-burst interval  of 50 ms for Px , which is considered optimal for R to elicit saltation .
Tactile feedback can be rendered at various body locations, and it can be composed of different cues.
A pulse is the simplest cue that delivers information.
In this work, we will use pulses as basic building blocks to compose patterns that represent motion instructions.
We further introduce a formal notation to better describe these instructions.
The naming of patterns is partly based on Tacton Design Principles .
However, we will use the term pattern instead of Tacton:
2 shows the placement of actuators on the body as investigated in this work.
With help of the introduced notation, we can formally describe patterns and the location where these patterns are rendered.
Pattern RU   RD , for example, starts with upward saltation laterally at the right thigh and concludes with downward saltation laterally at the left thigh.
Pattern RU  + RU  simultaneously elicits saltation in upward direction at the front of the right and left thigh.
After establishing this notation, we conducted three studies to inform the design of full-body tactile motion instruction patterns and to explore if users perceive these instructions during physical activities: 1.
The first study aimed at identifying how users without prior experience with vibrotactile feedback perceive and intuitively interpret patterns rendered at different body loci.
The second study tested user perception and response to learned motion instructions during a physically and cognitively demanding task in the lab.
Finally, the third study was conducted in an indoor winter sport resort to assess the perception and applicability of patterns under real-world conditions while snowboarding.
These studies are described in turn in the next three sections.
In order to design a first set of tactile motion instructions that best represent body movements from categories C 1 to C 5 , we conducted an exploratory study using an open response paradigm.
Our goal was to collect qualitative data on the natural interpretation of tactile cues delivered across the body.
Participants could freely assign any meaning to the tactile output they experienced.
Collected data was analyzed to reveal if patterns exist that can be inherently associated with specific body movements.
Such cues are likely to require only minimum training and to increase the correct identification of instructions during physical activities.
Testing all possible combinations of patterns across the body would lead to clearly impractical experiment durations.
To cut down the search space, we identified a total of 29 patterns that we gauged as useful.
This setup limited the time required for each participant to about one hour, including donning, doffing, and debriefing.
Participants were told they would perceive tactile stimulations at different body loci and that delivered cues were intended to correct posture.
Participants were not aware of the nature of the rendered patterns or of the movements these patterns might represent.
Their task was to describe the perceived feedback and to explain whether they associated each sensation with a specific body movement.
Participants stood upright, wore headphones, and listened to soft music that blocked auditory cues from the vibrating motors, which would not be available in a real-world noisy outdoor environment either.
Tactile patterns were randomly triggered and repeated on request.
Table 3 summarizes responses to tactile cues.
Responses to single directional patterns R were more concrete than responses to single pulses P 3 or to simultaneous and compound patterns.
Participants tended to prefer cues with directional information, which were often linked to specific body motions, and provided more answers to such patterns.
Reactions to single pulses were usually vague and interpreted as request to move the corresponding body part somehow.
Pulses delivered to the left shoulder, for example, were interpreted as request to lift the left arm , once to lean right, but not to turn the body around.
Responses were most concrete and interpreted as request to correct upper body posture when delivered either to the upper chest , to the upper back , or to both shoulders .
Responses to directional patterns RU and RD delivered to the back or to the chest showed similar tendencies as single pulses.
For example, RU  was interpreted as lean backward  and once as lean forward.
RU  yielded either straighten up , lean forward , and once lean backward.
Though these tendencies, participants also considered and followed directional information rendered on the skin.
Three participants responded to these patterns with pull the shoulders up.
Directional patterns triggered laterally at the torso, such as RU , were most often interpreted as move the arm away from the body .
We used cylindrical motors as found in Nokia 3210 mobile phones to render vibrotactile feedback.
Each motor was placed inside a thin plastic tube to avoid blocking of the rotating mass when attached to the body.
Motors were connected to custom-built actuator boxes  and powered by four AA batteries, each 1.2 Volts.
Throughout our experiments, we triggered motor pulses with full intensity .
Though we had the possibility to adjust motor strength on participants' request, maximum vibration never turned out to be unpleasant.
A Python script running on a Nokia N70 mobile phone was used during the outdoor study to control actuator boxes over Bluetooth serial port profile and to log the triggered patterns for off-line data analysis.
Transmission time to send commands for triggering motors was 39 ms.
20 university students took part in this experiment, eight female and twelve male participants aged 22-28 years .
19 participants stated that they exercise in some sport regularly.
None of them had previous experience with vibrotactile feedback in relation to our technology.
A pilot study for this experiment revealed that testing all patterns with each participant was too time consuming.
We observed that about half of the participants tended to move away from the particular side where vibration was triggered.
The remaining participants were inclined to move towards on the side where vibration was triggered.
Both compound and simultaneous patterns, when delivered laterally at the thighs, such as RU   RD  and RU  + RD , produced a similar effect to oneelement patterns, such as RD .
Simultaneous patterns were processed more slowly and demanded more attention from participants to identify directional information.
Four participants stated that compound patterns displayed laterally were rather contradictory; these patterns evoked countermovements.
As soon as our candidates perceived stimulation laterally at the right thigh, e.g., RU , they were tempted to shift the weight towards the left foot.
However, when stimulation at the right thigh ceased and RD  stimulation at the left thigh started, they were tempted to shift the weight back towards the right foot.
RD simultaneously delivered to the back of both thighs revealed a slight preference to bend the legs  compared to when delivered to the front of thighs .
RU at the back of thighs was rather unclear: half of the participants could not interpret this pattern at all, 20% would bend the legs, 20% would lean forward.
Similarly, responses to RU at the front of both thighs varied and showed no obvious trends.
30% responded with lean backward, 20% with jumping.
Simultaneous patterns that activated all motors around the thighs were described as strong and less pleasant .
About half of participants could not interpret these patterns.
For the other participants, RD mostly felt like bending the legs , RU like stretching  or jumping .
These patterns seemed to request more powerful or faster movements than patterns either at the back or front of thighs.
Rotational patterns around the torso were interpreted as turn left / right  when rendered fast and twice .
Single rotation using the standard BD and IBI was rather perceived as localized taps than continuous movement and was less effective for turning .
The placement of motors on the body can influence the interpretation of tactile cues.
Vibration over bones  feels harder than over soft or muscular areas .
The lateral sides of the torso seem to be more sensitive.
Tactile cues delivered at BRL and BLL, for example, were occasionally rated as ticklish but also as stronger and more intensive.
Such vibrotactile cues can represent more intensive and powerful movements, as was stated and interpreted by several participants.
Likewise, activating more motors at the same time or repeating the same pattern twice might result in wider or stronger movements: jumping instead of stretching the legs, turning around 360 instead of turning only the upper body around the spine.
The positioning of actuators on the body with regard to intended movements as well as the nature of delivered pulses might further influence reactions.
Students might benefit from perceiving cues at key muscles that initiate specific motions.
Smooth pulses made of increasing-decreasing intensity might represent fluent movements.
In contrast, quick jerky pulses might represent and trigger jerky reactions.
Initially, our participants were not used to artificial vibrotactile cues across their body, thus first reactions were sometimes sudden and jerky.
We did not address such questions in our studies, however, these issues are interesting future work.
Another limitation of this study is due to the fact that participants were standing upright, which definitely influenced their reactions.
This might be one reason why pattern RU , for example when delivered either to the back or front of thighs, was rather inexpressive and showed no clear trends to stretch the legs.
Moreover, the mapping of tactile cues to movements is not necessarily definite.
The great variety of intuitive responses to the same tactile pattern, such as RU , illustrates that one pattern can represent different body motions.
The meaning of tactile instructions should change to best represent a specific motion for the chosen physical activity.
Future research should consider alternative body postures and systematically explore design parameters and patterns presented across the body, aiming at a design space for full-body tactile cues and their interpretations.
One interesting observation is that about half of the participants preferred to move away from impulses delivered laterally at the upper body or laterally at the thighs.
The other participants tended to move towards the stimulation.
These reactions suggest that tactile instructions can be based either on a push or a pull metaphor.
To illustrate the difference between these two approaches, assume that you were instructed to lean your body to the left.
The pull technique will trigger an impulse on the left side of your body to indicate the direction to lean.
The push technique, on the other hand, will trigger an impulse on the right side of your body to evoke the sensation of being pushed to the left.
Choosing one of these metaphors seems to be a matter of preference.
For the following study, we decided to compose instructions using directional patterns and the push metaphor.
The rationale was to keep all instructions consistent, without varying the metaphor.
This study only investigated the perception and participants' intuitive interpretation of a small set of possible patterns delivered to different body loci.
Due to the fact the we had to split both the participants and the composed patterns into two groups, drawing strong conclusions was not always possible.
Moreover, it was difficult to remain unbiased when interpreting some reactions and responses.
Answers to a particular pattern often considerably varied across participants, were vague, or could not be related to specific motions.
Repeating the experiment with forced-choice paradigm might help to resolve ambiguities.
Based on participants' answers and debriefing after delivering impulses, we were nevertheless able to observe some trends that can be used for designing tactile motion instructions.
The goal of this experiment was to determine how well people perceive the designed set of tactile motion instructions when involved in tasks that demand both cognitive and physical load.
We tested participants over a period of two consecutive days  in relaxed and mobile setting to provide first insights into the discriminability of learned patterns.
The Nintendo Wii Fit balance board served for the mobile setting.
Due to limited hardware, we were not able to test all ten instructions at the same time.
Patterns for upper and lower body were tested separately and the order counterbalanced across participants.
After completing the training phase but before starting the test on the balance board, we first asked participants to stand upright and to respond to the learned instructions with the corresponding body movements.
Participants were not corrected in case that they made mistakes.
We included this relaxed setting to determine how cognitive and physical load will influence the perception of patterns.
We define participants' performance under relaxed condition with prior training as baseline for optimal perception for our tactile feedback communication system.
This setup is similar to real-world situations: students first learn and memorize instructions, later they react to feedback during exercises.
Participants were then instructed to step on the balance board and to play the snowboard game as precisely as they could.
For both upper and lower body instructions, each participant replayed the game for two times.
Whenever they perceived tactile motion instructions, our candidates had to say out aloud the instruction and then to perform the movement.
Patterns were randomized and delivered with a delay of 10- 15 seconds.
At the end of the experiment, participants were told which patterns they confounded during the test.
The same test was repeated for the retention phase , however, no training session was included before the experiment.
This study was conducted one month after the first study.
18 university students  between 19 and 30 years participated.
Eight subjects had participated in the initial study and had previously perceived tactile cues in relation to our technology.
However, these participants were not aware of the final composition of patterns, nor did they know the meaning we had assigned to patterns for this study.
The practice phase  consisted of a training phase followed by a test phase.
Participants were first given ten minutes time to familiarize themselves with the ten chosen patterns by pressing buttons on a GUI.
Buttons were labeled with instructions, such as Bend the legs, and triggered the corresponding tactile cues.
Training further included practice runs on the balance board, allowing participants to become familiar with controlling the snowboard on the screen.
Five participants had previously played with the board, three of them had tried the snowboard game.
These participants rated snowboarding as more demanding than other games.
4 shows performance under relaxed and mobile settings for users who did not participate in the first study .
During the practice phase, performance for upper body instructions was significantly better under relaxed than mobile condition  = 0.021, p = 0.05.
No signifiant difference of performance was found for the retention phase or for relaxed or mobile settings between both days.
Performance on day 2 slightly improved under both settings due to previous training on day 1.
Overall, three participants confounded at least once patterns for category C 1, two confounded C 3, three confounded C 4, and nine participants confounded C 5 .
Patterns were triggered though corrections were not required during gameplay.
For example, the instruction turn upper body to the right interfered with correct turns to the left on the screen.
Participants were also asked to translate instructions to speech before performing movements, which required additional cognitive resources.
Performing movements before speaking would put a different cognitive load on the participants.
These issues might have influenced and skewed results; we observed that our participants had increased response times and also used their hands to express themselves.
One participant explained that though he knew what patterns meant, he had difficulties to articulate their meaning and tended to mix-up left and right.
The body anatomy further influenced perception.
Spine and sternal were less suited for delivering directional cues.
Several participants pointed out that they always noticed vibration at the upper back and belly but seldom at the lower back and chest.
No significant differences in performance were found for users who had participated in the initial study and thus had previously experienced our vibrotactile cues .
The practice phase revealed, both under relaxed and mobile settings, 100% correct scores for all instructions except lean right, turn left, turn right .
Turn left achieved 87.5% in the mobile setting.
The retention phase yielded similar scores, though two participants confounded stretch the legs  and bend the legs  under both conditions.
Overall, two participants confounded C 1 and three confounded C 5 patterns at least once.
Group B performed significantly better than group A for upper body patterns  = 0.049, p = 0.05.
This performance is very close to the baseline for our tactile feedback communication system .
The promising results obtained in the second experiment, which indicated that participants perceive full-body patterns with high accuracy during mobile demanding tasks, motivated us to further explore this first set of instructions.
We decided to repeat the experiment under realistic conditions with potential users on the slope, as this environment was our initial motivation for applying tactile motion instructions.
Snowboarding is both cognitively and physically demanding.
People are subject to numerous forces and natural vibration during the descent.
Riders are faced with situations that require rapid and continuous adjustment of posture to maintain balance as well as paying close attention to the environment to find an appropriate way on the slope without endangering themselves or others.
The harsh environment often leads to cold limbs, pain, and muscular strains.
Moreover, riders wear thick tight-fitting clothes and tight boots, which cause a considerable amount of friction and tactile experience across the body.
All these factors influence cutaneous perception.
We expected that the recognition rate of tactile patterns would considerably degrade compared to the lab study on the balance board.
The aim of this experiment was to investigate the effects of extreme physical activities on the perception of tactile feedback, and to compare tactile motion instructions to corresponding audio counterparts.
The results obtained in this experiment indicate that cognitive and physical load, as experienced on the balance board, did not seriously degrade the perception of the designed set of full-body instructions.
Though previous vibrotactile experience improved performance , participants of group A had no major difficulty in perceiving and correctly identifying motion instructions based on the push metaphor.
Only few participants confounded related instructions; the chosen metaphor might have confused those who intuitively prefered to be pulled rather than to be pushed towards a specific direction.
Participants also stated that although they had perceived vibration around the torso, which indicated turn left or turn right, they had difficulty to accurately identify the direction of movement.
Further research should investigate whether discrimination of such patterns improves by increasing the number of actuators, varying BD and IBI for delivered pulses, or choosing alternative body loci, such as saltation around shoulders to indicate upper body rotation.
This experiment took place three weeks after study 2 and was conducted in an indoor winter sport resort on a slope 1700 ft  long at -5 C. Participants were recruited over email with help of our university's sports center.
Ten snowboarders aged between 23 and 28 years volunteered .
On a scale ranging from level one  to level five , two participants rated their skills as level two, six as level three, and two as level four.
Participants practiced snowboarding between one and three weeks per year.
One participant had previous experience with our tactile feedback patterns as he took part in the initial study.
Most participants wore underwear under our tightly fitting clothes.
We replaced pattern LF with pulses simultaneously delivered to the back shoulders: LF = P 3  + P 3 .
We further modified instructions for rotation  to resemble the push metaphor.
T L started and ended at the right side of the body, T R at the left side.
We used a within-subjects design with two conditions: * Tactile motion instructions * Audio instructions played back over earplugs.
In contrast to the lab study, where instructions were worded as illustrated in Table 1, we used a different verbal description for instructions delivered during the ride.
Instructions were worded such that they guide the rider's attention to the movement effect .
Except for lean forward and lean backward, we selected wordings that are commonly used during snowboard training: Fries , Burger , Hello mountain , Hello valley , Pressure towards the nose  .
The length of these audio messages ranged between 0.8 sec  and 1.7 sec .
Before descending the slope, every participant was familiarized with the instruction set that was triggered during the following runs.
We further demonstrated each movement to participants during this training phase.
Participants were then asked to always say out aloud the perceived instruction while descending and, if possible, to try to perform the corresponding movement.
Similar to study 2, instructions would be also triggered at inappropriate times during descents, when corrections might not be required.
For both conditions, we used one mobile phone to record speech using a microphone that was attached to the collar of the jacket.
A second phone automatically triggered and logged time-stamped audio and tactile instructions.
Participants descended the slope four times for each condition.
Two descents addressed the instruction set for the upper body.
Two other descents tested the instruction set for the lower body.
The order of conditions as well as the order of instruction sets were counterbalanced.
In addition, the order that instructions were triggered during each descent was randomized for every participant.
A random delay of five to ten seconds was chosen between consecutive instructions.
Less experienced snowboarders could not recognize the direction of spatiotemporal patterns unless they paid close attention to delivered cues.
Four participants confounded at least once C 1 instructions, two confounded C 2, three confounded C 3, and six confounded C 5.
Three participants recognized all patterns without mistakes.
The delay between the end of triggered instructions and the start of participants' utterances revealed a significantly faster response time to tactile instructions  than to audio instuctions  = 7.6E-05, p = 0.01.
6 shows Likert scale ratings for the two conditions.
A Wilcoxon signed ranks tests revealed a significant difference between audio and tactile conditions for question 4, addressing how well participants succeeded in mapping instructions to movements .
According to six participants, the audio channel was easier to interpret.
Audio message were also simply repeated without having to translate tactile cues back to speech.
Four participants  preferred tactile instructions, stating these commands were more subtle, less annoying, and less stressfully to wait for.
Moreover, no external noises interfered with tactile cues.
Our experimenter, who descended right after each snowboarder, confirmed our participants' additional body motions related to delivered instructions.
More experienced snowboarders commented after the experiment that it was annoying to execute instructions at inappropriate times.
Instructions often interfered with their current riding technique.
Perception of audio instructions was near-perfect .
5 shows results for the tactile condition .
The modified tactile instruction lean forward was always correctly recognized.
One male and three female participants had difficulties in perceiving lean backward.
All participants stated that they clearly located the various positions where feedback was delivered to the body but suggested to increase vibration intensity.
Tactile patterns felt rather weak and demanded more attention.
Rotational patterns around the torso were not clearly perceived as con-
Compared to , which reported a decrease in perception and discrimination of random tactile cues delivered to the torso under cognitive load, performance on the slope is close to results obtained in study 2.
Our participants missed only few patterns during descents, though they had less training and were subject to real-world conditions.
Though participants could identify the location on the body and noticed movement rendered by patterns, cognitive load degraded the recognition of the direction of movement these patterns produced on the skin.
Less experienced snowboarders, who spent most of their attentional resources on moving their body while descending the slope, had to pay close attention to identify direction.
This suggests that spatial location is well suited as primary parameter for encoding instructions whereas temporal patterns should rather be used to encode information redundantly, and to intensify tactile experience.
Patterns that share actuators and patterns that depend on the displayed direction to be discriminated or interpreted are more likely to be confounded during mobile tasks.
We based our patterns on the push metaphor.
During initial training before conducting experiments, some participants mentioned they actually expected to move towards vibration instead of away from the location where cues were triggered on the body.
These comments confirm our initial assumption that motion instructions can be based either on the push or the pull metaphor.
Choosing one option seems to be a matter of subjective preference and might influence performance.
Some participants stated that during the cognitive load condition they often had difficulties to express the meaning of perceived patterns in words, though they knew exactly what these patterns represent.
Having to respond verbally to tactile cues definitely influences performance.
Future studies should look at alternative ways to better validate responses to instructions under cognitive and physical load.
In sports training, coaches normally focus on a single mistake that they consider as most important to improve a student's skills.
One or two instructions would be enough to remind and help the student correct posture.
We suppose that under this assumption, together with more intensive cues and longer training sessions, performance in recognizing tactile patterns under mobile tasks will further increase.
Mapping audio instructions to movements was easier than mapping tactile instructions to movements.
This preference might stem from the fact that participants received only brief training before descending.
Other aspects regarding tactile feedback did not significantly differ from audio instructions.
This suggests that tactile instructions can potentially replace or augment audio instructions during physical activities.
The faster response time to tactile instructions over their audio counterparts is an important advantage for sports such as snowboarding, which require quick reactions to adjust posture for maintaining balance.
Tactile patterns used during this experiment were unique and delivered at dedicated body loci, such as to the front of thighs or the upper left torso; participants could start to respond to these cues as soon as they noticed vibration.
In contrast, audio instructions required to listen to the whole spoken message until their meaning could be fully interpreted .
This work introduced tactile motion instructions intended to guide people while learning new motor skills.
We started with an initial experiment that informed the design of tactile patterns based on the intuitive reaction of people to vibrotactile cues delivered across the body.
Two studies were conducted that assessed the perception and discrimination of ten instructions under relaxed and mobile tasks, and compared tactile instructions to audio instructions during realworld conditions with snowboarders on a slope.
The results of our studies suggest that vibrotactile feedback can be perceived and applied for delivering instructions during daily physical activities or sports training.
These instructions use the location on the body where feedback is delivered as main parameter to signal which body part has to be moved or adjusted.
Spatio-temporal patterns that display directional lines on the skin further intensify the sensation and provide additional cues that indicate the direction in which a movement has to be performed.
All our volunteers were able to discriminate tactile motion instructions with high accuracy during physical activities, and responded quicker to tactile instructions than to audio instructions.
We are now continuing our work on full-body tactile feedback to create a language of motion instructions that can be applied across various sports domains, such as martial arts,
We also plan a more extensive evaluation of tactile cues to further increase the recognition accuracy of patterns and to assess performance on responding to successively triggered instructions.
Tactile motion instructions also need further evaluation to test their effectiveness on motor skill learning when students execute instructions in the right context during training.
In particular, we follow our dream to create a wearable snowboarding assistant that automatically recognizes mistakes and provides real-time instructions to ease the learning of this fascinating sport.
