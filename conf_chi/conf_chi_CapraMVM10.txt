Improving search interfaces and algorithms are major foci of HCI and information retrieval  research respectively.
However, less attention has been given to understanding how users collect, manage, organize, and share the results they find from conducting searches on the Web and designing tools to support their needs.
In this paper, we present results from a study in which we interviewed 30 people in three cohorts  about their current practices conducting, managing, and sharing information from ongoing, exploratory searches.
We report results on users' current practices, tool use, areas of difficulties and associated coping strategies with emphasis on how information seekers use a variety of "tools-at-hand" beyond search engines and web browsers as they search, process, and share results, and on the learning processes that occur as they seek and use information over time.
There are, however, important kinds of information seeking that leverage current search technology but are not well served by it.
These more difficult information-seeking challenges involve information needs that are open-ended, ongoing, comprehensive, and multi-faceted; and search activities that are exploratory, discovery-oriented, possibly collaborative, and depend as much on results examination and interpretation as on query specification.
These challenges are described in different terms, for example, exploratory search  or collaborative search .
This kind of information seeking also overlaps with the personal information management literature  and the study we describe here is part of our work to fill a gap between query-oriented IR and the personal/group information management systems  that support information use.
In particular, we aim to understand problem-centered searching that takes place over time  in collaboration with other stakeholders in authentic settings.
This paper reports results from a set of interviews that were conducted with 30 people in three different kinds of problem settings.
Our broad aim in this research is to inform the design of tools that will help users find, manage, and share results found in ongoing, exploratory searches.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
People search for information objects that embody ideas, use cognitive effort to understand what they find, and employ additional effort to use these understandings to create problem solutions.
Most of the models aim to be general, but tend to focus on discrete search episodes.
Bates'  berrypicking model emphasizes how searches evolve as the searcher explores and learns.
Marchionini  characterizes the information seeking process with seven subprocesses  that recur according to the information seeker's ongoing sense making and reflective monitoring of progress.
Kulthau's  work includes an affective dimension as people seek information and learn over time.
Two aspects of these views of information seeking that motivate the work reported here are results examination and sharing, and how the overall process evolves over multiple search sessions.
In the Keeping Found Things Found project, Jones et al.
Many studies have reported on bookmark use and the problems of recognizing, using, and managing large bookmark collections .
Studies have found that users struggle to make these ad-hoc strategies work for their needs and that PIM is a challenge .
The PIM work motivates the multi-session search and results management emphases in the work reported here.
A related body of research has examined current practices to deal with information seeking over multiple sessions.
Saving web pages locally as a file  and email to self  had low percentages.
They suggest features to support multi-session search: a task reminder feature, support for working on multiple tasks simultaneously, and tools to help manage and return to information found during multi-session tasks.
A recent thread of research that builds on these literatures aims to create support for collaborative information seeking.
Other work on collaborative information seeking such as Twidale et al.
One additional important area of background research is medical/health information seeking.
Recent studies have found that 74%-80% of U.S. Internet users have searched for health information on-line , that people often start with Web search engines , commonly look for information about specific diseases, conditions, or treatments , and that searches are often done for someone else .
Studies have also reported that users assess accuracy of found information by factors including endorsements by recognized agencies or groups  and "the understandability of the information" .
These prior studies inform our analysis and provide a basis for situating and evaluating our findings.
We interviewed 30 people about their current practices conducting, managing, and sharing information from ongoing, exploratory searches.
Participants were recruited from a university and the surrounding metropolitan area by posting messages to a campus-wide opt-in mass email service and to local professional organizations.
In our recruitment, we screened for people who had done exploratory, multi-session searches and had shared the results of their searching with others.
We recruited into three cohorts as described below.
They had a mean age of 34  and consisted of three men and six women.
Medical information seekers  were all university faculty or staff members who had conducted ongoing searches for medical information for themselves or a family member.
This group had one man and nine women with a mean age of 46 .
Participants in this group searched for information on a wide variety of conditions including a childhood birth defect, an autoimmune disease, a heart condition, and insomnia.
Participants in all three groups had substantial on-line search experience .
In the statistics above, we note that age and search experience data was missing for three participants, one in each group.
By paraphrasing, we were able to generate the transcriptions quickly, while still maintaining the richness of the data.
These paraphrased transcriptions then formed the basis for our qualitative analysis coding.
After coding, we went back to the audio and extracted verbatim quotations to illustrate key points.
The three authors who conducted the interviews met as a group and reviewed each question.
For a few questions, we determined that a small number of closed codes would cover a majority of the responses.
In our analysis of methods for sharing information, we used a set of codes similar to a subset of the results of Morris .
We also used closed codes for note taking behaviors.
However, for most questions, there was great variety in the responses and we used an open coding approach.
We divided the interviews into three groups and each independently coded a group such that each participant's responses were coded by one coder.
We then met again over several days and, for each question, merged and collapsed our open codes by a process of consensus.
The results we present here are based on the common themes that emerged from this process of analysis.
We developed a semi-structured interview form with 16 questions based on our research goals and knowledge of prior research.
The questions were designed to inquire about specific situations of interest, but also to be open enough to allow participants to describe their variety of behaviors and practices.
The complete interview form is available for download from http://www.ils.unc.edu/ resultsspace/.
Interviews were conducted mainly in participants' private offices or in quiet conference rooms to avoid disturbing co-workers.
Some participants chose to be interviewed in a conference room in our department and one was held at a local coffee shop.
Some participants showed us artifacts such as their bookmark collections, searches they had conducted, and tools they used.
However, these were not available in all cases.
The interviews typically lasted about one hour.
At the start of the session, participants signed an informed consent form and completed a short questionnaire with demographic and background information.
The interviewer then started a digital voice recorder and began the questions.
To help ground the interview, we asked participants to describe a particular collaborative exploratory search project they had worked on recently to be the primary focus.
However, we encouraged comments about their information management behavior in general, and many participants described experiences from several different projects.
Twenty of the interviews were conducted by one author, and two other authors conducted the remaining 10 interviews to help balance any potential interviewer bias.
Many participants  described starting exploratory searches by going to one of the major Web search engines and entering keyword queries.
The academic and corporate searchers mentioned a mixture of starting points including databases such as ISI, PubMed, and specific known sources, but the medical group overwhelmingly  reported using a Web search engine as part of their initial exploration .
Participants described a variety of subsequent behaviors to refine and continue their searching; keyword refinement, changing the scope of the search, and reference chaining were all common behaviors in all three groups.
Finding "good" results - Over a third of our participants  talked about difficulties in finding information that was "good" along some dimension such as accuracy, credibility, or timeliness.
The medical group was especially attuned to finding relevant and trustworthy information, a process that involved learning about information sources: Personal web sites are popped up between legitimate web sites... somebody's personal blog... where they... say, oh, this is what you need to do  You start to know what are the reputable sources... and then I would begin to go directly, instead of entering my symptoms,... to those sources.
Name recognition differed based on the domain.
For the medical group it often involved recognizing a major research center such as the Mayo Clinic or a national organization such as the American Cancer Society .
Academic researchers knew the names of authors, universities, and research groups of interest.
The corporate group referred to known organizations, trusted sites, established magazines and popular blogs.
Filtering search results is time consuming - About a quarter of our participants  mentioned that searches would return too many non-relevant results, or "too much junk" in the words of one person.
Often, the "junk" were search results that did match their query, but took time to determine the relevance of: It just takes longer to sift through all that information... you know, reading different sites and deciding if you are going to get anything out of it.
It's just the length of time it takes to get very little information.
When saving documents found from searches, three participants  talked about renaming the files based on meaningful metadata such as the author, source, or topic.
Sites that I couldn't find easily...
There's no need to bookmark the Johns Hopkins Center... but... information that was hard to find, I bookmarked.
Bookmarking commonly used sites is a kind of personal information seeking infrastructure development that recognizes reuse .
Bookmarking hard to find pages is likely to be much more problem-centric.
Many participants took notes about the information they found from their exploratory searches.
For example, across all three groups, copying and pasting found information into a text, word processing, or email document was mentioned by a third  of our participants.
In the academic group, six of eleven participants reported using a reference manager such as EndNote, but no other groups reported using these.
Participants also reported relying on hand-written and mental notes .
In this section, we focus on note taking in its organizational role, but revisit the practice again in our discussion of collaboration and sharing.
If I find something that is really interesting, what I'll do is right-click it and open it in a new tab.
So in this way, I'll have maybe 10 tabs open, maybe up to 15 tabs.
And then I'm going to look at all of this and then take some notes into a Word file.
Participants often described adding their own notes to these documents and using them to organize and annotate the results they found.
By reducing the information to simple text, complexity is removed, there is a low barrier to use, and it is easy to share with others.
However, information may be lost in the process - table formatting is removed, metadata structure is eliminated, and source information is not automatically kept with copied data.
Participants reported printing , creating bookmarks/favorites , saving to disk , and copying and pasting text  as the most common saving behaviors.
This simple practice of copying and pasting found information and annotating/summarizing in text documents is perfectly logical, but we were surprised by its prevalence and the importance it played in many participants' exploratory search and collaboration process.
In one sense, it is a great adaptation of tools-at-hand to fill a need.
In another sense, it highlights the need for better tools to extract information pieces, re-use them, annotate them, and share them with others.
One university professor used an especially innovative approach to note taking using a somewhat heavyweight but familiar tool-at-hand: It's a system that I came up with a couple years ago...
I organized it in PowerPoint...
I'm old enough to have had to use 3x5 file cards... you know, you write your quotes down on it, or you write your references down on it... well, that's what PowerPoint does for you.
You create slides... and then you can organize it and just move stuff around... until you get the flow that you want.
For example, one participant worked as an intern at a consulting company and her job involved developing profiles of their clients for business development.
She developed a template document for each client that served several purposes: it helped guide her searches and make them more efficient, it helped her resume her work , and the completed templates were her finished work product.
Thus, she created a simple tool to reuse for each client search.
Another participant made sure he had easy access to articles by keeping multiple copies - one copy in each project folder for which it was used.
Managing bookmarks also presented challenges.
For example, two participants expressed how over time their bookmark collections became unmanageable: For a long time I think I was putting everything into Delicious, but I realized that was too much.
I did in the beginning, but it turns out to be too long...
In the very beginning I sorted them into... different folders...
But then later it mixed up with my own personal collection of my own web sites.
So in the end, I gave that up.
Using well-known tools-at-hand may help in this regard.
Criteria for when to save/print/bookmark - Deciding whether or not to save a found result is what Jones refers to as a "keeping decision"  and can also be applied to printing and bookmarking decisions.
One of our participants described the saving decision based on how much effort they put into finding the information: If it is something that I know I can get to easily again, like something on WebMD, then I don't save it... if I had to read through... a lot of abstracts...
I thought well, this will take me longer to get back to that again, so that would be one I would save.
If it's really really good, I print it.
If it is the latest, or a well-done research study...
I also print it because my mother-in-law does not have email access or Internet, so if it is something medically related to her... then I print it so she can have a hard copy to read.
Saving and managing found information - Organizing found information is often complicated in exploratory search by the lack of context early in the process .
One participant described this in terms of what would make organizing easier: If I knew more in advance about what categories... what pigeonholes I am going to need.
For example, one participant, apparently in an effort to preserve details of found web pages, described saving web pages by "printing it to Adobe", and "taking a picture of it in Adobe", meaning that she would print the file to PDF, look at the print preview to make sure everything was there, and then save the PDF to her hard drive using a descriptive name.
With my husband, it's definitely through sending him the link.
With my sister, it's through printing it out, or both.
She is more likely  if she has a piece of paper.
I re-do the searches and then  the search results...
I can remember the first several sentences... or sometimes if I can remember some peculiar words in the article, I just use this peculiar word  About a quarter of our participants  described looking for information they needed to re-find from earlier searches in their personal information collections.
Jones  has described these "forgetting" problems and they were mentioned by our participants as well: Sometimes when I find something I forgot to bookmark it.
But maybe a day or two later I need to turn to that web page again... I have to think about it again, I'm like, "Oh gosh, how did I get there?"
One additional participant seemed to know about this feature and thought it would be helpful, but had not used it: I'm kind of assuming that Windows Vista has a search function where I can look for certain words... to do the equivalent of a keyword search... but on my own hard drive... would be helpful.
But since I was doing searches everyday... so many pages... it's just really hard to go through all of them one by one  Interestingly, only two participants talked about using bookmarks when they encountered re-finding difficulties.
Over half our participants  described resuming searches based on their memory of previous search sessions.
Reviewing notes  was another common strategy.
Participants talked about reviewing general project notes, notes to see where they had left off, and specific to-do lists they had created.
A related practice was to resume a search by looking specifically for information that was not found in prior searches : I already looked at a lot of papers...
So it's... looking at what I've typed up so far, and looking at what the gap is, or what I need more information of... and then targeting towards that.
Re-finding results that have been seen before can be a particularly tricky problem.
The searcher may or may not have saved the information, may not remember where it was seen, and the information may have moved from its original location on the Web .
Forty three percent  of our participants talked about relying on memory when trying to re-find information found in earlier searches, including efforts to re-create the query that they had used to originally find the information, and making use of recalled details such as an author name to shortcut the original search process: I try to remember what search or a little bit more about where it was, what the source was  I remember a lot of the keywords, so I have to retry all of the combinations of the keywords 
People reported using a variety of methods to communicate, collaborate, and share information found from searches with each other, including: email , face-to-face , telephone/conference calls , and printouts .
Other methods for information sharing included blogs/webpages , shared network hard drives , and instant messaging .
These findings are similar to those of Morris .
Directed collaboration - In the academic and corporate groups, collaborative search was often directed, with one person leading the work and other team member conducting the searches.
This was typically the case with a graduate student working on the research project of a faculty member, or a corporate worker looking for information as a task assigned by their supervisor.
Tightly coordinated collaboration - In coordinated collaboration, the collaborators work together to divide the search task into parts.
One university professor described an example of this with students working on a class research project.
Actually, what we did in class was, a couple students bring a computer, I bring a little projector, and one of them would log into Blackboard and... we could all look at it... these are the articles I found, who wants to go find this one, who wants to read this one, who wants to do the summary.
For example, family members or friends might do searches and share information on an ad-hoc basis.
Although informal collaboration can be opportunistic and beneficial, one corporate participant described how shared information can be lost: We don't have a good way of creating and sharing a list of resources...
So... that kind of collaboration can be very informal... via IM or email...
But there's no place that I can go and easily reference those links... there's no one place to go and find that information once it's been shared.
Note taking played a key role not only in helping participants organize the information they found, but also in creating summaries to share with others.
For example: I put it into a Word document and I cut and paste... and I email myself so that I can review it before I send it to somebody...
I copy the direct link so that that person can go to that web site and read the whole thing if they want.
Either that or I'll give them a summary...
I'll say okay, here's the link, but this is really what the research found.
They wanted to organize, annotate and share their results with the client on an ongoing basis.
To do this, they used a tool at hand, posting their bibliography entries to a blog: We opened the WordPress blog to the client from day one, so she could check-in daily and get a feel, see the directions we were pursuing.
An example mentioned separately by two unaffiliated participants involved conducting a literature review in two parts: an initial searching stage in which promising looking citations were collected and a second stage in which the citations were reviewed in more detail.
The collaborators shared their lists of raw citations because they were being added to an overall shared list.
Sharing "raw" results was also mentioned as a way to quickly send a link of interest to a colleague with little annotation: We share links back and forth, saying, `You should check this website out, it's got good examples.'
For instance, the medical cohort was usually characterized by a central figure - either the patient themselves or the primary care giver.
This central person disseminated information to others, i.e., family members, friends, and medical professionals, with less information transmitted in the other direction .
Anecdotally, many participants across all groups identified themselves in a "central" searching role, even in cases where they were not the leader of the project.
First, we note as a general observation that our participants often described sharing information in aggregated sets with their own annotations and commentary provided as part of a "value-added" package to be shared.
Although browsers and other software have added capabilities such as emailing a web page, our interviewees were using tools-at-hand  to aggregate, annotate, and document results found from both single session searches and across multiple search sessions.
Much of the information sharing that was described by our participants occurred after the information was found and synthesized/aggregated to some degree.
Participants rarely reported sharing "raw" lists of results.
More often, they reported sharing summarized / filtered sets of results.
I don't share the raw materials that I have found... the team doesn't have time to read all the web sites...
When I share all of this information with them it's not the original information, but the integrated information into our project.
After learning the basic background information, detailed intermediate level information may be hard to find.
In many cases, advanced information exists, but it may be beyond the technical level of laypeople.
No middle ground between technical journals and a sea of crap.
Several participants with chronic conditions described reaching a point where they were monitoring sources, looking primarily for new treatments or breakthroughs: At the beginning I was just trying to get a wide range and basic information.
Now I'm looking for breakthroughs... and recent information.
In a few cases , the participant became an "expert" on the condition and begin presenting and informing their doctor of new information.
People learn at many levels.
They do so by adapting systems and themselves, by understanding their collaborators' needs and abilities, and by spending time learning/reflecting on content.
Scaffolding techniques provide temporary supports that evolve and dissolve as learning takes place.
Ongoing searches will benefit from these kinds of flexibility.
Quintana and his colleagues have found over multiple studies with several different systems and domains that adding even simple supports such as note taking to instructional materials leads to improved performance.
Designers of systems to support multisession search should keep learning progressions in mind and use scaffolding techniques to support different stages of the information-seeking process.
Exploratory search is characterized by learning and investigation .
Knowledge acquisition, comprehension, interpretation of ideas, analysis, synthesis, and evaluation are all components of an ongoing learning process supported by exploratory searches.
We observed a common learning/seeking progression described by the medical information seekers that moved from looking for information about symptoms, to possible diagnoses, through treatment options, and for some, to living with a chronic condition.
These progressions often followed the initial stages of Kuhlthau's  model of the information search process: initiation, selection, exploration, formulation, collection, and presentation.
How do I treat it?
I was just looking for general information...
I'd never even heard of this before so I needed to get all the background information.
I think I give her more than she gets from her doctor.
She will also send me lab results... to explain them... In exploration, participants echoed the frustration and uncertainty of this stage described by Kuhlthau as they found information that was contradictory or unreliable: There is just a lot of... people putting information out as if it's a fact and it is wrong... it would be nice if there was... some quality control...  There were these weird little ramshackle websites that would come up, that I totally didn't trust... once you're outside... your WebMDs and your journal articles, it's hard to know really what to trust.
The same, sort of `cookbook' information, gets put all over the place.
And also, even you can tell that your medical doctor has that same information.
The repetitive information... finding something new.
Our results compare and support the recent findings of Morris et al.
The use of computer tools-athand such as simple text editors and email persist as commonly understood, frequently used tools for a variety of tasks, despite their limitations.
Users experience real and perceived barriers to learning and adopting new, specialized tools, but will adapt existing tools to meet their evolving needs .
Our results, considered with those of prior studies, have both general and specific design implications.
Generally, tools for managing, organizing, and sharing search results may benefit by leveraging existing work practices involving tools-at-hand and by minimizing changes to existing systems.
Specifically, tools are needed to support tasks within the Web browser  for collection of results, note taking, summarization, search resumption, and sharing of results.
Tools such as SearchBar  provide a hierarchical query history and the ability to organize search results by user-defined topics.
One of the most common activities reported by our participants was taking simple text based notes  about the results they found and then sending summaries to themselves and/or other people.
Currently, this activity is not well supported by browsers, email, or websites.
Many websites provide "email this page" links, but these only work for a single page, whereas our participants described situations that involved summarizing across several Web pages.
Tools such as SearchBar , Zotero , and sparTag.us  support note taking, and more research is needed to understand users' integration of electronic note taking tools into their workflows.
Renaming downloaded files as they are saved locally is part of broader set of behaviors to save important metadata with files.
When saving found information to local files, participants described renaming the files based on authors, journal titles, topics.
One participant also described renaming files for version tracking.
These behaviors suggest the need for better support for metadata to be stored with files and transferred across systems.
We also note that users still deal with issues of keyword selection and understanding search domains, especially for exploratory searches and situations in which the user may be unsure if the information being sought exists on the Web.
Although web browsers and search services are the primary tools that people use for information seeking, our interviews make clear that people employ a variety of other tools and techniques that go beyond the functionalities offered by today's search engines and web browsers as they seek and process information over time.
Although many of the interviewees noted that they depend on their memory over sessions, there were many examples cited of using tool-based cues in the browser  and memory functions .
These tools were not sufficient for results management and collaboration and many examples of using tools beyond the browser were discussed as people added value to results for both personal and collaborative purposes.
It is clear that people leverage well-learned and familiar tools and techniques for multiple purposes while searching.
This illustrates Norman's notion of information appliances  that are so comfortably at hand that they become invisible.
Using email as a way to remind oneself or to store notes are just two examples of how people adapt tools to their needs.
Additionally, people make satisficing decisions that take into account personal effort as well as the needs or preferences of collaborators when choosing these tools at hand .
These examples demonstrate what may be low-hanging fruit for new kinds of functions that might be added to browsers  to support the many aspects of exploratory information seeking.
The interview data for these three cohorts of information seekers demonstrate how multisession and collaborative searching occurs in different settings.
The data show that people use a variety of tools-at-hand to augment what search engines and current browsing software support.
Additionally, they take into account the needs of collaborators when choosing these tools.
A key challenge for designers is how to leverage this tension between users' reliance on familiar tools at hand and features that can be incorporated into web browsers and other information-seeking support tools.
In this paper, we have provided insights into users' current practices and designs that we believe are useful in this design process.
As people learn more about the topics they investigate, different accompanying support tools are needed.
Designs that accommodate this evolution over time and that allow people to seamlessly integrate the examination, use, and sharing of results represent the next generation of information-seeking support systems.
This work was supported in part by the National Science Foundation, grant IIS 0812363.
We thank Diane Kelly, Barbara Wildemuth and our anonymous reviewers for their insightful suggestions for improvements to this work.
We also thank our participants for sharing their experiences, especially those dealing with difficult medical conditions.
