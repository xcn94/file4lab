Unistrokes are a viable form of text input in pen-based user interfaces.
However, they are a very heterogeneous group of gestures the only common feature being that all are drawn with a single stroke.
Several unistroke alphabets have been proposed including the original Unistrokes, Graffiti, Allegro, T-Cube and MDITIM.
Comparing these methods usually requires a lengthy study with many writers and even then the results are biased by the earlier handwriting experience that the writers have.
Therefore, a simple descriptive model can make these comparisons easier.
In this paper we propose a model for predicting the writing time for an expert user on any given unistroke alphabet thus enabling sounder argumentation on the properties of different writing methods.
A major problem in the research of new character forms is that the old form has been so thoroughly learned by all literate people.
Experiments aiming to evaluate a new character set are doomed to be biased by the fact that the test subjects cannot help thinking that the old character set is the right one and that the new one, though possibly very promising, is not natural.
Experiments are certainly valid if the goal is to evaluate the immediate usability of a character set given the skills that the writers have.
If, however, we aim to compare expert performance, the tests become much more difficult to arrange.
Therefore, it seems desirable to develop the ability to compare character sets theoretically.
Of course, we can already do this to some extent.
Most people would argue that a straight line like "I" is simpler and thus faster to write than, for example, "W", which requires four times the number of straight lines.
Unfortunately, not all characters are composed of straight lines.
We need to develop a more general set of rules for estimating the complexity of characters.
In the remainder of this paper we explore models for explaining the time requirement for drawing a unistroke character.
First we summarize previous work related to unistroke modeling to find hints on how to successfully model handwriting.
Then, we proceed to describe potential models for extracting the crucial time-consuming characteristics of a stroke.
We choose a model that satisfies our goals and then we test this model by applying it to samples of actual writing to see if it indeed describes the reality with any accuracy.
Finally, we use our model to estimate the time-complexity of four different handwriting alphabet.
Unistrokes were introduced as a text input method for penbased user interfaces by Goldberg and Richardson in their 1993 paper .
Unistrokes are an alternative character set for the Roman alphabet.
Each character is written with a single stroke.
This solves the character level segmentation problem that previously plagued handwriting recognition.
The curve drawn between pen down and pen up events can be recognized in isolation.
Unistroke recognition algorithms can be relatively simple because there is no need to decide which parts of the curve belong to which character or to wait for more strokes that belong to the same character as is often the case when we try to recognize conventional handwriting.
After the original paper, other character sets have been proposed with characteristics similar to the Unistrokes .
In this paper all these character sets are considered to belong to a family of handwriting character sets collectively known as unistrokes .
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Modeling human-computer interaction is difficult as long as we do not have a complete model for the human part of the interface.
Current incomplete models are either slightly inaccurate in their predictions or only capable of modeling a small portion of the interaction.
GOMS  is an example of a widely applicable, but slightly inaccurate model.
The model for one-finger typing by MacKenzie et al.
GOMS analysis is basically a task of dividing a given interaction sequence into subtasks and these subtasks again into subtasks and so forth until the time consumption of each bottom level subtask can be estimated accurately enough.
Then the time requirement of the upper level task is simply the sum of its subtasks' time requirements.
In the end we have an estimate for the whole sequence of interaction.
The model for one-finger typing uses Fitts' law, Hick-Hyman law and character-pair frequencies in the English language to describe both novice and expert typing speeds.
Our goal is to create a similar model for text input using handwriting.
In this paper we describe the first step of developing a predictive model for the drawing of unistroke characters.
We want to know how long the writing act will take.
A useful finding in handwriting research is the fact that the velocity of the pen as a function of time can be used to segment handwriting into separate strokes .
Before going any further into this, we must clarify the different meanings that the concept of stroke has in different contexts.
A stroke in the context of unistrokes means the whole movement between pen down and pen up events.
However, in the context of traditional handwriting research stroke has a different meaning.
Stroke is a single movement that can be extracted from the pen trace using various methods.
Thus, one unistroke stroke may contain several strokes, as they are understood in traditional handwriting research.
Figure 1 illustrates the segmentation of a w into four strokes using local minima of the time-velocity curve.
Both x and y coordinates of the w have been filtered to eliminate some high frequency noise before computing the velocities between the sample points.
The need for a good model for handwriting time consumption is relatively new.
For example our current Roman character forms were developed in the Middle Ages.
Often the goal was not to make writing an easy and fluent task, but to make the end result aesthetically pleasing.
When the official type is too difficult, other forms of writing develop for purposes where content surpasses form in importance.
Already in ancient Rome, cursive handwriting styles were used instead of the formal Roman book hands, when practical .
Today the need for aesthetically pleasing characters has not disappeared in general.
However, the motor activity that is needed for producing the characters is usually not connected to their visual appearance.
This is a by-product of the use of computers for text processing.
In theory the computer can track any movements that the writer makes, map them to abstract representations of the characters, and synthesize beautiful character forms for output.
This separation between writing movements and the form of the resulting text allows us to emphasize the speed of the writing movements more than was possible in the pen-and-paper era.
The ends of the curve were padded for filtering by duplicating the last sample at both ends.
We see that the low points in the velocity curve coincide with the sharp corners in the character.
Another feature of handwriting that can be seen in the velocity curve in Figure 1 is the bell-like shape of the velocity curve over each stroke.
Assuming that the shape of the velocity curve stays the same, the average velocity is greater when the strokes are longer.
This means that the proportional increase the writing time is smaller than the increase in distance as the strokes become longer.
All this, of course, assumes that the nature of the movement does not change much.
For example, if the writer has to move the whole arm instead of just the fingers and wrist, the shape of the velocity curve will probably change.
An underlying assumption in our attempt to describe the timerequirements of different handwriting characters is that the human information processor has a certain maximum rate at which it can produce and process information.
Furthermore, we assume that writing different characters requires different amounts of information to be processed in order to move the pen.
In the light of Fitts' law research  these assumptions do not seem unreasonable.
The task is thus to identify the critical features in the characters that can be used to estimate the amount of information that needs to be processed in order to write the characters.
These features need to be measured in a uniform scale so that we can easily measure the amount of time needed for one feature unit and thus produce writing time estimates.
Recently handwriting research has had two main goals.
The first goal is to understand human motor performance and the second is to produce accurate handwriting recognition software.
Handwriting research aiming to improve automatic handwriting recognition is also aiming to understand the processes that are involved in handwriting.
This is necessary because the process of handwriting recognition does not merely try to ascertain what the text looks like, but rather to guess what the writer intended it to look like.
A successful handwriting recognizer uses knowledge of the characteristics of hand motions in order to differentiate between intentional and unintentional features present in the text.
Next we will shortly describe properties of handwriting to illustrate some of the phenomena that need to be accounted for in a successful model of handwriting activity.
Handwriting recognizers use measurements on handwriting activity to track the writing process back to the intentions of the writer.
We can use the same information to proceed in the opposite direction.
A class of complications in handwriting modeling is the physical properties of the hand.
A model aiming at perfection should predict, for example, the difference in the velocities in up and down strokes.
Evidence of upstrokes being faster is visible in Figure 1.
The velocity curves for upward motions are clearly higher than for downward motion.
A Similar relationship may hold for movements to left and right.
These differences stem from the flexions and extensions of the joints of the hand.
The axes of these joints do not always land in the same positions in relation to the writing surface.
Therefore including such refinements in our model would lead to great complexity and difficulty in avoiding features specific to Roman handwriting.
W and the filtered velocity of the pen tip while writing it.
Various models for describing handwriting motions do exist.
However, they tend to be prohibitively complex for quick estimation of time consumption, or their modeling power is based on several parameters measured from actual writing.
For example the velocity curve for a segment of handwriting can be synthesized accurately if we know parameters such as the length of the movement, the movement time .
Models like this are clearly intended for postmortem analysis of handwriting and help little in predicting writing if we do not have skilled writers whose performance to measure in order to produce the parameters.
Our goal is to produce a model that can be used to compare handwriting characters in a quick and preferably reliable way before training anybody to write with them.
This means that the user of this model has access only to the preferred geometric form of the character, not to dynamic information measured in real writing situations.
In order to be usable, our model should be as simple as possible.
The first reason for emphasizing simplicity even at the cost of some accuracy is that it lowers the threshold for using the model.
The second reason for simplicity is that, while a more complex model might better describe writing performance on current handwriting characters, it would probably model some behavior specific to Roman handwriting characters.
We are trying to develop a general model for all possible handwriting characters and therefore, at this stage, we chose to be very conservative in including different features of handwriting in our model.
It is tempting to explain handwriting as a sequence of Fitts' law tasks as follows.
A character is defined as an ordered sequence of Fitts' law pointing tasks.
Each target in the sequence is defined as a point and radius.
The points are located on the ideal path that the pen must take and the radius indicates how far the pen may digress and still be acceptably close to the right track to form the correct character.
Thus we can find the optimal writing time by applying Fitts' law to these pointing tasks and summing up the time used on the unit-tasks.
The problem is that many lines in handwriting are not straight and that the size of the Fitts' law targets cannot be easily determined even for the straight lines.
The alternative formulations of Fitts' law proposed by Accot and Zhai  do not make a significant difference in this respect.
Although, instead of points and radii, the task can be defined as a trajectory and maximum allowable distance from the trajectory, the task of defining these for a unistroke character is not significantly easier than finding the points and radii.
A Fitts' law description of handwriting would imply that writing time does not change if we scale the size of the characters .
Claims regarding timeinvariance of handwriting have been made, but the truth seems to be that writing time does increase slightly when the size of the characters grows from the normal size preferred by a given writer .
However, the increase in writing time is small enough to be ignored at this early stage of model development.
In general it may be that a sequence of separate movement impulses is not the way that handwriting is actually controlled .
Overlapped impulses, on the other hand, can be used to produce fairly accurate models .
However, it seems that regardless of whether the movement impulses are overlapped in time or not, the right way to proceed is to first identify the impulses and then see how they are best treated in the model.
Namely, we can assume that all straight lines take an equal amount of time to draw despite their different lengths.
This assumption is not true in general, but within the very limited variation of line lengths that appear in unistroke writing, the error may be small enough not to invalidate our model.
Armed with our constant-time line, we can reduce handwriting into a sequence of straight lines and estimate time requirement by counting the lines.
The sequence must be minimal.
In this case minimal is defined rather vaguely as the number of lines that is needed for making the character recognizable.
Figure 2 depicts a selection of characters and their straightline reductions.
It is clear that the method for reducing the characters into lines is somewhat ambiguous.
Different people may produce different estimates based on their judgment on what is needed to make a character recognizable.
However, the probable errors will mostly be in the order of one complexity unit.
Some people may estimate that 3 lines are needed for u and 2 for v while others estimate both to be worth 2.
The same ambiguity is present in the act of writing.
Some people draw very sharp u characters while others cannot produce a sharp v. The fact that no absolutely correct estimate exists is not a great problem if the variation of the estimates stays small.
With a correct model we will be able to estimate the average time requirement of a certain character with some confidence.
When comparing whole character sets a user of the model is likely to be systematic in his or her interpretation of the model and therefore err in the same direction with both character sets.
Still, the stability of the estimates across users must be validated empirically.
Drawing of a simple hand-printing character, such as any of the Roman alphabet, is likely to be controlled by a single well-rehearsed motor program regardless of whether it is drawn without lifting the pen or in separate parts.
Therefore, we can extend the straight-line reduction model to characters with more than one part.
We assume that moving the pen from the end of one part to the beginning of the next can be reduced to yet another straight line.
This model is very simple to use.
Accuracy, however, must be validated before relying on the time-complexity figures so gained.
Instead of straight lines, we can count other features in the character.
Counting local extreme points in x and y directions gives estimates that seemed very good in our early experiments.
If we add some additional rules, like giving extra weight to sharp corners connecting two round curves, we can somewhat increase the accuracy .
However, we abandoned this technique as our pilot test subjects found it hard to use and reverted to their own ad-hoc models.
If instead of pencil and paper, we use a computer for comparing unistroke characters, we can easily extract, for example, the normalized length of a character or an angular velocity profile of a character.
The normalization was achieved by scaling the character down to 1x1 box and measuring its length.
Instead of a full angular velocity profile we used the cumulative angle between curve segments along the character, counting a complexity point whenever the curve had turned more than /4 radians.
Both of these methods produced informative results, and could be improved with better algorithms.
However, they are difficult to apply without a computer and custom made software.
Characters and their minimal straight-line versions.
The feature extraction process described above produces an estimate for the velocity-based segmentation of the characters.
Local velocity minima appear at points of high curvature and points of high curvature are likely to be points where a joint between two straight lines is placed in our model.
The number of lines to use for areas of relatively low curvature and high speed is not as clearly defined.
However in order to capture significant features in situations such as the O in Figure 2 one must use a number of lines.
Thus these areas of the curves are also represented in our model.
As described above, we can generate several metrics that correlate strongly with the measured writing times of characters.
The expected use of the model must be the guide for choosing metrics to include in the model.
We hope to create a model that is easy to use with low-tech devices like pen and paper.
This excludes the three models that are most conveniently implemented as computer software.
These are the Fitts' law models, length, and direction change models.
The choice between the remaining two, the straight-line reduction and extreme point models is based on simplicity and intuitiveness.
The straight-line reduction model was superior in both according to our pilot testing.
To recap, our chosen model is used as follows: * * Each straight line needed for drawing the character is worth one complexity point.
Round shapes are redrawn with a minimal number of straight lines.
We expect a perfect model to produce complexity figures that place all the points in Figure 3 on the regression line.
Thus, the better R2 values we get the better the model It is not surprising that the line fit is good for Unistrokes.
Assigning data to the four complexity classes that we found in Unistrokes is trivial because Unistrokes characters are actually four simple geometrical forms drawn at different angles.
Also, the measured writing times are median values computed from a greater population thus the variation is reduced.
However, we see no faults in the performance of our model in this example.
We cannot expect our model to completely explain the variation in measured writing times because we ignored known minor features of handwriting as described above.
In addition, performance of the motor system under maximal concentration and control is a fairly rare occurrence even in laboratory conditions.
The higher level of brain activity that controls the motor system is easily disturbed by factors external to writing.
Therefore, a person's writing performance almost continually changes due to factors that our model cannot account for.
Another source of variation in the writing process is the noise generated in the nerves and muscles during the execution of the movements.
The goal of the experiment that is described next was to establish how well our simple model works despite the obvious shortcomings.
One of our goals for the model is to make it easy enough to use for people without extensive experience on handwriting time requirements.
A model like this would help end users of handwriting products to design their own character sets.
To be useful for end users, the model must satisfy two requirements.
First, the model must be more accurate than the ad hoc models that people can come up with within the same amount of time that it takes to apply the model.
Secondly, the predictions must be stable, that is, the model must produce the same results for the same character set when different people use it.
For the evaluation we use the following writing samples: 1.
Goldberg's and Richardson's account on one Unistroke writer writing English text .
Twelve people using Roman hand printing, Graffiti, Unistrokes and MDITIM to write approximately ten repetitions of each character.
Measured writing time  vs. straight-line complexity of Goldberg's and Richardson's Unistroke writer.
A look at the poorest fitting points in Figure 3 reveals that the writer is still handicapped by Roman handwriting experience and is therefore not writing at his maximum attainable speed.
The highest points with complexity of 2 are c and g .
They are drawn in opposite directions in Unistrokes and Roman characters.
Also, the lowest points with complexity of 3 
These Unistroke characters have forms similar to the Roman alphabet equivalents.
The writer has more experience with these characters and faster writing is a consequence of more practice.
The fact that the regression line does not pass through zero is a matter of some concern.
This behavior can be partly explained by the mechanics of the data gathering.
For digitizing pen strokes we used an inexpensive graphics tablet .
The pressure sensing mechanism in the pen causes the tip to yield a little as pressure increases.
This means that the beginnings and endings of the strokes in the digitized data are not exactly where the writer intended them to be.
In the beginning the pen touches the surface before the writer starts to get enough feedback on that the pen is actually touching the pad.
Likewise, when the writer lifts the pen, the tip stays in contact with the surface longer than is necessary.
This behavior introduces curves and loops at the ends of the strokes.
The length of these unwanted features can be controlled by setting the pressure threshold of the digitizer.
The Goldberg and Richardson Unistroke data and the samples on Roman hand printing can be considered to represent skilled performance.
In the remaining samples the level of experience with the characters varies from none to several hours of prior writing experience.
We will first use the Goldberg and Richardson data as an example to explain our model evaluation methodology.
Thus, to be on the safe side, we will always get slightly longer strokes than we would hope for.
If Goldberg and Richardson experienced similar difficulties with their digitizing equipment, this may explain some of the 85ms intercept value in the regression model discussed above.
For the purposes of this study we must conclude that the ligatures at the ends of the strokes exist and that their effect on the measured writing times is proportionally greater for short characters than for long ones.
Goldberg and Richardson collected their data from a mailsending program used by a person familiar with the Unistroke character set.
Our test subjects were not familiar with all of the character sets and therefore our procedure was different.
Each of the characters was written approximately ten times in a row.
The character prototypes were given for the writer on A4 sheets showing one character set in alphabetical order.
The order of the character sets was varied to counter bias due to fatigue and learning towards the end of the session.
The pen traces were saved and then post-processed using a browser application that showed one character at a time.
Those characters that did not look like the prototype were excluded.
This phase was somewhat sensitive to errors since there is no objective way of saying which trace looks enough like the prototype and which does not.
We adopted a policy of discarding only those traces that were really bad with practically no resemblance at all or large artifacts connected to them.
The goodness of the estimates was evaluated using the R2 values produced by a linear regression model as was already done with Goldberg's data to produce Figure 3.
However, instead of medians of the character instances, we used arithmetic means computed over all instances of a character written by a specific writer.
Note that our R2 values do not represent the percentage of variation that our model explains in each individual instance of a given character.
Instead the values reflect the degree to which the model explains the mean of all instances of a character written by a given writer.
In the second part of the experiment the same test subjects were divided randomly into two groups .
One group was given our straight-line reduction model and the other was not.
Then the test subjects were asked to give complexity estimates for all of the characters they had just written.
A summary on the results is shown in Figure 4.
Each bar is the mean computed over the four different character sets.
The bars labeled "yes" are test subjects who were given the straight-line reduction model before they gave the complexity figures for the characters.
The bars labeled "no" are subjects who were not given the model, but had to make one themselves.
The left bar in each pair shows the accuracy  that the researcher achieved for the subject's data.
The right bar in each pair is the accuracy that the subject achieved.
We see that the subjects performed consistently worse, which is to be expected because the model leaves space for judgment in places of high low curvature and high speed.
Also, the test subjects made more mistakes in counting the complexity points.
As expected, there seems to be a difference between the mean accuracy in the two groups of subjects.
The difference, however, is not statistically significant in our data for 12 writers.
Goodness of fit R2  achieved by different people.
Bars with "yes" are for subjects with the model an "no" signifies subjects without the model.
The low accuracy of our model with some data can be partially explained by a large number of very long writing times on various, mainly unfamiliar, characters.
This seems to be a feature of some people's writing style.
They do not draw all instances of a character fluently, but instead stop in midstroke.
Obviously our model cannot explain the writing times if all instances of the character are not drawn the same way.
We are not interested in predicting this kind of artifacts.
Instead we are interested in the maximum fluent writing speed.
In the lack of proper criteria for excluding the nonfluent instances, however, we report the raw results.
The effect of the unfamiliar character sets on the accuracy of our model can be seen in Figure 5.
However the subject  performance degrades with more familiar and complex characters.
Curiously, the group without the model  was more accurate in modeling their own Roman hand printing than the group with the model.
The explanation is that the group without the model had more unpredictable handwriting since even our best effort in applying the model  produced lower mean R2 for that group.
Note that people have different habits in drawing the Roman characters.
The complexity values given in column R apply only to the style adopted by the author.
For example some of the test subjects write y with two separate straight lines yielding complexity of 3 according to our model.
The penultimate row in Table 1 requires some explanation.
The row is on the space character, which is by far the most frequent character in English language.
Graffiti and MDITIM have spaces that are drawn with lines.
In these cases our model works well.
However, in Roman hand printing space is not drawn and therefore our model gives zero complexity.
This, too, is an accurate figure, as we are only modeling the drawing time, not the time spent between characters.
The case of the Unistrokes is more problematic.
Unistroke space is a dot.
A dot can be drawn faster than a line, but not in zero time.
Therefore the correct value is close to 0.5 complexity units.
We rounded it to 0 because we prefer to use integers in this phase of modeling.
The stability of the complexity estimates can be described by the bivariate correlations between the estimates of different people.
In our group of five working with the model the mean correlation between estimates for Graffiti was 0.88, for MDITIM 0.98, and for Unistrokes 0.99.
For Roman hand printing these correlations are not meaningful measures of stability since the characters written by different people are different and therefore the complexity estimates too should be different.
The goal of all the work described above is to enable a more informed discussion on the speeds of different writing methods.
We will now use our model to compare the writing time requirements of four known character sets.
The basic rationale is that we assume that our model accurately describes the writing time of characters for a fully trained expert.
Generally one person cannot be simultaneously fully trained in two character sets because of negative skill transfer from one to the other.
However, our claim is that if we could fully train a person in another character set, our model would predict his or her writing times based on his or her performance with the native character set and the shape of the new characters.
The maximum rate at which the writer can produce the basic straight-line units of our model remains constant within a person and therefore by computing the complexity figures for two character sets we can say which of them is faster under the assumption of fully trained writers.
Table 1 presents complexity figures for four character sets.
The first column labeled "char" gives the character whose figures fill the row.
The second column "weight" gives the frequency of the character in English language.
These numbers are from Soukoreff's and MacKenzie's 1995 paper  and they do not vary much in different sources.
Complexities of different characters sets.
The last row in Table 1 gives complexity figures for the character sets.
These numbers were obtained by multiplying the complexity figure for each character by its frequency and summing up the results across the whole character set.
The result may not be a great surprise if we consider only the order of the character sets.
One can, without much difficulty state without any explicit modeling that Unistrokes are simplest and the others are pretty much equally complex.
The numbers in Table 1 reflect only the prediction for the writing time of the characters.
To account for the intercharacter intervals, the model needs to be extended.
There is evidence on that modeling inter-character times for individual characters is not very fruitful because the inter-character times tend to be constant when only the character following the inter-character transition is considered .
However, Goldberg's and Richardson's analysis on their results suggests that inter-character times measured for a specific pairs of characters surrounding the transition vary greatly .
Therefore a meaningful model more detailed than a constant time for inter-character transitions may be feasible and should indeed be investigated in the future.
Our current model for estimating unistroke writing time is easy enough to use without extensive study of handwriting.
So much so, that it may be useful to end-users working with handwriting gestures.
There are several methods for character recognition available to end users or that can be modified or implemented without extensive programming skills.
These include various trainable handwriting recognizers such as Rubine's statistical classifier , which is included in systems like the Amulet , and some simple algorithms such as Goldberg's Unistroke recognizer  and the MDITIM recognizer .
So far our model is based mostly on simplified ideas drawn from previous work on handwriting.
In our exploratory experiments it seemed to work as expected.
However, the model typically fails to account for about 30% of the variation in the writing times.
Obviously, a more accurate model is desirable.
An experiment that could produce convincing evidence for or against our technique is one where the writers are well trained in a handwriting system other than the Roman alphabet.
In its present form our model is already usable as a tool for estimating unistroke writing times in a comparative analysis of user interface designs.
Accot J., and Zhai S., Beyond Fitts' Law: Models for Trajectory-based HCI Tasks.
Card, S. K, Moran, T. P., and Newell, A., The Psychology of Human-Computer Interaction, Lawrence Erlbaum Associates Inc., Hillsdale, New Jersey, USA, 1983.
