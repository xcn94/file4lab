Many sophisticated tools have been developed to help analysts detect patterns in large datasets, but the value of these tools' individual features is rarely tested.
In an experiment in which participants played detectives solving homicides, we tested the utility of a visualization of data links and a notepad for collecting and organizing annotations.
The visualization significantly improved participants' ability to solve the crime whereas the notepad did not.
Having both features available provided no benefit over having just the visualization.
The results inform strategies for evaluating intelligence analysis tools.
A variety of tools have been developed to improve the sensemaking process.
For example, tools help analysts visualize and manipulate data at different levels of granularity to detect links between objects in large datasets and construct alternative hypotheses , as well as collect and arrange data and notes for later reference .
Typically, these tools have been evaluated informally, with a handful of users , or with all features available simultaneously .
While such studies are valuable, they do not shed light on the unique benefit or cost of any one single design feature to the analytical process, nor do they in most cases provide sufficient data for statistical testing of the effects of a given feature.
In crime analysis, detectives and other police personnel examine witness and suspect interviews, crime scene reports, coroner's findings and many other documents in order to detect an underlying pattern and identify a culprit .
Solving a crime requires the analyst to "connect the dots" by identifying patterns and links between facts across documents, time and space.
This process of analysis is one of sensemaking , in which analysts iteratively forage for relevant information, integrate that information into schemas or hypotheses that explain what they have found, and use these schemas to guide decisions.
For example, a homicide detective must identify which documents are most relevant to solving the crime, pour through them to uncover key people, places, weapons, and motives, and uncover relationships among these entities.
Finally, during the decision making phase, analysts choose hypotheses to act on.
For example, a homicide detective might decide that the evidence points to a single culprit and recommend that he be arrested.
The current paper aims to evaluate two features commonly available in analysis tools: a visualization of relationships among documents and entities, and a notepad that allows recording and summarizing information.
Based on previous research emphasizing the benefits of these elements for the analysis process, we propose: H1: Analysts with a visualization feature will be better able to solve an analysis task than analysts without it.
H2: Analysts with a note-taking feature will be better able to solve an analysis task than analysts without it.
It is less clear if these two features will work synergistically, leading to better performance than with either one alone, or clutter the interface and take away from focusing on finding and reading documents.
We therefore ask: RQ: What will be the benefits of providing both the visualization and note-taking features?
To evaluate the value of the visualization and note-taking features, we asked participants to solve a crime problem in which evidence for a serial killer was hidden among various documents.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
The cold cases included a summary of the victim, time, method, and witness interviews.
Four of the six cold cases were "serial killer" cases, and they demonstrated similar crime patterns .
The key clue to naming the serial killer was hidden in one of the active homicide documents.
Additional documents included city maps, bus route diagrams, crime statistics, and a police department organization chart.
In summary, clues for the serial killer were hidden across 30 carefully constructed documents with 56 possible suspects.
Additional materials included training materials, a practice task, a MO  worksheet in which participants could indicate key details pertaining to the crime, and an empty suspect list.
A post-task report sheet included spaces to indicate, for each crime, the prime suspect , any known attributes of the suspect, the victim, the MO, and the location.
A post-task survey included demographic questions, task performance measures, 5point scales for rating the tools and a comment section.
This visualization was implemented using the open source Radial-Tree component of ProtoVis .
The Notepad  is a text editor where evidence can be imported from an open document as well as freely typed in.
Highlighting important text found while reading a document automatically copies it into the notepad for easier access in the future.
The notepad can also be used to jot down comments and hypotheses, and resized like other features.
The modularity of the system components allows testing the value of each component individually and in combination.
White space replaced the area where one or two components were absent according to the experimental conditions.
The tool was implemented using Java Applet and XML.
We designed a research prototype consisting of five primary panes that can be turned on/off independently .
The Visualization feature  shows all the documents in the dataset that contain entities in common with the active document as edges between the document nodes.
The thickness of an edge is based on the number of unique entities in common between the joint documents, using TF-IDF.
Documents are color-coded based on the cases or categories to which they belong.
In many analysis tasks seeing links between documents from separate categories is critical.
Forty U.S. students  were recruited through campus flyers and paid $22.50 for a 90-minute study.
They were randomly assigned to one of the four conditions: Vis only, Notepad only, both, or none, resulting in 10 participants per condition.
They first performed the practice task.
Then, they were seated at a 25" monitor and trained on using the analysis tool with the features available in condition.
Participants then proceeded to work on the homicide cases.
They were told that they had one hour to solve as many cases as they could, but were not informed of the presence of the serial killer .
Afterwards they completed the post-task report and survey.
Based on the post-task report, participants received a score of 1 if they correctly identified the serial killer and 0 otherwise.
We also counted how many key clues, out of 9, participants described in the post-task report.
In the post-task survey, one question asked participants if they identified connections between the cold cases, and another question asked whether participants saw a connection between the cold cases and the active case holding the key clue.
They received a score of 1 if they responded "yes" to both questions, a score of .5 if they responded "yes" to one question, and a score of 0 otherwise.
Participants rated the usefulness of the interface features on five-point scales and added open-ended comments.
We also approximated the time spent using each interface feature based on cursor location as indicated in the log files.
We removed two values that were more than 2.5 SD above the mean, and divided by the total amount of time spent on the task to create percentage time measures.
These results support H1, do not support H2, and show no specific benefit or detriment for using the visualization and the notepad together.
The visualization significantly increased participants' ability to detect relationships among documents, whereas the notepad had no effect .
These findings, again, support H1, show no support for H2, and provide no evidence for benefit of both features together over one alone .
Participants with the visualization  were more likely to identify the serial killer than participants without the visualization  .
In contrast, participants with the notepad were somewhat less likely to identify the serial killer  than participants without the notepad , and participants who had both the notepad and the visualization were less likely to identify the serial killer  than those with the visualization alone .
In other words, it seems that the visualization improved task performance, whereas the notepad undermined performance.
These results provide partial support for H1, and no support for H2.
Clue recall was highly correlated with successfully identifying the serial killer .
When the visualization was available, participants spent about 11% of their time on it, and when the notepad was available they spent about 9% of their time on it .
Having both visualization and notepad did not influence the amount of time people spent on either one.
Two one-way ANOVAs comparing time on the visualization with and without the notepad and time on the notepad with and without the visualization showed no significant differences .
The amount of time spent on the visualization had no impact on how many clues participants detected.
A one-way ANOVA using only participants who had the visualization showed that neither the presence vs absence of the notepad nor the percentage of time spent on the visualization affected the number of clues detected .
Thus some other aspect of the visualization feature than the time spent on it helped participants find clues and solve the case.
Participants found the tool features somewhat useful .When given both features, they found visualization more useful.
Differences in ratings of the visualization and notepad were not statistically significant.
The open-ended responses shed light on the benefits and downsides of these features.
Some participants indicated that the visualization helped them understand how pieces of information were connected: "For just looking at one case, it isn't very useful, but it is useful for trying to find links between cases" .
Similarly, some participants liked the ability to collect, organize and revisit pieces of information using the notepad: "to gather my notes and see and reread information that I had highlighted."
Others wanted more editing and sketching capabilities, as well as better contextualizing the notes in the documents: "scribble on or add comments to files" .
The notepad, as a simple text editor, might have lacked the richness of plain paper.
These comments point to ways in which a note-taking feature could be better designed.
In this study we separately assessed the value of a visualization feature and a notepad feature in an analysis tool.
As H1 predicted, the visualization helped people identify key clues for a serial killer and to point out the culprit.
Counter to H2, the notepad provided no task performance benefits, alone or in combination with the visualization , even though participants found it subjectively useful.
Observations of the experimental sessions suggest several explanations for how the visualization led to improved performance.
Interacting with the visualization might have made it more obvious that there were connections among documents from separate crime cases, and thus potentially a single underlying culprit.
In addition, the visualization may have given starting points for the investigation, shaping the paths participants took through the documents, or informed participants' strategies for investigating the homicides.
Unlike full-fledged analysis systems, the notepad we implemented was not as sophisticated, which might explain why it did not improve performance.
Another possibility is that while people successfully used the notepad to organize their thoughts, it slowed down their reading of the documents or reduced time spent developing schemas and hypotheses, leading to no net benefit for analysis.
One limitation of our study is that it used a simplified task with fewer documents and uncertainties than in most reallife crime investigations.
Second, we focused on only two of the features that analysts would need.
Third, the design of notepad was simplistic, and lacking a sketching capability, suggesting the low performance to be a function of this particular design, and perhaps not note-taking in general.
Fourth, this experiment was a single session experiment to simulate time-sensitive sensemaking.
However, in other situations, sensemaking might be a multi-session task, requiring extensive note-taking for archival .
We also did not test the value of tools for collaborative analysis .
