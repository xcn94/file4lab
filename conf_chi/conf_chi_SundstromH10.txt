Designing for a supple interaction, involving users bodily and emotionally into a `dance' with a system is a challenging task.
Any break-ups in interaction become fatal to the sensual, fluent, bodily and social experience sought.
A user-centered, iterative design cycle is therefore required.
But getting to know the affordances of the digital material used to build the application plays an equally important role in the design process.
The `feel' of the digital material properties sometimes even determines what the design should be.
We describe three situations in which the properties and affordances of sensor network technologies guided our design process of FriendSense - a system for expressing friendship and emotional closeness through movement.
We show how the sensor node look and feel, choice of sensors, limitations of the radio signal strength and coverage, as well as iterative prototyping to properly exploit the software/algorithmic possibilities guided our design process.
Isbister and Hook sees suppleness as an interaction that relies on subtle social signals, emergent dynamics and moment-to-moment experiences: "a supple system is doing sort of a social/emotional `dance' with the end user."
They though point to the difficulties in designing for suppleness.
So far, we have only seen a few attempts to articulate and describe design processes leading to supple systems .
In the following, we aim to describe one such design process and the struggle to get the supple experience in place.
The system we designed, named FriendSense, allows a group of friends to express their friendship and emotional closeness through gesture-based interaction.
As pointed out by Isbister and Hook, it is particularly important to respect and cultivate deep knowledge of the material in which the system is being built when designing for suppleness.
Suppleness is in the details of the moment-to-moment unfolding of the experience-- something hard to understand without tinkering with it for a while."
We have gained more and more experience of the necessity to keep a very tight design process to achieve these kinds of experiences in interaction.
We have seen how using the body and gestures in interaction tend to be far more vulnerable to slightest delay or mistake in interaction compared to more traditional interaction where the physical body is not as involved.
This may be because we are less used to interacting bodily, but also since this kind of interaction is publicly visible and thereby a potential source of embarrassment.
We become more aware of ourselves and may fall out of a potential flow experience.
A supple system is a system where there are no, or very few, such `breaks' between users' emotional engagement, the interaction and system response.
Isbister and Hook introduced a use quality they named suppleness .
According to Lowgren and Stolterman, use qualities arise in the interaction with a digital artifact creating for particular experiences of the interaction as such.
Use qualities are not to be confused with usability qualities or seen as a checklist for design, but as articulated values that can help steer the design process.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
The socio-digital material is the material that arises from the combination of the digital material and how it in the end become understood and `lived' by people using it .
We are not the first to criticize Lowgren and Stolterman's position, to cite Vallgarda and Redstrom "Such a perspective, however, makes it difficult to understand how this material relates to other materials we use in design, as it almost seems to exist in isolation on its own premises."
By creating composites of digital technology and other materials, such as wood or paper, Vallgarda and Redstrom try to answer the question of how we can characterize, and work with the properties of the digital material.
In short, by creating composites they expose properties of the digital material as well as putting the material into a physical form that can be handled.
While their work is very insightful, we want to go further and argue that even the pure software components and the programming language hold properties that are important from an experience perspective and therefore have to be put into a form that can be experienced by the design team.
In our previous work, we often spent too much time developing the design idea before starting to consider the digital materials and their affordance in realizing our design.
For example we at one time treated Bluetooth simply as a means to connect two devices and did not consider the time it takes to actually achieve such a connection.
Moreover overlooked the potential to be inspired by the properties of the materials we wanted to use.
Our point is not that we should abandon user-driven design processes and work entirely technology-driven, but perhaps we need to find a balance between the two.
We need to let the material become yet another driving force in our design process, alongside with contextual or ethnographic studies, users' input and all other sources of information and inspiration we make use of.
Sensor networks were, to us, a new material we had to become acquainted with.
In getting to know its properties, such as the range and shape of the radio signal or the reactivity of the sensors, we run into both limitations to what we can design, but also novel affordances that would not have arisen if we had created the design without getting to test and `feel' the inherent properties of the material during the design cycle.
Building several experiential prototypes that we could test ourselves , `feeling' the interaction was essential in directing the design process as well as exploring the material properties.
While any design process has to consider the affordance of the material, we argue that designing for supple experiences require that the design team share a hands-on, experientially grounded, understanding of the material.
The experience and meaning of the interaction is understood in and through the emotional and bodily acts themselves - we have to perform them  during the design process.
Important to point out is that FriendSense in itself is not meant to be a full-fledged system, but a so-called technical probe .
Designing FriendSense has been about gaining a better understanding of suppleness.
As with  any design work, it is not a step-wise rational, simple waterfall design process, but a complex mess of understanding the material, how users make use of the system, and trying to achieve the use quality of suppleness.
It has been argued that HCI researchers should look more closely at the practices of architects and industrial designers and be inspired by how they design by building artifacts that can be discussed, criticized, redesigned, tested and so forth both by people within the design team but also together with potential users.
As Greenberg and Buxton  put it: "getting the right design vs. getting the design right".
If we adopt this perspective on the design process of computer systems, we must start to carefully consider the properties of our material, the digital material, in similar ways to how these practitioners explore their concrete, iron, brick or plastic materials.
By the term `digital material' we refer to technology that can sustain an interaction over time with a user ; thus it includes both hardware and software, and is manifest in both complex artifacts such as mobile phones or computers, but also in the different parts they are made from, such as sensors, network communication, radio or touch screens, all the way down to the programming languages themselves such as C, Java, or Flash.
On the one hand, the digital material is very plastic - we can design almost anything in our material.
This has lead researchers such as Lowgren and Stolterman to talk about it as "the material without properties" .
As discussed by Larssen and colleagues  when dealing with movement and body we are designing for a feel dimension rather than the more commonly visual dimension that most web and computer applications rely on.
Users become involved in a body-artifact dialogue where movement is the basis for interaction and meaningmaking.
In addition, we are addressing movement not as a modality for performing task-oriented, functional input to a system, but as an aesthetic, experiential activity.
Others who have attempted to address aesthetics of movement include Schiphorst and Moen .
Sciphorst has constructed an interactive tangible art installation called soft, where she has used conductive multitouch fabrics to capture differences in touch.
Moen has taken inspiration from modern dance in her work on the BodyBug system.
BodyBug is a small `robot' moving on a wire that users strap on to their body.
BodyBug moves in response to users' movements.
It can be seen as a game, a dance partner, or jewelry depending on how users appropriate it.
In Schiphorst, Moen and our design processes, we have all made use of a movement analysis tool named Laban Movement Analysis , in order to get at the experiential aspects of movement.
As we will make use of LMA below, we need to provide a brief introduction here.
Light would be the weight required to lift a feather while the weight required moving an elephant would be strong.
Time is the duration of movements and is measured from sudden to sustained.
Catching a fly is most often a sudden movement while stroking a pet is a more sustained movement.
Flow is related to the control of movements and is set somewhere between free and bound, similar to how people most often are more `free' in disco dancing compared to doing yoga.
As we will show below, this kind of analysis can help not only to describe characteristics of movement and body posture, but to some extent capture the experience of conducting them.
Also this analysis helps us to model movements in forms we can make a computer understand and respond to.
But obviously the inner, subjective experience of movement cannot be reduced to only these dimensions - as often pointed out by Laban himself.
Rudolf Laban was a famous dance choreographer, movement analyzer and inventor of a language for describing the shape and effort1 of different movements .
Shape describes the changing forms the body makes in space, while effort involves the `dynamic' qualities of the movement and the inner attitude towards use of energy .
Shape can be described in terms of movement in three different planes: the table plane , the door plane  and the wheel plane, which describes sagittal movements.
Horizontal moments can be somewhere in-between spreading and enclosing, vertical movements are presented on a scale from rising to descending, and sagittal movements go between advancing and retiring.
Effort comprises four motions factors: space, weight, time and flow.
Each motion factor is a continuum between two extremes.
Space attends to the surrounding, and is either direct to its' goal as in inserting a light bulb or more indirect as in waving away bugs.
The overall aim behind FriendSense was to design for the physical sensations of emotional closeness between friends.
The design task we set ourselves was to allow small groups of friends, say 3 - 10 friends, to communicate with one-another using bodily gestures through a sensor network.
A set of radio-enabled sensor nodes can only communicate when in reasonable range from oneanother .
Our idea was that the system would allow a group of co-located friends to communicate in a `virtual universe' in parallel to their verbal or facial communication.
When their sensor nodes come into range of oneanother, they will be connected in an ad-hoc local network and can start expressing and experiencing each others' interactions with the sensor nodes.
This before we go through the three examples of where the properties of the digital material came to have a decisive role in the design process.
We would like to point out that all four versions of the system were intentionally left rough in certain ways - partly because we tried to go through a faster experiential prototyping cycle, and partly to make our friends more willing to comment on the design.
The basic interaction of the FriendSense system consists of sensor nodes given to a group of friends so that they can express themselves.
The results of their expressions are displayed on a public screen.
The idea is that you may want to express your mood/emotion/closeness to others through expressive gestures with the node, mapping to colorful, animated expressions on the screen.
The first, second and third version of the FriendSense system made use of a sensor node from Freie Universitat, Berlin, see Figure 1.
These nodes were equipped with two sensors: one picking up on temperature and one registering vibration.
They were chosen from our previous experiences of how temperature and movement map very well to the emotional processes taking place in the human body .
When our friends/colleagues made gestures with the sensor node - banging the nodes against some surface or holding it in their palm to heat it - a colorful animated expression  was shown on a screen that all the other friends could see, see eMotoinspired screen dump in Figure 1.
Through manipulating the sensor node, users would move around in the colorful circle: * vibration would move them along the y-axis, portraying the energy of their expression - the lower on the y-axis the calmer expressions and animations, the higher the more wildly animated higher temperature would move them out from origo along the x-axis, showing the intensity of their feeling - higher temperature rendered the more red intensive colors while lower temperature rendered more blue, cool colors.
The left-hand-side of the circle portrays negative expressions - ranging from depressed, non-energetic states, all the way up to intense, angry, high-energy states.
The right-hand-side portrays positive states, all the way from calm, lowenergy, states, to high-energy happy states.
In sense, the first FriendSense prototype turned out to force us to express singular, individual emotions rather than group-oriented expressions such as empathy or closeness to others.
From the ethnography performed before the design process started , we also knew that friends often attempt to create `experiences' together, be concrete joint experiences as singing or dancing together or more ephemeral experiences as cocreating a particular mood.
We therefore moved to a second version where we took inspiration from a Russianborn painter Kandinsky  and his painting Farbstudie.
Here friends' individual expressions on the public screen were given one `square' each, thereby allowing each friend to describe their own mood/emotion, as can be seen in Figure 1.
But as a group they were dynamically creating the whole screen together.
The color, a scale going from `basic blue' to `basic red', was mapped to the temperature sensor.
Another problem with the second version was that we could not make out who was who amongst the different Kandinsky squares on the public screen.
In our third version, we therefore altered the graphical expressions again.
We were inspired by marbles and how marbles can have objects inside, under a see-through but sometimes colored surface.
In the system, each friend has their own marble that they can change the color  and animation  of.
They can also put a personal picture inside their marble and have it covered with the  color of the marble.
On the surface of each marble, previous states are portrayed as old smaller marbles attached to their big, current marble, see Figure 1.
We also changed the color scale into a scale designed to express more of the physical experience of temperature  , going from `cold' blue colors all the way to bright red `warm' colors, see Figure 2.
But the most important change in this third version was that the friends could socially position themselves on the public screen by `far-from' and `close-to' buttons in the client software on their computer.
If you feel close to one of your friends, you could tell the system that you wanted your marble to be close to that friend's marble.
In the latest version of the FriendSense system each user is given a sensor node  equipped with an accelerometer that picks up on acceleration in all three dimensions.
We map this to characteristics of gestures, in Laban-terms the shape and effort of movements.
Effort is mapped to how much `weight' a user puts into the movement, and for how long the effort is maintained.
This measurement is then mapped to the color of the marble.
The flow of movements is categories as either smooth or jerky, and is mirrored in the movements of marbles as smooth or jerky animations.
The shape of users' movements are calculated from the size of the gesture and mapped to how marbles move over either a small or a larger space on the public screen.
In a sense, this became a more holistic ways for users to express themselves through movement - an issue that we come back to and explain below.
To make the overall picture of the FriendSense system a little more comprehensive we will present two example situations of FriendSense in use.
Both these examples are from using the third version of the FriendSense system, the marble version.
Figure 3 presents screen dumps of the public screen by the end of these two situations.
The first example comes from when one of our colleagues was close to defending his thesis and the rest of us wanted to show him our support without disturbing him in his stressful situation.
As we know, users tend to forget about updating their status in social systems when being engaged elsewhere.
The same happened to this colleague, who had left a very stressed and annoyed expression of himself on the screen for several days.
What happened was that the rest of us, who had a little more time to interact with the FriendSense system, fiddled with our expressions to look equally stressed, placing ourselves close to his expression on the screen.
Some of us also filled our expression with photographs of our colleague.
But not only was this situation about a group formation of a collective empathic expression on the public screen.
To form these stressed expressions we had to move our sensor nodes and thereby ourselves in a stressed manner, which meant that we also physically and emotionally experienced reminiscents of the same stress he experienced.
Another example illustrative use example was when two of our colleagues were in conflict with each other.
In a workplace emotions such as anger and annoyance needs to be controlled and most often, we spend quite some energy on finding less harmful ways of expressing them.
Our intention was not to implement a system that would expose purposefully hidden emotional processes, but we also did not want our system to prohibit showing aspects of sensitive or even destructive actions.
In this situation one of the two colleagues was supervising the other and they had become good friends.
The differences in their relationships to each other sometimes made the situation a little bit tense, especially during stressful parts of their joint work.
In FriendSense they sometimes allowed themselves to reveal some of their current, perhaps more negative, emotions towards each other, emotions that at the time were too sensitive for them to explicitly talk about as it could have harmed their work relationship.
The way this was acted out in FriendSense was different from how it perhaps would have been acted out in real life: it became a `game' where the supervisor teased her student by challenging her `sulky' mood.
Figure 3b shows how the student reveals her sulky/angry mood towards her friend/supervisor by putting an angry picture inside her marble, make it orange/red and moving it far away from the supervisor's marble.
The supervisor responds to this by repetitively trying to place herself close to the student's marble - not to calm her down but instead to tease her and perhaps upset her even more, in a sense to take the edge off the quarrel.
This `hunting' across the screen through repeatedly positioning themselves relative to oneanother continues silently in parallel to their actual work together where the situation is still tense.
The first sensor nodes we used picked up on temperature and vibration but that did not, despite what we assumed, properly afford expressions such as moving, warming or cooling the node.
To really make the animation on the public screen lively, we had to bounce the sensor node against our hands or some more or less hard surface, such as the desk or a bunch of papers.
This activity became way too focused on the requirements of the node rather than moving and expressing yourself freely and letting the system pick up on that.
Likewise, heating or cooling your temperature sensor turned out to be a harder task than expected since the battery on the back of the circuit board emitted heat and the placing of this sensor varied between the nodes.
This resulted in differences in how hard it was for users to have an affect on temperature and thereby the color of their expression on the screen.
Some could not make their sensor cool down at all.
Occasionally we had to place our nodes on the windowsill outside a window to cool it down .
These activities distracted our attention from trying to express ourselves to instead focus on the physicalities of the nodes.
The interaction became to cite Heidegger `present at hand' rather than `ready at hand' .
The bulkiness of the node also better afforded negative gestures, noise and frustration, and not the more pleasant, warm or cheerful gestures.
One of our colleagues even dressed her node to make it both look nicer but also more comfortable to hold and thereby potentially affording more positive gestures, see Figure 4.
It became clear to us that the limitations of the Freieie Universitat sensor nodes were too big to overcome.
We needed different sensors and a different look and feel of the node itself.
The Sentilla JCreate sensor node is covered with a smooth plastic surface, it is smaller and the look of it is more neutral  than our previous sensor node.
This made it more comfortable to hold and therefore we hoped it could allow us to be more expressive.
Given the description of the development of the FriendSense experiential prototypes, some of the reasons why we progressed from one version to the other, and a few example of usage, let us now turn to three of the most significant design insights on suppleness that arose from the properties of the digital material itself.
Our design aim is that the gestures should not feel like symbols or functions - they should be involving, experiential gestures, resembling our emotional and social ways of being in the world.
From that we could calculate the energy/effort of movements  and together with its progression over time we could also calculate distance in all three planes.
That in turn allowed us to look for the size of movements and if they are smooth or jerky in terms of flow.
While some sensors, such as the vibration sensor used here, will force users to move the sensor in ways that makes sense to the sensor, but not to the user, the accelerometer picking up on movement in three planes allowed users to move freely, in ways that made sense to them - in this particular application scenario.
To verify this in the FriendSense setting and also to get more experience of what movements users wanted to express if not hindered by the sensor properties, we organized a workshop with some of the friends/colleagues who had been using the previous versions of the system.
They were given the sensor nodes to try out, but there was no functioning system in place.
This allowed them to show us expressions and interactions they wanted to perform, based on their prior understanding of the material qualities, thereby making them realistic to implement.
During the workshop, it was fairly easy for us to brainstorm and a range of expressive gestures was performed.
For example, one participant brought her sensor node close to her heart to show empathy with another participant who had bad luck with his employment situation.
He thanked her by moving his sensor node in a big circle.
Then when another participant told the group about his luck in finding a job, all participants showed how they had mixed feelings about this, happy for one and sad for the other.
Later during the workshop several participants got playfully annoyed with another participant who they said was talking too loud and started to mimic the sound of this by banging their sensor nodes against the table.
From a Laban analysis of the movements of this workshop  it became clear that we could use Laban notation to go from the participants' personal, individual gestures into a slightly generalized set of underlying dimensions of the gestures that reasonably captured the experiences of performing them.
And given our deepened material knowledge, we could pick dimensions that the accelerometer would be able to capture.
But this brought us to the second material encounter example: how could we map these dimensions to expressions on the public screen?
Different people may have quite different body language, and so we could not map the gestures in a one-to-one manner to some specific expression on the screen.
Not could we require users to perform one specific movement to get one particular expression, as that might not harmonize with how they want to express themselves.
We also needed quite some liberty to express a whole range of experiences - not be forced to choose among a limited set of possible states.
Here the properties of the software material - the algorithm for mapping from gesture to public screen expression - became prominent in our design process.
In the algorithm, the effort expenditure over time was mapped to the color of the marbles.
The underlying argument was that if you put a lot of effort into a gesture you get warmer, it feels more `red', while if you put less effort in, it feels cooler, a `blue' feeling.
Through focusing only on the effort dimension, different people can exert effort in different ways - it does not require one particular shape of the movement.
The flow of movements  was reflected in how your marble on the screen was animated.
Here we aimed for, more or less, a direct mirror of the movement.
The marbles should be in synch with your own body - making them part of your own expression.
We wanted to allow for the feeling that the expressions extended upon your own movements and that they were mirroring you rather than that you had to consciously affect certain aspects of them.
Finally, the shape of movements was only analyzed in terms of their size.
We mapped this size to how the marbles were animated as moving over either a small or a larger space of the public screen.
It may sound as if this mapping from movements with the sensor node to expressions on the screen was easy to find - or that we claim that this is the optimal and only possible mapping.
This is not the truth.
The Laban-analysis helped us in that we knew what characteristics of movements we were to capture and create a coherent expression for on the screen, such as flow, size and effort of movements rather than the complete picture of movements.
We could also work with these dimensions one at a time and make sure we got each part of an expression right before we combined it into one.
But still, it was a complicated, iterative process to fine-tune the graphical expressions to harmonize in terms of timing and `character' of users' movements.
For example, to capture the flow of movements we had to decide on an algorithm that felt as if it could exhibit the diversity required by users' different personality in bodily behaviours.
It was a matter of finding the characteristics of movement rather than a choice of graphics.
The only way to get this right was to repeatedly test it - `feeling' the interaction and thereby finding the right mapping algorithm.
In our long-term use of the third FriendSense prototype, the possibility to make your marble close or far away from someone else's marble, became one of the more important expressions .
The system mediated a `parallel universe' of interaction to that going on in the `real world'.
The way you sit on your chair, your facial expression, your sighing, or body posture all reveal aspects of what you are doing and what you are feeling.
But the probe did not mediate exactly the same signs and signals as your physical body does.
Emotional closeness, conflicts, and bodily experiences as expressed in the office were transferred, transformed and juxtapositioned against participants' virtual presence and positioning on the public display.
What was going on inside the probe was sometimes equally important as what was going on in the office in terms of expressing emotional, physical closeness or distance.
In our second and third implementations of the FriendSense system there was a software client running on users' PCs where friends first created their expression using their sensor node and then uploaded it to the public screen.
For the marbles version this software client also allowed users to position their marble in relation to other' marbles by clicking on `far-from' or `close-to' buttons.
In the fourth prototype, we wanted to remove the software client to strengthen the physical experience of expressing oneself using only the sensor node directly mapping to the big screen.
The software client had been an annoying layer of interaction, hindering a direct relationship between us and our expressions on the public screen.
But how could we use the sensor nodes to express whom we wanted to be close to or far from?
One suggestion we had got from one of our users was that users move their nodes physically closer to/farther away from their friend's nodes to express distance.
Her idea was to use the radio-signal strength to solve this technically, as radio-signal strength is oftentimes used for indoor positioning .
But, as it turns out, in a technically `noisy' environment the radio on the nodes will not map distance very well and especially not at the granularity level we needed.
To understand how radio in sensor nodes functions, we need to explain some of its digital-material properties.
One node is often set to be the host and collects communication packets sent from the other sensor nodes.
In such a hostset up, a packet from one node, is not only sent directly in a straight line to the host.
Instead there is a broadcast of packages sent in all directions from each and every node.
As discussed above, the ultimate design goal for FriendSense is to embody some of the more bodily aspects of emotional closeness and the bonds of friendship that hold a group of friends together.
But in a group of friends, we are not equally close to everyone, and over time, we may want to express more or less closeness to our friends , due to the everyday dynamics of empathizing, quarrelling, longing for or even getting bored with our friends.
And sometimes, we want to be alone, despite being physically amongst our friends.
But, unfortunately, this ideal scenario does not exist for several reasons.
First, all nodes are sending packages at the same time and they are also broadcasting which leads to multiple, ambiguous packets and changes in signal strength.
Second, there are other wireless communicating units in the room, such as mobile phones or Bluetooth units, which together with walls, furniture and people in the environment make some packets get lost or be stopped on route to the server.
In summary, using radio for positioning may render more or less random results.
There is not space enough to describe ArtSense here, but in short, it allows friends visiting a museum to express themselves physically, through gestures, leaving traces or co-created expressions for their friends to pick up on as they pass through the museum .
ArtSense does not rely on any screen, but uses leds and vibrations as feedback - all integrated into the egg-shaped artifact.
But the purpose of designing the FriendSense-probe was not only to work out the overall set up or possible functionality of a potential future system.
Our main purpose was to learn more about supple interaction based on a better, richer and deeper understanding of the material.
We had to figure out the affordances of the sensors and the sensor network technology in order to know how to create for "an emotional and social `dance with the system'" where expressing yourself also makes you feel bodily and physically involved in what you are expressing.
We needed to know what kinds of movements and expressions users would want to express in various situations - but perhaps more importantly, how those would arise from their dialogue with the material and what that would feel like.
This why FriendSense was permanently installed and used in our own lab.
Some readers will probably object to the idea that colleagues at work are friends.
Others might object to the method of letting designers base the design decisions solely on their own experience of the system they are designing.
But to us, this was a crucial step in living our own design and experiencing exactly how the different design decisions and choices of technology we brought in changed our experiences of the system.
Obviously, this does not remove the need to bring in outside users , to empathize with future users , or to find a relevant context and study it as input to the design .
By exposing some of our design process and the importance of considering the material properties we have started to uncover some of what Isbister and Hook discussed in their paper at CHI 2009 - partly from living with our design throughout the design process but also from truly getting to know our material.
Our emphasis has been on how the design processes can be shaped by the materials being used; to design with sensor networks is not the same as designing with some other digital material.
As can be seen from our three examples of material encounters, the look and feel of the sensor node, choice of sensors, limitations of the radio signal strength and coverage, as well as iterative prototyping to properly exploit the software/algorithmic possibilities guided our design process.
We had to go back to the drawing board and think carefully about what it was that we really wanted to achieve with the idea of `social positioning' and friends being close or afar from one-another.
The problems with sensing distance made us ask ourselves whether social position should be linked to physical closeness of the nodes?
Perhaps more important was emotional proximity - having the same mood or showing empathy through trying to have the same expression as a friend ?
From what we and other friends actually did with the system, we saw the potential of basing closeness on likeness of expression - `expressive likeness positioning'.
Two friends with the same expression could be moved close to one-another.
Expressive likeness positioning also allows for mimicking and letting users note the effort others have put into an expression.
But while this approach opened up for these other interesting aspects of emotional closeness expressed as empathy, it did not solve the original problem.
Properties of the material prohibited a perfect match with our design aims.
But instead of `fighting' the material to fit the design aim, we used the properties of what the material afforded,and what we had seen unfolding in the socio-digital material.
In this design process we put ourselves in an extreme starting position: without a clear and detailed idea of the purpose of the system , without a clear context of use, and with only minimal input on how friends create their and sustain their friendships .
Instead, we immediately dived into the lived experience of the material thereby finding out why, how and where friends could make use of this kind of system.
This extreme position allowed us to see how the socio-digital material unfolded in dialogue with the technological possibilities.
In retrospect, after having worked through this complicated and messy design task the lessons learnt were crucial for the next step in the design process where we moved from our probe-approach to creating a more realistic system, ArtSense.
The possible expressive gestures must therefore co-evolve with the exploration of the affordance of the digital material.
It is also interesting to note how the expressions of friendship inside FriendSense were different from their expressions `in real life'.
There is no way we could have jumped from the initial ethnographic study of long-term friends directly to designing the final version of FriendSense.
FriendSense is not a simple mapping from how people touch, quarrel, co-create mood, confide or have fun in real life.
We first had to live with the experiential prototypes to find the `alternative universe' of expression that the digital material enabled.
It is only when our groups of friends start expressing themselves in and through the experiential prototypes that the socio-digital material takes shape for us as designers.
Only then can we mould the interaction into meaningful gestures and interactions between the friends.
Inspirational patterns for embodied interaction.
Journal of Knowledge, Technology & Policy 20.
Cambridge, MA: The MIT Press.
Lowgren, J and Stolterman, E.  Design av informations-teknologi: Materialet utan egenskaper.
From Hand-Held to Body-Worn: Embodied Experiences of the Design and Use of a Wearable Movement-Based Interaction Concept.
SenToy: an Affective Sympathetic Interface, International J. of Human Computer Studies, Vol.
In Personal and Ubiquitous Computing, Volume 13 Issue 5, pp.
Stahl A  Designing for emotional expressivity.
Unpublished Licenciate Thesis, Institute of Design, Umea University, Umea, Sweden.
Probing the potential of non-verbal group communication.
Sundstrom, P., Stahl, A., and Hook, K.  In Situ Informants Exploring an Emotional Mobile Messaging System in Their Everyday Practice, In a special issue of IJHCS on Evaluating Affective Interfaces, vol.
Vallgarda, A. and Redstrom, J.
Wilde, D.  Using technology to poetically extend the dynamic moving body.
Empathy and experience in HCI, CHI `08.
Zhao, L.  Synthesis and Acquisition of Laban Movement Analysis Qualitative Parameters for Communicative Gestures, PhD thesis, CIS, University of Pennsylvania.
Thanks to Alex Taylor, Tove Jaensson, Annelie Schwanecke and Alina Pommeranz for valuable feedback and work in the project, and to Anna Karlsson for graphical illustrations.
The research was done in the Mobile Life centre, funded by VINNOVA, Ericsson, Sony Ericsson, TeliaSonera, Microsoft Research, Nokia and Stockholm City Municipality.
Davies, E.  Beyond Dance, Laban's Legacy of Movements Analysis, Brechin Books ltd., London, UK.
Greenberg, S. and Buxton, B.
Usability evaluation considered harmful .
State University of New York Press, Albany.
Technology probes: inspiring design for and with families, CHI'03.
On being supple: in search of rigor without rigidity in meeting new design and evaluation challenges for HCI practitioners.
Supple interfaces: designing and evaluating for richer human connections and experiences.
The Feel Dimension of Technology Interaction: Exploring Tan-
