In this paper we explore whether implicit sharing, in which the system automatically shares insights between analysts, can support distributed collaborative analysis.
The design idea is that making sharing automatic reduces friction for knowledge sharing, and improves awareness  that might limit collaboration, while sharing notes rather than raw data both reduces cognitive load and supports organizational policies around information ownership.
We examine the effects of such implicit sharing compared to a system where analysts must explicitly tell their partner about their insights through chat.
In an experiment, pairs of remote individuals played the role of crime analysts solving a set of serial killer crimes with both partners having some, but not all, relevant clues.
Participants with implicit sharing detected more relevant clues and rated the collaborative features of the tool as more useful, without increasing cognitive workload or reducing explicit communication.
This paper contributes to a growing body of literature in the area of collaborative analysis and sensemaking, by providing findings from a controlled experiment that focuses on the value of implicit knowledge sharing for task performance, use of interface features, team experience, and cognitive workload.
Most previous work evaluated collaborative analysis tools with a handful of participants without comparing tools to alternatives , by running a solo study , by studying explicit knowledge sharing , or have not evaluated the tools with human participants at all .
In this paper we present a methodical study that demonstrated the benefit of a specific design feature, implicit knowledge sharing, on the process and outcomes of a collaborative analysis task.
When crime analysts collaborate to solve crime cases, they need to share insights in order to connect the clues, identify a pattern, and attribute the crime to the right culprit.
We designed a collaborative analysis tool to explore the value of implicitly sharing insights and notes, without requiring analysts to explicitly push information or request it from each other.
In an experiment, pairs of remote individuals played the role of crime analysts solving a set of serial killer crimes with both partners having some, but not all, relevant clues.
When implicit sharing of notes was available, participants remembered more clues related to detecting the serial killer, and they perceived the tool as more useful compared to when implicit sharing was not available.
In 2007, Robert Pickton was convicted for six murders of women in British Columbia and connected to 24 others in the Vancouver region .
The Vancouver Police Department  came to suspect that the cases involved a serial killer, but they did not communicate this hypothesis to their cooperating partner, the Royal Canadian Mounted Police .
Furthermore, missing women reports filed with one agency were not shared with the other except when specific requests were made.
These problems potentially delayed the investigation and led to more victims.
In complex crime investigations that span geographical regions, time periods, and cases, relevant information and insights are distributed among individuals, teams, and agencies.
These entities need to exchange information in order to create a full picture of the case , but barriers ranging from privacy settings, institutional policies to the costs of exchanging information hinder sharing even when incentives  or tools that recommend previously shared information  are available.
Copyrights for components of this work owned by others than the author must be honored.
Abstracting with credit is permitted.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Copyright is held by the owner/author.
Publication rights licensed to ACM.
In order to analyze and solve crimes, investigators systematically examine timely and pertinent information in search for patterns and trend correlations in the cases they are investigating .
According to Pirolli and Card , analysts first forage for relevant information in large amounts of dynamically changing data, often from many different sources.
While some of the foraged information might satisfy this representation, other pieces might not fit.
Analysts then iteratively forage for additional information to support their mental model or to develop competing hypotheses .
Finally, analysts choose the best explanation and schema that fits the information and disseminate it to the relevant audience.
When multiple analysts work together to solve a crime or a set of crimes, the analysis process  must be performed jointly and strategically to be successful.
Analysts working together may be able to collect more data, provide different perspectives on the data, and stimulate each other's thinking processes through sharing knowledge and insights.
Such sharing can improve both process and performance in collaborative sensemaking and analysis tasks, measured by accuracy of task outcomes  and recall of decisions .
Sharing can also help analysts flexibly organize data to discover insights and form schemas  or concept maps , identify and link evidence from different sources , identify entities in the data , and encounter otherwise hidden and overlooked connections between pieces of information , leading to better decisions .
The success of shared workspaces in team performance has been attributed to promoting exchange of information and data with others , as a result improved common ground  and awareness of the status of the analysis task and others' activities in the task .
In order for these benefits to accrue, however, the sharing must actually happen .
In general, research on collaborative analysis casts sharing as an explicit process in which analysts consciously choose to share data objects, annotations, and sketches .
For instance, Convertino et al.
Analysts choose which information pieces and notes to push to the public workspace.
Designs that put the burden of sharing on analysts, however, risk undersharing because of insufficient knowledge of when to share what, failing to understand the importance of sharing, inability to weave sharing into the task at hand, or costs and discomfort in using tools designed for sharing .
One way to promote explicit sharing is to motivate sharing through incentives .
For example, CrimeFighter  supports sensemaking and dissemination by inducing participants to voluntarily share information.
Another approach is to remind analysts to share relevant pieces of information with others, as in AnalyticStream .
However, even when systems encourage voluntary sharing, organizational norms around information ownership, personal beliefs about these norms, or lack of explicit protocols around information sharing may also inhibit actual sharing , as in the Pickton case .
Instead of explicit sharing information, we examine the potential value of implicit sharing of insights.
We focus on insights  rather than raw data and facts  because the latter is often subject to organizational policies and norms of sharing .
Thus, unlike other studies  we assume that analysts do not--and should not--necessarily have access to others' raw data sources: separation of information represents organizational boundaries and individual expertise .
Instead, as analysts make their own notes about insights from their own evidence, those notes are automatically shared with their partners.
This removes the effort involved in assessing whether or not to share an insight and then explicitly placing it in a public workspace .
Our hypothesis is that because of this reduction in effort and increase in sharing and awareness, analysts working collaboratively will perform better when implicit sharing is available than when it is not: H1.
Participants using implicit sharing of notes will perform better on a collaborative analysis task than participants without implicit sharing of notes.
Implicit sharing may also shift the value of certain elements of the analysis workspace.
Individual features of analysis tools emphasize different aspects of sensemaking, and small changes to these features  can affect analysts' sensmaking strategies .
A tool used to capture notes and insights may therefore become more valuable when it is shared with other analysts.
Similarly, a workspace viewed only by a single analyst may be less valuable than one that multiple analysts can view.
If analysts perceive that these tools are more valuable, they might use them more, interacting with their features and manipulating the data in them.
We hypothesize that the availability of implicit sharing of notes will therefore affect both people's evaluations of the features of the tool and their use of these features.
Participants using implicit sharing of notes will rate the usefulness of collaborative features of the tool higher than participants without implicit sharing of notes.
Participants using implicit sharing of notes will interact with collaborative features of the tool more than participants without implicit sharing.
We also believe that implicit sharing has the potential to improve the experience of working together.
For example, sharing document collections was shown to be valuable to get novice analysts up to speed with the status of what others are doing .
In medical settings, implicitly shared awareness information can ease the flow of communication and establishment of common ground between clinical staff members .
Similarly, in an emergency management setting, increased common ground was associated with higher perceptions of the team process .
Participants using implicit sharing of notes will rate their team experience higher than participants without implicit sharing of notes.
By changing the amount and type of information available, implicit sharing may affect the mental demand of the crimesolving task.
On the one hand, a shared workspace may reduce the time and effort put in the analysis task compared to working alone .
Further, implicit sharing helps establish common ground , and thus might reduce analysts' need to explicitly formulate messages and communicate information, thereby reducing their workload.
On the other hand, shared workspaces might increase communication costs .
Seeing partners' activity might divert attention from one's own thoughts and increase the need for explicit discussion of process and data, especially when shared insights are connected to unshared data .
Since the direction of impact is unclear, we pose two research questions: RQ1.
How will implicit sharing of notes affect participants' cognitive workload?
RQ2: How will the availability of implicit sharing affect the amount of information exchanged via explicit channels?
The crime cases were distributed between the partners, with a hidden serial killer that had to be identified.
Half of the pairs worked on the task using an interface that provided implicit sharing of notes.
The other half worked on the task using an interface without implicit sharing.
We collected data via post-task surveys, participant reports, and computer logs.
We adapted Goyal et al.
SAVANT has two main components, the Document Space  and the Analysis Space .
The Document Space has a number of features for data exploration and discovery.
A document library and a reader pane are for viewing and reading crime case reports, witness reports, testimonials, and other documents.
A network diagram visualizes connections between documents based on commonly identified entities like persons, locations, and weapon types.
The Document Space also provides a map of the area where crimes and events were reported and a timeline to assist in tracking events over time.
Users can highlight and create annotations in the text of documents, locations on the map, and events in the timeline.
Such annotations automatically appear in the Analysis Space, an area for analysts to iteratively make and reorganize their notes until they see emerging patterns that lead to hypotheses .
The Document Space showing  the directory of crime case documents, a tabbed reader pane for reading case documents, a visual graph of connections based on common entities in the dataset, a map to identify locations of crimes and events, and a timeline to track events.
Stickies can also be created directly in the Analysis Space, unconnected to specific documents.
Analysts can move Stickies around, connect Stickies together, or stack them in piles.
The Analysis Space supports collaboration through both explicit and implicit information sharing.
For explicit sharing, a chat box at the bottom-left corner allows analysts to discuss their cases, data, and insights and to ask and answer questions.
For implicit sharing, the Analysis Space shows other analysts' Stickies in real time as they are created and organized in the space.
Stickies are color coded by the analyst who created them, but anyone can move, connect, or pile anyone's Stickies.
Mouse cursors are independent of each other, while dependencies between Stickies are handled by the server on a first-come-first-serve basis.
The server updates the interface every second.
We created two versions of SAVANT for this study.
In the implicit sharing condition, Stickies in the Analysis Space are automatically shared as described above: there is no private workspace for analysis, only a public one.
In the no implicit sharing condition, partners only see their own Stickies in the Analysis Space: there is no public workspace, only private ones for each analyst.
The chat box is available in both conditions to support explicit sharing.
The experimental materials were adapted from Balakrishnan et al.
A practice booklet with a set of practice crime case documents introduced participants to the process of crime analysis and highlighted the importance of looking for motive, opportunity, and the lack of alibi.
The primary task was created to be reasonable, but difficult, for novice analysts to complete in a limited time.
The main task materials were a set of fictional homicide cases.
There were six cold  cases, and one current  case.
Each of the cold cases included a single document with a summary of the crime: victim, time, method, and witness interviews.
Four of these six cold cases were "serial killer" cases.
These four had a similar crime pattern .
The active case consisted of nine documents: a cover sheet, coroner's report, and witness and suspect interviews.
Additional documents included three bus route timetables and a police department organization chart.
The documents were available through the SAVANT document library and were split between the two participants such that each had access to 3 cold cases  and 5 documents from the active case .
The additional documents were available to both participants.
Overall, each participant had access to 13 documents, of which 6 were shared with the other participant and 7 were unique.
Twelve clues for detecting the serial killer were dispersed across the 20 documents with 40 suspects/witnesses, equally distributed between the two participants with four in common and four unique to each partner, following a hidden profile task paradigm .
The key clue to naming the killer was included in one of the witness reports of the active case, although the active case was not one of the serial killer cases.
The task for this study was carefully designed to include data and aspects that are similar to real-world crime cases that remain unsolved, at a scale that could be analyzed in a one-hour session, and at a level of difficulty where many people are unable to solve the crime .
At the end of the session, each participant wrote down as many clues as they could recall supporting their hypothesis about the serial killer.
A participant's clue recall score was the number of correct clues written down, similar to the measure used by Convertino et al.
The post-task survey included multiplechoice questions, each related to one of the 10 clues hidden in the dataset.
For example, "On the day of his wife's murder, Ron Raffield claimed that A.
He'd run into an old acquaintance on the bus.
He'd been out of town on a business trip.
C. He'd been tied up in a meeting all afternoon.
D. He'd tried to call Darlene, but she never answered her cell.
A participant's score was the number of correct answers to these 12 questions.
At the end of the session, each participant wrote a report in which they were asked to name the serial killer.
We counted this as binary variable: either the serial killer was identified  or not .
Two workstations  were connected to the Internet and ran SAVANT.
Each was connected to two 25" monitors, the left showing the Document Space, and the right showing the Analysis Space.
SAVANT logged keyboard and mouse activity as locally stored time-stamped CSV files.
To simulate remote collaboration, the workstations were in separate cubicles to prevent eye contact and participants wore noise-cancelling headphones to prevent noises  from affecting each other.
In order to answer H2a, we asked several questions probing participants' evaluations of features of the SAVANT system in the post-task survey.
This is similar to other studies that examined the usefulness of system features .
Stickies: Four 5-point questions asked participants about the degree to which the Stickies promoted discussion, helped achieve understanding, and communicate ideas.
For example, "The Stickies in Analysis Space helped me understand what my partner was thinking."
These four questions formed a reliable scale  and were averaged to create a measure of Stickies' usefulness.
Five 5-point questions asked about the degree to which the Analysis Space helped participants feel physically, cognitively, and emotionally closer to their partner, helped them work with their partner, and helped them understand their partner's activities.
These five questions formed a reliable scale  and were averaged to measure Analysis Space usefulness.
After being seated in separate cubicles, participants signed a written consent form, and read the training materials and performed the practice task individually for about 10 minutes.
Participants then received a 10-minute tutorial on the SAVANT interface.
The experimenter explained the different parts of SAVANT using example tasks that participants would perform.
Then, using SAVANT, participants worked as a team on the primary task to identify cases associated with a serial killer, name the serial killer, and find as many clues as possible in 60 minutes.
At the end of the task, each participant received a paper report form at their workstation to fill out with name of the serial killer, associated cases, and the clues they could recall that would incriminate the killer.
They then completed an online survey with questions about clue recognition, the utility of the interface, the collaboration experience, cognitive load, analytic ability  and demographic information.
In order to answer H2b, we used system logs to derive In order to answer H2b, we used system logs to derive measures of participants' actual use of features in the Analysis Space, including the number of connections they made between Stickies, the number of piles they created, and the overall number of movements  of Stickies.
In the implicit sharing condition participants could manipulate both their and their partner's Stickies, whereas in the non-implicit sharing condition each participant could only manipulate their own Stickies.
Therefore, these three measures are at the pair level, aggregating both participants' actions in a session.
There was a significant effect of implicit vs. no implicit sharing on the number of clues participants recalled in the written report .
As shown on the left side of Figure 3a, participants in the implicit sharing condition recalled more clues  than those without implicit sharing .
Given the large Cohen's d  and the fact that these clues were buried in 20 documents with many information pieces, we regard this as a meaningful increase in clue recall, paralleling other work that has found increases in task-relevant recall in shared workspaces .
The right-hand side of Figure 3a shows participants' performance on the multiple choice clue recognition questions in the post-task survey.
We also examined whether interface condition affected the likelihood that participants could solve the crime.
Since solving the case was a binary dependent variable, we ran a binomial logistic regression with condition as the independent variable and pair as the random effect variable.
Sharing subset of knowledge manually did not improve answer accuracy in  but sharing knowledge implicitly in a small experiment did increase answer accuracy in .
The post-task survey contained ten survey questions about the quality of the collaboration .
These ten questions formed a reliable scale  and were averaged to create a team experience score, to answer H3.
This measure is similar to  who used a post-task questionnaire to assess quality of communication within the group.
In order to answer RQ1, the post-task survey contained five questions based on the NASA TLX  that asked participants to rate how mentally demanding, temporally demanding, effortful, and frustrating the task was, as well as their subjective performance.
After inverting the performance question, these five responses formed a reliable scale .
Participants' responses were averaged to create one measure of cognitive load.
SAVANT logged the chat transcripts for each session, which were then cleaned to remove extraneous information like participant identification and timestamps.
To answer RQ2, explicit sharing was measured at the pair level as the number of words exchanged in the chat box during a session.
This is similar to  who assessed the number of chat lines exchanged during the experimental session.
H1 proposed that pairs would perform better when implicit sharing was available than when it was not available.
To test this hypothesis, we conducted mixed model ANOVAs, using clue recall and clue recognition as our dependent measures.
In these models, participant nested within pair was a random factor and condition  was a fixed factor.
We analyzed participants' ratings of the usefulness of Stickies and of the Analysis Space using mixed model ANOVAs with participants nested within pair as a random factor and interface condition  as a fixed factor.
As shown in Figure 3b, H2a was supported.
Use of SAVANT features H2b predicted that the availability of implicit sharing would lead participants to interact more with Stickies in the Analysis Space than without implicit sharing.
Using system logs, we counted the number of connections between Stickies, piles of Stickies, and overall Analysis Space manipulations that pairs made over the course of a session.
Overall use of connections and piles was quite low and not normally distributed, so we did not perform ANOVAs on this data.
In contrast, Hayne et al.
They conclude that without a shared workspace, the workload on each individual analyst was increased as a result of the increased interactions with interface and information elements.
RQ2 asked whether the availability of implicit sharing might change the amount of explicit sharing via the chat box.
A one-way ANOVA was used to compare word counts at the pair level, using condition as the fixed factor.
Participants' open-ended responses on the post-survey shed some light on just how implicit sharing was valuable and how it interacted with explicit sharing features.
Several participants mentioned that implicitly shared Stickies helped them "make connections" and also added value "by comparing information" or "cross-referencing information" visually between each other to promote awareness: "The Stickies enabled a connection between my partner and I, we could see each other's train of thoughts and methods of organization.
I used the connecting lines for the Stickies to show myself and my partner the connections that I was seeing."
Much of the value came from the combination of implicit and explicit sharing.
For example, implicit sharing could reduce the need for explicit communication: "The chat was easily the most helpful because it allowed us to communicate and tell each other specifics about the case.
The Stickies were very useful also because they allowed us to make connections between the information we both had independent of talking with each other.
On the other hand, implicit sharing could also prompt explicit chat and sharing, when it revealed needs and gaps: "I used the Stickies as jumping off points for conversations with my partner - I would see her Sticky and then ask her to fill in some details that she may have skipped over since she had access to certain documents that I did not."
Finally, Stickies were intentionally designed to be free form and open-ended, and participants did use them to separate aspects of the problem: "I simply piled them together and placed them in strategic positions.
We used two stickies sometimes for the same case.
Each sticky would have another side of the case like emotional and the other would be factual."
H3 predicted that participants would rate the quality of their collaborations with their partners higher when they could implicitly share information compared to when they could not.
To test this hypothesis, participants' team experience scores were analyzed in a mixed model ANOVA in which participant nested within pair was a random factor and condition  was a fixed factor.
They demonstrate the power of implicit sharing to improve collaborative analysis without requiring partners to explicitly push or pull information by triggering understanding and insights on both sides, improving efficiency of conversation, and initiating explicit discussions.
Task, scope, team size, and organizational policies might drive the choice of different sharing policies and design decisions  for different kinds of information, including raw data, operations on raw data such as reading or organizing it, annotations, and operations on annotations such as connecting and moving them.
There are many possible choices around what and how to share that will require a number of rigorous, carefully designed studies that evaluate these specific design features in different contexts.
Finally, the motivation behind our design of sharing insights instead of case documents was to respect organizational policies around sharing confidential materials across institutional boundaries: sharing inferences and notes might allow greater awareness without direct access to confidential raw data.
Our findings show mixed results about the value of implicit sharing for collaborative analysis performance .
Participants were better able to identify relevant clues in the data when implicit sharing was available, but were not better able to name the killer.
The hidden profile nature of this dataset has been shown to make this task quite difficult .
So, although we had hoped to improve outcomes, we are still encouraged by improvements in process elements such as clue recall.
Both participants' perceptions  and actual usage logs  of the Stickies and Analysis Space features of SAVANT suggest that these features were more valuable when implicitly shared--but that they did not increase cognitive workload  or change the amount of explicit conversation about the case .
However, participants' appreciation of implicitly shared features in SAVANT did not carry over to improved perceptions of the team experience , perhaps because factors such as task difficulty and distributed interaction harmed team dynamics as strongly as the tool helped them.
Based on our findings, we suggest a number of design implications that can further improve collaborative analysis performance and process.
One important observation is that not all Stickies were created equal.
Our intent was that they would represent "insights" , but people appropriated the Stickies for a variety of purposes: tracking "emotional" versus "factual" sides of the case ; "highlighting important parts" of a case versus "making connections" ; "trains of thought" versus "methods of organization" .
Providing ways to distinguish between different kinds of analyst note  that help analysts bend the notes to their ways of thinking might encourage the sharing of different kinds of information that helps establish common ground .
NLP techniques that distinguish document-based facts vs. inferential comments  could be used to suggest categorizations, both making this feature smoother to use and encouraging analysts to be more aware of when they are making inferences.
Distinguishing types of notes might also help reduce risk of groupthink that can happen when people are influenced by each other's behavior.
In our case, the overlap between the clues recalled by each partner was high both with implicit sharing  and without .
This suggests that much of the collaboration focused on already found clues and inferences around them, rather than finding gaps in the team's knowledge, a robust problem .
One obvious difference between this study and real-world crime investigations is scope.
Real investigations have more documents, multiple data types, larger teams, more agencies, and longer durations than our task.
This is a general problem for evaluating collaborative analysis tools: the high stakes and established processes of real investigations makes it hard to deploy new tools in the field.
These controlled contexts and tasks do provide compensating advantages, such as the ability to systematically vary tools in ways that allow researchers to carefully examine specific factors that together build a body of knowledge to inform real world tools design.
Additional research is required to assess how the value of implicit sharing may change over longer time periods, with larger datasets, varied data types, teams, and analysis tasks on factors like cognitive-load etc.
This is related to the idea of cognitive fixation in brainstorming, where previously expressed ideas in theory inspire new ones but in practice can limit the space where people think.
Thus, providing interfaces that help reduce this tendency become attractive.
One option would be to combine implicitly shared, unstructured notes with explicit support for formal hypotheses as provided by CACHE , Jigsaw , and Sandbox .
As with the NLP techniques described above, having semantically different representations for notes and inferences might help analysts separate these activities, reducing the tendency to fixate on hypotheses early and increasing the chance that analysts develop competing hypotheses, which is important to final outcomes .
Implicitly shared notes could also be used as resources for creating, supporting, or refuting these hypotheses, with the system suggesting connections between existing notes and newly proposed hypotheses.
Notes also served as a bridge between analysts, according to our qualitative findings about the interplay between implicitly shared Stickies and the chat communication channel .
We also propose that they could serve as a bridge between their private knowledge stores: the system could look for similarities between newly posted notes and the documents in each analyst's space.
Related documents could be highlighted, helping members of the distributed team do a better job of fact- and hypothesis-checking, sharing of private information relevant to another analyst's work, and doing the kind of cross-referencing that is important in collaborative analysis .
Knowing how implicit sharing may improve task performance is critical to improve the design of collaborative analysis tools between organizations that restrict data sharing for privacy and between collaborators that fail to communicate necessary details.
Improving the design of collaborative analysis tools is key to getting more crimes  solved correctly and promptly.
We show in this paper that designing implicit sharing into such tools is one step toward these goals.
In this paper, we presented findings from an experiment in which individuals played the role of crime analysts and worked to solve crimes.
This study is a step in a series  of rigorous, carefully designed studies for testing the impact of specific design features on collaborative analysis processes and performance.
A variety of tools have been proposed, designed, and developed for collaborative analysis, but very few evaluate specific design features .
Some of these tools have been evaluated with a small number of users and without comparison to alternative tools or to the same tool with design feature variations .
Others have evaluated tools in a solo study, failing to examine the collaborative aspects of the analysis task , or have not evaluated the tools with human participants at all .
Other tools require collaborators to manually decide what and when to share in a structured tabular format .
We found that adding implicit sharing of notes to explicit communication via chat improved the ability to detect clues hidden between the partners that represented patterns of a serial killer crime, without sacrificing cognitive workload and explicit forms of communication.
We also found no improved sense of collaboration when the crime analysis system offered implicit sharing of insights with digital notes.
