One of the most significant challenges for many online communities is increasing members' contributions over time.
Prior studies on peer feedback in online communities have suggested its impact on contribution, but have been limited by their correlational nature.
In this paper, we conducted a field experiment on Wikipedia to test the effects of different feedback types  on members' contribution.
Our results characterize the effects of different feedback types, and suggest trade-offs in the effects of feedback between the focal task and general motivation, as well as differences in how newcomers and experienced editors respond to peer feedback.
This research provides insights into the mechanisms underlying peer feedback in online communities and practical guidance to design more effective peer feedback systems.
Empirical research has demonstrated that peer feedback predicts the amount and quality of recipients' subsequent contributions.
On the one hand, feedback can increase contribution; for example, Choi et al.
Feedback can also decrease motivation: Halfaker et al.
A more nuanced view may be required which takes into account the type of feedback given.
For example, Zhu et al.
A key problem with these and other similar studies investigating the effects of peer feedback in online settings  are their correlational nature, which limits the causal inferences one can draw.
For example, Wikipedians who receive negative feedback from peers likely behave differently from those who receive positive feedback and these pre-existing differences may account for outcomes researcher want to attribute to the feedback.
In this paper, we address this problem of endogeneity through a true experiment in which Wikipedians who write new articles randomly receive different feedback messages.
We investigate whether feedback messages have different impact depending on the receivers' experience, and whether they affect performance on a specific task that the messages explicitly target as well as on more general contribution.
This research seeks to understand the mechanisms underlying peer feedback in online communities and provides practical guidance to design more effective peer feedback systems.
Over the past decade, thousands of volunteers working in online communities have created complex products important to society.
Examples include Wikipedia, the world's largest and most popular general reference work on the Internet ; Linux, the leading operating system on servers ; and Apache, the open source web server that hosts half of the world's web pages .
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
In this section, we first briefly summarize the four feedback types.
Then we use feedback intervention theory  to predict the effects of feedback on people's performance on the specific task the messages were designed to influence and on general contribution.
Feedback is defined as "actions taken by  external agent to provide information regarding some aspect of one's task performance" .
Feedback can come from school teachers, company managers, peers, boarding school counselors, or even computer programs and in online setting can come from formal leaders, peers and bots.
Table 1 shows the feedback types, description, and example messages from Wikipedia.
Specifically, they identified positive comments to a contributor , criticisms or reprimands to a contributor for not complying to Wikipedia guidelines , giving directions to correct an error , and feedback with a sociable, personfocused, friendly, and supportive tone .
Their findings suggest that receiving feedback messages changed recipients' subsequent editing in Wikipedia.
Positive feedback and social feedback can motivate members to contribute more, whereas negative feedback decreases members' contributions.
Furthermore, feedback messages from core members  are more influential on recipients' subsequent behaviors than the feedback sent from peripheral members.
However, the previous research has three limitations.
First and most importantly, to the best of our knowledge, research examining peer-feedback and peer-influence in online communities  has been correlational.
As previously indicated, one cannot conclude from correlational research that leadership feedback actually changes the behavior of those who receive it.
However, omitting variables, such as politeness or extraversion that potentially predict both the type of messages people receive and their subsequent behavior can still undermine causal inferences.
Moreover the use of a true experiment allows us to investigate limits of feedback only hinted at in prior research.
While previous research suggests that feedback messages have stronger effects when delivered by formal leaders , it failed to examine how effectiveness varies with differences among people who receive them.
There is correlational evidence showing that newcomers and established members react differently when receiving feedback.
For example, Halfaker et al.
We tested this distinction more definitively in the experiment reported here.
Finally, most prior research only investigated how feedback affected receivers' general motivation to work .
It remains unknown about how feedback affects people's performance on the specific tasks which the feedback explicitly targets.
Research in education demonstrates that negative feedback motivates students to reduce the gap between current and desired understandings and thus enhances learning on the domain which feedback targets .
Other research on peer influence in Wikipedia suggests that while receiving negative feedback depresses motivation, it can improve task performance among editors who continue to participate .
We used Feedback Intervention Theory , described in more detail below, to predict how different types of feedback influence both general work motivation and specific task performance.
Feedback Types Positive Feedback Description and Message Examples Feedback intended to energize people through acknowledging work and provides rewards "I'm so impressed.
This is a very fine article!"
Feedback intended to regulate people through negative messages, warnings and reprimands.
Using one of the template..." "... do you think you could take some pictures at Mission Mill?
I'd like to spruce up the article but it really needs some photos..." Feedback intended to maintain close social relationships, support group cohesion, and develop subordinates' self-confidence and skills.
We are glad to have you.
Although leadership behavior, defined as the behavior of persuading and influencing other people to pursue a common goal , is not identical to feedback intervention, the concept overlaps substantially.
Many leadership influence attempts are interpreted by the recipient as feedback from others about their prior behavior.
The first key assumption of FIT is that feedback is processed hierarchically .
To simplify the presentation, the hierarchy can be divided into two levels: meta-task processes involving the self  and task processes involving the focal task and the detail of the task2.
Processes at the higher level  can supervise the performance in the lower level .
The processes in the lower level may also divert attention up the hierarchy and influence higher level process.
The second key assumption of FIT  is that people use feedback to evaluate their performance relative to their standards, often referred to as feedback-standard comparisons.
When they note a discrepancy between performance and standard, people are motivated to reduce it.
Typically people choose to eliminate the discrepancy by attempting to attain the standard.
Based on these two assumptions, we can predict people's reaction towards four types of feedback - providing positive feedback, negative feedback, directive feedback and social feedback.
First, positive feedback, negative feedback and directive feedback are all task-oriented feedback and focus on details and progress towards a focal task.
Negative feedback, which signals that performance falls short of a standard, leads people to increase effort towards the focal task.
Directive feedback, which provides instructions to either achieve standards or raise standards, will also lead people to invest more effort in the focal task and improve performance.
In contrast, positive feedback signals that performance exceeds the standard.
Therefore, when people receive positive feedback, they typically maintain their effort or even reduce it .
In contrast, social feedback focus on the person level rather than the task level, and therefore should have little effect on people's performance on specific task.
Providing negative feedback and directive feedback can increase people's effort on focal task and improve task performance; while positive feedback and social feedback should have less effect on focal task performance.
Although positive feedback tends to have little effect on performance of specific tasks, it has its effects at the metatask level, influencing people's view of themselves.
Positive feedback might increase people's self-efficacy and self-esteem and thus increase their general motivation to work.
This increased motivation might spill over to nonfocal tasks , lead to persistence in an activity and increase self-report interest in the activity .
Similarly, although social feedback does not affect specific task performance, it can help to develop people's selfconfidence, build commitment toward the community and thus increase general motivation.
In contrast, negative feedback might be perceived as a threat to self-esteem and decrease motivation.
Directive feedback does not draw attention to the self-level and should not influence motivation.
Providing positive feedback and social feedback can increase people's general motivation to work; directive feedback has limited effects on general motivation, while providing negative feedback might decrease people's motivation.
The effect of feedback is substantially influenced by the willingness of the recipients to respond to the feedback .
Specifically, prior experience is an important variable moderating the reaction to feedback interventions .
People with little experience in a task are less certain about standards and their abilities.
In conventional organizations, newcomers, in contrast to more established members, have greater uncertainty regarding role requirements.
As a result, they are especially eager to try to learn the beliefs, values, orientations, behaviors, skills, and so forth necessary to fulfill their new roles and function effectively within an organization .
Therefore, we expect that newcomers will be particularly susceptible to influence, compared to experienced members .
Therefore, we propose our third hypothesis.
Positive, negative, directive and social feedback is more influential on newcomers than experienced users.
The hierarchy can be more complex and contain more sublevels.
Actually in the Kluger and DeNisi 's original work , they divided the hierarchy into three levels: meta-task, task-motivation  and tasklearning .
Hattie and Timperley added one more level--self-regulation level .
However, the two-level abstraction is already enough to explain the mechanisms of how four types of feedback work.
Research participants were the original authors of newly created Wikipedia articles that were 2 to 10 days old.
They were randomly selected without replacement via a computer script from Wikipedia's new article list.
The lower bound of 2 days old ensured compliance with Wikipedia's policy to give users, especially new ones, some time to revise their articles before critiquing them.
The upper bound of 10 days old ensured that the user we chose was still involved in the article's development.
We excluded participants whose new articles were deleted or tagged for a "speedy deletion" by other Wikipedians.
We also excluded editors whose new articles were under 1500 characters, because these articles contained too little content on which to give feedback.
We also excluded authors of pages that were simply lists of other pages.
For example, the Wikipedia page "Science " is a list of articles associated with science, and would have been excluded.
The authors of other pages that were clearly tagged as "under major restructuring" or indicated that Wikipedia administrators were changing a page for copyright reasons, were excluded because the authors already understood the page's shortcomings.
Finally, each new article was evaluated on several dimensions to insure that potential feedback messages were relevant to it.
If the article was not relevant to at least one feedback template, the author was excluded.
For example, authors of new articles with nothing explicitly incorrect were excluded, because that editor could not be randomly assigned to receive negative feedback or not.
Similarly, editors of an article that contains nothing praiseworthy were dropped because it could not randomly receive positive feedback.
Seven-hundred and three editors were included in the experiment.
The experiment period lasted from August 2011 to November 2011.
All messages contained some or all of the following components.
Figure 1 is an example which contains all the components.
All messages contained a base and signature.
In order to provide experimental control, a computer script randomly decided whether to include the additional components positive feedback, negative feedback, directive feedback, or a sociable wrapper .
The base message provides an addition control.
Comparing the behavior of editors who received only the base message with those receiving no-message at all shows the effects of getting a non-feedback message that did not contain any explicit positive, negative, directive or sociable components.
The base message simply acknowledged the editor's new article .
All feedback messages included the base message component, drawn randomly from one of four base messages, and the researcher's signature, automatically generated by using four tildes "~~~~".
We created twelve templates for positive feedback, ten templates for negative feedback, nine templates for directive feedback, four templates for social greeting and eight templates for social closing.
Table 2 shows two examples of each message component, and Figure 1 shows an example of a message assembled from the components.
To generate both positive feedback and negative feedback components, a script was used to run through the various templates in a random order, asking the researcher if a specific positive or negative template applied to the article.
This ensured that the aspect was both appropriate and randomly chosen.
Note that the negative feedback only politely critiqued the editor's work by pointing out an error, but was not directive, such as requesting that the editor make a particular change.
Eighty percent of selected Wikipedia editors were randomly assigned to receive a message, and the remaining twenty percent who did not receive a message served as a control group.
All messages contained some common content .
The additional components - positive feedback, negative feedback, directive feedback, and a sociable wrapper  each had a 50% chance of inclusion.
We used a 2  x 2  x 2  x 2  between subjects factorial design for the 80% who received a message.
To understand the effects of different types of messages, we measured the users' contribution to the particular article we gave feedback to  as well as their contributions to any Wikipedia articles  over the following month.
Messages assigned to the social condition contained both the social greeting and social closing component.
The social greeting component contained a personal greeting, such as "hello", followed by the editor's Wikipedia username.
The social closing component contained phrases of encouragement, or wished the editor a good day, etc.
A script was used to randomly select a social greeting and social closing component from our selection of Sociable message templates.
Directive feedback asked for the editor's help with improving a related article without being positive or negative about the new article that the user created.
We used Suggestbot  to help find related articles that needed work.
SuggestBot matched keywords within the new article, and generated the top five choices that were most closely related to the article.
For those participant who were randomly assigned to directive conditions by our computer script, the researcher chose the most relevant, appropriate, and valid article suggested by SuggestBot to be incorporated into the message.
The researchers posting the messages are members of the New Page Patrol, a collection of Wikipedia editors who evaluate and comment on new articles.
They both had experience editing in Wikipedia.
Furthermore, all the component templates sent to editors were based on observations of messages on Wikipedia, suggestions by senior Wikipedia editors, and the guidelines of civility in Wikipedia.
Thus, these messages are very similar to those that Wikipedia users might encounter in their everyday interactions on the website, although perhaps more polite.
In particular, negative feedback components in the experiment are milder than negative feedback messages often sent between editors.
In the wild, some editors use intimidation, threat and harsh language to decrease undesired behaviors from targets.
Here are two examples: "If you continue in this manner you will be blocked from editing without further warning" and "Blech.
This really needs  ," which is Wikipedia's jargon for "Blow it up and start over.".
In our experiment design, negative feedback consisted only of constructive criticism.
To insure that recipients had natural reactions to the feedback messages, messages did not indicate that they were sent as part of an experiment, and recipients were not asked to sign consent forms.
If participants receiving messages knew they were in an experiment, we would not be able to generalize the results to understand how editors react to messages from other Wikipedians.
We believe these messages will have their effects in part because they imply a relationship between the sender and recipient.
This relational meaning would be undercut if the recipients believed they received feedback simply because they were part of an experiment.
However, we did not try to hide the experimenters' research affiliation.
The researchers who sent the messages had a brief description of the experiment and links to a fuller description on their user pages.
Their user pages also contained instructions on how to withdraw from participation, for users who wanted to opt out.
However, none of our participants have opted-out.
If message recipients initiated further interaction with the experimenters , experimenters responded as briefly as possible, and pointed the recipients to appropriate pre-existing Wikipedia help pages.
This prevented participants from feeling confused because the researcher initiated contact, but failed to maintain it.
The brevity and links to other relevant Wikipedia was intended to protect against confounds from additional feedback from the researchers.
The experiment was approved by the Carnegie Mellon Institutional Review Board, as well as the Wikipedia research committee.
Information about the experiment was posted on public Wikipedia pages and received unanimous agreement of active discussants from the Wikipedia community .
We designed this experiment with the twin goals of observing how different types of messages naturally affect Wikipedia editors while at the same time minimizing potential risk to Wikipedia editor-participants and the Wikipedia community as a whole.
Component Type Social Opening Template 1 Hi XX, I'm posting this message on your talk page because you've recently created the new article XX -The content seems wellorganized.
However, I noticed the article contains an error: this article currently does not contain any references.
As a new article, the most important thing is to find reliable references for all existing information.
It would be great if you could also improve the related article XX.
Hope your day is going well and you are having fun.
Template 2 Hey XX, I saw your article XX in the new articles list -There is a good number of citations and references.
However, I noticed the article contains an error: the article does not contain any Wikilinks, and so doesn't follow Wikipedia style guidelines.
It would be great if you could also cleanup the related article XX.
It's always nice to see users contributing to make Wikipedia better!
To measure participants' performance on their focal task, we calculated the number of edits they made in the month after receiving a message on the article that was the target of the message.
Note that for participants who received a directive message asking them to improve a related article, efforts on focal task also included edits on that related article3.
To measure the effects of messages on participants' general motivation to work, we calculated the number of edits the participants made in the month after receiving our feedback messages on any Wikipedia articles excluding the focal article which the feedback messages target.
This dummy variable indicates whether the participant received a message with the positive feedback component  or without this component .
This dummy variable indicates whether the participant received a message with the negative feedback component  or without this component .
This dummy variable indicates whether the participant received a message with the directive feedback  or without this component .
This dummy variable indicates whether the participant received a message with the social components  or without the components .
This dummy variable indicates whether the receiver is a newcomer  or not .
We define newcomers as editors with less than six months experience in Wikipedia and had received fewer than four messages before receiving our message.
We excluded participants who were blocked by Wikipedia or those whose new articles were deleted within one month after receiving our messages.
Finally, we included six hundred and five participants in the analysis.
The statistics of these participants is shown in Table 3.
Because the dependent variables  are count data and because editors might not log in to Wikipedia and have a chance to see the messages during the time window , we analyzed the data using a zero-inflated negative binomial regression.
Zero-inflated negative binomial regression is often used when the dependent variable is a count value and is over dispersed, with more zeros than predicted by a regular binominal distribution .
The basic idea is that the excess zeros can be generated by a separate process that can be modeled independently.
In our case, the goal is to predict whether reading the messages changes participants' behavior.
Some recipients might not have been influenced by the message, because they were not persuaded by its content.
However, others might have failed to log in recently and hadn't actually seen the message meant for them.
To model these two separate processes, the zero-inflated negative binominal analysis has two stages.
In the first stage, we used a logit regression to predict the excess zero .
In the second stage, given the likelihood of being exposed to the message, we predicted the effects of messages on the number of edits.
Specifically, we used the following two estimates of editors' recent activity to predict the likelihood of their seeing the message.
Number of edits one day before receiving our message.
The more edits the participant did in the 24 hours before we sent them messages, the more active they were and the more likely they were to have seen our message.
We also tested the effects of directive feedback on the two types of articles separately and found that directive messages have positive effects on both the related article and the original one.
Directive messages led participants  to make on average 0.4 edits on the related article, which is significantly more than zero .
Furthermore, newcomers receiving directive messages made 2.8 more edits than those who did not receive directive messages on the original articles .
Directive messages have no statistically significant effects for the experienced members on the original articles.
The results of zero-inflated negative binominal regression are shown numerically in Table 4 and graphically in Figures 2 to 5.
The error bars in Figures 2 to 5 indicate 95% confidence internal.
The analysis focuses on the participants who received our messages.
We treat the behavior for participants who didn't receive messages at all as the baseline and indicate the baseline with dotted lines in Figures 2 to 5.
We report the main effects of receiving a particular type of feedback component.
For example, in the figures, the condition of "with social feedback components" includes "social" and "social + positive" and "social + negative" etc; the condition of "without social feedback components" includes "base" and "positive" and "negative" etc.
We did not find significant interaction effects between different types of feedback components.
The bottom panel of Table 4 indicates that the likelihood ratio test of alpha = 0 is significantly different from zero.
Dependent variable Focal task Model 1 Predictors Intercept Positive feedback Negative feedback Directive feedback Social feedback Receiver is newcomer Newcomer * Positive feedback Newcomer *Negative feedback Newcomer * Directive feedback Newcomer * Social feedback Inflate Number of edits during one day before receiving our message Number of days between last edit before receiving our message and the time they receive the message Alpha Likelihood-ratio test of alpha=0 Vuong test of zinb vs. standard negative binomial Coef .51 .09 .04 -.09 .06 -1.2* -.48 1.4** 2.2** .25 -.31 .46**
The Vuong test suggests that the zero-inflated negative binomial model is a significant improvement over a standard negative binomial model.
Furthermore, the predictor "number of days between last edit and receiving our message" in the part of the logit model predicting excessive zeros is statistically significant.
The longer the time between the last edit and the time receiving our message, the less likely the participant was to edit, suggesting that he or she missed our message.
These results suggested that we used the right statistics model.
The top panel of Table 4 shows analyses testing hypotheses 1-3.
Model 1 tests whether receiving feedback message led editors to edit more on the article the feedback message targets .
Model 2 tests whether receiving feedback message increased editors' activities in general.
Each coefficient represents the change in the log of the expected number of edits the editor will produce when increasing the independent variable by one unit, when other variables in the model are held constant at zero.
For ease of interpretation, we also included the change in edit counts in the original units.
Thus, the intercept indicates that oldtimers who received base messages  can be expected to make 1.7  edits to the focal article .
Model 1 measures the effects on efforts to the focal task: participants' editing activities on the particular articles which our feedback message targets; Model 2 measures the effects on general motivation: the effects on participants ' general contributions excluding the particular articles which the feedback message explicitly targets.
Therefore, newcomers who received base messages make 0.51 edits  to the focal article.
For experienced editors, receiving any type of feedback message has no significant impact on their subsequent editing behavior, either for the specific articles on which we gave feedback  or any other articles .
Model 1 shows that messages had significant effects on newcomers' subsequent editing of the target as our hypotheses predict.
Receiving negative feedback and directive feedback increased their editing in the target article.
The coefficient of newcomer*negative feedback is 1.4, indicating that newcomers who received negative feedback are estimated to make edits on focal articles approximately four times compared to newcomers who did not receive negative feedback.
Positive feedback and social feedback do not have effects on local tasks.
Results of Model 2 confirm our hypothesis about the effects of messages on editors' general motivation.
In contrast to Model 1, negative feedback and directive messages do not have effects on general motivation.
Instead, messages with positive feedback and social feedback components substantially increase newcomers' general work motivation.
The coefficient of newcomer*positive feedback is 1.3, indicating that positive feedback causes 3.67 times change in number of edits for newcomers.
The coefficient of newcomer*social feedback is 2.2, indicating that messages with social feedback cause 9.03 times change in number of edits for newcomers.
Although we predict that the effects should be stronger for newcomers because they are particularly susceptible to influence, we are still surprised to see that the messages had no significant effects at all on experienced members.
From the messages the participants sent back to the researchers' user pages, we found evidence that experienced members might have psychological reactance to our messages.
Psychological reactance was originally proposed by Brehm, in which a person has a negative emotional response in reaction to being persuaded, and thus chooses the option which is being advocated against .
For example, some participants wrote to us and said that: "Well, er, yes, I am not new here and the stub tag was intended as a cheerful acknowledgement of the effort's insufficiency."
I can show you plenty of pages that do not have any external references - worry about those first..." - P2.
Participants' comments above suggest that experienced members might perceive negative feedback and directive message as a challenge to their knowledge and expertise , especially when noticing that the message senders4 have less experience than themselves .
Previous research shows that when people perceived feedback as self-threatening, they might avoid exposure to the feedback  or even abandon the entire task .
It is possible that experienced editors chose not to follow what their newbie colleagues suggested, so as to preserve positive self-belief about their expertise.
The results suggest that although any member can try to send feedback to others in online communities, the relative status of the sender might still matter.
Therefore, to ensure the effectiveness of feedback, it is probably better to have senior community members to deliver feedback messages.
Negative feedback and directive feedback benefit focal task performance but do not have effects on general work motivation, while positive feedback and social feedback can positively influence general work motivation but do not have effects on focal tasks.
Practitioners can consider their primary goal  and then design feedback messages accordingly.
One possible way to optimize both the focal and the general effects is to combine multiple feedback types.
Unfortunately, although the study was originally designed as a full factorial experiment, the sample size is small because the effects seem to be only significant for the newcomers.
Therefore we have limited statistical power to draw any reliable conclusions about the interaction effects between different feedback types.
In future work, we will increase the sample size to explore the optimal feedback intervention strategy.
Our results suggest that negative feedback caused newcomers to work harder on the target article and no effects on general motivation, while Zhu et al.
Furthermore, the negative feedback Halfaker and his colleagues investigate is the action of reverting, which is stronger than textual messages since "Actions speak louder than words".
The different ways of conveying the same meaning might influence how the recipients interpret and perceive the negative feedback, and thus lead to different reactions.
One direction of future work is to conduct qualitative study to investigate how people interpret different types of feedback messages  to further understand how feedback messages take effect.
We conducted a field experiment in Wikipedia to examine how different types of feedback affect receivers' focal task performance and general work motivation, moderated by receivers' prior experience.
This research furthers our understanding of the effects of feedback in online communities and provides practical guidance to design effective feedback systems.
Both researchers who sent out messages are relatively new in Wikipedia.
One has 2 months experiences and 133 edits before conducting the experiment; and the other has 6 months experiences and 65 edits before conducting the experiment.
It is easy for experienced Wikipedia editors to find out such information in Wikipedia.
