Precise alignment of graphical objects and the creation of accurate layouts are crucial activities in many applications, such as graphics design tools, presentation software or graph editors.
Surface computing is very promising for these application domains but not fully explored yet.
In this paper we contribute two tools which support layout tasks on interactive displays: interactive grids and multi-touch alignment guides.
Both tools allow the precise positioning of graphical objects in a flexible and fluent way by multitouch input.
Direct bimanual interaction and physical metaphors are applied to arrange objects along straight lines and curves.
A formative user evaluation showed promising results with regard to a productive and easy use of the tools.
However, these approaches have several drawbacks.
Interactive displays supporting multi-touch interaction or even the combination of touch and pen input are very promising for graphics applications .
Gestures allow quick mode switches and a more natural and direct way of interaction.
Moreover, many tasks can be performed simultaneously by both hands.
However, their potential is not fully exploited yet.
Especially the creation of pleasant and precise layouts is challenging with these modalities.
Therefore, tools are necessary which are tailored to multitouch input and provide automated assistance.
In this paper we are contributing two specific tools for aligning graphical objects on multi-touch enabled displays: interactive grids  and multi-touch alignment guides .
They allow path alignment tasks in a continuous flow of interaction which are difficult to achieve in existing tools.
The following three interaction principles are realized by our new tools:  Productive use of multi-touch input and bimanual interaction.
Users are able to achieve compound tasks by both sequential actions and continuous input without interrupting the workflow.
Thereby, touched objects can serve as representatives of a group of objects.
Manipulating them affects all other objects in the same way.
Magnetic effects and flicking and shaking gestures are used to provide natural interaction.
For both tools, we conducted a formative qualitative user study which showed promising results.
Accurate positioning of graphical objects is an essential activity in many applications.
In desktop publishing tools  and presentation software, images or textboxes have to be aligned in a precise way to create good layouts.
Graph editors are another example, in which child nodes have to be properly arranged below their parent nodes.
In existing tools these tasks can be accomplished indirectly, for example by invoking functions from menus  or by entering values .
Beyond that, there are techniques which allow precise positioning by direct manipulation.
Users drag objects and the system provides automated assistance, for example by snapping .
Objects snap to grids on the background, to the bounds of other objects or to previously created guides.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Several works describe techniques for rotating and translating digital objects in a precise way applying multitouch interaction .
However, they focus on positioning single items and do not consider alignment tasks such as adjusting the spacing between several objects.
In existing tools usually snapping mechanisms  are applied to align graphical objects according to alignment-objects.
A widely used alignment-object is the grid.
By HyperSnapping  grids are changed during dragging.
We also change background grids dynamically, but apply bimanual multitouch interaction.
Furthermore, besides orthogonal grids we also consider radial grids.
In order to align objects or to create symmetric shapes, several applications integrate ruler tools .
Our multi-touch alignment guides are similar to the approaches presented by Raisamo .
In contrast to them, we are investigating the application of multi-touch input for aligning graphical objects, not only along straight lines, but also along other shapes.
Graphical objects snap with their center to the grid if positioned within a certain threshold .
Thus, with interactive grids objects can be arranged not only along straight lines or rectangles but also along circular arcs.
However, positioning handles on touch screens in a pixelprecise way can be cumbersome.
Even on commercial devices objects are often accidentally repositioned due to jitter or the intrinsic fat finger problem.
For the pixel precise adjustment of the grid size, without invoking menus or entering parameters, we propose a technique called single-step-nudging.
When users perform a short flick gesture on a handle, it moves just one pixel in the direction of the flick.
Thus, the grid size can be set to a precise value after the handles were moved roughly to their target position.
This is analogous to positioning tiny real world objects with slight nudges after coarse placement.
Similar to grids used in existing graphics applications our proposed interactive grid is located in the background of a canvas.
It allows precise positioning of graphical objects by snapping .
In contrast to most grids which are typically adjusted by dialog boxes, the cell size of interactive grids can be changed directly by multi-touch input within a single fluent action.
Furthermore, it is possible to switch between orthogonal and radial grids in a smooth and seamless way.
Holding a finger at a position where two grid lines intersect invokes four handles - one at each corner of the cell .
By moving them apart or together, the size of all cells of the grid can be adjusted.
Dragging one handle changes the width and height of the cells uniformly.
Dragging the edge between two adjacent handles allows the adjustment of the grid in one dimension without affecting the other one.
In that way, the size of a cell can be adjusted precisely as feedback is continuously provided by displaying the distance in pixels between the handles.
Furthermore, all four handles can be dragged simultaneously with up to four fingers.
This allows to freely adjust the cells' width and height within a single action.
These grid adjustments are typically done at the beginning of a designer's layout session, but can also be made during editing.
We suggest supporting this by saving and reusing grids later on.
If one handle is fixed and one of its neighbors is deflected above a certain threshold, the orthogonal grid is changed to a radial grid .
Again, this can also be achieved by using four fingers simultaneously.
A radial grid consists of concentric circles and diametral line segments which are evenly distributed within the disk.
The amount of concentric circles and the angle between two lines can be adjusted by dragging the handles or the edges between them.
Thereby, feedback is given by displaying angle and distance.
In order to address more complex tasks such as flexible object alignment and scaling, we developed multi-touch alignment guides.
They consist of a handle  combined with a geometric shape such as straight lines , an arbitrary curve or a two dimensional closed shape .
This shape is used to bind graphical objects, e.g.
The arrangement of bound objects can be manipulated by multi-touch input.
Multi-touch alignment guides can be created by sketching.
The type of the guide corresponds to the shape of the sketched stroke.
For example, sketching a straight stroke results in a line guide which has the same length as the stroke, and sketching a circle results in a circle guide with the respective diameter.
In that way, multiple guides can be created simultaneously.
In order to distinguish these gestures from common sketching, we suggest starting them by holding & dragging.
Holding a finger on the background and starting a drag gesture nearby with a second finger results in creating a guide.
Guides can be easily deleted by dragging them offscreen or by performing a wipe gesture across them.
Thereby, attached objects are not affected.
In order to create line guides of infinite length we suggest dragging them from the edge of the display, as known from existing tools or holding two fingers on the canvas.
Furthermore, if touch and pen input is combined  the pen can be laid down on the display to create a guide of the same orientation and to move it in a tangible way.
Changing the size and length of a guide.
A guide can be shortened by drawing a short stroke across the guide.
When an infinite line guide or a circle guide is cut, handles appear at the intersection points.
They can be used to adjust the length of a line guide or to create a circular arc from a circle guide.
Furthermore, the diameter of a circle guide can be changed smoothly by a two-finger pinch-gesture.
A guide  can be positioned by using a handle attached to it .
It consists of two areas for rotation at its ends and one for translation at its center.
Touching the handle with one finger constrains the interaction to translation  or rotation depending on the touched area.
This allows precise positioning of the guide by sequential steps of interaction as the guide snaps to the background grid.
If both rotation areas are touched simultaneously by two fingers, the guide can be rotated and translated freely within a continuous flow of interaction .
Furthermore, the handle adapts to the current context of use.
When it is touched it adjusts its size to the distance of the fingers.
When it has been released, it is set back to its minimal size after a short delay.
It becomes semitransparent to make it less interfering with graphical objects.
Bound objects are manipulated directly by touch for adjusting their positions.
The guide constrains the movement of the objects by its shape.
A button at the handle is used to specify if a gesture affects just one object  or all bound objects .
The all-mode can be considered as an intelligent way of grouping.
Thereby, the touched object serves as a representative and manipulating this object affects all other bound objects in the same way.
For example, all objects can be released in a single step by releasing just one object.
For toggling the all-mode we did not introduce an additional button.
Instead, the buttons for activating Collide & Snap change their functionality when the handle is released.
This context-dependent change is possible, as moving the guide and positioning its objects cannot be done simultaneously.
Dragging objects across a guide results in centering objects or aligning them to the left or to the right side of the guide.
While dragging, feedback is given by outlines, and when the finger is lifted, objects snap to the respective position.
The all-mode can be activated to align all bound objects by dragging just one .
Creating proper spacing between objects is an important and often applied task in layout applications.
We support this by touching a bound object and dragging it along the guide without affecting other objects.
The distance to its neighbors is displayed in pixels.
If an object is dragged in all-mode, all other bound objects are translated as well.
They are moved apart or together whereby the ratio of their spacing is maintained .
A similar effect is achieved by holding an object and dragging another one with a second finger.
As a result, all objects in between are pushed together or moved apart .
Furthermore, a metaphorical "shake"-gesture  can be performed on the handle which equally distributes all bound objects along the guide.
To avoid confusion, outlines of bound objects can be shown during shaking, whereas the actual objects remain in place before they are distributed.
For pixel-precise spacing, single-step-nudging can be applied on bound objects, too.
Objects can be rotated and scaled by means of a two-finger gesture.
If an object is positioned near the guide within a certain threshold, it snaps to the guide automatically.
Beyond that, we implemented two additional interaction techniques: Flick & Snap and Collide & Snap.
Initially the guide is set to the Flick & Snap mode and can be positioned freely on the canvas without affecting any object.
Binding a graphical object is achieved by flicking the object towards the guide.
As a result, the object is animated to the guide.
In that way a quick and explicit assignment of objects to several guides is possible by flicking in the respective direction.
When Collide & Snap is activated, objects stick to the magnetic guide if they collide with it.
In that way, users can move the guide across the canvas and "collect" objects .
In both modes an anchor point appears on the guide when the object is docked.
Switching between the two modes is achieved by pressing a button located at each side of the handle.
The mode switch is possible during the movement of the guide, thus allowing a smooth way of interaction without interrupting the workflow.
An object can be released by holding the object and dragging the guide away.
Furthermore, it is possible to flick or to drag the object away from the guide.
These three gestures are designed to be symmetric to the ones which are applied to bind objects to the guide.
We consider this to be an important principle for gestural interaction.
Additionally, we suggest combining two line guides to scale objects.
Objects with one edge attached to a line guide are scaled by moving a second line guide to their opposite edge.
Moving both guides apart or together is an elegant way of scaling all bound objects simultaneously to the same size .
We fully implemented the interactive grid  and two types of multi-touch alignment guides: a line guide  and a circle guide .
Both tools are integrated in a simple picture layout application and a nodelink diagram editor.
The former was used to conduct an initial user evaluation to investigate the tools' usability.
The evaluation was conducted on a multi-touch enabled SMART table .
Ten participants took part in the study .
Eight participants were employees of the computer science department, two of them had deeper knowledge of HCI and interaction design.
The remaining two participants were professional architects and expert users of tools such as CAD programs.
The evaluation consisted of two parts: one for the interactive grid, the other for the alignment guides.
We observed the participants during both parts and took notes about their behavior and comments.
For each part the respective tool was explained to the participants.
After a short training phase they were asked to solve two types of tasks:  `Align five pictures along a straight line with different spacing between the pictures'  and  `Align five pictures on a semicircle around a sixth picture'.
The target state of each task was handed to them on a printout.
For T1 the size of the orthogonal grid had to be changed and the spacing of objects had to be adjusted along a line guide respectively.
T2 had to be solved by the radial grid in the first part and by using a circle guide in the second part of the study.
At the end, the participants were asked to fill in a usability questionnaire consisting of six items for each tool using a five-point Likert scale .
The duration for both parts was about 30 minutes.
All participants successfully achieved the given tasks, and the concepts of both tools were well understood.
Single-step-nudging and shaking the handle for equal distribution turned out to be easy and natural.
Based on our observations we suggest the following improvements to the interactive grid: additional constraints for snapping the lines of the radial grid to regular angles should be added.
Some participants started manipulating the grid by dragging with four fingers without invoking the handles beforehand.
We suggest supporting this gesture  as it permits interaction in the flow.
Concerning the questionnaire we see the reason for the better results of the grid in its lower complexity.
Beyond that, we observed that some participants had problems to reach the button for activating collide & snap.
As a consequence, we made the button bigger.
It moves back to its original size when the handle is released.
We presented two tools for layout and alignment tasks on interactive displays.
The interactive grid allows adjusting the size of its cells directly and can be easily changed to a radial grid.
Multi-touch alignment guides can be used for flexible alignment of graphical objects along different shapes.
Both tools allow a continuous way of interaction as well as sequential actions by multi-touch input.
They also apply physical metaphors to manipulate bound objects such as shaking or single-step-nudging for precise positioning.
Alignment guides provide intelligent grouping of objects and change their appearance according to the context.
An initial user study showed promising results for our concepts.
For future work, we will create guides for shapes such as arbitrary curves.
More formal user studies shall be conducted with more complex tasks, also in other domains.
