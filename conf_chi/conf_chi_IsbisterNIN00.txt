It is increasingly common for people to meet for the first time through a computer interface.
This is a wonderful opportunity to build new social networks based more on common interests than on location, but it is also a tremendous challenge.
Virtual meeting places usually provide very little socially meaningful context to use as a basis for finding common ground with each another.
Because it easy to arrive at a virtual meeting place from many entry points, it is often hard for visitors to assume much about one anothers' cultural backgrounds, group memberships, and other aspects of social identity.
Psychologists have demonstrated that people need this sort of common context in order to build new relationships .
Some commercial chat rooms make use of human moderators to help fulfill this need.
However, human moderators are a scarce resource.
We believe this is an appropriate new application domain for social interface agents.
Social interface agents could provide ongoing, in-context help in forming social connections and building common ground between visitors to virtual environments.
Our project is a first step toward exploring this new application space for interface agents.
This paper introduces a new application area for agents in the computer interface: the support of human-human interaction.
We discuss an interface agent prototype that is designed to support human-human communication in virtual environments.
The prototype interacts with users strategically during conversation, spending most of its time listening.
The prototype mimics a party host, trying to find a safe common topic for guests whose conversation has lagged.
We performed an experimental evaluation of the prototype's ability to assist in cross-cultural conversations.
We designed the prototype to introduce safe or unsafe topics to conversation pairs, through a series of questions and suggestions.
The agent made positive contributions to participants' experience of the conversation, influenced their perception of each other and of each others' national group, and even seemed to effect their style of behavior.
We discuss the implications of our research for the design of social agents to support humanhuman interaction.
Communication contexts are becoming an ever more prominent part of the computer interface.
People spend a great deal of their computer time communicating with one another.
HCI researchers have already discussed and demonstrated some benefits of interface agents in one-on-one task settings, such as taking an educational tutorial , going on a tour , or looking at real estate .
Although the CHI community has a range of opinions about when and where agents should be deployed in the interface, most would agree that there are some beneficial applications.
Cassell discusses the value of an embodied conversation partner with the proper human verbal and nonverbal communication skills .
However, these findings concern task-support agents.
There are projects which have used text-tracking to create agent-based social support.
However, these agents are designed to engage in one-on-one social interactions, rather than facilitating human-human interaction.
The agents described above were all designed to be communication partners with human users, and to be present and active at all times during the interaction.
We do not believe that an interface agent should be an equal partner in the conversation, or equally active, when supporting human-human communication.
This led us to make some important design decisions in creating our agent prototype.
We designed Helper Agent to be a supporting character rather than a central figure in the conversation.
Helper's job is to pick up on contextual cues from the conversation, provide help, and then fade back into the background, allowing the central activities of the conversation environment to move forward.
As we mentioned in the abstract, this behavior mimics the activities of a host at a party.
The prototype Helper Agent was designed for a minimalist test of the effectiveness of our concept for a human-human communication assistant.
The prototype tracks audio from a two-person conversation, looking for longer silences that will trigger its conversation aid.
The agent basically acts in the same way a busy human party host does, looking for clues that the guests' conversations are going badly.
Helper then directs a series of text-based, yes/no questions to both conversation partners in turn, and uses their answers to guide its suggestion for a new topic to talk about.
Then the agent retreats until it is needed again.
Our prototype works within an existing 3-D virtual meeting space called FreeWalk , which was developed by us  .
Using FreeWalk allowed us to track and use audio silences, and supported the metaphor of the agent coming and going from the conversation, rather than becoming a conversation partner.
For our first prototype, we focused on an extreme case of low social context in a virtual meeting space: strangers from different national cultures, meeting for the first time.
Even when people can use a common language with reasonable fluency, they do not necessarily have a common context for their conversation.
Different cultures have different notions of how to begin and develop conversations.
What is a safe topic in one culture, may be very awkward in another culture.
For example, in some cultures it is appropriate to ask about family members right away; whereas in other cultures this is private .
We developed an agent prototype that could provide safetopic suggestions, if the conversation was faltering.
We focused on conversations between Japanese and Americans.
These two national groups are known to have very different interaction styles and cultural norms , and so we felt this was a good test case.
FreeWalk: Virtual Meeting Place Environment Users are represented as three-dimensional pyramid objects, with their video image mapped onto one face of the pyramid .
In the lower right corner of the screen there is an overhead view of all avatars; however the user does not see his/her own avatar on the main screen .
The user does see a small video window of themself in the lower left corner, to help them adjust their camera.
Each user's voice is transmitted to others around them in the virtual space.
The volume of other peoples' voices is proportional to how close they are to you in the space .
Helper Agent is presented on-screen the same way users are .
This allowed us to take advantage of nonverbal cues in designing the agent's behavior, such as turning to face users as it poses a question to them, and approaching and departing the conversation physically.
The agent is an animated dog, done in a style somewhere between typical Japanese and American cartoon dogs.
We chose a dog because we wanted users to think of the agent as subservient, friendly, and reasonably socially intelligent.
We chose stylized animation instead of more realistic, because we did not want the agent to be interpreted as a specific individual, but as more iconic and minor .
After concluding a suggestion cycle, the agent physically departs from the conversation zone, and meanders at a distance from the interaction, until it detects another awkward silence.
This makes it clear to the conversation pair that the agent need not be included in their discussion .
The dog has a set of animations of the proper nonverbal conversational moves for asking questions, reacting to affirmative or negative responses, and making suggestions.
We crafted these animations as a supplement to the agent's speech , and focused on making them friendly and submissive in style .
We gathered topics using an internet survey, that university students from Japan and the United States filled out.
We used the collected pool of topics to select common safe and unsafe topics for people from both countries.
From these topics, we crafted a set of questions that the agent could ask during interaction, drawing users into conversation.
Safe topics included: movies, music, the weather, sports, and what you've been up to.
Unsafe topics included: money, politics, and religion.
A sample safe question: "Is the weather nice where you are right now?"
A sample unsafe question: "So, do you think it is alright for a country to fish for and eat whales?"
Positioning: The agent decides how to position itself, based on the location and orientation of each participant.
The agent turns toward the participant that it's currently addressing.
If the participants move while the agent is talking, the agent adjusts its location and orientation.
The agent tries to pick a place where it can be seen well by both people, but also tries to avoid blocking the view between them.
If it's hard to find an optimal position, the agent will stand so that it can at least be seen by the participant to whom it is addressing the question.
State-transitions: The agent has three states--idling, approaching, and talking.
When idling, the agent strolls at the corner of the virtual space, further away than the normal conversation zone .
When the agent detects an awkward pause in the participants' conversation, it begins an approach.
Upon reaching the participants, the agent goes into the talking state.
However, if the participants start talking again before the agent reaches them, it stops the approach and goes back to idling.
The agent will also remain in idling state if the participants are standing far apart from each other , or are not facing each other.
If the participants turn away from each other during the agent's approach, or while it is talking, it will return to idling state, as well.
This question might be directed at A or at B.
If it is directed at B, the agent turns to B to pose the question.
When B answers, the agent replies to B.
Finally, the agent makes a general comment that is meant to guide the participants into using this topic.
This general comment is selected based upon the previous answers from the participants, so that it makes sense given their replies.
After making this comment, the agent departs.
We wanted to test the benefits of our prototype in a controlled setting.
Our initial expectations were: 1.
The safe-topic agent would create a more satisfying experience, than if there were no agent.
Participants would feel they were more similar, would be happier with the interaction and partner, and would form more positive impressions of one another's nationality.
The unsafe topic agent would make people uncomfortable, but might lead to a more meaningful and interesting conversation than the safe topic agent.
The user interface for communicating with the agent is very easy to learn.
The agent does not use voice--it presents questions to the participants in a text-balloon above its head.
The user indicates `yes' or `no' using the mouse to click on their answer.
Both participants see all questions, but only the user addressed sees the Yes/No options.
When the person answers the question, their answer is displayed in a text-balloon above their own avatar .
Each topic has a tree structure, with nodes that are: first question for a participant, possible answers by participants, agent's reply to each answer, and flags indicating whether the agent will address its next question to the other person or to the same person.
Topics were designed to draw participants into a dialogue, so each turn is tailored for this purpose.
The cycle always concludes with a recommendation for how the participants could make use of the particular topic area, given their own answers to the agent.
When the agent approaches to start a cycle, it selects a topic from its repertoire of safe  topics randomly, out of those that have not yet been used.
Then it randomly chooses one of the two participants as the target for the first question.
Let's call this person A.
When A answers, the agent replies to A's answer .
The study was a collaboration between the NTT Open Lab, Kyoto University's Department of Social Informatics, and Stanford University's Communication Department.
We used a high-bandwidth  dedicated line between the universities.
The two research teams used chat software to communicate while running the study.
We set up a PC with a small camera and microphone/headset at each location , and installed FreeWalk and Helper Agent at both sites.
We modified our prototype so that those in the agent conditions would all be exposed to the same number of topics.
We divided the conversation session into segments, and forced the agent to display a topic within each time segment.
Thus, in the safe-agent condition, the agent introduced all 5 safe topics in random order.
In the unsafeagent condition, the agent introduced all 5 unsafe topics in random order.
Each research team recruited students for the study.
The Stanford students were all part of an undergraduate class, which required study participation for credit.
The Japanese students were undergraduates from Kyoto University and other nearby universities, who were paid for their participation.
Because the study would be held in English, we screened Japanese students and selected those who scored at a reasonably high level on English proficiency tests.
Both sets of students were screened for a high level of familiarity with one another's culture, and those with high experience were not asked to participate.
In total we had 90 participating students.
Due to some problems with equipment, we ended up with data from 45 Japanese students, and 43 American students, for our analysis.
Students were assigned randomly to same-gender pairs.
Each pair was randomly assigned to one of the three conditions.
Students were told that they would be testing out a new communication environment with a student from the other country.
They were asked to talk about anything they liked, just "get to know each other a little bit".
They were trained in how to use the system, then left alone to talk for 20 minutes.
We made video recordings of all sessions, capturing what was on the screen on the Japan side onto videotape.
After their 20-minute conversation, participants filled out a web-based survey in their native language.
The questionnaire included questions about the interaction, their conversation partner, the agent , as well about the participant's own performance.
We also asked them to make assessments of themselves, their partner, and the typical person of both participants' cultures on some commonly used stereotypic adjectives.
American Reaction The safe agent had positive effects for American participants as we expected : * opinion of their own behavior higher--they rated themselves as more confident, less domineering, and less restrained in the safe agent condition.
Those in the safe agent condition rated the typical Japanese person as more creative and more friendly.
However, no-agent condition participants rated the typical Japanese person as more emotionally expressive5.
Japanese reaction The Japanese participants had a different response to the safe agent's presence--it did not improve their experience.
However, it did seem to make them think their partner was more like themselves, as expected .
They were less interested in continuing such a conversation, and were less satisfied afterward.
Yet, they rated their partners as less typically American and more similar to themselves.
In the safe agent condition, they rated the typical American as more competitive, more domineering, more selfish, and more effusive than those in the no agent condition7.
Awkward isn't necessarily bad As we had expected, the unsafe agent made things more awkward, but also more interesting.
We counted awkward pauses, by observing the videotapes, and found a higher number of awkward pauses in the unsafe versus safe condition =-3.06, p < .01.
Despite the higher level of awkwardness in these conversations, both Japanese and American participants found the conversation that included the unsafe topic agent more interesting.
Americans rated the unsafe agent interaction more interesting; Japanese rated the unsafe agent experience more desirable to continue .
Japanese participants found the unsafe agent experience more comfortable as well.
We cannot be sure why the two groups had such different reactions.
One reason may be that the agent's questions were implemented in English.
It's possible that Japanese subjects felt it was a two-against-one situation.
This might explain why they disliked the interaction, even though it seemed to make them rate their partner as more similar to themselves .
We would need to test the system again, using a bilingual agent that address all questions to users with both languages displayed, to be sure.
In any case, the positive American reaction was a strong support of our research concept.
American partner seemed better in the safe topic condition Japanese participants rated their partner as less similar to themselves, less considerate, more domineering, less friendly, and less talkative in the unsafe condition.
These rankings suggest that the safe agent led to more positive impressions of the partner, for Japanese participants.
Japanese tend to stereotype Americans as talkative and emotionally effusive.
All stereotypical American traits, from the Japanese point of view.
It might surprise American readers that `effusive' is bad; in Japan one is expected to regulate one's emotional expressions, or risk appearing childlike and uncultured .
Our evaluation also suggested that a communication assistant can be helpful both when it offers safe topics to talk about, and when it steers the conversation in less safe directions.
In fact, the Japanese participants seemed to prefer the unsafe topic agent, and both groups found it more interesting than the safe topic agent.
For overall conversational support purposes, both kinds of help may be desirable.
We suspect that an agent with a model for offering both kinds of topics, depending upon the conversation flow, would be the most desirable.
Safe/unsafe topic choice affected stereotyping in contradictory ways Japanese participants in the unsafe agent condition thought the typical American was less domineering.
This conflicts with their ranking of their own partner's level of domineering-ness.
American participants rated the typical Japanese in conflicting ways: after the unsafe condition, they thought the typical Japanese person was more emotionally expressive, more outgoing, and more talkative; but also more evasive and quieter.
Safe/unsafe agents `read' differently for Japanese and Americans The two groups differed in their impressions of the safe and unsafe agents.
The Americans formed the intended impression: they rated the unsafe agent's topics as less appropriate, thought it acted more blunt, more domineering, less restrained, and less friendly.
They also said it was less typically American, distancing it from their own in-group's behavior.
The Japanese thought that the unsafe agent was nicer and more competent than the safe agent.
They rated the unsafe agent as less typically Japanese, and as less talkative.
They found the unsafe agent more nationalistic, probably because it brought up more political topics than the safe agent.
The two cultural groups had very different impressions of the same agent behaviors, and reacted in different ways.
For example, behavior that was perceived as blunt and unfriendly by Americans was seen as nice and competent by Japanese.
An effective agent for different types of people will probably need to adapt its behaviors to user subgroups, or perhaps to individuals' own interaction styles and preferences.
We believe we created a more American identity for our agent by delivering its topic help in English.
In future iterations, we plan to create an agent whose presentation is adapted to different user styles and preferences.
Both the Japanese and American participants noted that Japanese seemed to act more American in the unsafe agent condition.
This result indicates that it may be possible to mold user behavior with the choices one makes about how the agent will behave, creating a different conversational environment by bringing different traits to the fore.
This could have very interesting implications for those interested in setting a specific group conversational tone or style in a virtual meeting space.
We believe our prototype's success was partially due to design choices that made it a graceful supporting player in the interaction.
We summarize key features here, as suggestions for CHI community members who may be interested in creating this kind of interface agent: * Unobtrusive observation of users, and easily visible and controllable approaches.
The users could see when the agent was approaching, and could shoo it away simply by talking before it arrived.
Focused interactions with a limited duration.
The agent had a clear purpose in its approach, and the users could quickly grasp its interaction pattern, and knew it would leave after making a topic suggestion.
They could see the agent in-between interactions, but did not need to include it in their conversation.
This kept the focus on the task at hand: human-human interaction.
If users ignored the agent, it simply gave up and went away!
It did not hang about forever waiting for them to answer.
Clark, H.H., Using Language, Cambridge University Press, 1996.
Foner, L., Entertaining Agents: A Sociological Case Study, in Proceedings of the First International Conference on Autonomous Agents, Marina del Rey, CA, 1997.
Hall, E.T., and Hall, M.R., Hidden Differences: Doing Business with the Japanese, Anchor Books, 1990 reprint.
Isbister, K., and Doyle, P. Touring Machines: Guide Agents for Sharing Stories about Digital Places, in Proceedings of the Workshop on Narrative and Artificial Intelligence, AAAI Fall Symposium Series, 1999.
Social Implications of Using Synthetic Characters, in Animated Interface Agents: Making Them Intelligent , 19-20.
The Persona Effect: Affective Impact of Animated Pedagogical Agents.
McCloud, S., Understanding Comics: The Invisible Art, Harper Perennial, 1993.
Parise, S., Kiesler, S., Sproull, L., and Waters, K. My Partner is a Real Dog: Cooperation with Social Agents, in Proceedings of Computer Supported Cooperative Work '96 , ACM Press, 399-408.
Reeves, B., and Nass, C., The Media Equation: How People Treat Computers, Television, and New Media Like Real People and Places, Cambridge University Press, 1996.
Sugawara, S., Suzuki, G., Nagashima, Y., Matsuura, M., Tanigawa, H., and Moriuchi, M., InterSpace: Networked Virtual World for Visual Communication, IEICE  Transactions on Information and Systems, E77-D, pp.1344-1349, 1994.
Though silence-sensing produced strong results, we would like to incorporate content recognition, to make Helper Agent a more powerful assistant.
Also, our first prototype supported only two people.
With more participants, we can experiment with additional features, such as recognizing active conversation groups and leading a newcomer to an ongoing conversation.
We are also interested in supporting groups with the same base language, but different subcultural memberships.
It would of course be interesting to run follow-up studies using pairs from other cultures, and to continue to refine and deepen our understanding of how cultural differences should affect an interface agent's behavior.
Our work is really only a beginning in exploring this terrain.
We built a social agent prototype, that was designed to facilitate human-human interaction.
A cross-cultural evaluation of the prototype demonstrated its effectiveness, and raised interesting considerations for further development of this class of interface agent.
We feel the support of human-human interaction in virtual meeting places is an exciting and useful new domain for interface agents.
Given the proliferation of online spaces, and the interest in community formation that far exceeds the industry's ability to staff communities with human hosts, this kind of agent may become a familiar part of the virtual landscape.
We hope that CHI community members who are called upon to think about and design these kinds of interface agents will find our prototype design and evaluation results useful for their work.
