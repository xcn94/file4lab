ABSTRACT This paper reports on the first of a series of analyses aimed at comparing same room and video-mediated conversations for multiparty meetings.
This study compared patterns of spontaneous speech for same room versus two videomediated conversations.
One video system used a single camera, monitor and speaker, and a picture-in-a-picture device to display multiple people on one screen.
The other system used multiple cameras, monitors, and speakers in order to support directional gaze cues and selective listening.
Differences were found between same room and video-mediated conversations in terms of floor control and amount of simultaneous speech.
While no differences were found between the video systems in terms of objective speech measures, other important differences are suggested and discussed.
CSCW, videoconferencing, conversation always hold .
There is no concept of a negotiated mutual distance between speakers, and speakers have no sense of how their voices are perceived by listeners.
Other differences are more subtle and harder to define, such as the relative impotence of gestures and gaze in securing another's attention through video , and the feeling of being "distanced" from others.
INTRODUCTION People meet for a variety of reasons: to discuss and share ideas, to argue and make decisions, to plan, and to socialize.
Video and audio technology has obvious potential for bringing people together at remote locations.
Cameras and microphones provide electronic eyes and ears; monitors and speakers deliver visual and auditory information.
Combined with computer supported groupware such as electronic whiteboards, all the right ingredients for a simulated face-to-face meeting seem to be in place.
There are nonetheless important differences between video and face-to-face  meetings.
Some of these are rather obvious.
Unlike eyes, cameras have a freed field of view and usually cannot be controlled by the viewer.
Failure to make eye contact tends also to be a problem because of separation of camera and monitor.
In videomediated meetings, the principle of reciprocity does not *Author is now at Rank Xerox Cambridge EuroPARC, and the MRC Applied Psychology Unit, CamWldge, UK.
This experiment was conducted in order to compare same room conversations with video-mediated conversations, and also to compare conversational behavior in two video systems.
One video system uses the picture-in-a-picture  approach and thus suffers from the limitations listed above.
The other, called Hydra, was designed specifically to support these abilities.
A series of analyses are planned for the data collected in this study.
This paper reports on the first analysis -- an examination of the gross structure of conversation for each of the three conditions.
The general question of interest is how video-mediation affects conversational structure in terms of the on-off patterns of speech.
A more specific question is whether the properties of the Hydra video system are sufficiently different from the PIP approach to affect speech patterns.
For example, head turning and gaze cues are thought to be important in regulating the flow of conversation.
Since Hydra is intended to support these kinds of cues, this maybe reflected in objective measures of speech.
These issues are addressed in the context of discussions involving four people.
While there are many interesting theoretical issues that arise, there are also practical issues motivating this work.
Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and thetitleof the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery.
To copy otherwise, or to republish, requires a fee and/or specific permission.
In particular, this study is part of a more comprehensive design effort examining different ways of supporting multiparty videoconferencing.
The "Hydra" System is a system which uses multiple cameras, monitors and speakers to support multiparty videoconferencing .
Hydra simulates a 4-way round-table meeting by placing a camera, monitor and speaker in the place that would otherwise be held by each remote participant.
Using this technique, each person is presented with a unique view of each remote participant, and that view, and its accompanying voice, emanates from a distinct location in space.
Figure 1 shows Hydra in use in a four-way conversation.
In this way, head turning and gaze cues deliver consistent and meaningful information.
Gaze and the Regulation of Conversation In this experiment, whether directional gaze cues were present in the conversation was one factor of interest.
It is estimated that 60 percent of conversation involves gaze and 30 percent involves mutual gaze .
Gaze serves at least five functions : to regulate the flow of conversation; to provide feedback on how the communication is being perceived by the listener; to communicate emotions; to communicate the nature of the interpersonal relationship; and to avoid excess information input.
Video systems which fail to support gaze and mutual gaze may affect any of these five functions.
One effect which may reveal itself in patterns of conversation is in the regulation of conversation, or how floor control is passed from speaker to speaker.
There area variety of different cues which are used to coordinate tumtaking such as intonation, paralanguage, body motion, and syntax .
Among these, gaze and head turning have been well established as being used to keep the floor, to take the floor, to avoid taking the floor, and to suggest who should speak next .
Kendon  found that gaze by a speaker at a listener increases just before ending a long utterance, and that when there is no such terminal gaze, there was more likely to be a pause before switching speakers.
In general, a speaker will tend to look away at the beginning of a turn and then terminate the turn with a sustained gaze, usually at presumptive next speaker.
A speaker wishing to hold the floor at a pause point will look away from the listener.
The fact that each participant is represented by a separate camera/monitor pair means that gazing toward someone is effectively conveyed.
In other words, when person A turns to look at person B, B is able to see A turn to look towards B's camera.
Looking away and gazing at someone else is also conveyed, and the direction of head turning indicates who is being looked at.
Furthermore, because the voices come from distinct locations, one is able to selectively attend to different speakers who may be speaking simultaneously.
Audio and video connections for Hydra are configured by software which ensures that a consistent "around the table" mapping is made for each person.
In other words, the switching network ensures that if person A appears in the center unit for person B, then B appears in the center unit for person A.
As Short, Williams and Christie  have noted, reintroducing the visual channel via conventional video systems may exacerbate problems in regulating conversation.
Not only do head turning and directional gaze cues tend to be eliminated, asymmetry may also be an important aspect of the problem.
For example, one participant may believe that they are making eye contact, but this is not perceived by the other participant.
Similarly, participants from time to time will look at the camera, and this may be interpreted as a signal by the receiver of the look.
There is some empirical evidence to support the fact that asymmetry can be problematic.
Argyle, Lalljee, and Cook  found that asymmetry in the amount of visibility between conversant led to greater effects in terms of pauselength and interruptions than symmetrical lessening of visual cues.
The Experiment In this study four-person groups were used.
Number of participants is an important consideration.
Dyads are typically the basis of research on conversational structure, in part because they we simpler to study.
However, as soon as a third party is ktroduced, "next turn" is no longer guaranteed to the non-current speaker.
Further, three party conversati~ns are notably different from four-party conversations in that four people provides for the possibility of two different ongoing conversations.
Four people in a discussion also means that it is potentially more difficult to gain the floor.
Thus it was hoped that using a larger group would accentuate differences between conditions in terms of regulation of conversation.
There are few studies which have objectively measured patterns of spontaneous speech across media.
Studies of dyadic conversations in audio-only conditions  have found that when one takes away visual cues, there tend to be fewer interruptions , shorter periods of simultaneous speech , and longer utterances .
However, there is some conflicting evidence.
Argyle, Lalljee and Cook  found more interruptions during dyadic conversations when visual cues were reduced.
The findings with regard to pauses are also inconsistent.
Argyle, Lalljee and Cook  found longer pauses when visual cues are reduced.
Cook and Lalljee  found no difference between media for length of pauses.
Jaffe and Feldstein  found slightly shorter pauses within utterances and between switching speakers in a novision condition, for mixed sex pairs only.
Only Cohen  has objectively measured conversational parameters for groups of more than two people in the context of face-to-face versus video conditions.
Cohen compared a face-to-face condition with a meeting using Bell's Picturephone Meeting Service .
Objective measures of conversational structure showed that the face-to-face condition resulted in more speaker turns and more simultaneous speech than the Picturephone Meeting Service.
Some have taken these findings to mean that technologymediated conversations are better synchronized than face-toface meetings.
Technology mediated conversant experience fewer intemuptions, and turn-taking appears to be more orderly.
Regulation of turns is obviously not wholly dependent on face-to-face visual cues.
The audio channel also carries synchronization cues and perhaps compensates for the loss or attenuation of visual cues.
However, what has been called more "orderly" conversation may in fact reflect a reluctance on the part of listeners to interject and try to seize the floor when visual cues are attenuated.
Rutter  showed that no-vision discussions are perceived to be less spontaneous, more formal and more socially distant than face-to-face discussions.
Experimental Hypotheses Because Hydra is designed to simulate a four-way meeting using video surrogates, the overriding expectation was that Hydra would tend to produce conversational patterns more similar to same room conversations than a PIP approach.
The PIP approach not only fails to support selective gaze and listening, but it is designed so that a viewer sees themselves in addition to the other three people.
This design feature also is unlike a face-to-face situation, and thus was thought to contribute to its "unnaturalness", perhaps to the extent that it affects the structure of conversation.
With this in mind, and by extrapolating from the existing literature, the following hypotheses were put fortlx HI.
Same room conversations will result in the highest number of turns per srssion.
The fewest will occur in the PIP condition.
The average duration of turns will be shortest in the same room condition, and longest in the PIP condition.
Hypotheses 1 and 2 are based on Cohen's  finding that there were ahnost twice as many speaker switches in a faceto-face meeting than in a Picturephone meeting.
If this finding holds for other kinds of video systems, we would expect more frequent and shorter turns in a conversation, all else being equal.
There will be the most unequal distribution of turns among speakers in the PIP condition, and the most equal distribution in the same room condition.
Thus in the video conditions, and especially in the PIP condition, dominant speakers will dominate more, and non-dominant speakers will attempt to take the floor less often.
There will be more simultaneous speech in same room condition than in the two video conditions.
The Hydra system will produce more simultaneous speech than the PIP condition.
This hypothesis is based on Cohen's  results which found more simultaneous speech in face-to-face meetings than in Picturephone meetings.
Cohen concluded that faceto-face meetings were thus less polite, less orderly, and If Hydra is more like a same room more interactive.
No specific hypothesis regarding time between speaker switches was put forth.
As discussed previously, the data regarding the effect of visual cues on switch pauses are inconsistent.
However, if perfect coordination between speakers means minimizing interruptions and minimizing pauses, then a zero switching time is ideal.
The average switch pause is typically in the range of .62 to .77 seconds .
As coordination gets worse, we would expect longer switch times to occur, However, we might also expect more overlapping speech during speaker switches.
These overlaps are typically not examined separately but are classified as simultaneous speech.
One alternative is to conceptualize switching time as a single metric which is sometimes negative  and which is sometimes positive .
The effect of video-mediation on this measure remains to be explored.
METHOD Subjects Twelve groups of four adults participated 15 women and 33 men.
With only a couple of exceptions, none of the subjects knew each other previously.
Task and Experimental Design Each group was asked to participate in a set of three informal debates lasting approximately sixteen minutes each.
Subjects were randomly divided into teams of two, and each team was randomly assigned either to the "Pro" or "Con" side of the issue.
Three different topics were introduced with the help of one or two short newspaper clippings.
The topics were: the right to smoke in public, mandatory drug testing, and censorship in the news.
Each group discussed all three topics, one in each condition.
Teams remained the same for all three topics and topics were counterbalanced across conditions.
This was a simple one-factor repeated measures design, comparing performance in three conditions: Same Room, Picture-in-a-Picture video system, and the Hydra video system.
Order of condition was counterbalanced using a Latin square design.
Experimental Conditions and Apparatus The three conditions are described below.
In this condition, all four subjects met in the same room around a table.
A video camera was set up in one comer of the room and the video output was channeled thtough coaxial cable to a VHS videmworder in the experimental control room.
In addition, each subject wore a headset microphone.
This audio output was also fed through coaxial cable to the experimental control room.
There, it went both to a mixer where all four voices were laid down on the audio track of the video cassette, and to the speech tracking equipment, also located in the control room.
Each subject was seated in separate room outfitted with a color video monitor, video camera, a speaker, and a headset microphone.
The camera was mounted on top of each monitor and the speaker was located immediately adjacent to each monitor.
A video board allowed the display of four composite images as illustrated in Figure 2.
This configuration allowed each participant to see the~ther three participants as well as an image of themselves.
Each subject saw exactly the same configuration of images as the other subjects.
The Hydra system was set up in each of the same rooms used in the PIP condition.
Each of the three Hydra units was constructed from a Sony Watchman color monitor , a black and white camera from a Radio Shack surveillance unit mounted 4.5 cm below the screen, and a speaker mounted just below the camera, also from a Sony Watchman.
Each unit tilts back and forth for best viewing position.
In the other thrm rooms, simulated Hydra units had to be used due to budget constraints.
In these rooms, three Radio Shack black and white monitors were used , along with two black and white Radio Shack surveillance cameras, and the color camera used in the PIP condition.
The color camera was used to feed the prototype Hydra units in order to take advantage of the color monitors in those units.
Each camera was mounted directly on top of each monitor.
In addition, each camera/monitor pair was mounted directly on top of a speaker.
In all cases, the Hydra or simulated Hydra units were located 15 cm apart on the desk top, and set back 38 cm from the edge of the desk.
RESULTS Analysis of Speech Data Each 16 minute conversation was checked for accuracy against the videotape data, edited where necessary, and coded using specialized software designed for this purpose.
Despite the impressive accuracy of the speech tracking system, some sporadic crosstalk did occur from time to time which had to be deleted.
In addition, 200 msec pauses were filled in, in order to account for stop consonants .
Laughter and also backchannel responses were coded so as to differentiate these data from speaker turns or attempts to take turns.
Backchannel responses are vocalizations such as "mmmhmm", often used to show attentiveness, which do not constitute turns or attempts to take turns .
Definitions The data were analyzed using definitions taken both from Jaffe and Feldstein  and Dabbs and Ruback , and then modified slightly.
Dabbs and Ruback's scheme is an extension of that of Jaffe and Fekiatein to better account for groups larger than dyads.
A turn consists of the sequence of talkspurts and pauses by a speaker who "has the floor".
A speaker gains the fhr when they begin speaking to the exclusion of everyone else and when rhey are not interrupted by anyone else for at least 1.5 seeonda.
The conversion of speech into digital on/off patterns was accomplished by obtaining audio output from each of the four subjects using unidirectional dynamic, headset microphones.
Each microphone output controlled its own externally keyed audio noise gate.
When a subject spoke louder then a preset threshold, the corresponding audio noise gate would open, allowing a fried pitch generated by a Yamaha TX802 synthesizer to pass through.
When a subject fell silent the gate would close and cutting off the pitch.
Each of the output signals from the four noise gates were fed into four input channels of an IVL Pitchrider 7000 Mark II pitch tracking device.
The pitch tracker converted the pitch ort/off signals into digital on/off signals and send them, via a MIDI connection, to a Macintosh II computer.
These on/off events were stored in the computer and each time code.
This time event was time stamped with sm code was simultaneously laid down on the videotape so speaker eventa could be later synchronized when playing back the videotape.
Procedure On arrival, subjects on the same team were introduced to each other and given approximately 15 minutes to get acquainted while completing the experimental consent forms.
Following this, they were introduced to the members of the other team and were instructed to read the first topic for debate.
They were then placed in separate rooms  or in the same room, and were instructed on wearing the headset microphones.
All three conditions used a similar procedure, Subjeets discussed the prescribed topic for 16 minutes, and then were asked to complete a questionnaire a~out the conversation they had just experienced, independently of each other.
Using Dabbs and Ruback's  definition: "A group turn begins the moment an individual turn taker has fallen silent and two or more others are speaking togetheq the group turn ends the moment any individual is again speaking alone" .
Dabbs and Ruback proposed the group turn to cover instances where individual turn takers are effectively "drowned out" by the group.
Switch time consists of switching pauses A switching pause is a period of mutual silence bounded by different turn takers .
Unlike existing definitions, I also include as a related measure the concept of overlap.
An overlap is a period of simultaneous speech immediately before and leading to the person who utters it taking a turn.
The two measures can be conceptualized as a single continuous parameter which measures the relationship between one person ending a turn and another starting.
A negative switch time is thus an overlap, while a positive switch time is a switch pause.
Turn distribution among speakers was calculated after Dabbs and Ruback  who used Shannon and Weaver's  equation for calculating information .
This equation defining H, or amount of information, is essentially a way of calculating the average amount of uncertainty about who has the floor at any given time.
Simultaneous Speech Analysis Table 2 presents the data summary for simultaneous speech and switching measures, Analyses of variance  showed 5.
Percentage of time one person spoke did not differ significantly across conditions.
Percent time of one person talking was based on the summation of all time intervals during which one person only spoke, expressed as a percentage of total session time .
Percentage of simultaneous speech was significantly different across conditions.
Means comparisons showed Same Room conversations to contain more simultanems speech than the video conditions  = 6.78, p c .016, but showed no difference between the two kinds of video conditions.
Percent of simultaneous speech refers to the proportion of time during which two, three or four people were speaking simultaneously.
No difference was found in the total amount of noninterruptive simultaneous speech across conditions, although the differences were close to significant  = 2.56, p c .10.
Amount of non-interruptive simultaneous speech is the sum of all simultaneous speech events not leading to a speaker switch.
Amount of interruptive simultaneous speech was found to differ across conditions.
Amount of interruptive simultaneous speech is the sum of all simultaneous speech events which result in the interrupting speaker taking the floor.
Percent of simultaneous speech taking control did not differ across conditions, Percent of simultaneous speeeh taking control is the percentage of simultaneous speech which is interruptive .
Percent of speaker switches consisting of overlaps  did differ across conditions.
More speaker switches consisted of overlaps in the Same Room conditions than the video conditions  = 7.85, p < .01, with no difference between video conditions.
Percent of overlaps in speaker switches calculates what percentage of speaker switches takes place with a negative switching time , rather than a switch pause.
Switching time was signitlcantly different across conditions.
The Same Room condition gave rise to a mean switch overlap, while the video conditions gave rise to a positive switch time value, or switch pause.
The difference between Same Room and video conditions was significant  = 27.67, p < .0001, but no difference between video conditions was found.
Switching time is an average of switch pauses , and overlaps .
Questionnaire Data The mean scores flom the questionnaires averaged acroas48 subjects are shown in Table 3.
Analysis of variance tests found four statistically significant resultx 12.
Subjects rated the Same Rmm meeting as allowing them to better take control of the conversation than both video conditions  = 10.59, p < .002.
There was no difference between video conditions.
Subjects rated the Same Room conversation as being more interactive than either video condition  = 5.65, p c .022.
There was no difference between video conditions.
14, Subjects rated the Same Room conversation as allowing them to selectively attend to one person at a time most easily  = 8.73, p < .005.
While the Hydra video system gave rise to a higher overall mean than the PIP system, this difference did not reach significance.
Subjects rated the Same Room condition the best for knowing when others were listening or attending to them.
DISCUSSION Turn Frequency, Duration, and Distribution Mediating conversations with video technology appeared to have no discernible effects on the number of turns taken per session, the average length of those turns, or on the distribution of turns among speakers.
These results were unexpected, especially considering previous research which generally fiids that audio-only conditions, and in one case, a video-mediated condition , tend to increase turn length relative to face-to-face conversations.
In light of the lack of differences betwetm same room conversations and videomediated conversations, it is perhaps not smprising that no difference was found between the hvo video conditions on these measures.
The conversadon seemed highly interactive.
I could selectively attend to one person at a time.
The discrepancy between Cohen's  results and these results may be due to the design of the Picturephone Meeting Service she used.
Picturephone is a voice activated system which, in her study, switched between six different cameras depending on who in the group was talking.
This meant that the whole group could never be viewed simultaneously.
She also introduced a 705 msec audio and video transmission delay in or&r to simulate round-trip satellite conditions.
These two factors could well account for differences in turn length and frequency, since this design would presumably more radically reduce the effectiveness of both verbal and visual cues to regulate turn-taking behavior.
Perhaps the results of this study with respect to turn frequency, duration, and distribution speak to the successof both the PIP and Hydra approach in preserving the structure of the conversation, at least at this level, The results of the questionnaire confirm that subjects did not feel that any of the three different situations was especially unnatural or uncomfortable.
In both systems, and unlike the Picturephone system, participants are visually available all the time.
Thus each person can monitor all other members of the group whether they are speaking or not and nonverbal signals for turn-taking can be perceived.
Showing that this factor alone accounts for differences between Cohen's results and these results would require running a voice switched video condition with no audio or video transmission delay.
A final point to note is that the groups were highly variable in overall amount of talking, amount of simultaneous speech, and distribution of turns among speakers.
Pronounced between group differences can be contrasted with relatively stable group characteristics across conditions.
This emphasizes the importance of using within-group designs for this kind of study.
Simultaneous Speech and Floor Control Subjects did feel it was more difficult to take control of the conversation in the video conditions than in the Same Room condition .
Nonetheless, this difficulty was not reflected in the distribution of turns among speakers, as might be expected.
Where differences do emerge, however, is in the amount of simultaneous speech that occurred and in the time between switching speakers.
A lower percentage of time was occupied by one speaker talking, and a higher percentage of time was occupied by simultaneous speech in the Same Room condition relative to the two video conditions.
This result is in line with previous findings for audio-only and video-mediated conversation, although some researchers have found more interruptions when visual cues are reduced .
A more informative analysis may come from asking what function simultaneous speech serves, or what it may indicate.
On the one hand, simultaneous speech may be taken to indicate a problem in floor control.
Studies which label simultaneous speech as "interruptions" make this tacit assumption.
On the other hand, simultaneity may also be taken to be an indication of the degree of interactivity and spontaneity of the conversation.
Conversations which have more simultaneous speech may be due to participants who feel more engaged in the conversation, and are more willing to attempt to take the floor.
Rather than attaching a value judgement to simultaneous speech, it may be more useful to distinguish between simultaneous speech which gains control of the floor versus that which does not.
One can then discover how often attempts at floor control occur, and how often they are successful.
Most existing studies do not make this distinction.
Video conversations gave rise to less non-interruptive simultaneous speech , and less interruptive simultaneous speech overall.
In addition, the Hydra system gave rise to less simultaneous speech of both types than the PIP system, although this difference was not significant.
What this may indicate is a reluctance on the part of conversant to attempt to take the floor in video-mediated conversations.
This is in line with many subjects' spontaneous comments.
Many reported feeling "distanced" by the video systems, and less a part of the conversation.
Perhaps they felt that bids for floor control would be less effective in video-mediatkd conversations.
The actual effectiveness of bidding for the floor while someone else is talking can be estimated by calculating the percentage of simultaneous spwch that gains the floor.
As is shown in Table 2, simultaneous speech was successful in gaining the floor about 34 to 42 percent of the time, and the differences across conditions was not significant.
Thus, there was no real difference in the probability of bids for the floor being effective in Same Room versus video conditions.
If subjects were more reluctant to bid for the floor in the video conditions, and bidding was equally effective, why would this not result in fewer speaker switches in the video conditions?
The answer may lie in the fact that speaker switching in the Same Room condition was more likely to occur with an overlap between speaker turns than a pause.
Speaker switching in the video conditions, on the other hand, was more likely to occur with a brief pause.
The analysis of switching time confirms this finding.
Switching time in the Same Room condition was -.46 seconds on average, while mean switching time in the video conditions was a positive value .
It is as if conversant in video-mediated conversations were more opportunistic or polite, waiting for a pause or for a speaker to finish before attempting to take the floor.
This theory is speculation at this point, however.
A clearer picture will likely emerge after a more thorough analysis of the videotape data.
PIP versus Hydra Systems Contrary to expectation, there were no differences between the two video systems in terms of objective measures of on-off patterns of speech.
However, both the questionnaire data and informal discussions with subjects after each experimented session confirmed that subjects did notice differences between the systems, and most had strong opinions on which system they preferred.
The majority of subjects preferred the Hydra system.
Reasons given included the fact that they could selectively attend to people, and could tell when people were attending to them.
Another frequent comment was that they liked the multiple sources of audio in the Hydra system, and that this helped them keep track of one thread of the conversation when people talked simultaneously.
The questionnaire data confirm that keeping track of the conversation in the PIP condition was the most difficult.
Thus, it is reasonable to conclude that Hydra was successful in facilitating selective listening and selective gaze, in line with the original intent behind its design.
A preliminary analysis of the videotape data also confirms that Hydra was successful in affording aside and parallel conversations.
Separate conversational threads occurred concurrently a total of four times in the Hydra condition, and three times in the Same Room condition, but never in the PIP condition.
Therefore, even though no differences appeared in the structural analysis of speech, it seems likely that an indepth analysis of the videotapes will reveal differences that do exist between these two systems.
Why the selective gaze and headtuming cues did not affect the structure of the conversation is an interesting issue.
Head turning and directional gaze could be readily observed in the Hydra conversations.
However video-mediation may render these kinds of cues ineffective for their recipients.
As Heath and Luff  have pointed out, movements in the periphery which appear on a screen lose their power to Presumably this is even more of a attract attention.
Speakers may also face difficulties in knowing how their gestures are received.
Indeed, many subjects commented that they wanted a mirror to see how they were framed from the point of view of others.
Thus even though Hydra is designed to support directional gaze cues, video mediation may nonetheless detract fmm the ability of such cues to affect behavior.
Finally, about one third of the subjects preferred the PIP system to the Hydra system.
It was interesting to find that most of these subjects commented that they enjoyed having all of the participants on one screen because it meant that head turning was not necessary.
Some subjects said they liked to see themselves to know how they were seen by others, even though this could sometimes be distracting.
CONCLUSIONS This paper provides some statistics on differences between same room and video-mediated conversations for multiparty However, some unexpected similarities conversations.
Videoconferencing did not seem to have much effect on how often people spoke, or for how long, or on the patterns of distribution of turns among Both video systems used in this group members.
This may account for the lack of drastic differences between conditions.
Other kinds of systems such as voice-activated video switching systems have the characteristic that only the current speaker is displayed to the other participants.
This aspect of design may result in much larger effects on conversational structure.
We currently have such a system in place and are running a second study to test this assumption.
Very few, if any, studies exist which compare objective measures of conversation for different kinds of video systems.
This paper provides some of those statistics, and has also shown that such measures may be relatively insensitive to more subtle but nonetheless important aspects of videoconferencing system design.
One factor which may have downplayed any differences was the small monitors used in the Hydra design.
Because image size was so small, this may have decreased the effectiveness of directional gaze cues in peripheral vision.
Despite this finding, there is every indication that significant differences between the two systems examined here do exist.
Both the ability to selectively attend to different audio streams, and to different video images appeared to be successful in making aside conversations possible.
In addition, subjects commented that multiple speakers made it easier to follow the conversation.
These are clearly important aspects of design, and a more indlepth, qualitative analysis of the videotapes explore them farther.
Bill Buxton is responsible for much of the conceptualization behind the design of the various systems.
He also contributed to the content of this paper.
Gordon Kurtenbach configured the hardware for the speech tracking equipment, and invested a great deal of time writing the software for recording, editing, and analyzing the speech time lines.
I also gratefully acknowledge the contribution of the Amott Design Group of Toronto for the design and fabrication of the Hydra models.
Bodily Methuen & Co. Ltd.
