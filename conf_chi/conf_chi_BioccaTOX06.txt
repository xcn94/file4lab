The attention funnel is a general purpose AR interface technique that interactively guides the attention of a user to any object, person, or place in space.
The technique utilizes dynamic perceptual affordances to draw user attention "down" the funnel to the target location.
Attention funnel can be used to cue objects completely out of sight including objects behind the user, or occluded by other objects or walls.
An experiment evaluating user performance with the attention funnel and other conventional AR attention directing techniques found that the attention funnel increased the consistency of the user's search by 65%, increased search speed by 22%, and decreased mental workload by 18%.
The attention funnel has potential applicability as a general 3D cursor or cue in a wide array of spatially enabled mobile and AR systems, and for applications where systems can support users in visual search, object awareness, and emergency warning in indoor and outdoor spaces.
AR techniques in fully mobile, spatially enabled pervasive computing environments  offer the possibility of supporting users with structured overlays of large volumes of three-dimensional spatial information anywhere in indoor or outdoor space: workrooms, manufacturing plants, streets, or open outdoor environments.
These systems present a modified view of the environment with overlaid virtual annotations, either in head-mounted displays that directly augment the visual field, or in video see-through devices that augment a camera image, often captured out the back of the device, creating the appearance of looking through the computer.
The spatial coordinates of physical objects and locations that will be augmented using this process can be retrieved from known Global Positioning System  coordinates , tracking systems , visual tagging such as fiducial markers  or radio frequency tags .
Realized virtual information objects such as labels, overlays, additional 3D objects, and other data are integrated into the physical environment using a variety of display devices that make the virtual annotations appear to be elements of the real environment.
One basic user interface functionality is the ability to direct user's attention to physical or virtual objects in the environment.
Mobile, context-aware, and ubiquitous computing interfaces will often be tasked with directing attention to physical or virtual objects that are located anywhere in the environment around the user.
Often the target of attention will be beyond user's visual field and the field of view of the display devices in use.
Mobile AR systems allow users to interact with all of the environment, rather than being focused on a limited screen area.
Hence, they allow interaction during visual search, tool acquisition and usage, or navigation.
In emergency services or military settings, AR can cue users to dangers, obstacles, or situations in the environment requiring immediate attention.
These many applications call for a general purpose interface technique to guide user attention to information populating a potentially cluttered physical environment.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
The challenge is part of a larger need for attention management  in high information bandwidth mobile interfaces.
Example Scenarios To illustrate the benefits of management of visual attention in an AR system, consider the following application scenarios:
Information-rich applications of mobile AR interfaces  begin to push up against a fundamental human factors limitation, the limited attention capacities of humans.
For example, the attention demands of relatively simple and low bandwidth mobile interfaces, such as PDAs and cell phones, may contribute to car accidents .
Attention is used to focus cognitive capacity on a certain sensory input so that the brain can concentrate on processing the information of interest .
Attention is primarily directed internally, "from the top down" according to the current goals, tasks, and larger dispositions of the user.
Attention, especially visual attention, can also be cued by the environment.
Visual attention is even more limited, since the system may have information about objects anywhere in an omnidirectional working environment around the user.
Visual attention is limited to the field of view of human eyes , and this limitation is further narrowed by the field of view of common HMDs .
In mobile AR interfaces, the attentional demands of the interface on mental workload  must also be considered.
Attention is shared across many tasks, and tasks in the virtual environment are often not of primary consideration to the user.
Individuals may be ambulatory, working with physical tools and objects, and interacting with others.
The user may not be at the correct location in the scene or looking at the correct spatial location or object needed to accomplish a task.
So, attention management in the interface should reduce demands on mental workload.
An emergency technician wears a head-mounted camera and an AR Head-mounted Display  while collaborating with a remote doctor during a medical emergency.
The remote doctor needs to indicate a piece of equipment that the technician must use next.
What is the quickest way to direct her attention to the correct tool among a large and cluttered set of alternatives, especially if she is not currently looking at the tool tray and doesn't know the technical term for the tool?
A warehouse worker uses a mobile AR system to manage inventory, and is searching for a specific box in an aisle where dozens of virtually identical boxes are stacked.
Tracking systems integrated into the warehouse detect that the box is stored on a shelf behind the user using inventory records, an RFID tag, or other markers.
What is the most efficient way to signal the target location to the user?
A trainee repair technician uses an AR system to learn a sequence of steps where parts and tools are used to repair complex manufacturing equipment.
How can the computer best indicate which tool and part to grab next in the procedural sequence, especially when the parts and tools may be distributed throughout the entire space in 4 steradians?
A tourist with a PDA equipped with GPS is looking for an historic building in a street with many similar buildings.
The building is around the corner down the street.
How can the PDA efficiently indicate a path to the main entrance?
These scenarios share a common demand for a technique that allows for:  precise target location cueing,  in near or far open spaces,  at any angle relative to the user, and  under conditions where speed and accuracy may be important.
Any technique must be able to provide continuous guidance and direct the user around occlusions.
The scenarios illustrate various cases where attention must be guided or managed by the interface.
Currently, there are few, if any, general mobile interface paradigms to quickly direct spatial attention to objects or locations anywhere in the environment.
Users and interface designers have evolved various ways to direct visual attention in interpersonal interaction, architectural settings, and standard interfaces.
WIMP  interfaces benefit from the assumption that user's visual attention is directed to the screen, which occupies a limited angular range in the visual field.
Visual cues such as flashing cursors, pointers, radiating circles, jumping centered windows, color contrast, or content cues are used to direct visual attention to spatial locations on the screen surface.
Large display areas extend this angular range, but still limit the visual attention to a clearly defined area.
Khan and colleagues  proposed a visual spotlight technique for large room interfaces.
Spatial cueing techniques used in interpersonal communication , WIMP interfaces, and architectural environments are not easily transferred to AR systems.
Almost all of these techniques assume that the user is looking in the direction of the cued object or that the user has the time or attentional capacity to search for a highlighted object.
Multimodal cues such as audio can be used to cue the user to perform a search, but the cue provides limited spatial information and must compete with other sound sources in environment.
Spatialized audio  can be used on its own to direct attention but the resolution may not be adequate for some applications, especially in noisy environments.
Interface design in a mobile AR system presents two basic challenges in managing and augmenting attention of the user:  Omnidirectional cueing.
To quickly and successfully cue visual attention to any physical or virtual object in 4 steradians as needed.
Minimize mental workload and attention demands during search or interference with attention to tasks, objects, or navigation in the physical environment.
The Omnidirectional Attention Funnel is an AR display technique for rapidly guiding visual attention to any location in physical or virtual space.
The basic components of the attention funnel are illustrated in Figure 1.
The most visible component is the set of dynamic 3D virtual objects linking the view of the user directly to the virtual or physical object.
The attention funnel visually links a head-centered coordinate space directly to an object-centered coordinate space, funneling focal spatial attention of the user to the cued object.
The attention funnel takes advantage of spatial cueing techniques impossible in the real world, and AR's ability to dynamically overlay 3D virtual information onto the physical environment.
Like many AR components, the AR funnel paradigm consists of:  a display technique, the attention funnel, combined with  methods for tracking and detecting the location of objects to be cued.
Three basic patterns are used to construct a funnel:  the head centered plane includes a bore sight to mark the center of the pattern from the user's viewpoint,  funnel planes, added in a fixed pattern  between the user and the object, and  the object marker pattern that includes a red cross hairs marking the approximate center of the object.
The integration of audio with visual cues helps draw attention even when vision is not directed to the screen.
Of course, these systems work within the confines of a very limited amount of screen real estate; an area most users can scan very quickly.
The audio cue often initiates the attention process, requiring completion using visual scanning.
In mobile AR environments, the volume of information is large and omnidirectional.
AR environments have the capacity to display a large amount of informational cues to physical objects in the environment.
Most current AR systems adopt WIMP cursor techniques or visual highlighting to direct attention to an object .
Recently, Chia-Hsun and colleagues  proposed projecting light into the environment.
The attention funnel has been realized as an interface widget in an augmented reality development environment.
The attention funnel interface component  and is one component in a planned set of user interface widgets being designed for mobile AR applications.
These components are being built and tested as extensions of the ImageTclAR augmented reality development environment .
The curve follows a path from the starting point in the direction of the starting end tangent vector.
It ends at the end point with the curve approaching the end point in the direction of the end tangent vector.
As a cubic curve segment, the curve presents a smoothly changing path from the start point to the end point with curvature controlled by the magnitude of the tangent vectors.
Hermite curves are a standard cubic curve method discussed in any computer graphics textbook.
Figure 3 illustrates the curvature of the funnel from a bird's eye perspective.
The starting point of the Hermite curve is located at some specified distance in front of the origin in a frame defined to be the viewpoint of the user .
The curve terminates at the target.
The tangent vector for the Hermite curve at the starting point is in the -z direction1 and the tangent vector at the ending point is a vector specified as the difference between the end and start locations .
The curvatures of the starting and ending points are specified in the application.
A single cubic curve segment creates a smoothly flowing path from the user's viewpoint to the target in a near field setting.
Larger environment that include occlusions are require complex navigation are realized using a sequential set of cubic curve segments.
The join points of the curve segments are specified by a navigation computation that takes into account paths and occlusions.
As an example, a larger outdoor navigation system under development uses the Mappoint commercial map management software to compute waypoints on a navigation path that then serve as the curve join points for the attention funnel path.
The key design element is the smooth curvature of the path that allows for the funneling of attention in the desired target direction.
The orientation of each pattern along the visual path is obtained by spherical linear interpolation of the up direction .
Spherical interpolation allows the rotation angle between each interval to be constant, i.e.
The computational cost of this method is very small, involving the solution of the cubic curve equation , the spherical interpolation solution, and computation of a rotation matrix for each pattern display location.
Computational costs are dwarfed by the rendering costs for even this low-bandwidth display rendering.
The purpose of an attention funnel is to draw attention when it is not properly directed.
When the user is looking in the desired direction, the attention funnel becomes superfluous and can result in visual clutter and distraction.
The solution to this case is to fade the funnel as the dot product of the source and target tangent vectors approaches one, indicating the direction to the target is close to the view direction.
As the head and body move, the attention funnel dynamically provides continuous feedback.
Affordances from the perspective cues automatically guide the user towards the cued location or object.
Dynamic head movement cues are provided by the skew  of the attention funnel.
The level of alignment  of the funnel provides an immediate intuitive sense of how much the body or head must turn to see the object.
Example of the attention funnel drawing attention of the user to an object on the shelf, the red box.
The basic components of the attention funnel, as illustrated in Figure 2, are:  a view plane pattern with a virtual boresight in the center,  a dynamic set of attention funnel planes,  an object plane with a target graphic, and  an invisible curved path linking the head or viewpoint of the user to the object.
Along this path are placed patterns that are repeated in space and normal to the line.
We refer to the repeated patterns on the linking path as an attention funnel.
The path is defined using cubic curve segments.
Initial experiments have instantiated the path as Hermite curve .
The attention funnel uses various overlapping visual cues that guide body rotation, head rotation, and gaze direction of the user.
Although various patterns could be used, an "attention sink" pattern introduced by Hochberg , provides strong perspective cues as shown in Figure 4.
Each attention funnel plane has diagonal vertical lines that provide depth cueing towards the center of the pattern.
Each succeeding funnel plane is placed so that it fits within the preceding plane when the planes are aligned in a straight line.
Increasing degrees of alignment cause the interlocking patterns to draw visual attention towards the center.
Three basic patterns are used to construct a funnel:  the head centered plane includes a bore sight to mark the center of the pattern from the user's viewpoint,  funnel planes, added in a fixed pattern  between the user the object, and  the object marker pattern that includes a red bounding box marking the approximate center of the object.
Patterns 1 and 3 are used for dynamically cueing the user that they approach an angle where they are "locked onto" the object .
As the head and body moves, the attention funnel provides continuous feedback that cues the user how to turn the body and/or head towards the target location or object.
Continuous dynamic head movement cues are indicated by the skew  of the attention funnel.
The pattern of the funnel provides an immediate intuitive sense of the location of object relative to the head.
For example, if the funnel skews to the right, the user knows to move his head to the right .
The funnel skew and alignment provides a continuous dynamic cue that one is getting closer to being "in sync" and locked onto the cued object.
When looking directly at the object, the funnel fades so as to minimize visual clutter.
Attention funnels may be applicable to different augmented vision display technology capable of presenting 3D graphics.
We have implemented attention funnels for headmounted displays and video see-through devices such as tablet PCs, but they can also be design for handheld computers and cell phones that have 6 degrees-of-freedom tracking.
The location of target objects or locations in the environment may be known to the system because they are:  virtual objects in tracked 3D space,  tagged with sensors such as visible markers or RFID tags, or  at predefined spatial locations as in GPS coordinates.
Virtual objects in tracked 3D space are the most straightforward case, as the attention funnel can link the user to the location of the target virtual object dynamically.
Objects tagged with RFID tags are not necessarily detectable at a distance or locatable spatially with a high degree of accuracy, but local sensing in a facility may be sufficient to indicate a position for attention direction.
A within-subjects experiment was conducted to test the performance of the attention funnel design against other conventional attention direction techniques: visual highlighting and verbal cues.
The experiment had one factor, the method used for directing attention, with three levels :  the attention funnel,  visual highlight techniques, and  a control condition consisting of a simple linguistic cue.
A pressure sensor was attached to the thumb of a glove to capture the reaction time when the subject grasped the target object.
Presentation of visual and audio stimulus materials to participants, experimental procedure sequencing, and data collection for the experiment was automated..
The experiment was developed in the ImageTclAR AR development environment .
Search Time, Error, and Variability.
Search time in milliseconds was measured as the time it took for participants to grab a target object from among the 48 objects following the onset of an audio cue tone.
The end of the search time was triggered by the pressure sensor on the thumb of the glove when the user touched the target object.
An error was logged for cases when participants selected the wrong object.
Participant's perceived task workload with each interface was measured using the NASA Task Load Index administered after each experimental condition .
Participants entered a training environment where they were introduced and trained to use each interface .
They then began the experiment.
Each subject experienced the interface treatment conditions .
Within each condition, participants were cued to find and touch one of the 48 objects in the environment as quickly and accurately as possible.
Participants participated in 24 trials with half of the trials involved searching for a randomly selected primitive objects and half a randomly selected general everyday objects.
To control for order effects, the order of the conditions and the cued objects was completely randomized for each participant.
A 360-degree omnidirectional workspace was created using four tables as shown in Figure 5.
Visual cues were displayed in stereo with the Sony Glasstron LDI-100B head-mounted display, and audio stimulus materials were presented with a pair of headphones.
Head motion was tracked by an Intersense IS900 ultrasonic/inertia hybrid tracking system.
A general linear model repeated measure analysis was conducted.
Consistent with the behavioral indicators, there was a significant effect of interface type on the participants perceived mental workload, F = 4.178, p = 0.027.
When compared to conventional cueing techniques such as visual highlighting and verbal cueing, we found that the attention funnel decreased the visual search time by 22% overall, or approximately 28% for search phase alone, and 14% over the next fastest method, as shown in Figure 6.
While increased speed in the aggregate is valuable in some applications of augmented reality, such as medical emergency and other high risk applications, it may be critical that the system exhibit consistent performance.
The attention funnel had a very robust effect on search consistency .
The interface increased consistency by 65% on average, and 56% over the next best interface.
In summary the attention funnel led to faster search and retrieval times, greater consistency of performance, and decreased mental workload when compared to verbal cueing and visual highlighting techniques.
The attention funnel, however, has some limitations when compared to conventional interfaces.
The interface does produce some visual clutter, although the current implementation greatly reduces the number of cueing planes as the object enters the field-of-view.
This issue is less problematic for user driven attention, for example when the user prompts the system for the location of a target object.
Managing visual clutter for system or task driven attention funnel is more problematic when the system or a remote user is trying to draw the user's attention to a spatial location using the attention funnel.
The strong visual cueing may be valuable in emergency situations, but unexpected visual cueing might irritate users or distract attention when it is needed for another task.
So applications implementations of the attention funnel require strong user driven controls so that the user can manage their attention.
In the case of system/task driven attention events, an indicator can be placed on the peripheral visual area to indicate an attention funnel is ready to be activated by the user.
The AR attention funnel paradigm represents an example of cognitive augmentation specifically adapted for users of mobile AR systems navigating and working in information and object-rich environments.
An initial evaluation compared the attention funnel to two conventional cueing methods.
Experimental results of the initial evaluation shows that the attention funnel led to higher search consistency and lower search time and mental workload.
Follow up evaluations comparing the attention funnel to various unconventional cueing methods  in various 4 steradian omnidirectional search environments are currently in progress.
A mobile testbed is under development for the evaluation of different spatial cueing techniques in large outdoor and mobile environments.
This project is part of the Mobile Infospaces project and supported in part by a grant from the National Science Foundation CISE 02-22831.
Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author and do not necessarily reflect the views of the National Science Foundation.
The authors would like to acknowledge the assistance of Betsy McKeon, Amanda Hart and Corey Bohil in the preparation of this manuscript.
The attention funnel paradigm provides a basic technique applicabile to a common problem in different mobile interfaces: How to quickly draw a user's attention to any object or location in the environment in order to accomplish tasks.
We are currently implementing the technique on other mobile devices including hand held devices such as PDAs and cell phones.
A survey of augmented reality.
Spatial hearing: the psychoacoutics of human sound localization.
Attentionbased design of augmented reality interfaces.
Nonverbal communication: the unspoken dialogue.
Constellation: a wide-range wireless motion-tracking system for augmented reality and virtual set applications.
IEEE International Conference on Robotics and Automation.
Development of NASA-TLX : results of empirical and theoretical research, in Human Mental Workload, Hancock, P. and Meshkati, N., Editors.
Representation of motion and space in video and cinematic displays, in Handbook of Perception and Human Performance, Vol.
Hofmann-Wellenhof, B., Lichtenegger, H. and Collins, J.
Global positioning system: theory and practice.
Models of attention in computing and communication: from principles to applications.
Johnson, A. and Proctor, R.W.
Sage Publications, Thousand Oaks, CA.
Marker tracking and HMD Calibration for a video-based augmented reality conferencing system.
2nd International Workshop on Augmented Reality.
Spotlight: directing users' attention on large display.
Telepointer: Hands-Free Completely Self Contained Wearable Visual Augmented Reality without Headwear and without any Infrastructural Reliance.
Fourth International Symposium on Wearable Computers.
Introduction to This Special Issue on Context-Aware Computing.
ImageTclAR: a blended script and compiled code development system for augmented reality.
STARS2003, The International Workshop on Software Technology for Augmented Reality Systems.
Association between Cellular Telephone Calls and Motor Vehicle Collisions.
Symposium on Eye Tracking Reasearch & Applications.
A handheld augmented reality museum guide.
IADIS International Conference on Mobile Learning 2005.
Visual processing capacity and attentional control.
Journal of Experimental Psychology: Human Perception and Performance, 5: p. 522-526.
Driven to distraction: dual-task studies of simulated driving and conversing on a cellular phone.
Attention in vision: perception, communication, and action.
Psychology Press, New York, NY.
Towards massively multi-user augmented reality on handheld devices.
Third International Conference on Pervasive Computing.
First steps towards handheld augmented reality.
7th Internation Symposium on Wearable Computers.
