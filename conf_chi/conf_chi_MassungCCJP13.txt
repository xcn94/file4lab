Community activist groups typically rely on core groups of highly motivated members.
In this paper we consider how crowdsourcing strategies can be used to supplement the activities of pro-environmental community activists, thus increasing the scalability of their campaigns.
We focus on mobile data collection applications and strategies that can be used to engage casual participants in pro-environmental data collection.
We report the results of a study that used both quantitative and qualitative methods to investigate the impact of different motivational factors and strategies, including both intrinsic and extrinsic motivators.
The study compared and provides empirical evidence for the effectiveness of two extrinsic motivation strategies, pointification - a subset of gamification - and financial incentives.
Prior environmental interest is also assessed as an intrinsic motivation factor.
In contrast to previous HCI research on pro-environmental technology, much of which has focused on individual behavior change, this paper offers new insights and recommendations on the design of systems that target groups and communities.
This group aims to reduce energy waste by encouraging shop owners to keep their doors closed during cold weather.
In spite of winning national environmental advocacy awards and having dedicated core members, the CTD campaign faces challenges that are common to many community activist groups.
In particular, they have found that to achieve scalable and sustainable change, it is not sufficient to rely purely on their core members.
Activist groups also need to develop effective strategies for drawing on support from casual volunteers.
One particular challenge for CTD is to maintain their database of shops and monitor the behavior of shop owners on an ongoing basis.
In this paper we evaluate different strategies through which computer-supported citizen science and crowdsourcing techniques  can be brought to bear to help in addressing this challenge.
We focus on developing mobile applications  that allow members of the public to undertake lightweight environmental data collection.
The aim is to increase the scalability of activist groups like CTD by collecting data on a much larger scale than otherwise possible and freeing core members to focus on high impact advocacy activities.
Members of the public are unlikely to be as motivated as community activists and overcoming public apathy is often difficult for pro-environmental movements.
The question thus arises: what design strategies can we apply to motivate people to engage in pro-environmental data collection?
The key contributions of this paper are to implement a set of mobile data collection apps and then provide both qualitative and quantitative evidence for the effectiveness of the different motivational strategies that are applied in the apps.
Overall we developed three apps.
The first used "pointification", a subset of gamification that uses game mechanics such as points, badges, and leaderboards to encourage engagement and competition .
The second offered participants financial incentives to carry out data collection tasks .
The final app did not use any explicit motivational strategies and acted as a control.
We conducted a study in with each app was used by 16 participants for two weeks.
Results show that pointification increased performance, though not to a statistically significant level.
However, financial rewards led to a significant increase in the amount of data collected.
Community activist groups, including pro-environmental groups, are typically driven by a core group of highly motivated individuals.
These people are often willing to dedicate a great deal of time and effort to help bring about desired changes within their community.
While they may derive intrinsic personal satisfaction from their activities, and enjoy the benefits of participation in a group, there is often no expectation of, or need for, other extrinsic rewards, e.g.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Qualitative data, collected through semi-structured interviews, allowed us to investigate such issues in greater details.
For example we found that the factors that encourage people to initially take part in a community activism project can differ from those that maintain interest.
Also, although motivational factors impact a person's use of an app, motivation is complex and is only half the battle.
Designers must also consider the enabling factors that influence casual volunteers' use of crowdsourcing apps.
The research presented in this paper extends HCI research on pro-environmental technologies in several key ways.
Prior research in this area has largely focused on systems targeting individual behavior change .
This paper provides new insights on systems targeting groups and communities rather than individuals.
It provides both quantitative and qualitative evidence on the effectiveness of different motivational and enabling strategies.
By drawing on this evidence we provide recommendations to guide the design of crowdsourcing applications that support proenvironmental community activism.
With the increasing ubiquity of smart phone technology, mobile data collection through crowdsourcing is increasing.
It has been used in citizen science to collect data in support of scientific research, including monitoring the spread of invasive plants through the What's Invasive app  and monitoring animal population distributions through the reporting of roadkill .
It has also been used in participatory urbanism, by municipal authorities seeking to engage people in monitoring and improving their urban environments.
Examples include monitoring noise pollution  and repairing potholes and streetlights .
The boundary between these two genres blurs in applications such as water quality  and air quality  monitoring, where the data both increases scientific understanding and can also contribute to local management policies.
Our work can be viewed as a form of participatory urbanism, but rather than supporting the efforts of municipal authorities it instead supports the efforts of community activists.
As such, it adopts a similar position to the work of Kuznetsov et al.
Prior HCI research on technology-supported environmental behavior change has been dominated by systems targeting individual behavior change .
Such systems are often driven by rational choice models, which assume that individual behavior is driven by self-interest.
For example, rational economic models assume that - given access to the relevant information - people behave in such a way as to maximize rewards and minimize costs , thus adopting behaviors that are advantageous .
An alternative approach to behavior change, which has received less attention in pro-environmental HCI research, focuses on communities rather than individuals.
Theories such as the norm-activation model hypothesize that individual behavior is strongly shaped by community norms and everyday practices .
Rather than focusing on individual reward, such approaches recognize the benefits of collective and coordinated actions.
These approaches are beginning to be applied to pro-environmental behavior , and some studies, such as , have shown that these norms can more positively affect behavior than traditional proenvironmental messages or messages highlighting money saving opportunities.
The CTD campaign, and apps described in this paper, aim to take advantage of both individual  and community  strategies.
In common with all crowdsourcing approaches, Citizen Science and Participatory Urbanism face key challenges in engaging contributors - namely how to recruit them, and how to get them to make an active ongoing contribution.
In a review of crowdsourcing literature, Doan et al.
In citizen science literature, Kim et al.
However, neither compared or analyzed the effect of these different types of approaches to assess their effectiveness on recruitment or contribution.
Focusing on motivation, the factors that motivate individuals can be viewed as either intrinsic or extrinsic.
People who are intrinsically motivated are willing to do an activity "for its inherent satisfactions rather than for some separable consequence" ; examples of intrinsic motivators include interest, curiosity, competence, and enjoyment .
Within the context of sustainability, De Young  posits that behavior that is intrinsically motivated is more effective for self-sustaining individual behavioral change.
In community activist campaigns such as CTD, core members are likely to have a high degree of intrinsic motivation.
Extrinsic motivation is carrying out an activity "to attain some separable outcome", such as material incentives or social reinforcement .
Elements can include point scoring, leaderboards, goal setting, questing, and artifact collecting.
Gaming techniques have been applied in the domain of ecofeedback technology.
A series of games concentrating on creating awareness of household energy in adolescents were trialed through the use of smart meters and mobile phone applications , and participants often compared the changing ambient display of UbiGreen to gaming levels .
However, these applications focused on the behavior of an individual, with the ultimate goal of awareness or behavior change by system users, rather than data collection.
Providing participants with small financial rewards in return for carrying out basic tasks such as image identification has also been successfully employing as a way of attracting and motivating participants, e.g.
This approach has been found to increase the amount of effort expended ; however, it has also been suggested that financial rewards may reduce intrinsic motivation .
The study in this paper provides the first systematic analysis of the effectiveness of two forms of extrinsic motivation on environmental data collection performance: a financial pay-for-results scheme, and a virtual reward scheme, which uses points, badges and a leaderboard.
We also analyze the effect of intrinsic motivation by examining if a positive disposition towards environmental behaviors affects performance.
Furthermore, through a qualitative study, we examine the interrelationships between different motivators and the other factors affecting the motivation and performance of people using the CTD app.
Members of the public are given information about the environmental benefits of closed doors and encouraged to support shops carrying a CTD logo.
The message to the public is: "If a shop will not Close the Door: don't shop there, go elsewhere."
By targeting both shop owners and their customers, the campaign aims to make closed doors the accepted norm.
Ultimately this new norm benefits both shop owners and the environment.
Through conversations with members of the CTD campaign, we found that the time spent recruiting and retaining shop owners is critical to their success.
However, in order for this advocacy to work, members need to collect data about shops in the local area.
This is time and labor intensive and must be undertaken on an ongoing basis to check that shops continue to follow the Close the Door policy.
It has placed great strain on the core members of the campaign.
Working in collaboration with campaigners, we therefore decided to develop mobile apps that allow casual participants to record shop doors via a smartphone.
If people use our apps on a regular basis it would allow the CTD campaign to scale up their data collection and would also free campaigners to focus on advocacy activities.
Rather than evaluating a single data collection app, we chose to design three iPhone apps.
Each app applied a different strategy to encourage users to collect data.
By comparing the effectiveness of these apps we aimed to provide evidence of the effectiveness of different motivational strategies that can be applied to engage casual participants to collect pro-environmental data.
In designing the apps, we deliberately sought to keep things simple.
Rather than exploring a wide range of functionality and overlapping motivational strategies, our aim was to compare and provide strong evidence on the relative effectiveness of particular strategies.
Our apps are designed to allow people to collect data while they go about their daily routines.
Each app is built around a core design that uses the map and GPS functionality on an iPhone.
As people move around a city they can open a map that shows an overlay of shops in their vicinity .
People can click on shops - represented by door symbols - and record whether the shop door is open  or closed , Figure 1b.
The initial shop database was populated using the CTD campaign's existing list of shops.
If a shop was not in the existing database a user could add it manually.
A traffic light system was employed to signal a shop's status: a consistently opened door would appear as red, an occasionally open door as yellow, and a consistently closed door as green .
Participants also had the option to report any problems, such as duplications, incorrect shop names, or to record if a store was permanently closed, allowing the database to be kept up to date.
The statuses of shops were updated in real time to reflect participants' ongoing ratings.
On UK high streets it is common to see shop doors propped open to encourage potential customers to step over the threshold.
However, during cold weather these open doors allow heat to escape.
A detailed study of typical 150m2 UK high street shops found that keeping doors closed can reduce emissions and energy from heating by 30-50% .
The CTD campaign was established in response to this finding.
Since its inception in 2007 it has grown to include chapters in nine UK and two international cities, and it was named Best Campaign by UK Climate Week 2012.
Considered purely in terms of energy costs, closing doors is a rational choice for shop owners.
However owners fear that they will lose customers if they close their doors whilst other shop doors remain open.
This is a classic "I will if you will" environmental problem .
The CTD campaign attempts to combat this problem by sending volunteers to shopping streets to record whether shops have their doors open or closed.
Owners or managers are then approached to determine if they want to join the campaign - i.e.
Shops that join the campaign are listed on the CTD website and Facebook page, and are given a door sticker to publicize their membership.
Across all our apps, two approaches were used to promote data quality and help to avoid cheating.
Firstly, a system of independent verification by a second user was used to validate new shops.
Thus, new shops only appeared on our maps when validated by two independent users.
Secondly, participants were only able to add new shops or to record doors within 200 yards of their present location and could only rate a shop once each day.
Our first app acted as a Control.
It used the full functionality described above.
Participants using this app were asked to record as many shop doors as possible and could also add new shops to the database.
The second app - the Virtual reward app - again used the full functionality described above, but also incorporated pointification techniques.
Participants earned points and badges for their contributions.
They received 2 points for rating a shop already in the database and 15 points for adding a new shop .
Participants could also earn up to 15 badges  worth 15 points each.
Badges were earned for activities such as using the app for five days in a row or for rating a shop on the weekend.
Participants could keep track of their point score and badges and get information on how to earn new badges through a status screen .
The Virtual app also included a leaderboard.
This showed people their position and point score relative to other Virtual app users.
The Virtual app therefore augmented the Control app with extrinsic rewards  and a source of extrinsic motivation for the participants: the desire to achieve a high score and a high position on the leaderboard.
The leaderboard listed usernames rather than real names.
The Financial app was an adapted version of the Virtual one.
It also had a leaderboard, but in this case participants received a financial reward based on their points score and position on the leaderboard .
The leaderboard showed a real-time tally of the amount of money each participant would earn based on this running point total .
Participants were recruited through a mixture of sources: a university bulletin board, an online classified service, and local environmental sustainability groups.
Participants were told they could earn gift vouchers for taking part in a study that would involve using an iPhone application and was undertaken in collaboration with the CTD environmental campaign.
Our participants were randomly assigned to three groups - Control, Virtual and Financial - with 16 participants per group.
In all cases, participants were asked to record data on as many shop doors as possible while going about their everyday routines for a period of 2 weeks.
The Control group were advised that they would receive a 50 voucher in return for participation.
The Virtual group were also advised that they would receive a 50 voucher for participating in the study, but in addition that virtual points, badges and a leaderboard would be available to track their individual performance.
The Financial group were told that what they earned  would depend on how much they used the app relative to other participants.
They were told they would receive 2 per badge earned, plus a share of a fixed pot based on their relative performance on the leaderboard.
The size of the pot was set so that the total amount available to the participants was equivalent to 50 per head, i.e.
All the participants completed a preliminary online questionnaire to assess their attitude to environmental sustainability.
The Control app kept track of the points and badges that the participants would have earned from their behavior to allow for comparison between the three groups, but this information was not revealed to participants.
At the end of the two-week test period, a follow-up survey was sent to all participants to obtain an overview of their opinions on the app.
Finally, based on total points, two high, two mid-range, and two low scorers from each group were selected for a semi-structured interview.
This delved into further detail about app usage and motivational factors.
Ethical permission was granted by the University of Bristol Ethics Committee.
Overall, the three apps proved very successful in allowing us to map and monitor shops.
Over the two-week period, participants made 6674 individual recordings and added 1113 new shops to the CTD database.
As illustrated in Figure 2, this resulted in a detailed mapping of key shopping streets in the city center.
Table 1 shows the total points scored by participants, together with the number of new shops added and badges earned.
As can be seen, the Financial group achieved the highest points totals, with the Virtual group second and the Control group third.
Data quality was very high across all experimental conditions.
Using Google maps and local knowledge, we checked a random 10% of all added shops  across the three groups.
All but one was found to be accurate.
The remaining one was unverifiable, not necessarily wrong.
Figure 3 plots the points earned by participants in each group.
The behaviors within each group do not follow a normal distribution, so the non-parametric Kruskal-Wallis Test was carried out to test for differences between the groups.
The question took the form of a five-point Likert scale.
Past studies in environmental psychology have shown that an individual's general environmental attitude is not a guaranteed predictor of whether they will behave in a pro-environmental way .
For that reason, we calculated an environmental disposition score for each participant by summing their responses to the behavior questions only.
This provides a measure of their intrinsic motivation to engage in environmental activities.
The app was then distributed through Apple's TestFlight software, which relied on the participants to actively install the relevant CTD app on their iPhone, mimicking real-life deployment.
The study then ran for two weeks.
The effect size  between the Financial group and the Control and Virtual groups ranges from medium to very large.
Though there is no significant difference in performance of participants of the Virtual and Control groups, visual inspection of Figure 3 suggests a different distribution of performance in these groups.
The higher scorers in the Virtual group outperformed the Control, but the lower performers were comparable or lower than their Control equivalent.
This is reinforced by the observation that, although the mean point score in the Virtual group  is greater than that of the Control , the median of the Virtual  is less than that of the Control .
To investigate this further we plotted the Z-scores of all participants to test the relative comparative performance of individuals in each group .
Results show that that the Virtual and Financial groups followed a roughly similar trajectory, with the top three or four participants outperforming the others.
The Control group, with the exception of the highest scoring participant, follows a flatter trajectory showing a more even spread of behavior.
The highest-scoring participant from the Control group earned a score over three standard deviations from the mean and, per the extreme studentized deviate method, her result can be considered an outlier .
Overall the Z-scores suggest that competition, both in the Virtual and Financial groups, motivated the higher performers, but may have demotivated some of the middle performers.
This issue was investigated further our semistructured interviews.
It appears that the option of collecting badges did not have a significant effect on participants' behavior.
In fact, the Virtual group earned two fewer overall than the Control, despite the Control group being unaware of what they were earning.
Furthermore, it was predicted that a majority of the Financial participants would earn the full set of 15 badges, worth 30.00 in online vouchers.
The interviews helped elucidate the badge discrepancy; many participants reported being unaware of how to earn the badges despite prior instruction: "I wasn't really aware of when you would get a badge.
In addition to testing extrinsic motivational factors, our study was also designed to examine whether pre-existing environmental tendencies would function as an intrinsic motivator and influence app usage.
We therefore performed a correlation analysis within each group comparing participants' environmental disposition scores, from the initial questionnaire, and their point scores.
This is in line with previous studies .
Again, this finding is explored further in our qualitative study.
The results and analysis presented in this section are derived from the follow-up survey completed by all participants, and from semi-structured interviews with 18 participants, six from each group.
The interviews were audio recorded and transcribed.
We then undertook a thematic analysis .
The following sections address the key themes that emerged.
A vast majority of the participants felt that the app was intuitive and easy-to-use.
For example: "It was easy to use, only two taps on the screen were needed to report the status of a shop door."
Some participants expressed frustration at the GPS receiver not accurately locating their position.
This occasionally prevented them for rating a shop.
Overall, however, it is unlikely that basic usability issues impacted on the results of our study.
In considering the design of systems to target individual behavior change, Fogg emphasizes the importance of both motivation and ability .
A similar trend emerged in our thematic analysis.
Alongside motivational factors, enablers proved critical to participants' engagement.
As presented above, the Financial group gathered a significantly greater quantity of data/points, confirming that an extrinsic financial incentive tied to contribution served to motivate users far more than either the extrinsic motivation of leaderboard position or intrinsic motivation to contribute to an environmental activity.
However, the qualitative data suggested that this came with a cost.
Participants in both the Control and Virtual groups reported 100% agreement, when asked in the follow-up survey, whether they would be willing, without financial compensation, to continue using an app like CTD to help a community organization on an ongoing basis.
Quantitative results suggested that the participants near the top of the Virtual and Financial leaderboards were actively competing for the top position, and that this competitive aspect can provide extrinsic motivation to maintain engagement with the app.
The interviews backed this up, with some high scoring participants reporting feeling encouraged by competition, and indicating they were willing to use the app more than they would have otherwise: "The competition was an extra element that I wasn't expecting with the app ...
I would check it  even if I knew I wasn't going to go out that day to see if people were coming up near me, and if they were then I'd be like, `Right I've got to get on with it'."
Conversely, distant competition, for participants who were hundreds or thousands of points behind, had the opposite effect and served as a very clear demotivator.
One lowscoring participant described this, stating: "I gave up as I felt as though there was never a chance to catch the leaders.
When I saw that someone had stacked up hundreds of pounds all my motivation dissipated.
Games rely on positive feedback for the player to want to continue.
This de-motivated me massively so for me the game failed."
Several of the participants interviewed adopted "selfgamification" strategies, in which they set goals or challenged themselves to record more than previously.
Two high-scoring participants in particular exhibiting a tendency to self-gamify: "I think being kind of competitive with myself, like `Today I'll do a few more than I did yesterday, maybe I'll walk up that street because I've not been up there before so I don't know what's up there'."
This trend has also been found in previous research on eco-feedback technologies, such as smart meters, which are not explicitly gamified .
Whilst this issue was not specifically addressed by the app designs used in this study, it would be interesting to investigate how designs that encourage selfgamification can be used to motivate participants who find head-to-head competition to be demotivational.
For example, a participant felt the leaderboard "was an indication obviously on how much other people were using it and I wanted to make sure I was sort of in the middle or top half rather than the bottom end."
Overall, the simple pressure or desire to be seen as an active member of the community, by having an acceptable presence on the leaderboard, regardless of score, appeared to affect app usage: "It made me feel bad because I realized that people had used it more than I had ...
I felt guilty that I hadn't started using it so then I used it."
It is interesting to observe that this occurred even though the leaderboard in our study was anonymous and participants were not known to each other.
As shown in quantitative results section, environmental tendencies were not a guarantee of engagement or app use.
Furthermore, one participant informed us they had previously volunteered for the CTD campaign, yet was a low-scoring member of the Virtual group.
However, the topic of the app cannot be dismissed in its entirety as it can serve as a threshold motivator, encouraging people to engage initially.
Regardless of their final score, the idea that an easy-to-use mobile app allows a participant to make a small contribution of time and effort to support an environmental cause was cited by several participants as a positive element, and given as a reason for signing up in the first place.
As well as a source of potential competition, leaderboards can also provide feedback regarding the behavior of the community, and may therefore result in "norm activation" in participants, another source of extrinsic motivation.
We have some evidence of this occurring.
For example, activity on the leaderboard acted as a motivational trigger for a participant who initially delayed using the app: "I think it  probably did make me go, `Oh, okay, people have got started I should probably make sure that I make an effort to do it when I go out'.
Yes, that probably did give me a bit of a kick."
Despite the anonymous leaderboard, some participants also expressed a desire for what we can call "acceptable mediocrity", i.e.
Interviews suggest that participants' lifestyles played a significant role in this use of the app.
For some, their lifestyles acted as an enabler to active participation, while others' lifestyles reduced their opportunities for data collection.
A common factor shared by the highest scoring participants from each group was that they were not in regular employment during the testing period, and therefore could use the CTD app as and when they saw fit.
For example, the high-performing outlier in the Control group was on maternity leave: "... when I'm out with her she tends to sleep when I'm walking and it gives me something to do so I walked out of my way a lot of the time just to make sure I would catch as many shops as I could on the way."
Another expressed enthusiasm about the CTD app in terms of its purpose to reduce energy waste, but admitted: "I didn't have that many opportunities ... to go out to different places to have a look ... to go out to the different shops to try it".
Overall these responses reveal that while people may be intrinsically motivated in terms of supporting a cause, at the same time they can be "disabled" by the lack of opportunities to actually use the app.
Given this, organizations needing data collection on a compressed timescale may wish to seek out participants who are time rich, even if they do not seem to be part of a target motivational group.
The use of smartphones to collect data cannot be overlooked as a possible threshold motivator to initially attract participants.
Several participants mentioned that our recruitment advertisement specifically asking for iPhone users attracted their attention: "My partner works in IT anyway so I've got a soft spot for new bits and pieces and obviously I'm a bit of a MAC fan so it went together."
As previously mentioned, technology did serve as a disabler on occasions where the GPS receiver was not accurate, and prevented participants from recording data.
Some participants also expressed concerns that the app used their mobile data connection and might cause them to exceed their monthly data allowance.
Allowing the data to be stored and uploaded at a later time would avoid this problem, but it could also affect the pointified elements if the real-time nature of the leaderboard was influenced.
Further research is needed to determine whether this delay would have an impact on app engagement.
The CTD app was developed to investigate how a mobile app could be used to scale up the activities of a proenvironmental community activist group.
It did not seek to alter behavior or raise the participants' awareness of an environmental issue.
Nonetheless, there is evidence in the interviews that it did have some affect.
One-third of the 18 interviewees reported reading the CTD website as a direct result of taking part in the study.
These were spread among groups, but tended to be those who had a stronger environmental disposition in the initial questionnaire.
Furthermore, two participants claimed to have even changed their shopping habits to favor shops with doors closed: "Using the app made me much more aware of my surroundings as I walk around the city.
It has made me consider the environmental impact of choices I make when shopping.
I also find I am more inclined to visit a business whose door is closed!"
Whether this is a lasting, or even genuine, change is unknown.
However it does highlight another potential use of such data collection apps: as a way of drawing attention to the issue in a wider population and attracting more permanent volunteers to the organization.
Those who enjoy the app or have an interest in the subject may be willing to get further involved and take on additional responsibilities.
Based on the quantitative and qualitative results presented in the previous sections, we can make recommendations to researchers and organizations, such as CTD, wishing to exploit the potential of digital data collection.
Seek those whose lifestyle is likely to enable them to participate.
Use passion for a cause as a threshold motivator, but do not assume it acts as an engagement motivator.
The people in our study who were mobile but not "goal directed" in their mobility made the greatest contributions - the parent walking with a pram being our archetypal example.
Hence a good recruitment strategy for CTD would be to target online discussion boards for new parents, who are likely to have a lifestyle that would allow ongoing contribution, and use an environmental message as a threshold motivator to attract those with compatible intrinsic motivation to volunteer.
This is likely to be more effective than recruitment through an environmental forum, which may initially yield many enthusiastic volunteers who are motivated to cross the threshold to participation but then do little or no data recording due to lifestyles incompatible with ongoing contribution.
Make competition available, but easy to ignore.
It is clear that close competition among leaders is productive, but also clear that it demotivates those not in the leading group.
Wasting heating energy by leaving doors open in cold weather is the very raison d'etre of the CTD campaign.
However, the changing weather itself came up in the interviews as affecting a participant's ability to conduct the task.
Good weather acted as an enabler, encouraging people to spend more time outside and around the city.
However, there is also evidence that some participants avoided using the app if they felt a shop was justified in leaving a door open on an unusually warm day during the trial.
Cold and wet weather acted as a disabler.
This was due to one of four reasons:  the participant decided not to go out because of the weather;  the participant used a car or public transport instead of walking, precluding use of the app;  the participant did not want to get the phone wet; and  participants went out but were in a hurry due to the weather, so did not use the app.
This reliance on weather must be taken into account if an environmental data collection app is to be successful.
Some have weekly resets, ensuring that an existing player cannot build up a long-term, unassailable lead.
Additionally, we could envisage the use of `adaptive leaderboards' to provide competition when it is likely to be motivating.
Alternative approaches to doing this, and assessments of effectiveness, are areas for further research.
Provide information regarding `community norms' in a way which motivates desired behavior.
A number of interviewees were motivated by "doing their bit" as opposed to being top.
Based on this, it is perhaps as important to "normify" an app as it is to "gamify" it.
For example, providing the average amount of data collected by participants may encourage some to try to meet this figure, even if they cannot compete with the leader.
Recent research in the area of domestic energy reduction has also provided evidence to support this approach .
It is clear from the quantitative data that a "pay for results" approach is a powerful motivator and resulted in more data being collected.
However our interviews also suggested that it decreased participants' willingness to use the app in the future, with only 75% of Financial group participants expressing willingness in comparison with 100% of other participants.
Hence this short-term gain may be offset by a longer-term loss of engagement.
For that reason, it may be a better use of financial resources to adopt an approach combining a small payment as a threshold motivator  and funding prizes and rewards linked to both gamified and normified achievements.
Exploring the size, quantity and structure of alternative reward mechanisms and their impact on behavior is a fruitful area for future research.
Finally, we showed that intrinsic motivation to carry out environmental actions was not correlated with performance, identifying qualitative evidence that an appropriate lifestyle had a bigger impact.
Based on our findings, we made recommendations for organizations wishing to design and use mobile apps to support community activism.
Note that, though our trial participants were paid, all but the last of these recommendations apply equally to organizations recruiting unpaid volunteers.
As this paper is amongst the first to use both quantitative and qualitative techniques to explore motivators and enablers for pro-environmental data collection, there remain many topics for further research in addition to those addressed here.
Firstly, our trial was not long enough to explore how participants' behavior changes over time, so valuable work could be conducted to examine motivation over a longer time period and what can be done to support continued engagement.
Secondly, our participants were a priori unknown to each other and remained anonymous on our leaderboards.
As a result, we have not explored the motivating effect of competing with one's own social group, something that foursquare provides as an option.
Nor have we explored the effect of allowing teams of participants to compete together - something that the FoldIt citizen science game  has used to good effect.
Also, we have not investigated the effects of gamification approaches beyond simple pointification.
In particular, we believe the intrinsic pleasure of carrying out an enjoyable activity for its own sake is an important motivator, which our work has  not explored, due to our focus on simplicity in the app design.
Our qualitative results suggest that "self gamification" - allowing participants to set themselves challenges and compete against their prior performance - may act as a strong motivator for some participants.
Each of these areas warrants further exploration.
Finally, and perhaps most importantly, research is needed on effective design strategies to "close the loop" between casual volunteers and the "targets" of the community activist campaigns - in our case shop owners.
This could have several positive effects.
Firstly, by providing feedback to the participants on the ongoing effectiveness of the CTD campaign, such as newly signed-up shops or a measure of ongoing carbon emissions saved, intrinsic motivation may be increased as volunteers may gain a greater sense of contributing to a project with real impact.
Secondly, by providing data on local shops that keep doors shut, users could search for shops that support the CTD campaign and place pressure on retailers to change their behavior.
Finally, by providing data to the retail community, such as maps of local areas highlighting those shops who do maintain a doors-closed policy, retailers can see the spread of a community norm which is both environmentally and economically beneficial, potentially resulting in an increased speed of uptake of the norm.
Through ongoing research on these issues, digital technology may further contribute to the spread of pro-environmental behavior.
In this paper, through quantitative and qualitative approaches, we have assessed the impact of different motivating factors and design strategies on the performance of subjects collecting data for the CTD pro-environmental campaign.
In our trials a pay-per-results financial reward mechanism resulted in significantly increased data collection, though there is also evidence to suggest it may reduce long-term intrinsic motivation to participate in such activities.
We also found that pointification increased performance, though not to a statistically significant level.
Our analysis suggested that this was because close competition acted as an effective motivator of those who were high ranking, resulting in their increased performance relative to the Control group.
However, this effect was to some extent offset by reduced performance of lower ranking participants because of the demotivating effect of distant competition.
Gustafsson, A., Bang, M. & Svahn, M. Power explorer: a casual game style for encouraging long term behavior change among teenagers.
Hand, E. Volunteer army catches interstellar dust grains.
He, H.A., Greenberg, S. & Huang, E.M. One size does not fit all: applying the transtheoretical model to energy feedback technology design.
Analysis and synthesis of research on environmental behavior.
Conference on Theory and Practice of Electronic Governance 2007, 72-80.
Maisonneuve, N., Stevens, M., Neilssen, M., Hanappe, P. & Steels, L. Citizen noise pollution monitoring.
International Conference on Digital Government Research 2009, 96-103.
Malone, T. Heuristics for designing enjoyable user interfaces: Lessons from computer games.
Mankoff, J., Matthews, D., Fussell, R. & Johnson, M. Leveraging social networks to motivate individuals to reduce their ecological footprints.
Mason, W. & Watts, D. Financial incentives and the "performance of crowds".
Nolan, J., Schultz, P., Cialdini, R., Goldstein, N. & Griskevicius, V. Normative social influence is underdetected.
Citizen Science: Enabling Participatory Urbanism.
In Handbook of Research on Urban Informatics: The Practice and Promise of the Real-time City, M. Foth, editor .
Rotman, D., Preece, J., Hammock, J., Procita, K., Hansen, D., Parr, C., Lewis, D. & Jacobs, D. Dynamic changes in motivation in collaborative citizen-science projects.
Studley, M., Chambers, S., Rettie, R. & Burchell, K. Gathering and presenting social feedback to change domestic electricity consumption.
Workshop on Persuasion, Influence, Nudge & Coercion Through Mobile Devices 2011.
Sustainable Consumption Roundtable, "I will if you will": towards sustainable consumption.
2006, Sustainable Development Commission & National Consumer Council.
Wiegel, R.H. Environmental attitudes and the prediction of a behavior, in Environmental Psychology, N.R.
Zichermann, G. & Cunningham, C. Gamification by Design: Implementing Game Mechanics in Web and Mobile Apps.
