Real-time transcription generated by automated speech recognition  technologies with a reasonably high accuracy has been demonstrated to be valuable in facilitating non-native speakers' comprehension in real-time communication.
Besides errors, time delay often exists due to technical problems in automated transcription as well.
This study focuses on how the time delay of transcription impacts non-native speakers' comprehension performance and user experience.
The experiment design simulated a one-way computer-mediated communication scenario, where comprehension performance and user experiences in 3 transcription conditions  were compared.
The results showed that the participants can benefit from the transcription with a 2-second time delay, as their comprehension performance in this condition was improved compared with the no-transcript condition.
However, the transcription presented with delay was found to have negative effects on user experience.
In the final part of the paper, implications for further system development and design are discussed.
Globalization is driving more and more people to communicate using their non-native language via audio/video conferences.
However, as studies have indicated, understanding the speech of a second language often poses many difficulties .
Thus, non-native speakers frequently find it difficult to follow the conference and the collaboration tends to be ineffective.
Their results indicated that when synchronized with the audio stream, the automated transcripts with a word error rate  of 10% could significantly improve nonnative speakers' comprehension, while transcripts with a WER greater than 20% would lead to no improvement in comprehension.
Unfortunately, in addition to recognition errors, time delay often exists in automated transcripts as well.
The delay primarily results from the processing time the ASR system takes.
Even using the most advance speech recognition technology, the ASR processing can still be behind the audio stream for complex recognition tasks or low-quality signals.
For a distributed ASR service hosting system like the one described in , the ASR processing will slow down when many concurrent users request the ASR service at the same time.
The network delay for data transmission between the speech recognition client, server, and text showing interface also contributes to the overall delay.
This study will investigate how time delay affects the usefulness of automated transcription in improving non-native speakers' comprehension in real-time communication.
Most previous studies on the effects of transcription delay have focused on helping people with hearing impairment to better understand audio or video contents .
They reported that both enjoyment and intelligibility diminished when the delay existed, and the permissible limit for delay varied from 1.63 to 4.84 seconds depending on the degree of hearing impairment and caption formats.
While these findings provided valuable insights into how time delay affects the usefulness of transcription, none of them touched upon using automated transcription to improve non-native speakers' comprehension.
Furthermore, as non-native speakers need extra cognitive efforts to process the transcripts in a second language as one additional source of information, the delay could distract attention and result in little value of transcripts.
In this paper, we report an experiment that examines the effects of time delay of transcription on non-native speakers' comprehension performance and user experience, in which two research questions are addressed:  Does automated transcription still help non-native speakers' comprehension in computer-medicated communication when a reasonable level of time delay exists in the transcripts?
How does the time delay of transcription affect non-native sparkers' user experience?
Before the main experiment, we did a preliminary study to find out a time delay level worth being studied more thoroughly.
We started from 2 seconds and 4 seconds, which, according to previous studies , might be a critical level of time delay for the transcription to be usefully and acceptable.
Transcription delay of the two groups was set as 2 seconds and 4 seconds respectively.
After each clip was played, the participants were asked to answer 5 comprehension questions to evaluate how well they understood the materials.
The results showed that when delay was 4 seconds, the transcripts did not help the comprehension.
The comprehension score of using the delayed transcripts was even worse than that when no transcript was displayed.
All participants reported that they felt really frustrated by the delay and preferred to just ignoring the transcripts.
In contrast, when the transcription delay was 2 seconds, the comprehension performance was improved compared to the no transcript condition, though some of the participants still reported that the delayed transcripts were somewhat distracting.
Thus, in the formal experiment, we will use 2 seconds delay to confirm the usefulness of delayed transcripts.
Similar to , we designed a one-way computer-mediated communication  scenario, in which native English speakers talked in English via an audio and video channel, and native Chinese "listeners"  tried to understand what was spoken.
Though communication in this study was dominated by one or a few main speakers and others just listen, the findings or conclusions were believed to serve as a useful reference for future research on more interactive scenarios.
Figure 1 showed an example of the interface developed for the experiment.
Transcripts were displayed in a streaming mode, appearing letter by letter from bottom left to right.
This display mode is necessary in real-time scenarios as the speakers' words cannot be foreseen before being spoken.
The formal experiment was designed as a within-subject study in which participants were exposed to three different Transcription Conditions:  NT: No transcript was displayed .
DT: Transcripts with 2 seconds' delay were displayed.
No error was included in the transcripts.
D-ET: Transcripts with 2 seconds' delay and 10% WER were displayed.
This condition was to examine if automated transcripts with errors could help when they were not synchronized with the audio stream.
The 10% WER level was selected because it was the best accuracy that could be achieved in practice  and thus might serve as the benchmark for the most tolerable level of time delay.
Thirty highly motivated university or graduate school students from various disciplines were recruited as participants.
They were non-English major native Chinese speakers and had passed CET-6 , a national English test which is mandatory for all Chinese students if they are to get a master's degree.
A curious observation, however, is that though CET-6 indicates a relatively high level of English proficiency of Chinese students, there is no guarantee that those who have passed the test can understand spoken English conversations well.
Six English video clips were created, 2 for each transcription condition .
3 clips were dialogues cut from an English TV show, and the other 3 were lectures recorded with invited foreigners as speakers.
5 comprehension questions were designed for each clip, including both short-answer questions and multiple-choice questions.
All the materials had been validated in our previous research and their difficulty level was appropriate for the Chinese participants .
The whole experiment was computer-based.
A Latin square design was implemented to counterbalance order effects.
Each participant was asked to watch the 6 clips.
After each clip was played, the screen turned to the question-answer page immediately and no transcript could be seen any more.
After finishing the comprehension test in each Transcription Condition, the participants were asked to complete a follow-up questionnaire on user satisfaction and cognitive load.
The whole procedure of the experiment took about 60 minutes on average.
Performance was measured by response accuracy, that is, how many comprehension questions were answered correctly.
A perfect score in each condition was 10 .
User experience was assessed by user satisfaction and user cognitive load.
Participants were required to respond to three satisfaction evaluation questions on a 5-point Likert scale.
The three questions were:  Usefulness: "I think transcription is helpful for my understanding."
Cognitive Load investigated how well human resources could be employed in task completion or problem solving.
Three indicators were used:  Perception of task difficulty.
The participants assessed the difficulty of answering the questions by indicating their agreement with the following statements on a 5-point Likert scale: "It was difficult for me to correctly answer the comprehension questions" and "I fully understood what the clips talked about."
Perception of concentration difficulty measured how well one can focus their cognitive resources on the task by asking the participants to respond to the following statement: "It was difficult for me to concentrate my attention simultaneously on the information from all sources  ."
The participants assessed how the time delay of the transcription might interfere with their understanding by indicating their agreement with the following statements on a 5-point Likert scale: "The time delay of transcripts distracted my attention" and "The time delay of transcripts hindered my understanding of video clips"
The comprehension performance scores in different conditions were shown in Figure 2.
A repeated measures ANOVA was used to analyze the data.
The results showed that Transcription Condition had a significant main effect on performance, F  = 7.27, p < .01, indicating that comprehension was indeed influenced by the transcription condition.
To further explore the difference between the comprehension performance in NT, DT, and D-ET, multiple comparisons were performed.
Performance in DT was a little better than that in D-ET , but the difference did not reach a significant level .
These results suggested the usefulness of automated transcription when the time delay is less than 2 seconds.
The user-reported satisfaction scores for DT and D-ET condition were shown in Figure 3.
The participants confirmed the usefulness of the delayed transcripts , while the importance and preference scores were nearly neutral.
Cognitive load scores were presented in Table 1 in three dimensions.
With regard to the perception of concentration difficulty and understanding interference, the results suggested a negative impact in general.
The majority of the participants  agreed or strongly agreed that it was difficult to concentrate their attention simultaneously on the information from all sources .
In addition, over half of the participants  agreed or strongly agreed that the time delay of the transcripts would interfere with their understanding .
In this paper, we investigated how time delay in automated transcription produced by a speech recognition system affects non-native speakers' comprehension and user experience.
The results demonstrated the value of delayed transcription in improving non-native speakers' comprehension in one-way communication scenario.
When the time delay was 2 seconds, the participants' comprehension performance was significantly improved with the aid of the transcripts, and the users' self-reported satisfaction also confirmed the usefulness of the transcripts.
But the users' selfreported measures still showed some negative effects of time delay, e.g.
It seems somewhat surprising that while the non-native speakers' comprehension performance was factually improved by using the transcripts, they still reported some negative user feelings.
This can be explained from several aspects.
First, the task being simulating the passive one-way communication, instantaneous response on the part of the users was not required.
Thus, despite the time delay, the appearance of the transcripts provided a chance for gist extraction and therefore improves the comprehension .
Second, the users had to pay more attention and work harder when there was time delay in the transcripts.
The increased attention would result in better comprehension.
But paying more attention and working harder would be more stressful and decrease the satisfaction.
In summary, this study demonstrates that automated transcription in a good accuracy and with a reasonable level of delay  can significantly improve non-native speakers' comprehension, though user experience evaluations are not all positive.
But since time delay would result in negative user experience, the system should ensure that important conferences can get sufficient computation resources and high quality network connection to avoid the delay.
Future work will investigate the effects of time delay in more interactive scenarios involved in remote collaborations.
In addition, finer levels of word error rate in automatically generated transcripts combined with delays should be studied, as WER in automated transcription could change within a broad range from 10% to over 30%.
Burnham, D., Robert-Ribes, J., and Ellison, R. Why captions have to be on time.
In: Proceedings of International Conference on Auditory-Visual Speech Processing , pp.
In: the 25th Annual International Technology & Persons with Disabilities Conference, .
Cognitive Experiments on Timing Lag for Superimposing Closed Captions.
In: Proceedings of the Sixth European Conference on Speech Communication and Technology, pp.
Effects of real-time transcription on nonnative speaker's comprehension in computer-mediated communications.
In: Proceedings of the 27th international conference on Human factors in computing systems, CHI 2009, pp.
Effects of automated transcription quality on non-native speakers' comprehension in real-time computer-mediated communication.
In Proceedings of the 28th international conference on Human factors in computing systems, CHI 2010, pp.
1725-1734, ACM Press  Tucker, S., Kyprianou, N., and Whittaker, S. Time-Compressing Speech: ASR Transcripts Are an Effective Way to Support Gist Extraction.
In: Proceedings of the 5th Joint Workshop on Machine Learning and Multimodal Interaction, pp.
The Effect of Background Knowledge on First and Second Language Comprehension Difficulty.
In: Proceedings of the 5th International Conference on Spoken Language Processing, .
Zekveld, A.A., Kramer, S.E., Kessens, J.M., Vlaming, M.S., and Houtgast, T. The influence of age, hearing, and working memory on the speech comprehension benefit derived from an automatic speech recognition system.
