Flicking is a common interaction technique to move objects across large interactive surfaces, but little is known about its suitability for use on non-planar, curved surfaces.
Flicking consists of two stages: First, visually determining the direction in which to flick the object, then planning and executing the corresponding gesture.
Errors in both stages could influence flicking accuracy.
We investigated flicking interactions on curved interactive surface to evaluate which type of error influences accuracy.
Therefore, we carried out three user studies to analyze how each stage of flicking on a curved surface is influenced.
This simulates the real-world throwing action that people use to move objects, e.g., a book, over a large distance on a table.
To flick a digital object on an interactive surface, the user performs a sliding gesture into the direction of the target, then lets go, and the object continues to move into the direction thus indicated.
In this paper, we are not interested in questions of velocity or how far the object travels, focusing instead on better understanding the direction of flicking gestures.
To conduct this gesture, a user has to first visually identify the spatial relation between source object intended target position, then create and execute a motor plan such that her sliding gesture points in the direction of the target.
This implies that flicking accuracy depends on how accurately the user can  identify the correct direction with her visual system and  create and execute the motor plan using her motor system.
Identifying the correct direction on a planar surface is not very complex, because the three-dimensional line between the source object and the target position lies directly on the surface on which the digital object will move.
Furthermore, the user can use the usually rectangular frame around the surface as a basic reference system.
This leads to the assumption that the accuracy of flicking gestures on planar surfaces depends mostly on the motoric ability to derive and execute the motor plan of the sliding gesture.
Prior research has proposed systems with multiple but discrete interactive horizontal and vertical surfaces, such as the DigiTable  or the WeSpace .
Moving objects around is a common action on large interactive tabletops and surfaces.
For this, users have to touch the object and drag it to its destination.
For long distances, this operation can become slow and awkward as the target position moves beyond the user's reach.
To improve the efficiency of these movements, several approaches have been proposed.
Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted.
To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
According to Weiss et al.
On a curved surface, in contrast to a normal planar tabletop, the shortest line between an object and its target position will span the 3D space between the surfaces unless object and target happen to be on the same planar display section.
The user has to map this direct 3D line onto the curved surface to identify the correct direction from the source object to the target position for flicking.
In this paper, we investigate how accurately users can conduct flicking gestures on curved surfaces, and how the visual perception and motor systems influence this accuracy.
Furthermore, we examine if there are any regularities that can be used to derive a model of this gesture, to define guidelines for implementing more accurate flicking gestures on curved surfaces.
In the following, we present three studies that investigate flicking accuracy in different setups.
The first study compares a system with horizontal and vertical displays connected via a continuous curve, to a system with vertical and horizontal surfaces separated by a gap , and to a system with both surfaces adjacent to each other but with a straight edge  between them.
The goal of this study is to analyze if the continuous curved connection has any effect on visual perception on the accuracy of the visual planning stage of a flicking gesture, even though the curve is only on the intended trajectory without being involved directly in the interaction.
The second study compares the accuracy of flicking gestures from different areas, and in different directions, on a curved surface.
Its goal is to derive a mathematical model to help estimate and thus correct systematic errors users may make when flicking across a curve.
The third and final study analyzes the impact of where the curve lies along the flicking trajectory , to derive recommendations for when and where to use flicking gestures on curved surfaces.
In 1994, Sun's seminal Starfire video prototype  already proposed a single, curved horizontal and vertical interactive display surface for use in the office.
More recent research has followed through on this idea, merging those two orthogonal surfaces with a curved area .
Three benefits arose from these such curved surfaces:  Users are able to sit while interacting, allowing long-term usage.
These findings, combined with recent developments in bendable organic light-emitting diodes  and touch sensing technology suggest that curved surfaces could replace the traditional desktop computer workspace as envisioned by Tognazzini's Starfire .
Air traffic controller workstations, with their frequent combination of horizontal and vertical interactive screens, are another example of a likely candidate for adopting curved displays.
Interaction with nonplanar surfaces has, consequently, recently become a topic of interest in HCI.
This makes studying the basic interaction techniques for curved surfaces, and the mental models that users develop when using them, relevant to the CHI community.
The DigitalDesk  introduced one of the first interactive tabletop workspaces.
The Sun Starfire vision video  envisioned a much larger desk consisting of horizontal and vertical areas merged into one curved interactive surface.
In contrast to a purely horizontal surface, Starfire's curved surface mimicked a typical office workplace with its horizontal table and vertical computer display.
This provided users with the ability to choose which surface they wanted to use for which task, and Starfire included the suggestion of a flicking gesture to move objects.
In recent years, this concept of a curved surface as a desk workspace was picked up by Weiss et al.
On all of these systems, moving digital objects around is one of the most frequent interaction techniques.
Over the last years several techniques have been proposed as alternatives to dragging.
They divide into two groups of movement control mechanisms, closedloop and open-loop.
Closed-loop control techniques, such as dragging, provide the user with continuous real-time feedback, allowing them to correct their movement as they approach the target.
Through this real-time correction, these types of movement control mechanisms are very accurate.
However, they also force the user to pay attention to movement action until the action is completed.
Dragging in particular can become cumbersome or physically impossible if it extends beyond the user's natural reach.
This may require the user to reposition herself, potentially dropping and re-grabbing the object in the process, paying attention to avoid triggering unintended effects at the intermediate drop location.
Combining vertical and horizontal surfaces is not new.
In fact, a desktop computer workspace consists of a combination of both surfaces: an interactive vertical display and a horizontal table.
Nevertheless, providing both surfaces in a disconnected manner causes users to quickly lose awareness of surface not in focus .
Open-loop control techniques, such as Drag-and-Throw  or Shuffle , let the user define the direction in which the object should move at the beginning of the action.
Once the automatic part of the movement was initiated, they do not provide the user with opportunities for interaction, so they cannot be corrected anymore.
This leads to the problem that open-loop techniques are less accurate than closed-loop techniques.
However, the user does not have to focus on the moving object during its automatic movement, until it arrives at the target position.
Most open-loop techniques also allow the user to move objects to positions beyond their reach.
Flicking is one of the most common open-loop techniques.
It is fairly natural, like moving a physical object across a large surface by pushing or flicking it in the designated direction.
On interactive surfaces, flicking is usually executed with one finger or the entire hand .
Hinrichs and Carpendale  showed that even users that had never used an interactive tabletop readily used this gesture to move digital objects.
To simulate the flicking of a physical object more realistically, Sato et al.
However, none of the above approaches investigated flicking gestures in more detail, or evaluated its accuracy.
This was only studied for flicking gestures using a pen or mouse.
They proposed a new gesture called Superflick that allows users to control the direction while the object is moving.
Adding this online correction to flicking gestures significantly improved their accuracy.
Another study by Moyle and Cockburn  compared linear mouse and pen flicking gestures, and found mouse flicking to be more accurate.
They also showed that downwards flicking gestures where conducted more slowly than those pointing upwards.
The vertical surface was placed at the same distance to the user as in the other conditions.
In this setup, the depth of the horizontal surface was 50 cm, and the height of the vertical surface was 55 cm.
As in the separated display condition, the top pixel line of the horizontal surface was directly connected to the bottom pixel line of the vertical surface.
Participants were seated in front of the table, in a dimly lit room for best infrared tracking results.
They worked throughout three different flicking studies.
Each study was introduced by a standardized instruction and a practice trial to familiarize participants with the task.
The study order was randomized for each user so that no study could benefit from learning effects.
The goal of each study was to flick a digital source object onto a digital target using the index finger of the dominant hand.
To conduct the flicking gesture, participants had to put their index finger onto the digital source object, and slide their finger along the surface in the direction in which they wanted to flick the object.
After executing the flick gesture, the source object moved in the computed direction at constant speed until it hit the surface boundaries.
Then the interactive start area went blank, and a new trial appeared.
Participants were instructed to solve each task as fast and accurately as possible.
To measure the direction, we recorded all touch points of the user's sliding movement, and computed a direction vector with a first-degree Least Squares regression.
This method to determine the direction was also used by Reetz et al.
They analyzed several approaches to computing the direction, and found that firstdegree Least Squares regression was closest to users' expectations.
To estimate gesture accuracy, we used the flicking error as a dependent variable.
For our experiments, we used an interactive curved-surface tabletop with the same specifications as the BendDesk system by Weiss et al.
However, we used four instead of three identical infrared cameras to improve finger tracking robustness.
All cameras operated at the same resolution of 640x480 px and framerate of 60 fps.
For the first user study comparing the effect of the curve on perception, we had to adapt this setup.
This provided users with the impression that the horizontal and vertical surfaces were two separated displays.
Furthermore, we disabled the projection in the curved surface such that the top line of pixels on the horizontal surface beneath the gap was vertically directly connected to the bottom line of the vertical surface above the gap.
This first study investigated if the continuity of a curved surface has any effect on flicking accuracy, even if neither the source object nor the target lie inside the curve segment.
Of these, 15 were computer scientists, 2 business administration managers, 4 school teachers, 2 medical scientists, and 1 mechanical engineer.
All participants had normal or corrected-to-normal vision.
21 out of 24 participants were right-handed.
The experimental task and the conditions are depicted in figure 4.
The system displayed the source object as a blue dot  and the target as a red circle .
This distance resulted from the current position of the source and target as illustrated in figure 4.
Therefore, the distance on the surface between source and target was different for each table condition, being smallest in the Gap condition and largest in the Edge condition.
Source and target appeared in 3 different positions on the surface.
For upward flicking movements , the source appeared within the horizontal area either 10 cm from the left edge, in the center, or 10 cm from the right edge, while the target appeared within the vertical area, again 10 cm from the left edge, centered, or 10 cm from the right edge.
Downward movements were tested analogously.
This resulted in 9 different tasks presented, with 3 repetitions for each movement direction.
Participants were randomly assigned to one of the table types .
They worked through a trial block with upward movements  and through another block with downward movements .
The experiment lasted about 5 minutes.
The experimental design was a 3  x 2  mixed design with repeated measurements.
Additionally, we wanted to explore if the smoothly curved surface would be of further benefit for flicking compared to the Edge condition with orthogonal planes.
H2a: If users take the active arm as a reference line , then flicking downwards should be more accurate than flicking upwards.
H2b: If users visually represent the task by a virtual line , then flicking downwards should be less accurate than flicking upwards.
This was assumed because for downward movements, the effector will block a part of the interface from view.
We also looked for differences between the two continuous surface conditions Curve and Edge.
We did not find any further facilitation of operations for the Curve condition.
However, 7 of 8 users in the Edge conditions stated that they needed more time to plan their flicking gesture, because they tried to identify a point on the edge between the horizontal and vertical surfaces as a reference point to determine the direction to the target.
Probably, the disadvantage of edge surface was compensated through a more extensive movement planning.
It could be presumed that poorer accuracy in edge surfaces would be observed, if the planning time would have been kept equal across different surfaces.
Time required for movement planning, which indicates the demand on the cognitive system, will be taken into account in future works.
Considering the direction, we assumed that users plan the action either with reference to internal coordinates  or with reference to distal coordinates .
We found that flicking upwards was more accurate than downwards.
This is in line with the alternative hypothesis .
It seems beneficial to have a full view of the surface when planning and executing the flicking action, especially when interacting with a disrupted surface.
Flicking errors were most present for the Gap condition  and decreased for the Curve and Edge conditions .
Furthermore, upward flicking was more accurate than downward flicking .
In summary, when comparing table types with a continuous versus separated surface , the results clearly showed more accurate flicking actions for the continuous surfaces than for the separated one.
This is in accordance with H1.
This clearly shows that flicking accuracy depends on the user's visual perception and on the ability to visually identify the spatial relations between the source and the target.
If flicking accuracy would only depend on the user's motor system, there would be no difference between the continuous table conditions and the separated table condition.
It also shows that a continuous surface improves the user's ability to identify the correct flicking direction to hit the target.
This could be explained by the fact that in contrast to the continuous surfaces, in the separated table condition, users have to develop a mental model of how both surfaces are connected, which is difficult for surfaces with different orientations as in our setup.
Figure 6 depicts the experimental task and conditions.
The system again displayed the source as a blue colored dot  and the target as a red colored circle .
In contrast to the first study, the distance between source and target was measured as the distance on the surface between these two points, and was 29 cm  for all conditions.
Participants worked through a block of trials with upward movements and through another block with downward movements.
This resulted in 252 trials total.
The order of trials per source position was randomized.
We used a 3  x 2  x 7  design with repeated measurements.
The experiment lasted about 15 minutes.
We assumed that a larger flicking angle would yield a lower flicking performance, especially within the curve: H3: The flicking error is smaller for flicking within the horizontal area than within the vertical area or the curve.
Furthermore, flicking upwards was more accurate than flicking downwards .
There was a trend that flicking within the horizontal area was more accurate than flicking in the curve or within the vertical area .
When flicking downwards, actions were most inaccurate at 0 , irrespective of the interaction area.
For upward flicking, this inaccuracy was only observed for interactions within the curve, but not for actions within the horizontal or vertical area.
There are two main findings from this study: First, we successfully replicated the impact of flicking direction that was observed in study 1: flicking upwards was more accurate than flicking downwards .
The impact of the interaction area was only partially confirmed.
Second, and completely contrary to our hypothesis, we did not find an increase of flicking errors with increasing flicking angle .
This result is quite surprising and in contrast to findings from dragging actions.
However, in our general discussion we will discuss the potential responsibility of motor constraints for this outcome.
Flicking was more accurate when the source was positioned farther away from the curve center than when it was directly at the curve .
The impact of flicking angle was more pronounced for start positions near the curve than farther away, yielding a significant interaction  = 4.11; p = 0.006.
The factor "start position and sideways direction" further showed flicking operations were most accurate when the source was positioned to the right side, with flicking to the left , and least accurate when the source was centered, with flicking to the right .
The three-way interaction  = 3.04; p = 0.001 showed an impact of flicking angle for all start positions and sideways directions, except when the source was on the right side.
This was the most accurate condition, and the impact of angle nearly diminished.
Finally, we found a significant performance decrease for flicking actions that originated near the curved area .
This finding supports our assumption that the curved surface induces a perceptional bias.
It seems that its impact decreases the farther away the action takes place.
Furthermore, we successfully replicated the impact of flicking angle observed in study 2 .
For all source positions we found very inaccurate flicking actions at 0 , except for the source positions on the right side.
Here, flicking was most accurate, and flicking angle had almost no effect on performance.
Please note, that in our study all participants were right-handed.
Thus, when the source was in the right position flicking performance was most accurate compared to the center or left position of the source.
We conclude that for right-handed users a spatial alignment between dominant hand and source facilitates motor control, while all other source positions required somewhat awkward postures of the moving limb and therefore restricted motor control.
Consequently, left-handed users should feel most comfortable and be most effective when the source is in the left position.
This will be addressed in future studies.
Figure 8 depicts the experimental task and conditions.
The system again displayed the source as a blue colored dot  and the target as a red colored circle .
The distance between source and target was 368 px .
Participants worked through a block of trials with the start position near the curve, then through another block with the start position farther away from the curve.
This resulted in 120 trials total.
Order of trials per source position and order of source positions were randomized.
The study is based on a 2  x 4  x 5  design with repeated measurements.
The study lasted about 10 minutes.
We hypothesized the following outcomes: H6: The flicking error increases if the source position is closer to the curve.
H7: The flicking error is higher at 0 than when flicking sideways .
As described previously, a flicking gesture consists of two different stages: a visual planing stage, in which the user has to determine the spatial relation between the source and the target, and a motoric execution stage in which she executes a sliding gesture in the previously determined direction towards the target.
Errors that influence flicking accuracy can appear in both of these stages.
To improve flicking on curved surfaces, we first have to understand how, where and which errors can appear, and how they affect the flicking gesture.
The visual planing stage can be biased through contextual factors so that perception errors occur.
Previous psychological research has demonstrated various perceptual illusions that impact visual planning performance.
These examples indicate that the shape of an interactive tabletop could be such a contextual factor leading to an error that influences the visual planning phase.
We assume that this error is extremely strong in the separated "Gap" table condition of the first user study, leading to the larger flicking error that we observed compared to the continuous conditions.
Another of these contextual factors could be the curved area.
This would explain the different flicking error rates in the third user study, in which only the distance between the source object and the center of the curved area changed.
In contrast to the visual planning state, the inaccuracy of the motoric execution stage is less context-specific, and manifests itself primarily in movement execution.
The major source of motor inaccuracy is the motor noise originating from noise in the nervous system, which is responsible for controlling the movement apparatus .
The magnitude of motor noise has been proven to be a function of the number of involved joints in an action and the resolution of the involved joints per se.
Previous studies have demonstrated differences in performance between the muscle groups controlling the various upper limb joints.
For instance, the hand was proven to be superior to the forearm , and evidence was found that the fingers may possess a higher resolution than the wrist or forearm .
As predicted by Fitts' Law, the movement time turned out to be a function of increasing ID.
However, the slope of the function differed remarkably between finger, wrist, and whole arm.
If the reciprocal of the slope was supposed to infer the information-processing capacity of the motor system, then the fingers showed a much higher information-processing rate  than the hand  and the arm .
The results of the second user study showed a tendential main effect of the area.
Movements within the horizontal area turned out to be more precise than movements executed in the curve, while the most difficult movements were those in the vertical area.
This finding matches the results of Langolf et al.
The working areas were at different distances to the user's body.
When the working area was within the horizontal area, the arm was bent and relaxed in front of the chest, and flicking could be carried out by simply moving the index finger.
In contrast, if the working area was in the vertical area, the arm was stretched out straight.
In order to accomplish the same action, movement of the whole arm, including all upper limb joints  had to be coordinated.
Therefore, we assume that the effect of different flicking accuracies on different areas of the curved surface is an error in the motor execution phase.
Additionally, we observed a similar error in the third user study that follows the same pattern described in .
Note, that in this study all users were right-handed.
The results showed that the most accurate flicking gestures were made from the right position, which is the closest position to the right arm.
In this condition, users could leave their arm in a very comfortable position, and could use only finger movement to conduct the flicking gesture.
In contrast to that, in the other conditions of the test, users had to conduct a more complex movement that involved the entire hand.
Consequently, we assume an opposite pattern of results for lefthanded users.
This has to be proved in future studies.
Another effect that we observed was that, independent of the source position, flicking gestures directly upwards or downwards  showed the largest error.
This is in direct contrast to the findings that were made by Weiss et.
They showed that hitting objects that are placed directly above or below was highly accurate, in contrast to other target positions.
These differences can only be explained by a motor error of the flicking gesture, because according to their study, users can identify the correct direction to these targets very well.
That most users had significant problems with this flicking direction can be explained by the way they executed this gesture.
In the second posture, users placed their hand lateral to the source object, and moved only their finger.
These issues do not occur when simply tapping with two fingers to define a direction, explaining the different results from  mentioned above.
To explain the relationship between the flicking angle and the flicking error, we developed a first rough mathematical model from the data acquired at the center position of the third user study.
In this model, we redefined the flicking error as a signed angle.
The negative values means error to the right.
Therefore, we have nine angles .
The angular error are shown in Figure 11.
We approximated these results with the following sinusoidal function: a + b x sinus.
Although this function is only a very rough approximation of the results and can only be used to give a hint about the flicking error by flicking angle, it shows that flicking can be described by a mathematical function.
This paper investigated flicking gestures on curved surfaces.
Flicking is a common and simple gesture that lets users move digital objects across large interactive surfaces.
Its accuracy can be influenced by two types of errors: an error in the visual identification of the spatial relation between the source object and the target object, and an motor error in the planning and execution of the gesture.
We presented three studies analyzing flicking accuracy on curved interactive surfaces, and for each condition identified which error types influenced accuracy.
Table 1 summarizes our results and suggests from what factors the effects appear to originate.
This is a first attempt to systematically explore empirical findings for this technique, to make the results more digestible for practical purposes,
We are only beginning to understand how users interact with curved surfaces as a new class of devices.
Even studying a basic gesture such as flicking in depth has shown that our methodical understanding of this interaction is still in its infancy.
Our initial mathematical model for angle-specific systematic errors is a first approximation; such a model would enable us to correct these systematic errors and improve flicking accuracy, but the observed data exhibits higher-frequency patterns that warrant further study, to improve the predictive power of our initial model and its usefulness as a design tool.
The errors that occur in the motor stage also require further analysis, by focusing on hand movement during gesture execution.
Furthermore, cognitive load caused by movement planing could also be used as relevant criterion beside accuracy in order to characterize flicking movements.
Finally, we intend to create mathematical model of how flicking works on the various areas of curved surfaces.
