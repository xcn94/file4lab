Motion-capture-based biomechanical simulation is a noninvasive analysis method that yields a rich description of posture, joint, and muscle activity in human movement.
The method is presently gaining ground in sports, medicine, and industrial ergonomics, but it also bears great potential for studies in HCI where the physical ergonomics of a design is important.
To make the method more broadly accessible, we study its predictive validity for movements and users typical to studies in HCI.
We discuss the sources of error in biomechanical simulation and present results from two validation studies conducted with a state-of-the-art system.
Study I tested aimed movements ranging from multitouch gestures to dancing, finding out that the critical limiting factor is the size of movement.
Study II compared muscle activation predictions to surface-EMG recordings in a 3D pointing task.
The data shows medium-to-high validity that is, however, constrained by some characteristics of the movement and the user.
We draw concrete recommendations to practitioners and discuss challenges to developing the method further.
Mocap-based biomechanical simulation is becoming an option for HCI laboratories as well.
The computational intensity is no longer a bottleneck and there is biomechanical simulation software available with human body models.1 Moreover, optical motion capture equipment2 matured and became affordable in the recent past.
Modern marker-based systems track rigid points on the body with high precision and sampling rates.
However, to our knowledge, mocap-based biomechanical simulation is presently not deployed in HCI research.
The method could allow cost-efficient estimation of physical ergonomics.
In contrast, the standard ergonomics instruments have turned out to be too expensive, constraining, and specialized to be routinely used in HCI.3 The mocap-based method studied in this paper does not restrict natural movement .
This makes it possible to study full-body interactions where EMG recordings and other measurements are impractical.
Although work-related injuries and incidents have declined , the method could improve the analysis of user interfaces by better taking into account biomechanical stresses and muscle loads.
Designs with cumbersome postures could be avoided, such as the "gorilla arm" when using vertical touch screens.
Many times in the history of interaction design, this would have been of benefit.
Consider the fate of the light pen: Touted as the ideal input device for information workers, it foundered as it caused strain in shoulder and arm muscles.
We believe that the method bears even more potential in the design of novel interfaces.
While the ergonomics of desktop-based interfaces have been intensively studied , interactions "beyond the desktop" need more attention.
For example, tangible computing, tabletops and surfaces, mobile interaction, and various forms of 3D interaction all insist on novel postures and movement types for input.
Such interactions can be too demanding for long-term use, or they can be too easy as in the case of exergames.
Understanding the physical ergonomics of full-body motion is an important part of designing such interfaces.
Furthermore, the performance data from the captured movements and the ergonomics data from the biomechanical simulation can be analyzed in a combined manner to find good trade-offs between them.
Motion-capture-based biomechanical simulation is a combination of optical motion capture  to record the 3D movements of the human body and the simulation of the biomechanics involved with those movements.
The output of optical motion capture is the 3D motion of pointlights, from which performance measures such as speed or accuracy can be derived.
Biomechanical simulation augments this with a rich description of human movement, including velocities and angles of limb segments, forces and moments at joints, and most importantly muscle activations .
Copyrights for components of this work owned by others than ACM must be honored.
Abstracting with credit is permitted.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Such instrumentations can restrict the natural movement, narrow the scope too much, and are generally too time-consuming for regular HCI studies.
For HCI, we insist that the method should be usable without extensive manual modeling, and the scope of biomechanical simulation should be decidable a posteriori.
The contribution of this paper is two-fold.
First,this is the first work applying and validating a state-of-the-art biomechanical model with muscles for HCI tasks.
Second, in broader context, this is the first validation of muscle activation predictions of a state-of-the-art model for whole-arm movements in all directions.
Two studies are presented that assess the method both technically and against ground truth measurements in typical HCI tasks.
As it is impossible to cover all HCI tasks, we carefully selected a broad yet representative set with diverse requirements.
Study I assesses technical feasibility in five scenarios: a full-body dance game, full-body flight simulator controls, mouse pointing, multitouch gestures, and typing on a keyboard.
Our focus is on the technical feasibility, that is, whether the simulation can yield reliable outcomes for such diverse tasks.
Moreover, the inspection of mouse and keyboard allows us to compare our predictions to previous work where EMG was used.
Study II presents a 3D inair pointing task with 16 subjects and directly compares the muscle activation predictions from the biomechanical simulation against measured ground truth data obtained using surface EMG.
Our focus is on the predictive value of muscle activation predictions.
The experimental design allows us to gauge inter-subject differences, differences between muscles, as well as to compare against self-reports of fatigue.
This paper critically examines the validity of the method for the needs of HCI, which are different from sports, medicine, and industrial ergonomics.
First, in medicine and sports, biomechanical simulation is mostly used with the purpose of deeply understanding one particular subject or a special group.
In contrast, HCI research must be able to address large samples with varying age groups and other characteristics.
Second, typical analyses in sports and medicine focus on a particular muscle or muscle group, tendon, or joint, such as the knee moment during jumping or landing.
In contrast, HCI research is hardly interested in anatomical details, but in the effects of motion: uncomfortable postures, stress, load, and fatigue.
It is clear that muscles have special importance in HCI.
Third, movements in sports and medicine are often gross and, in the case of athletes, very fast.
In contrast, HCI focuses on middle- and small-range movements, such as those involving the hand when using input devices.
Fourth, sports and medicine are often interested in the lower limbs and analyze gait.
In contrast, both industrial ergonomics and HCI tend to have more emphasis on upper extremities.
Fifth, industrial ergonomics and HCI have interest in aimed movements to external targets.
However, whereas industrial ergonomics has looked at movements to physical objects , setups in HCI often involve dynamic displays and dynamic contact forces on surfaces.
Such forces are not directly observable using motion capture, but must be recorded with external instruments and integrated into the simulation.
Due to the novelty of mocap-based biomechanical simulation, it has not yet been extensively validated.
Validity here refers to the accuracy of the biomechanical simulation results when compared to ground truth.
Because the other outcomes of biomechanical simulation are better known, we focus on the validity of muscle-related predictions in user groups and movements that are characteristic to HCI.
As we will show, every step of the method pipeline  has different sources of error, which can accumulate.
It is not known from previous work whether these errors pose severe problems for HCI studies.
What is known from previous work is that the current biomechanical models cannot be considered as "valid in general," but they have to be validated for each application or task .
These concerns call for rigorous research to assess validity in HCI tasks.
In our view, the method should be developed for HCI as a generic method, which shall be available without strong assumptions about specific equipment or movement ranges.
In contrast, previous work outside HCI has developed taskspecific simulations, such as a model of workers in reaching and assembly tasks , or simulations of prostheses in medicine .
Biomechanical simulation "reverse engineers" observed motion to explain it in terms of anatomical events.
Its input is the movement of pointlights in 3D space.
When accompanied by information on how the pointlights map to the human anatomy , motion is first explained as rotations of joints .
Then, given mass distribution of the body, required forces at joints are estimated .
Finally, given muscle anatomy, plausible muscle activations are estimated .
We here compare the outputs to existing measurements in physical ergonomics.
We then review previous work in validating the outputs against ground truth.
Motion capture and biomechanical simulation create a high-dimensional description of a user's movement.
The output variables are best understood as descriptors of physical ergonomics costs, the anatomical and physiological costs of movement .
Within this scope, mocap-based biomechanical simulation can estimate six out of eight measures that would normally require specialized measurement instruments .
To our knowledge, there is no previous research applying or validating biomechanical simulation with muscles to core HCI tasks.
However, biomechanical simulation has been combined with motion capture in a few earlier tools for ergonomics, and applied to cases in office safety assessment  and automobile assembly analysis .
These implementations included simplified models that lack muscles or necessitate external EMG recordings .
Although mocap-based biomechanical simulation has gained ground only recently, some steps of the simulation have been known for decades and are more thoroughly understood  than muscle activation models.
Error in joint angle prediction has been estimated to be within 1 degree for flexion-extension and abduction-adduction, and within 3 degrees for axial rotation .
Mean joint dislocations were smaller than 0.5cm, which should be accurate enough for HCI.
Forces and moments have been validated in a study that compared the output of inverse dynamics to joint moments calculated with a machine learning algorithm from an EMG signal for the knee .
The only studies looking at the validity of muscle activation predictions of real movement of whole limbs involve lower extremities and consider gait or running .
They compare predicted muscle activations against sEMG.
Although there are a few validation studies of simulations related to upper extremities, all of them are constrained and simulate only one-dimensional movements of a single joint.
The previous validations of lower extremities or separate joints of upper extremities do not generalize to the upper extremity model and cannot be considered as "valid" for HCI tasks .
The only study with a comprehensive upper extremity model reported, qualitatively, a lack of agreement in a comparison of predicted muscle activations and recorded EMG of 3 muscles for single specific reaching movement .
Please see the Auxiliary materials for a summary of previous validation studies.
Study II is the first exhaustive validation of upper extremity models for whole-arm aimed movements in all directions and locations.
Joint angles are indicators of movement constraints and extreme postures and often measured by labor-intensive videometry, or goniometer measurement, which is limited to a few joints at a time and can perturb the movement.
Posture is the state of the whole kinematic tree.
It predicts overloading and musculoskeletal stress.
In mocap-based biomechanical simulation, inverse kinematics yields angles and posture.
Kinematics describes angles and the distribution of loads and mass during movement and predicts overloading and repetitive-strain injuries.
Force plates, on-limb accelerometers and on-joint friction/bending sensors can be used, but these have limited coverage, are cumbersome to apply, and can influence movements.
Moments and forces at joints can estimate the overall energy expenditure  and also point to arthrokinetic strain and stress.
Moments at joints are the sum of muscle forces multiplied by moment arms.
Dynamometers are used in sports sciences but are limited to static setups and cover one movement type at a time.
Mocap-based biomechanical simulation estimates moments and forces based on the outputs of inverse kinematics and full mass of the participant, assuming standard mass distribution.
Muscular load is the force produced by a muscle for a movement.
Direct measurement of muscular forces is intrusive, but surface EMG   can be used to estimate it if parameters such as cross-sectional area are known.
Muscle activation refers to the recruitment of muscle fibers by action potential induced by motor units.
In mocap-based biomechanical simulation, these two are given by static optimization.
Fatigue is the state of a muscle when it cannot produce its maximum force.
It is reflected in the sEMG signal.
Muscular fatigue can be described by total mechanical energy expenditure of muscle, which can be calculated from muscle activations integrated over time, estimated by static optimization.
Presently, the best way to measure muscular fatigue is to infer it from the EMG signal and to use self-reports.
To motivate the need for a validation study, here we outline the most significant sources of error in the method .
Generally speaking, the estimations of joint and muscle activities should be treated as hypotheses made possible by a strong prior: an anatomically correct but generalized fullbody model.
The two most important sources of error are, first, the precision of motion capture that affects all computations "downstream."
State-of-the-art marker-based tracking is accurate to the millimeter level.
Biomechanical simulation depends on a reliable mapping between the body model and pointlights in the 3D mocap data.
There are guidelines for marker placements that increase reliability by identifying anatomical landmarks that are more matchable  .
The mapping, called the virtual marker set, is manually defined after the data collection by the experimenter using a GUI.
Sources of error: First, typical optical tracking allows only a limited number of markers on the body .
The experimenter must define which limbs to track and which to leave out.
For example, tracking the articulation of hands is limited, if the rest of the upper torso should be tracked as well.
Second, the placement of virtual markers on the model can never be perfect, since the virtual body model does not have the exact same geometry, and because markers are placed with an offset from the bones that mark the landmarks.
Third, mapping is less accurate in segments that are farther away from anatomical landmarks.
SO resolves the required activations of muscles by minimizing total muscle activation as its objective function.
It uses two muscle models as constraints: ideal force generators and muscles constrained by force-length-velocity properties.
Sources of error: First, SO assumes that people move "optimally" in terms of minimizing total activation, which cannot be assumed in many HCI tasks.
Second, muscle anatomy and strength may differ between the user and the model.
Third, movement speed may be an issue: For slow movements, activation patterns could be identified incorrectly, because humans can use a different activation strategy, or use smaller musculature to move.
Every user needs to be scaled to match the anatomy of the generalized human model.
A measurement set is a set of marker pairs and body parts that are scaled according to the ratio of distances between virtual and physical markers.
The model size and weight are adjusted on the basis of the measurement set or from manual measurements.
Automatic Marker Adjustment is then done based on data from a calibration pose of the user.
It adjusts marker positions by means of inverse kinematics, which minimizes the errors between virtual and physical marker positions.
Sources of error: First, scaling assumes that the distribution of mass in a body is a linear function of the model's distribution.
Second, automatic marker adjustment can err due to improper weight distribution, causing correctly placed markers to be misplaced.
The two studies presented in this paper examine HCI-relevant motor control tasks in 3D space.
The system we utilize in the studies represents the state-of-the-art.
Our recordings are done with high-end, commodity motion capture equipment: the PhaseSpace system with Impulse cameras tracks a fullbody suit and gloves with flexibly attachable marker positions.
For simulation, we use OpenSim , the only comprehensive open source simulator.
It supports editing of the musculoskeletal model, scripting, and visual investigation of the results in a GUI.
We use the SIMM Full Body Model, which combines measurements from several anatomical studies  best representing an average adult male.
In the validation studies, the following practices were followed: * Marker placement guidelines were followed .
Some trackers, like ours, come with a marker suit that has some pre-positioned markers, and not all guidelines can be strictly followed.
For studies of aimed movements, it is necessary to add further markers on the end-effectors .
We used Micro Load Cell  with PhidgetBridge mounted under surfaces to-be-touched.
These may arise from shifts in the set of cameras observing a particular marker and are typical when the user moves around or the scene is crowded.
Both issues manifest themselves as "jumps" in motion paths that can be reliably identified from the second derivative of coordinate values that are further than 2 SD from the mean.
To fill gaps in the remaining data, we have experimented with several interpolations and found linear interpolation to yield sufficient quality.
IK calculates generalized coordinates that describe a skeletal movement in terms of angles between bones at joints, and translations and rotations of the human model relative to ground.
It minimizes the weighted least-squares distance between physical markers and corresponding virtual markers.
Sources of error: First, markers can drift during movement due to non-rigid skin movement.
Second, joints are modeled as simple "hinges" and omit for example translation at joints .
We have done calibration by asking users to touch the center of each target with an end-effector equipped with a marker.
We perform calibration for every session to avoid the effects of between-session changes in the coordinate system of the mocap sessions.
Generally this should be avoided, but it is necessary if the model contains muscles too weak to explain observed movements.
We report when this was done.
In all other aspects, we follow the manual of OpenSim .
For examples of the setup and outputs, we refer the reader to the supplementary video.
Multitouch gestures on a surface involve fine-grained movements that employ the small muscles of the hand and the arm.
We followed an existing gesture set : rotation , pinch with two fingers , pull with 2 fingers , pinch with all fingers , pull with all fingers , drag with index finger , drag with four fingers , and tap with index finger.
Each condition was repeated 50 times.
Typing involves fast simultaneous movements of multiple end-effectors and recruits small muscles.
The participant typed his name as quickly and precisely as possible 50 times on a regular physical Qwerty keyboard.
In all tasks, the subject was trained prior to motion capture to reach a level of performance we considered representative for that task.
Sufficient rest was provided throughout.
The first study addresses technical feasibility in five HCI tasks carried out by a subject.
The goal in selecting the tasks was to cover a wide range of movements with different velocities and varying number of contributing limbs and muscle groups.
We consider mocap-based biomechanical simulation to be feasible for a specific task if all computational steps can be completed without errors.
Typical error conditions are abrupt points appearing in the IK output, muscle activations approaching maximum, or large reserve activations appearing in SO.
Furthermore, we compare our results against the existing literature on EMG measurements, where available.
The subject is right-handed and has no perceptual, neurological, or cognitive deficits.
The PhaseSpace motion capture system with 12 Impulse cameras at 480 fps was used to record the movement of 43 active markers.
In tasks 3, 4, and 5, a force plate of our own construction measured external forces.
Interactive software was used in tasks 1, 3, and 5.
The tasks were performed in a single three-hour session.
This allowed us to use a single calibration and scaling.
Details of the tasks follow: 1.
Full-body dance game involves configural movements of the full human body.
It was performed to a song from Just Dance 2 on the Nintendo Wii.
Plane control involves steering a plane through continuous aimed movements of the upper part of the human body.
Three control schemes were used: The first used a "bird paradigm," the second a steering-wheel paradigm.
In the third, the arm was lowered and flexed.
The subject had to mimic the motions of a person "flying" in a video as accurately as possible.
Mouse pointing involves fine-grained movements that deploy muscles from the shoulder down.
It consisted of lateral reciprocal aiming movements performed with a commodity mouse.
Table 2 summarizes the success or failure of the biomechanical computations for the specific HCI tasks.
Three out of five tasks were completely successful.
For these tasks, the method is discriminative and the outputs are sensible as highlighted in Figure 2 using representative muscle activation patterns.
In particular, Figure 2a shows a clear activation of upper back, shoulder and biceps muscles, when the dancer moves his arm up, and lower back, shoulder and triceps muscles when he moves his arm down.
For the mouse pointing task , different shoulder muscles  are activated for movements from left to right and vice versa.
When typing , the subject mainly used his middle finger, which is reflected in a higher proportion of activation of muscles controlling that finger.
Data from all tasks except multitouch gestures could be processed for IK.
IK requires keeping RMS  error within 2 cm and largest marker error less than 4 cm.
Although such errors are considered to be normal for full-body simulation, they were too large for multitouch gestures where the movement size falls within this range.
Figure 2: Selected muscle activation predictions for three HCI tasks in Study I.
The other borderline case is typing: in our particular case IK was successful, because the participant used only 3-4 fingers with pronounced up/down movements when typing.
Had the participant used the ten finger touch-typing technique, IK would have failed.
Task that are successful in the IK stage can proceed to ID.
The only problem we encountered in this step were tasks where large external forces were applied.
For dance, where the user stepped up and down, because we did not have force plates on the ground, we manually estimated ground reaction forces based on observation of movements.
This approach improved the validity of full-body results, but the results are not reliable for the lower extremities.
We conclude that movement size was the determining factor for technical feasibility.
Movements with smaller than 4 cm radius were not feasible with current marker setup, however they may be successful with a more complicated setup involving multiple markers on hand .
Moreover, abrupt and overextended movements posed a challenge.
We also learned that including data from a force sensor  observably improved the realism of ID and SO predictions, even for small-range movements and small external forces.
Our analysis here is limited to selected shorter segments  of the full recordings, because of computational intensity.
Computing just 50 frames of SO for the dance task took 15 hours on a desktop computer.
One observed limitation is due to movements that are produced by muscles that are stronger than the corresponding ones of the generalized model.
Another was that of motions where limbs are overextended or produce very fast abrupt movements.
A successful simulation of the "bird" controller in the flight task required adding reserve actuators at the shoulder joints.
This issue can be partially addressed by adjusting the muscle parameters of the general full-body model to the individual participant.
Similarly to ID, SO needs correct external forces, so only part of the outputs from dance can be considered valid.
Study II addresses the predictive validity of muscle activations in HCI-relevant motions.
Informed by Study I, we decided to focus on gross movements instead of small movements, and chose mid-air pointing gestures as the topic.
This topic is relevant for research on interfaces that use computer vision and accelerometers for control.
Surface-EMG was measured for eight muscles of sixteen subjects while performing a 3D pointing task.
The participants carried out in-air reciprocal pointing movements among targets in the reachable space of their arms .
The experimental design covered the whole reachable space of the arm and allowed us to vary target size and amplitude of movements.
Moreover, we had 16 users with varying demographics, which allowed us to learn about potential inter-subject differences and differences between muscles.
EMG was chosen as "ground truth" following existing recommendations  in studies of lower limbs .
We use EMG amplitude as ground truth.
No subject had musculoskeletal or neural disorders, and every subject took part in some regular physical exercise.
Five targets from a total of 25 physical targets  were selected for each subject by stratified sampling from five segments of the reachable space of the dominant arm: left upper outer, left lower outer, right upper outer, right lower outer, and central inner.
We recorded three trials for every pairwise combination of the five targets -- in total, 30 trials per subject.
The order of trials was randomized.
In addition to motion capture, surface EMG was recorded with a Myon 320  and self-adhesive electrodes  at a sampling rate of 2000 Hz.
All subjects confirmed that the EMG electrodes did not restrict their movements.
Electrodes were placed on eight muscles: the pectoralis major, deltoideus anterior, deltoideus medius, deltoideus posterior, trapezius descendens, trapezius transversalis, biceps, and triceps .
The skin was prepared for electrode placement following recommendations .
Retrospective self-reports were measured by a questionnaire.
All motion capture data was processed through IK and SO.
Because of the computational cost of SO, we selected representative movements by choosing a movement for each trial with a movement time closest to the mean and which ended within the effective target.
Following the recommendation of the manufacturer, the DC offset was removed from the EMG data and frequencies below 20 Hz, above 500 Hz, and between 49 and 51 Hz  were filtered.
The signal was then full-wave rectified and normalized according to maximum voluntary contraction.
Then both EMG and the activations calculated via static optimization were low-pass filtered at a frequency of 4 Hz to create a linear envelope of the signals.
For each movement , we computed the Pearson correlation coefficients between the time series of the EMG signals and the corresponding SO activations of the studied muscles.
The full distribution of the correlation coefficients can be observed in Figure 5a.
The median of the correlation coefficients over the full dataset is r = 0.48.
Examples of high and low correlations are given in Figure 4.
Several observations were made: * SO predicts better for larger muscles: deltoideus  and trapezius .
Perhaps the recruitment of smaller musculature in the finer control of motion is well captured by neither sEMG nor SO.
This is understandable given that the musculature in the model  is based on measurements from adult males.
We did not find effects for the location of movement in the 3D space.
The following observations are also important to consider when assessing the outcomes of biomechanical simulation: * Activations of larger muscles are better predicted than smaller ones.
For favorably chosen tasks and subjects, correlation against S-EMG was as high as 0.81.
This is the case for middleaged adult males that are the best match with the human body model.
But both studies indicate that the highest muscle activations are very well predicted.
Moreover, the results from mouse pointing and typing  are in consensus with findings of previous studies using EMG.
These results should be taken into account when sampling users and designing tasks for experiments.
We conclude that the predictions of static optimization were poorer for small and non-contributing muscles, but adequate for the largest muscles and gross movements.
In ideal conditions, predictive validity was high: If we consider only the larger muscles of participants whose anatomical parameters are close to the full-body model, and movements between large targets, then the median correlation is 0.81.
Generally, middle-aged subjects were better predicted.
Finally, self-reporting of fatigue was not predicted by the method.
Mocap-based biomechanical simulation consists of many steps and it was previously unclear how sensitive the method is to the accumulation of errors.
The general thrust of the findings is that, presently, mocap-based biomechanical simulation is valid for some but not all HCI tasks.
In the following, we summarize the lessons learned.
Table 3 provides a list of recommended best practices.
Study I  found that movements of less than 4 cm amplitude are presently impossible to process by the standard simulation.
The noise level is too high for such signals, even with state-of-the-art tracking equipment and careful marker placement.
Very fast and overextended motions are problematic as well and require a temporary increase of the muscle strength during the simulation .
These results imply that movements involving small interactive surfaces or abrupt movements with large forces, as in exergames, are difficult.
However, many improvements are possible .
The main result of Study II is encouraging, namely that the correlation of muscle activation predictions with ground truth data from surface-EMG is as high as r = 0.48 for the 3D aimed movements of sixteen random subjects.
As there is increasing attention to biomechanical simulation in various disciplines, the involved technologies are likely to be improved by future work in different domains.
We identified a number of issues that should be of particular concern to HCI researchers, as detailed in the following paragraphs.
In order to expand the method to fine motor movements like multitouch gestures on a surface, the most critical shortcoming to address is the limited movement size.
Follow anatomical guidelines for marker placement.
Use additional markers for end effectors.
Use force plates to record contact forces at surfaces.
Use reserve actuators for overextended movements.
Use Kalman smoothing for more robust IK and ID.
Middle-aged subjects are better predicted than young.
Males are better predicted than females.
Movements with large amplitudes are better predicted.
Movements to large targets are better predicted.
Fine movements of less than 4 cm of amplitude are not feasible.
Faster movements are better predicted than slow.
Prediction is better for movements recruiting larger muscles.
Prediction improves when the muscle gets more tired over time.
Over-extended motions are poorly predicted.
On the positive side, the motion capture system itself introduces relatively small errors.
Some of the culprits are hard to avoid.
For example, the locations of anatomical landmarks vary slightly across users, and therefore also the marker placement relative to these landmarks.
Furthermore, the markers drift slightly during movements.
However, movement size can be partially addressed by adding more markers per joint and fine-tuning the body model to the individual subject.
Related to this issue is the fact that the present body models work best with a middle-aged male.
More work is needed in statistical body modeling that can account for statistical variation in body shapes and mass distributions.
This way, the method will be applicable to a wider range of subjects.
The model also makes simplifying anatomical assumptions, such as joints being "hinges," although for example the thumb has a saddle joint.
Improving the accuracy of the model will improve the permissible size of movements.
Moreover, more studies are needed to understand limitations with different demographics.
Our validation study showed no real relationship between predicted muscle activations and self-reports of stress and tension.
The experience of the user is obviously important for HCI researchers, but it is not novel to find a low correlation between objective and subjective measures in HCI .
We suspect that the reason for the low correlation is that our subjects were not tired enough for stress to emerge.
At present, we advise collecting said data via questionnaires, but future work should examine whether muscle fatigue can be estimated when more muscle parameters are known .
The standard biomechanical simulation considers movements "in a vacuum."
We used force sensors to collect ground reaction forces at contact points on surfaces, but our setup is limited to recordings of a single sensor.
For HCI investigators dealing with interactions that involve multiple objects , it will be important to have a way to collect and synchronize data from multiple easily attachable force sensors.
Finally, several practical issues need to be addressed.
Although we have shown that data collection and processing is possible and worthwhile, the process is still unwieldy.
Computation times of ID, IK, and SO are extensive: 15, 50, and 1800 seconds, respectively, on a desktop computer for an movement of the arm .
As an alternative to SO there are also two more sophisticated tools in the OpenSim called Residual Reduction Algorithm  and Computed Muscle Control  .
Together they should be able to provide more accurate results, although their computational cost is much higher.
For application in HCI, RRA and CMC also need to be assessed and validated.
Faster simulation methods exist , but they have not yet been validated for HCI.
But even the fastest simulation software cannot make up for the time-consuming setup of markers and other manual inspections and interventions that are required in the preprocessing phase.
To support practitioners better, future work should seek to streamline the method.
A promising direction is markerless motion capture .
It allows unhindered mobility for the subjects, and the setup effort is reduced to a minimum.
However, markerless motion capture has lower accuracy.
It remains to be examined for which HCI tasks this lower accuracy is still sufficient.
The combination of motion capture and biomechanical simulation allows measuring both performance and physical ergonomics of a user interface within a single session and with relatively low costs for the setup.
The benefit is that it allows obtaining a rich description of a user's movement: joint angles and posture, kinematics, forces and moments at joints, as well as muscular load and activation.
Computational and manual costs are addressable.
It is important to try to tap this rich source of information for HCI.
As a first step, we studied the feasibility and validity of this approach for HCI in aimed movement tasks.
The positive thrust of the present findings is that the method can already be used for a broad class of HCI studies.
Thus, it is a viable alternative to traditional ergonomics instruments.
We also identified some limitations.
They can largely be addressed by technical improvements, which will expand the range of HCI studies that can benefit from mocap-based biomechanical simulation.
All data and software described in this paper will be released on the project website.
Muscle anatomy images adopted with permission from Gray, H. Anatomy: Descriptive and Surgical, Lea & Febiger 1918.
This work was funded by the Max Planck Centre for Visual Computing and Communication and the Cluster of Excellence for Multimodal Computing and Interaction at Saarland University.
Ahsberg, E., Garnberale, F., and Kjellberg, A.
Perceived quality of fatigue during different occupational tasks.
Workplace injury and illness summary - 2012.
Washington, DC: United States Department of Labor, 2013.
