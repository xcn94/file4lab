But these environments, and others like them, are limited in that they typically allow only a single point of cursor or pen-based contact for manipulating objects from a single perspective through a single interaction plane.
Compared to the rich means available for controlling physical objects, this single point can be limiting.
Several hardware technologies allow multiple concurrent points of contact  and researchers have used them to create direct manipulation techniques that naturally emulate 2D rotation, translation, and scaling .
3D manipulations, however, have not yet been fully explored.
We argue in this paper that providing users with shallow-depth 3D capabilities allows for a more engaging and rich experience.
We first present design guidelines for direct-touch 3D interaction.
Next we discuss alternative candidate interaction techniques for supporting these manipulations using one, two and three points of contact, formally demonstrating how two-dimensional surface interactions can be used to directly manipulate shallow-depth 3D objects.
We then describe a usability study that compares the speed and accuracy of the techniques as well as the users' subjective perceptions of them.
In closing we discuss the implications and suggest two alternative techniques based on the results of this study.
On traditional tables, people frequently use the third dimension to pile, sort and store objects.
However, while effective and informative for organization, this use of the third dimension does not usually extend far above the table.
To enrich interaction with digital tables, we present the concept of shallow-depth 3D - 3D interaction with limited depth.
Within this shallow-depth 3D environment several common interaction methods need to be reconsidered.
Starting from any of one, two and three touch points, we present interaction techniques that provide control of all types of 3D rotation coupled with translation  on a direct-touch tabletop display.
The different techniques exemplify a wide range of interaction possibilities: from the one-touch technique, which is designed to be simple and natural, but inherits a degree of imprecision from its simplicity; through to three-touch interaction, which allows precise bimanual simultaneous control of multiple degrees of freedom, but at the cost of simplicity.
To understand how these techniques support interaction in shallow-depth 3D, we present a user study that examines the efficiency of, and preferences for, the techniques developed.
Results show that users are fastest and most accurate when using the three-touch technique and that their preferences were also strongly in favour of the expressive power available from three-touch.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Almost all windowing interfaces currently use shallow 3D effects to support interaction.
The layering and shadowing effects both enhance the visual appeal of the interfaces and provide a natural metaphor for switching documents and workspaces into and out of focus.
Researchers are also investigating problems and solutions that arise from moving between layers on the desktop.
Dragicevic , for example, describes 3D visuals of dog-ears, folding and shuffling to make working with overlapping windows more intuitive.
Agarawala and Balakrishnan's  `BumpTop' wholeheartedly adopts the emulation of reality on the desktop, using both rich 3D visuals and physics modelling to enrich interaction - objects can be piled on top of one another or flipped onto their backs; objects can be thrown at others, and the visual effects of collisions depends on their mass and velocity.
The reality of the lustrous environment, however, is hindered by its constraint to a single point of interaction through a stylus input device.
For comparison with the reality it attempts to emulate, though, consider the awkwardness of manipulating objects on your physical desk using only one index finger.
For collaborative tabletop displays, a variety of 3D effects have been proposed.
St ahl and Lundberg's  tabletop 3D virtual pond floats items in use to the surface and allows items to sink when they are no longer in active use.
The Lumisight table  and Nakashima et al.
While these systems are capable of rich 3D visuals in a collaborative setting, they do not fully address the interaction with these 3D models.
Furthermore, these systems require a very large tabletop to achieve a small central 3D display.
In the study of high degree-of-freedom  input devices, there has been a general consensus about the separability of rotation and translation.
It is widely believed that input is superior if these are kept separate.
They both argue and demonstrate empirically that the separation into "forceless isotonic rotational input" and "force-requiring elastic translational input" is key to a good design of a 6DOF input device.
However, other researchers suggest that rotation and translation are not separable in the human mind .
Studies of 2D interaction techniques for 2D tabletop interfaces, such as RNT , which require only 3DOF, tend to confirm that users typically ignore this difference and that integration of rotation and translation is essential for the support of communication in a collaborative setting .
Although these two claims appear contradictory, we argue that rotation and translation can be separated, but performed simultaneously and that this provides a natural interface for communication without sacrificing performance.
In this endeavour, we attempt to combine the benefits of both 3D interaction and digital tabletops.
In order to be successful, we need to take care in the design of new techniques to support interaction.
We suggest the following design guidelines for interaction on tabletop displays in 3D: * Provide More Degrees of Freedom: Interactions including flipping of objects, storage and communication through small adjustments of objects become possible by allowing full rotation and translation in three dimensions.
Similarly, a 3D tabletop interface should allow users to simultaneously rotate and translate an object.
Thus, users could combine these actions at the cognitive level instead of combining them in a potentially awkward way through the interaction technique itself.
We distinguish this from direct input - when input space and display space are superimposed - by specifically requiring that the object being manipulated, not just the display space, remain in physical contact with the input mechanism.
This guideline is also important when manipulating 2D objects on a digital table , but we emphasize its importance in 3D here, as it may be more tempting to ignore this constraint when more DOF are required.
For example, since it is impossible to push one's finger through the display, limiting the depth of interaction maintains that expectation and prevents disconnect.
Furthermore, traditional tabletops offer interaction on the surface of the table and the space between the top of the table and the user; however, most interaction takes place in the first few inches.
Limiting interaction to a small finite z depth places a virtual surface just below the actual display, providing a similar few inches for 3D interaction.
This can pose problems in recognizing concavity and convexity because in the absence of other cues, lighting will be assumed to originate from over one's shoulder , causing a button to appear depressed from one side of the table but not the other.
Use of full 3D projections with additional depth cues such as shape and cast shadows can reduce this effect.
Even for a single user, parallax can occur from left to right, simply due to the size of the display and the proximity of the user.
Some technologies allow for a large number of points of contact, without identifying information , and others provide identifiable input for a single point of contact for a small number of users .
In order to fully support direct-touch 3D interaction for multiple users on tables, the hardware needs to support identification of not only where a finger is touching, but also which finger of which user is touching.
We have designed three new direct-touch interaction techniques for manipulating 3D objects on a tabletop display.
These designs were in part informed by our suggested guidelines, but mostly have helped to generate them.
On the two-dimensional surface of the table, each point of contact provides two degrees of freedom of input.
It is possible to create interaction techniques that vary from being essentially 2D input , through being 2D+ input , to being fully 3D input .
The shallow-depth 3D output we wish to provide has the following five degrees of freedom: * * * * x & y - the position on the surface of the table yaw - object rotation about the z -axis  roll - object rotation about the y -axis  pitch - object rotation about the x-axis 
While the discrepancy in mapping between input degrees of freedom  and output degrees of freedom  is high, the actual action feels quite natural .
Touching a point on the cube works like a sticky finger in that the contact point will rise toward the surface and the leading direction, causing the cube to rotate in x, y , and z until the contact point is as close to the surface and the lead direction as the shape of the cube will allow.
Rotating the chosen side to the surface merely involves touching that side and dragging.
This can require a re-touch for an initially occluded side.
Despite the fact that this technique provides the ability to rotate and translate a 3D object to any position and orientation, it is common for users to want to perform more constrained interaction, such as translation alone or planar rotation.
We provide this ability through dedicated areas on the object.
For polygonal objects, a circular area about the centre of each face is reserved for translations and a doughnut-shaped region around that circle is reserved for planar rotations .
For non-polygonal objects, a more abstract central location can be chosen on some surface of the object, about which the circle and doughnut shapes can be drawn.
Five or six degrees of freedom of output can be achieved using only two points of contact .
The first point of contact can use the RNT algorithm  to achieve both translation in x and y as well as yaw.
The second point can be used to specify pitch and roll .
If z motion is desirable, this can be manipulated according to the change in distance between the two points.
Using the two-touch interaction, users can perform 2D rotations and translations with the index finger of the dominant hand using the RNT algorithm while simultaneously performing pitch and roll rotations  with a second finger on the non-dominant hand.
Using three-touch interaction, users can perform a simultaneous translation and rotation on the surface of the table, as shown here.
The user can also simultaneously rotate the object in pitch and roll with a finger on the non-dominant hand.
Let Ti =  and Ti =  be the initial and final points for the ith point of contact, where i  {1, 2}.
Let C =  be the initial centre of the object.
However, the technique is not limited to this configuration; other sensible configurations include reversing these two fingers or using the index finger and thumb on the same hand.
This technique provides easy causal movement coupled with rotation that maintains the vertical orientation of the object's projection.
If the vertical orientation needs adjusting, for example if the right side of a cube is not at the surface, it can be adjusted with a finger on the non-dominant hand.
As with the one-touch technique, it is often desirable to perform constrained translation-only movement.
This is again provided at the centre of each face of a polygon or an abstract central location on the surface of a non-polygonal object.
In principle this interaction is quite simple.
For example, a single touch with one's index finger supports translation only, including one's thumb adds rotation around the z -axis and the addition of a finger from one's other hand provides the other two rotations.
In theory, three-touch allows the most efficient means for control because users can concurrently and independently manipulate all six degrees of freedom.
However, there is a risk that this freedom may be confusing for users.
Furthermore, both the two- and three-touch techniques may disconnect the object from the initial touch location upon rotation in pitch or roll.
This disconnect may further confuse the user, creating an advantage to the one-touch technique.
Hence, empirical comparison of the techniques is necessary.
Our three-touch interaction technique maps 6DOF input to 5 or 6DOF output .
In this mapping, the first point of contact is used for translation, the second point for yaw about the first point, and the third point for pitch and roll about the centre of the object.
The depth can be specified by the difference in distance between the first and second touch points.
The order of the points can be specified either by taking the points in order of contact with the table or in a predefined order .
To better understand how people interact with these three  connected manipulation rotation and translation techniques, we conducted a study that compares them in terms of their speed, accuracy and the subjective preferences of the participants.
Since these techniques vary considerably in interaction styles, conducting an empirical comparison can shed light on which balance of design tradeoffs are the most effective and satisfying for people.
For example, one-touch interaction is likely to be slow, but users may appreciate its simplicity and reliability; threetouch interaction may be fast if the participants can adapt to its comparative power and complexity, but they may report a higher cognitive load if it fails to be perceived as `natural'.
Twelve students  from a local university participated in the study.
Both national and international students were selected from a variety of disciplines.
Five participants reported no prior experience with 3D gaming and seven reported some.
The experience of these seven varied from once a year to four times a month.
All participants were righthanded and no participant reported any colourblindness.
The experiment was performed on a front-projected 1024 x 768 pixel tabletop display using DiamondTouch  input with an 87 cm x 66 cm display area .
Multifinger input was provided by attaching distinct DiamondTouch sensors to both the index finger and thumb of a righthanded insulating glove.
The third touch-point was provided with a regular DiamondTouch pad through the left hand.
The display surface was 72 cm above the floor and participants were provided with an adjustable chair.
An orthogonal 3D projection was used to render objects on the display.
That is, objects could roll, tumble, and flip but the object's centre remained at a fixed z depth.
Thus interaction was limited in all conditions to 5DOF.
Software automatically logged the users actions and task times.
Each side of the cube had a distinct grayscale icon.
At the start of each trial, the cube was in the same location immediately in front of the participant, with the "top" side  uppermost.
Virtual participants were located to participants left, right and opposite.
To start each trial an icon appeared on the screen and one virtual participant was indicated in red.
The participant then matched that trial icon with one on the cube and passed the cube to the indicated virtual participant with the correct icon facing upward.
The task was repeated six times - once for each side of the cube - for each target destination.
Participants performed six practice trials each time they started with a new interaction technique.
Data from this task were analysed using a within-subjects analysis of variance for the following three factors: * Technique: one-touch, two-touch, three-touch; * Destination: left , opposite , right ; * Target-side: top, bottom, left, right, back, front;
For each technique , participants performed three tasks in the same order.
The order of techniques was counterbalanced between participants using a Latin square.
Afterwards, each participant was asked to complete a questionnaire to provide both background and feedback about their experience.
Participants were then interviewed by the experimenter.
The primary dependent measure in the two formally analysed tasks  was the task completion time.
We additionally analysed data characterising how the users interacted with the techniques, including the time spent touching, translating and rotating the objects, and also the locations on the objects that the users touched.
To explore performance differences in the three techniques, we asked participants to complete a docking task.
This task was a variation of the task developed by Zhai and Milgram  and used more recently to compare GlobeFish and GlobeMouse to other 6DOF techniques .
In this task, participants were asked to dock a tetrahedron inside another of equal size .
In order to determine a person's ability to use each technique for communication with other people, our first task required participants to pass a cube to one of three "virtual" people with a specific side of the cube facing upward and toward the virtual person .
This task was modelled after the study done on the 2D RNT rotation technique .
In summary, each participant was asked to do the following: for each technique : - complete 18 passing trials in random order  - complete 30 docking trials in random order  - complete a puzzle task The random ordering of passing and docking trials was different for each participant and technique.
The vertices and edges of the tetrahedra were coloured to aide the participants in determining object orientation and the edges were haloed to aide in depth perception.
When a given vertex was moved within target range, the vertex would change colour.
Once all four vertices were in place for 700 ms, the source tetrahedron would disappear and the participant could begin the next trial by pressing the start button.
Each trial had a 40 second time limit, after which the trial was abandoned and the next trial automatically began.
Trials were repeated for three levels of difficulty and for two levels of orientation.
The levels of difficulty varied the size of tolerance bars at each vertex on the destination tetrahedron - easy trials had a 54 pixel tolerance, medium trials 38 pixels, and hard trials 23 pixels.
The two levels of orientation allowed us to compare the techniques' support for planar rotations with more complex rotations - planar rotations used a 135 rotation about the z-axis, and complex rotations used and a 135 rotation about the x-y-z-axis.
Participants performed five repetitions of each combination of difficulty and starting orientation.
Each time they began again with a new technique, participants performed six practice trials .
Data from the docking task were analysed using a threefactor within-subjects analysis of variance on the factors: * Technique: one-touch, two-touch, three-touch; * Difficulty: easy, medium, hard.
Data from the task completion times violated Mauchly's test of sphericity for the repeated measures analysis of variance.
We therefore report results using the Greenhouse-Geisser correction .
Task completion times  in both the passing and docking tasks showed the same trend, with users successfully exploiting the more expressive capabilities of the two- and three-touch interaction techniques.
These results are summarised in Figure 8.
Post-hoc pairwise comparisons only showed a significant difference between one-touch and three-touch techniques .
Despite the comparative efficiency of the three-touch technique, it is worth noting that even its mean task times were high--few tasks involving passing real objects would take this long, regardless of the level of precision required.
We return to this issue in the discussion.
There was no significant effect of destination , nor were there significant interactions between it and the other two factors, suggesting that performance with the techniques is not substantially influenced by the direction of information sharing.
This task was used to examine how the participants' chose to use each of the techniques when completing a more realistic and less constrained task.
Participants were asked to assemble a tetrahedron-shaped puzzle composed of four smaller tetrahedron shapes and a centre piece .
Participants performed this task once for each interaction technique.
Although software logged the users' actions, data from this task was not formally analysed; our interest here was in observations of use, subjective preferences and comments about the techniques.
But again, there was no evidence that any of the techniques was particularly good or bad for complex manipulations .
Only tasks that were completed within the 40 s time limit were included in this analysis.
To check that these results were not adversely influenced by different rates of incomplete trials in different conditions, we analysed the number of incomplete trials using the same 3x3x3 ANOVA.
This analysis further supports the results above.
Timed-out tasks were significantly more prevalent when using fewer points of contact , with means of 1.3, 0.6 and 0.2 timeouts per condition with one-, two- and three-touch respectively.
There were significant effects for difficulty  and rotation ; but there was additionally a significant technique x rotation interaction , due to a much more dramatic increase in timed-out tasks between planar and complex tasks with one-touch than with two- and three-touch .
This effect is explained by the lack of rotation necessary with the top side as the target.
Such tasks, therefore, predominantly involved translation and planar rotation rather than the more complex spatial rotations required with the other sides.
Post-hoc analysis showed pairwise differences  between the top side and all other sides, and between the right and front sides.
This latter difference is likely due to the combination of the facts that forward motion can more easily combine the required translation and rotation  and that our participants were right-handed, causing occlusion and disadvantaging trials involving the right side.
The analysis above shows that the participants completed tasks more quickly when given more points of contact for interaction, and that the benefits of doing so become larger in more complex tasks.
In order to better understand the strengths and weaknesses of each of the techniques for particular types of object manipulations, we now further scrutinise data on the time spent conducting particular types of manipulations, and the object regions used to do so.
To conduct this analysis we broke down the TCTs into time spent performing translation, planar rotation and spatial rotation.
For the one-touch technique, this can be separated by time spent touching each dedicated area on the objects.
For the two-touch technique, it is done by separating time spent inside and outside the translation-only area, and by measuring time spent using the second finger.
For the three-touch technique, it is separated into time spent touching with each finger.
Note that the sum of all movement types can be more than the TCT for the two- and three-touch techniques, since the user can perform multiple movements at the same time.
The results for the docking task showed similar trends to those for the passing task, but with stronger significance.
Mean performance of the docking task with the three techniques improved significantly  as the number of touches increased from one to three.
Means for the one-, two- and three-touch techniques were 20.1 s, 17.0 s and 14.3 s respectively , showing a similar overall percentage improvement between one- and threetouch  to that observed in the passing task.
Post-hoc pairwise comparison showed significant differences between one-touch and both others , and a marginal difference between two- and three-touch .
We had anticipated that one-touch may suffer more than the other techniques on high precision tasks because it does not allow independent manipulation of each degree of freedom, but the data did not support this hypothesis.
We analysed the decomposed TCTs using a 3 x 3 withinsubjects ANOVA for factors technique  and movement type .
Figure 10 shows mean time spent for each technique.
Posthoc comparisons show that participants touched the screen significantly less with the one-touch technique than with the three-touch technique  and marginally less than with the two-touch technique .
The difference between the two-touch and three-touch techniques was not significant .
This effect is in direct contrast to the main effect of technique for TCTs alone.
This contrast suggests that participants spent more time performing cognitive processing than interaction with less DOF and that this resulted in higher TCTs.
Experimenter observations also confirmed that participants tended to have more difficulty with mental rotations when using the one-touch technique.
Note, however that the measures fail to discriminate between manipulations that occur in parallel and in series, so this result should be cautiously appraised.
Post-hoc comparisons show that for one-touch interaction, participants spent significantly more time performing spatial rotations than either translations  or planar rotations  and that for three-touch interaction, participants spent significantly more time performing translations than either planar rotations  or spatial rotations .
All other pairwise differences were not significant .
This interaction shows that participants typically spent an approximately equal amount of time performing rotations with all three techniques.
Furthermore, the larger amount of translations in the three-touch condition may be because participants were able perform translations in tandem with the other types of rotation.
Touch locations on a typical face of the cubes in the passing task  and tetrahedrons in the docking task  separated into one-touch , two-touch , and three-touch techniques .
The coloured arcs represent the mean distances to the nearest corner for each touch location, black arcs represent the standard deviation from these means.
The results for the docking task are sufficiently similar to not warrant reiteration here.
However, the fact that both tasks have the same main effect, interaction and pairwise differences further strengthens this result.
We observed during the experiment that participants tended to use object corners for spatial rotations much more with some techniques.
We recorded the locations of every touch intended for spatial rotation made by each participant and rendered each point using a constant transparency.
Patterns clearly show that for the one-touch technique, users concentrated their touches at the corners and for the two- and three-touch techniques, the touch locations were more central.
Figure 12 shows a typical face of both the cube from the passing task and the tetrahedron from the docking task for each technique.
We also recorded the number of times the participants missed the objects completely and found that this occurred most frequently with the one-touch technique.
Figure 13 shows the average scores on the follow-up questionnaire.
For the docking task, 9 participants preferred the three-touch technique and 3 preferred the two-touch technique.
For the passing task, 7 participants preferred the three-touch technique, four preferred the two-touch, and 1 preferred the one-touch technique.
Overall, 7 participants preferred the three-touch, 3 preferred the two-touch, and 1 claimed there was no clear winner.
All subjective data shows a clear order of preference from three-touch , two-touch, to one-touch .
Participants consistently rated the three-touch technique as the easiest to use  with the most appropriate reaction , as the least difficult to control  and rotate - both in the plane  and spatially .
Also, the three-touch technique was most preferred for docking, passing and overall.
The two-touch technique was rated second in all categories and the one-touch third, though with much higher variance.
There was a significant interaction between technique and movement type.
For the one-touch technique, participants performed more spatial rotations than translations or planar rotations and for the three-touch technique, participants spent more time performing translations than planar or spatial rotations.
The difference in movement type did not differ significantly for the two-touch technique.
However considering the actual TCTs in comparison with what people are capable of with physical objects, there is considerable scope for future research refining these and other new techniques for manipulating shallow-depth 3D objects.
Nonetheless, these techniques do provide the first steps toward enabling the more complex 3D interactions with which we are familiar.
In light of the results of our study, we have explored alternative designs for our interaction techniques.
Specifically, we believe that a redesign of the one-touch technique might make for a feasible method for interacting on tables incapable of multi-user, multi-touch, direct-touch interaction.
Furthermore, our multi-touch techniques typically assign object transformations based on the movement of every finger.
Another way of implementing bimanual, multi-touch rotation would be to use the additional touches to introduce constraints that limit chosen aspects of the interaction.
Such interactions have been shown to be an approach that users can easily cope with, due to the kinesthetic feedback .
Our study showed that the techniques that use a higher number of touches were better both in terms of performance and user preference.
These benefits likely appeared because the higher number of touches provided users with the opportunity to independently control more degrees of freedom.
This type of freedom provides increased flexibility for how users decide to perform the interactions.
Our study showed that one-touch interaction was rated as difficult to use and resulted in the worst performance.
This result implies that one-touch interaction  was not efficient for interacting in shallow-depth 3D on the table.
One response would be to redesign the one-touch interaction technique .
Perhaps a more important consequence is that most existing hardware input technology is currently insufficient for supporting multi-touch interaction.
Our results suggest that multiple independent inputs for each person at the table will be beneficial for both performance and satisfaction.
One concern we had when initially developing the techniques was that the complexity of multi-touch interactions would prove confusing and deter users from its acceptance.
In contrast, allowing users separate and simultaneous control of rotation and translation provided a more preferred interaction with better performance.
From watching people use these techniques, one could see that their interactions became more natural and easy as the number of touch points increased.
Users are not only capable of this more engaged, complex control, but prefer it.
Generally, participants in our study were both intrigued and excited by all three techniques.
This enthusiasm is likely due to the novel ability to use digital objects in a way that was more similar to their experiences with physical objects on tables.
The results of our experiment showed that, while spatial rotation interactions were accessible from both edges and corners, people typically made almost exclusive use of the corners.
We also found that users had difficulty acquiring the corners and would frequently miss the object entirely.
In our new design, the 3D rotation previously available on the entire surface of the object is only allowed at the corners and the user may acquire the corner by selecting anywhere inside a sphere about each vertex of the polygon.
The object still has a translate-only region in the centre of each face, but the remaining parts of the object allow only planar RNT interaction.
This new technique still benefits from the property that the selected point remains under the user's finger.
One of the disadvantages of both multi-touch techniques used in our study is that the point of contact may not remain under the user's finger once a rotation is performed with the finger on the non-dominant hand.
We propose an alternative three-touch technique that constrains the effect of the primary finger based on the presence or absence of contact of the thumb and/or the finger on the non-dominant hand.
When the user manipulates the object with their primary finger and no other finger is touching, the object reacts as it would in the one-touch technique.
When the user uses both the thumb and the index finger, planar rotation is performed as in the three-touch technique.
The user can then limit the movement to translation-only by touching the table with a finger on the non-dominant hand.
This technique also has the advantage that the point of contact remains under the user's finger.
It also corresponds to the way physical objects react, in that additional points of contact allow for more precise, constrained motion.
In light of insights gained through our study we suggest two additional approaches to providing this type of interaction.
These techniques are the first steps toward realizing our vision of shallow-depth 3D interactions in the digital realm which are much more closely aligned to those we are familiar with on traditional tables.
We provide guidelines for the design of direct-touch interaction in 3D and a user study that reinforces these guidelines.
Our study also shows that the greater expressive power of more touch points can improve performance and user satisfaction for direct-touch manipulation of 3D objects on a digital table.
In detail: * Shallow-depth was easily understood and interpreted as a natural environment.
While continuing to explore further refinements of our techniques, we also intend to empirically explore what type of feedback is appropriate in a shallow-depth 3D interface.
We are specifically interested in addressing issues of shading and parallax that are most closely associated with the use of 3D in a collaborative setting.
Our vision is an interface where multiple users can interact simultaneously from any side of the table combined with the rich expressive interactions available in 3D.
We would like to thank Natural Science and Engineering Research Council of Canada, Alberta's Informatics Circle of Research Excellence, Alberta Ingenuity, and the Canadian Foundation of Innovation for research support.
We also thank Edward Tse for help with glove building, Petra Neumann for her many insights, and both the reviewers and iLab members for their helpful comments on this work.
