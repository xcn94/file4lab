However, users may never realize these positive outcomes if worthwhile content is buried in the rush of messages typical in online discussions involving hundreds or thousands of participants.
Additionally, many online systems currently depend on persistent user identity and customization to operate over time.
Sites like Flickr, Wikipedia and YouTube, sometimes referred to as Web 2.0 sites, depend on mixes of anonymous and registered user interactions.
This work addresses how to leverage the choices made by some users to improve the interfaces of all users.
Information overload occurs when an individual is unable to process or use all of the available inputs.
Early research in psychology showed that humans have a limited cognitive capacity to accept new information .
This limitation is exacerbated in CMC settings where barriers to receive information are reduced through the use of computing systems.
Jones and Rafaeli  also found that in larger Usenet newsgroups, as measured by number of postings to the group, messages became shorter.
Previously, Jones and Rafaeli  proposed that communication online takes an S-shaped pattern of frequency of occurrence.
Early in the existence of a conversation space, or "virtual public" to use their term, there is a struggle to achieve critical mass of people contributing to the conversation.
A sharp increase after that critical mass is achieved results in information overload, and communication levels off as participants are disincentivized by the rate of messages.
Jones and Rafaeli  have described this as a tension between the critical mass needed to benefit from "shared public online interpersonal interactions" and the breakdowns that occur in information overload conditions.
Butler  found that large listservs lost a higher proportion of their users to attrition than smaller groups.
Too few interactions and nothing may result, but too many and results are lost in the noise.
Large-scale online communities need to manage the tension between critical mass and information overload.
Slashdot is a news and discussion site that has used comment rating to allow massive participation while providing a mechanism for users to filter content.
By default, comments with low ratings are hidden.
Of users who changed the defaults, more than three times as many chose to use ratings for filtering or sorting as chose to suppress the use of comment ratings.
Nearly half of registered users, however, never strayed from the default filtering settings, suggesting that the costs of exploring and selecting custom filter settings exceeds the expected benefit for many users.
We recommend leveraging the efforts of the users that actively choose filter settings to reduce the cost of changing settings for all other users.
One strategy is to create static schemas that capture the filtering preferences of different groups of readers.
Another strategy is to dynamically set filtering thresholds for each conversation thread, based in part on the choices of previous readers.
For predicting later readers' choices, the choices of previous readers are far more useful than content features such as the number of comments or the ratings of those comments.
Several strategies have been employed to help readers make sense of complex online environments.
Netscan provides statistics and visualizations about Usenet participation, helping to illustrate newsgroup interaction dimensions and styles .
Visualizations have also been used to provide context to email discussions , Wikipedia interactions  and cross-linking in blogs and personal Web pages .
Ackerman  has used a combination of software agents, social rules and automatic text summarization to "distill" comments from an online discussion forum into discrete discussion summaries.
Rating systems have been used widely to provide information about people, products and content online .
An early attempt to apply ratings to online messages was the Tapestry  system, which had users rate content in an intranet messaging site, and then made recommendations for new articles based on collaborative filtering strategies.
GroupLens  applied this idea to Usenet and introduced the technique of automated, personalized recommendations based on the ratings of people with similar tastes, a technique that is now commonly referred to as collaborative filtering or recommender systems.
GroupLens displayed its predictions of user interest in a message as a guide, but did not automatically use the predictions to sort or filter messages.
Slashdot, a popular news and commentary site, collects ratings from selected readers who act in a "moderator" role.
Moderators assign labels such as "Informative", "Funny", or "Troll" to comments.
Based on those labels, each comment accumulates a score from -1 to +5.
Slashdot not only displays the score of each message, but also allows users to sort or filter the available messages based on those scores.
Previous papers have examined both successes and limitations in the provision of ratings for messages at Slashdot  and the impacts that ratings have on writers .
Here, we examine the impact of ratings on readers.
First, we look for evidence about whether users prefer that ratings be used to sort and filter their messages.
Then, we suggest new features that could be introduced, to make the ratings more useful to more readers.
Evidence about users' preferences comes both from responses to subjective survey questions, and from objective measures of users' choices of setting when reading comments.
Literature on user access of customization features indicates that few people take advantage of advanced interface options.
Mackay  conducted interviews with and collected automatic records of customization activities of 51 members of a project at MIT over a four month period.
She found that users engaged in a continual analysis of the cost of learning to customize versus the benefit of having done so.
A significant barrier includes the lack of time to learn the specific tools available.
Triggers for changing preferences included when changing allowed the user to avoid learning new behaviors.
Mackay concluded that users "satisfice" rather than optimize; that is, they do the minimum necessary to use the software.
They also found a strong relationship between how much the software was used and the amount of customization that took place.
The more the system was used, the more customization users engaged in.
This research suggests that users only change options when absolutely necessary, for instance when their work is being seriously impeded, or they are heavy users and find certain repetitive tasks easier to customize.
Mackay mentions satisficing as a possible explanation for this behavior.
Satisficing is a term from Simon , and relates to the bounded capacity for humans to make rational decisions.
Cognitively, people are unable to hold all the variables necessary for making an optimal choice in mind, so they instead choose a "good enough" solution.
March and Simon  argue that only in rare occasions are people concerned with the optimal solution, and that people compare the marginal-benefit of making a decision with the cost of that decision in terms of risk.
Consequently, we must be circumspect in making inferences about the preferences of readers who have not made changes to the default settings.
Our approach is to focus on lead users, those who have made explicit choices about their viewing settings.
We extrapolate from the revealed preferences of those lead users to infer what other, less proactive users, might like the system to do, if there were no friction preventing them from telling the system what to do.
The default view for comments in a Slashdot forum is a threaded structure with a filtering "threshold" of +1.
This means that at the top level, comments rated +1 or above are shown with their full text.
Responses are indented and responses to responses are further indented.
The responses to any comment are listed in chronological order, with the oldest ones first.
At the top level, the direct responses to an initial news story, full text is shown for comments that have a score of 1 or higher.
For comments deeper in the thread , full text is shown for comments rated 4 or higher, a single line is shown for comments rated 1-4, and the comment is omitted if it's score is below the threshold of 1.
At the time of data collection, any reader, anonymous or registered, could make a local change to the display of comments for the current story, using the options shown at the top of Figure 1.
Through pull-down menus shown at the top of Figure 1, a reader can set the threshold to any value between -1 and +5.
In addition to local changes on a per-story basis, registered users may also make permanent changes in their personal profiles.
Any of the settings that can be elected locally can be set as the user's standard setting, the starting setting when reading comments about any new story.
Registered users can also make other changes in the personal profiles that are not available as local changes.
Options here include special penalties or bonuses based on such things as length of the comment, the reason given for moderation and whether the user is anonymous, or registered with high "karma", the name for Slashdot's user reputation system.
These settings generate personalized scores for comments.
A comment moderated as "Funny" may end up with a score of +3 for one user, who has given additional bonus points to funny messages, but as -1 for another user who has assigned a penalty to comments rated as "funny".
In total, there are 36 options that registered users can check to change their viewing patterns.
Figure 2 shows the interface used to change these setting.
This log includes moderation modifiers, viewing preferences, and other variables that affect how comments are displayed.
The second server log is a general user information table that records user history like account creation date, reputation level, comments made and similar items.
The third log tracks user requests for pages from the site.
This log contains time stamps of user page requests, user identification numbers, the URL of the page requested and whether any interface changes were the result of a specific user selection.
Slashdot has previously only logged aggregate number of page requests, and this log added the capacity to tell for each user which page was being requested.
The page request log represents an 80 hour period in mid-July, 2005.
The two user preference logs contain information for the 875,573 users who had created accounts on Slashdot.
Slashdot pages are divided into several sections, only some of which display user comments.
Of the number of page requests listed above, 47% were for pages that would display user comments.
Of these page requests, 2,341,628 were for pages that would display user comments.
For anonymous users, the index page that is a gateway into the site is most often displayed as a static page.
An artifact of the logging procedure was that these static page requests were not logged, so that the pages with user comments are a smaller portion of overall anonymous user hits than represented here.
This difference does not affect study results, as we are only analyzing comment pages, not the index page.
All requests for pages with user comments are dynamic, and thus recorded here.
We also conducted a survey with registered Slashdot users to learn more about their characteristics and attitudes.
The sampling frame for this survey was the list of registered Slashdot users, based on the Slashdot assigned unique identifying number.
User identification numbers were compared against IP addresses to assure that multiple numbers were not held by single individuals.
Each day a script chose 10% of the registered Slashdot users to receive an invitation to participate in the survey.
Potential respondents received an invitation to participate at the top of the index page of the site, an area commonly reserved for site messages, including notification to moderate and metamoderate.
The overall response rate for the study period was 19.1%, with some variation per day.
The survey responses may be suspect for several reasons.
First, there may be non-response bias: the people choosing to respond may be those most aware of and most favorably disposed to the Slashdot moderation systems.
Second, readers may think the ratings are helpful simply because they create feedback to writers and incentives for them to post better comments, even if they do not use them for sorting or filtering when reading.
Third, readers that are willing to put the effort forth to change the moderation system might be overrepresented in those that also put the effort forth to participate in the online survey.
Slashdot survey respondents showed many shared characteristics.
Respondents were 98% male, and 62% had completed a college or graduate degree.
Slashdot users also reported high levels of technology use.
84.5% of respondents reported visiting 2 or more news and discussion sites besides Slashdot each day.
13.5% reported visiting 6 or more news and discussion sites per day.
The choices readers make about how comments are displayed provide a behavioral measure of their reaction to the views where comments are sorted or filtered based on the comments' scores.
If a reader never strays from the default filtering threshold, we cannot infer whether he prefers that setting over all the others, or whether he simply has not explored the other options1.
On the other hand, there are a number of explicit choices that users can make that reveal a preference for an alternative view that also uses scores to filter or sort the messages, or for an alternative view that does not use scores in that way.
In this section, we consider what fraction of the users reveal a preference for a view of comments that does or not make use of the scores.
Table 1 shows how frequently users make changes to either employ ratings in customizing how comments are displayed, or take steps to suppress the role of comment scores.
Users may take more than one action, so percentages in the table are not cumulative.
The grayed area represents settings that employ ratings to customize their views.
The cells in white are settings that suppress use of comment scores.
Users can change their viewing settings either permanently via their user profiles, or on a local, per-story basis.
Originally, the default threshold for Slashdot comments was 0.
At an unrecorded time in 2000, the default threshold was changed to +1.
45.4% of users who logged in during the study period had their permanent viewing threshold set to either 0 or +1 and had not changed any of the other settings in their user profile that related to moderation score.
Of the 34.4% users who had not changed their permanent settings in their profiles, 95% also did not make any local changes to the threshold or sort order.
For these users, 32.7% of the total number of registered users who viewed comments during the study period, we are not able to infer whether they liked having comments filtered based on their scores.
Of registered users who logged in during our study period, 39.2% had set their permanent profiles to include either a threshold of 2 or higher, or sorting based on highest scores first, or both.
The survey asked users to indicate the extent to which they felt Slashdot's moderation system was important in identifying good comments, and the response was generally favorable.
84.7% of respondents agreed somewhat or strongly with the statement "The moderation system is important in identifying good comments."
Only 8.5% disagreed somewhat or strongly.
We have divided users into three groups: 45.4% who never strayed from the default setting; 48.3% who explicitly chose score-based views, and 15.0% who were score suppressors, with some overlap between groups.
The ratio of score-choosers to score suppressors, 3.2:1, is an estimate of the portion of Slashdot users who like using scores as a reading aid at least some of the time.
The estimate is conservative for three reasons.
First, users who never strayed from the default, and thus never expressed a preference, were actually employing a filtered view, with a threshold of 1 or 0.
Many of them probably did prefer their settings over other available settings, but because they had not explicitly choosen those settings, we count them as having indeterminate preferences.
Second, we included as score suppressors people who had not suppressed the use of scores in their permanent profiles but had suppressed scores locally.
Many of them may actually prefer as a general rule to have a filter threshold, and only sometimes suppress its use.
In our conservative interpretation, however, we count these users as score suppressors, since they never made an active decision to rely on scores, and they sometimes made an active decision to suppress them.
Third, even for users who use ratings for filtering sorting, ratings might be playing a role in their viewing behavior.
Scores are still displayed at the top of each message, and they may be scrolling and "berry picking" to select highly rated comments from the forum.
The 3.2:1 ratio means that, of registered users whose behavior showed a preference one way or the other, over three quarters preferred, at least some of the time, a reading view based on comment scores.
This estimate is consistent with the high percentage of users who gave favorable responses on the survey.
We conclude that moderation scores are, indeed, useful to most Slashdot readers, though a minority prefer not to use them.
These patterns lend some support to the idea that ratings are being used to change how comments are displayed, and that users seem to be employing ratings to explore the offerings at either end of the spectrum.
Another possible implication of these patterns is that Slashdot readers are using ratings to view comments with different purposes.
Readers who start out at +5 and maintain a high threshold might be readers with little time who want to get the core arguments in the thread.
Users who opt to go to -1 may have more time to explore.
Looking at the average threshold that a user chooses, 15.3% of users always change their temporary threshold to -1 and 11.4% always change their threshold to +5.
It could be that the viewing population can be divided into groups of "explorers" and "exploiters".
An additional 1.4% of users did not make such permanent changes, but at least once made a one-time change to select a view threshold other than -1 or sorting based on scores.
Overall, 48.3% of users made explicit choices in at least one of these three ways to use comment scores to affect their view.
The only viewing settings that suppress the use of comment scores are a filtering threshold of -1, or a sort order based on chronology rather than scores.
We have already seen that some users made no changes to their view settings, and some made permanent or one-time changes to settings that made use of comment scores.
This group of score suppressors includes 5.7% of the user population who set their permanent profile to have a threshold of -1 and no sorting based on scores, and never made a one-time change to a setting that used scores.
The score suppressors also includes 0.003% of the user population who had not changed their permanent profiles and whose only one-time changes were to set the filtering threshold to -1.
Users can temporarily change their thresholds to -1 by navigating the user interface, specifically by selecting the option "N comments below your threshold".
We found that 14.3% of users made at least one change to a -1 threshold through navigation rather than through the drop-down menus.
Of all registered users who visited the site during the study period, 3.8% navigated to -1, but made no other changes to either permanent or temporary settings.
When viewing a forum, how comments are displayed may be sub-optimal, as in too many comments, or not ordered in a sensible way.
The best strategy for the user might be to change the viewing threshold or sort order, yet the cost of doing so might be higher than the expected benefit from the change.
Each choice presents a cognitive burden; each mouse click takes time.
At the time of our data collection, each page reload also involved waiting for a page reload, which also destroyed the user's reading context.
Are these forms of friction preventing Slashdot readers from changing to more preferred settings, especially making situation-specific changes?
Here again, when people take no action we can't tell what their preferences are.
However, we can again make some inferences based on the patterns of changes made by those who do make changes.
First, of registered users who visited the site during the study period, we found that 10% made at least one temporary change to how comments are displayed.
We computed the ratio of stories where users change the threshold over total stories they viewed.
This ratio excludes the first change that the user makes in order to account for the use of a threshold change as a selection factor in identifying users.
For users who made at least one change, and viewed more than one story, on average they changed settings on 32% of the stories they read.
Half of the users changed settings on 22% or more of stories they read, and a quarter of users changed settings on 60% or more of stories they read.
Second, we find that readers who make one-time changes to filtering thresholds tend to make big jumps, not move to adjacent thresholds.
Figure 3 shows the pattern of changes from different thresholds for registered users.
The shaded boxes are the starting level, with the numbers next to them representing their proportion of all threshold levels set by registered users.
All anonymous users start with a default threshold of +1; their changes in threshold are recorded separately from registered users, in bold italics under the registered user score for that threshold level.
These numbers reflect only the first change on the first story that a user reads.
This is done to account for multiple changes within a story that would cloud the pattern of threshold changes.
The most common moves are to high thresholds of 3 or greater.
The other extreme, -1, is also somewhat popular, but the middle values of 0-2 are less popular.
The patterns of big jumps suggests that there is significant friction from clicking, waiting for a page reload, getting reoriented after that reload, and then assessing if the chance met the satisfied the readers reason for the change.
It seems natural to think that, for any user the distribution over stories of optimal filtering threshold would be a smooth, unimodal distribution.
That is, if n is the peak, the threshold that is most frequently the optimal one of the reader, then n1 and n+1 should be optimal more often than n-2 and n+2.
Without any friction, then, we would expect that the most frequent changes would be to adjacent thresholds.
With friction, however, when the adjacent thresholds are the optimal ones, they may not be sufficiently better than the default threshold, and the user would not bother to change to them.
Only when a threshold farther away is optimal would it be sufficiently better than the default to overcome the friction.
The pattern of actual threshold changes is consistent with this explanation.
Friction does not explain all of the patterns shown in Figure 3.
For example, users at the highest rating, +5, often made the one-step change to the +4 setting.
There are also other plausible explanations for the preponderance of big jumps, besides the friction caused by a need to click, wait, and reorient.
For example, preferences may not be unimodal; instead, a user may like low thresholds for some topics and high thresholds for others, but never prefer intermediate thresholds.
However, it remains true that many users are not taking advantage of the customization opportunities available to them.
Several possible mechanisms may be considered to help users take advantage of the feedback provided by ratings.
A noticeable minority, about 5% of registered users, apply positive bonuses to moderation labels like "Troll" and "Flamebait", essentially guaranteeing they will view material the system is largely designed to demote.
This is counter-intuitive, as one would expect users less entrenched in Slashdot to be the ones who might want to see such content.
One explanation might be that experienced users enjoy the entertainment value of comments that are rated negatively.
Changes to score bonuses tend to come in clusters.
For example, people who added positive bonuses to the "Interesting" label were far more likely also give a positive bonus to "Insightful" than they were to "Funny."
This suggests that users might find it helpful to be able to choose, with a single click, a schema that identifies a cluster of settings for score bonuses.
New system features may be able to help users find their optimal settings.
One idea is to identify useful schemas for score bonuses that users could select either for their permanent profiles or on a one-time basis.
Another idea is to automatically change filtering thresholds for each conversation thread.
We consider each in turn.
When moderators on Slashdot rate a comment, they are actually assigning a label that moves the comment's score up or down based on the value of the label.
Registered users have the option to assign additional weights in either direction to the effect any given label has on the score of a comment.
Table 2 shows the labels associated with comment ratings, the default value attached to the label, and the percentages of users who have added weight to the comments in either direction.
Just 3.2% of registered users have personalized the score bonuses assigned to moderation labels.
Cluster analysis is a method used to identify naturally occurring groups within a larger population by both maximizing in-group similarly and also maximizing between-group variation.
Cluster analysis does not provide significance tests, but rather finds groupings within different variables.
By treating the modifications made by the user as a continuous variable the cluster analysis found four natural clusters.
The first cluster of modifiers, Gem Seekers, are reinforcing the rating directions of the moderation labels by assigning additional weights to positively connoted labels.
For users who added weight to the "Insightful" label, we found that they were very likely to also add bonuses to "Informative" and "Insightful".
Conversely, they also tended to further decrease the rating values associated with negative labels.
These users are elevating weights in the rating system to create a schema whereby highly rated and lower rated comments are winnowed dramatically.
This shows that some users have already customized a Gem Seeker view that could possibly be of use to future readers.
The Rating Suppressor group assigned negative weights to all categories.
Such a change would make comments that had received no moderator labels at all more prominent than those that had received labels of any kind.
Conversely, the third cluster of users, the Free Thinkers, assigned positive weights to all categories.
The effect of such a change would be to give more prominence to comments that had attracted moderator attention.
As shown in Table 2, some users assigned positive ratings to typically negative labels like "Troll" and "Flamebait".
It could be that these users are setting a cluster of modified labels that bring poorly rated comments to light.
A schema for Muck Rakers might be of use to those who find entertainment value in the personal insults and deceptions that constitute "Troll" and "Flamebait" comments.
This data supports a view of Slashdot users with heterogeneous goals in reading comments who use the label weighting system to enact those goals.
Users without the ability to similarly customize, either because they are anonymous users without the option or high-friction registered users, may benefit from viewing schemas based on those users who do create custom ratings.
Here we focus on automatic threshold changes, where the system infers, for a particular story, that a user would be likely to prefer a different setting.
Given the costs involved in manual changes to settings, we have limited information about whether, for particular stories, users would have preferred different threshold levels than the ones they actually used.
However, we can get some indicator about what kinds of stories would benefit from local increases in filter thresholds by examining the behavior of lead users, those who seem to have less friction in making local changes.
We examine the behavior of users who read at least five stories during our study period, and made at least one local increase in their filtering threshold.
There were 884 such users; they read a total of 428 distinct stories during the study period, and increased their threshold while reading 23% of them.
We constructed a logistic regression model to predict when our lead users decided to make local increases in their filter thresholds.
Several factors enter the equation as independent variables.
First, of course, is the default threshold set in each user's profile: as Figure 3 showed, threshold increases were far more likely from a +1 threshold than at +4 threshold .
The second factor is the total number of comments that had been written about a story at the time the user read that story and its associated comments.
The third factor is the quality of those comments, as measured by the percentage that achieved scores of 3 or higher.
Analogous to collaborative filtering, where the opinions or behavior of other people leads to recommendations about items to attend to, the threshold choices of other users can be mined to predict when users increase thresholds: if many past readers increased their thresholds, the current reader may be more likely to as well.
For each reading of a story we computed the percentage of previous reads of that story by other lead users where the users increased their filtering thresholds.
Table 5 shows results of estimating the binary logistic  regression model.
The base result is for users with a permanent threshold of -1.
When interpreting a logit model, positive coefficients indicate higher probabilities.
Users with thresholds set at 0 or +1 in their permanent profiles were more likely to make a one-time increase in the filtering threshold than those with a permanent threshold of 1.
This makes sense since presumably those who have permanent thresholds of -1, which turns off filtering, are less likely to want to turn it on.
On the other hand, those with permanent thresholds of 3 or 4 were less likely to make onetime increases.
They have relatively little to gain from increasing thresholds from their already high levels.
Given the apparent friction, that users who would prefer other settings will not necessarily select them, there are opportunities for the system to assist in those selections.
For example, based on the pattern of local changes a user makes, the system could offer to make changes in the user's permanent profile.
Thus, in the regression model, there would not be any additional effect attributed to those factors.
This can not explain the negative coefficients, however.
One explanation may be that more comments and more highly rated comments are indicators of better conversations, and readers increase thresholds only for lower quality conversations.
We found that registered Slashdot users could be divided intro three categories: those who never change the default comment display, those who use ratings to modify the comment display, and those who change the comment display to suppress ratings.
Although a significant portion of users did not change from system set defaults, an even larger group of users employed ratings to modify how comments were displayed in the forum.
Interestingly, a non-trivial segment of users made modifications to diminish the effects of comment rating.
For those users who don't make changes, or only make changes rarely, we find some indication that a type of friction exists, preventing commonplace comment view modifications.
This friction is related to the perceived cost of changing opposed to the perceived benefit for having done so.
A possible remediation for this friction is to support comment view changes based on the behavior of other users.
One aspect of this is the use of schema labels as meta-data to create groups of user types, allowing highfriction users to take advantage of the customization done by others.
Another idea for of dynamic filtering is to use the behavior or Slashdot readers who seem to have low friction and active reading patterns, i.e.
Since the collection of these data, Slashdot has made an interface change that allows users to change comment thresholds by selecting up and down javascript arrows that correspond to "more" or "less" content.
Future research should examine how this interface change has affected user reading behavior.
This research indicates that Slashdot readers have different goals in reading comments, and widely support those goals by leveraging comment ratings.
Using previous experiences from users who change options easily, it is possible to further expand the role of ratings in structuring large-scale online conversations to provide customized, worthwhile content to a heterogeneous community of users.
Somewhat surprisingly, this is not the case: both more comments and a higher percentage of comments getting scores above 2 led to decreases in the probability that users would increase their threshold.
While statistically significant, the level of impact of the total number of comments is small.
For a lead user with initial threshold of +1, reading a story with the median number of comments , with the median percentage of highly rated comments , and the median percentage of previous lead users increasing their thresholds , the predicted probability of this user increasing his threshold while reading the story is 46%.
If, instead, there were 350 comments , the probability of increasing his threshold would decrease to only 44%.
The impact of the percentage of highly rated messages is also comparably small.
If that percentage increases to 22% , the predicted probably only makes a slight further decline, to 43%.
On the other hand, the behavior of prior users is both statistically and practically significant.
If the percentage of prior users who increased their threshold moves from 30% to 42% , the predicted probability jumps all the way to 60%.
This large impact suggests that a collaborative filtering style interface, where the threshold decisions of early readers affects the automatically selected thresholds of later readers could be quite effective.
Ackerman, M.S., Swenson, A., Cotterill, S. and DeMaagd, K., I-DIAG: From Community Discussion to Knowledge Distillation.
Adamic, L. and Glance, N., The Political Blogosphere and the 2004 U.S. Election: Divided They Blog.
Membership Size, Communication Activity, and Sustainability: A Resource-Based Model of Online Social Structures.
Crawford, S., McCabe, S., Couper, M. and Boyd, C., From Mail to Web: Improving Response Rates and Data Collection Efficiencies.
Mining interesting knowledge from weblogs: a survey.
Findlater, L. and McGrenere, J., A comparison of static, adaptive, and adaptable menus.
From laboratories to collaboratories: A new organizational form for scientific collaboration.
Social and Temporal Structures in Everyday Collaboration Information and Computer Science, University of California, Irvine, 2004, 214.
10.Jones, Q. and Rafaeli, S., User Population and User Contributions to Virtual Publics: A Systems Model.
11.Jones, Q., Ravid, G. and Rafaeli, S., An empirical exploration of mass interaction system dynamics: Individual information overload and Usenet discourse.
12.Jones, Q., Ravid, G. and Rafaeli, S. Information Overload and the Message Dynamics of Online Interaction Spaces: A Theoretical Model and Empirical Exploration.
13.Kelly, J., Fisher, D. and Smith, M., Debate, Division, and Diversity: Political Discourse Networks in USENET Newsgroups.
15.Lampe, C. and Resnick, P., Slash and burn: distributed moderation in a large online conversation space.
16.Mackay, W.E., Triggers and barriers to customizing software.
The Magical Number Seven, Plus or Minus Two: Some limits on our capacity for processing information.
20.Resnick, P. Beyond Bowling Together: SocioTechnical Capital.
HCI in the New Millenium, Addison-Wesley, 2001.
21.Resnick, P., Iacovou, N., Suchak, M., Bergstrom, P. and Reidl, J., GroupLens: an open architecture for collaborative filtering of netnews.
23.Smith, M. Measures and Maps of Usenet.
From Usenet to CoWebs: Interacting with Social Information Spaces, Springer Verlag, New York, NY, 2002.
24.Terveen, L. and Hill, W. Beyond recommender systems: Helping people help each other.
HCI in the New Millennium, Addison-Wesley, New York, 2002.
25.Viegas, F.B., Wattenberg, M. and Dave, K., Studying cooperation and conflict between authors with history flow visualizations.
