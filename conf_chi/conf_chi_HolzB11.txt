Current touch devices, such as capacitive touchscreens are based on the implicit assumption that users acquire targets with the center of the contact area between finger and device.
Findings from our previous work indicate, however, that such devices are subject to systematic error offsets.
This suggests that the underlying assumption is most likely wrong.
In this paper, we therefore revisit this assumption.
In a series of three user studies, we find evidence that the features that users align with the target are visual features.
These features are located on the top of the user's fingers, not at the bottom, as assumed by traditional devices.
We present the projected center model, under which error offsets drop to 1.6mm, compared to 4mm for the traditional model.
This suggests that the new model is indeed a good approximation of how users conceptualize touch input.
The primary contribution of this paper is to help understand touch--one of the key input technologies in humancomputer interaction.
At the same time, our findings inform the design of future touch input technology.
They explain the inaccuracy of traditional touch devices as a "parallax" artifact between user control based on the top of the finger and sensing based on the bottom side of the finger.
We conclude that certain camera-based sensing technologies can inherently be more accurate than contact area-based sensing.
Figure 1: A study participant targeting crosshairs using different finger angles.
Can you guess how this user is conceptualizing touch, i.e., what geometric relationship between finger and crosshairs the user is trying to maintain independent of how the finger is held?
Our findings suggest that users indeed target as suggested by this illustration, i.e., by aligning finger features and outlines in a hypothesized top-down perspective.
Our recent findings seem to put this assumption into question.
While the "contact area model" is clearly plausible on a macroscopic scale, our earlier findings with very small targets indicate that touch input on such devices is subject to systematic error offsets .
In fact, as much as two thirds of the overall inaccuracy of touch seem to be caused by these effects.
When users target with an almost horizontal finger, for example, the target position measured by a capacitive touch device is off by as much as several millimeters--on small screens devices this is a substantial effect.
In our earlier studies, the size and direction of the error offset was affected by a range of parameters, including finger posture measured in roll, pitch, and yaw .
In the aforementioned paper, we compensated for this effect using an elaborate schema of corrective offsets .
The existence of these systematic offsets, however, raises much deeper questions.
In particular, the existence of these offsets seems to indicate that the assumption these devices are built on, i.e., that users target based on finger contact area, is wrong.
Current touch technologies, such as capacitive touchpads  and FTIR , sense touch by observing the contact area between finger and device.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
In order to help us specify what we are trying to find out, Figure 2 illustrates the general concept of touch input: users communicate a 2D target location to a touch device.
As users acquire a target with their finger, such as the shown crosshairs , they effectively translate the 2D target location into the 6D posture of their finger .
As a preview of our analysis, take a look at the sequence of images shown in Figure 1.
They show a user  targeting a pair of crosshairs with different finger angles.
Looking across the sequence of images, we may already catch some indication of what mental model of touch this user adheres to.
Certain geometric relationships between finger and crosshair seem to remain--independent of what finger posture the experimenter makes this participant assume.
The participant shown in Figure 1 is a particularly good representative of the new model of touch we propose and which we call the projected center model.
This model says that users align certain visual features with the target.
In the shown example, it is the horizontal center of the finger outline and the vertical center of the fingernail that the user is aligning with the target.
We chose the specific viewpoint of this image sequence with intent: even though the user's head was actually located to the bottom left of the picture during these trials, our findings suggest that users imagine this top-down perspective during touch input.
Based on this perspective, they decide whether their finger is on target or whether it requires adjustment.
Figure 2: When acquiring a target, here marked with 2D crosshairs , users effectively translate the 2D position of the target into a 6D position of their finger.
On traditional touch devices, the finger leaves a contact area , which is observed by the touch pad and reduced to its 2D centroid .
Under the projected center model, the error offsets of the contact area model effectively disappear , suggesting that the projected center model matches users' mental model of touch very closely.
The projected center model also explains why capacitive touch input devices are inaccurate: devices based on the contact area touch model sense features located at the bottom of the users' fingers, while users target based on features located on the top/along the sides of their fingers.
The inaccuracy of touch on traditional touch devices is therefore an artifact of the parallax between the top and bottom of a finger.
The objective of any touch input device is to invert this translation, i.e., to reconstruct the 2D target location from this 6D finger posture.
We will refer to this 6D-to-2D mapping as the device's conceptual model.
Perfect reconstruction is achieved if and only if the mapping implemented by the touch device is indeed inverse to the 2D-to-6D mapping implemented by the user, i.e., if the device's conceptual model matches the user's mental model.
Current touch devices implement this back-translation as illustrated by Figure 2c and d: They observe the 2D contact area between finger and pad  and reduce it to its centroid .
As explained earlier, however, our previous findings indicate that this contact area model is not correct, i.e., it does not reconstruct the intended input position accurately.
Apparently, users do not aim by pointing using the center of the contact area.
Note: throughout this paper, we will use an apparatus similar to Figure 2, i.e., crosshairs marking the target.
In our previous studies, crosshairs performed indistinguishably from a dot target , which suggests that the influence of crosshairs onto users' mental model of touch is reasonably small.
In the remainder of this paper, we present a series of studies that validate the reasoning outlined above.
Many models in HCI are created by measuring a feature and fitting a function to it.
Unfortunately, we do not know yet what feature to measure or even what modality .
This forces us to take a more general approach to the problem: " Guess the law ,  compute the consequences, and  compare the computation to experiment/observation.
If it disagrees with experiment it is wrong ."
In this paper, we apply these three steps as follows:  Before we attempt to guess mental models, we narrow down the search space.
We conduct a series of interviews and then consider only the subset of models that are based on features mentioned by participants.
Since our primary goal is to understand touch, we require the remaining error offsets of a good candidate model to be small.
Only when the remaining offsets get reasonably close to zero can we argue that the tested model indeed corresponds to the actual mental model of the respective user and thus contributes to an explanation of touch.
We proceed in four steps.
Step 1--Interviews: We interview users to learn how they  target using touch input, i.e., what features they try to align with the target.
Step 2--Model creation: Based on participants' input, we create a set of 77 candidate models.
User input inspires us to focus on models based on a top-down perspective.
Step 3--Filtering models: We conduct two pointing studies in which we determine error offset for all candidate models under different variations of finger and head postures.
We eliminate models with large offsets, as they indicate a poor representation of participants' mental models.
We keep 23 candidate models.
Step 4--Final evaluation: We conduct a final pointing study using the combined set of independent variables from the studies in Step 3  to determine the error offsets and thus the "fit" of the remaining models.
Camera-based systems, such as the Digital Desk , typically cannot see the contact area and have therefore adopted a visual model.
The Visual Touchpad uses two cameras to identify the user's fingertips and determine finger yaw .
LucidTouch centers the contact point in the outline at a fixed offset from the fingertip .
PlayAnywhere observes fingers from above with a camera mounted at an angle and derives touch input from the distance between the user's fingers and the shadows they cast .
The inaccuracy of touch has been attributed to the fat finger problem , i.e., the softness of the fingertip in combination with the fact that the finger occludes the target.
A series of targeting aids alleviate the problem by enlarging the target, e.g., TapTap   and Dual Finger Stretch .
Others avoid occlusion altogether by introducing an offset between finger and target, e.g., offset cursor , shift , cross-lever and precision handle , as well as the use of styli .
Back-of-device interaction  avoids occlusion by moving the user's finger to the device's back.
We primarily make a scientific contribution.
With scientific we mean: an attempt to understand an underlying, not directly observable mechanism--in our case touch input, one of the key technologies in human computer interaction.
In particular, we explain why current touch devices are inaccurate by challenging the common assumption that touch input is about the contact area.
Still, essentially as a side effect, our findings have implications on engineering in that they inform the design of better touch input technology.
They suggest that devices that observe the outline or "projection" of a finger have the potential to offer better touch precision than devices based on contact area.
Modeling cursor-based target acquisition has a long tradition.
Fitts' Law models the targeting time for onedimensional targets .
Grossman and Balakrishnan's probabilistic pointing models two-dimensional target acquisition under visual control .
Both models assume that users can see target location and pointer, a requirement not fulfilled by touch on targets that are small enough to be occluded by the user's finger.
While touch systems traditionally reduce contact areas to a point , more recently researchers have proposed considering the entire contact area as input, such as Shapetouch  and Sliding Widgets .
Several researches suggested that the angle between the user's finger and the device might impact pointing.
When designing the shift technique, Vogel and Baudisch  included a correction to compensate for parallax.
Wang and Ren find that finger posture and motion impact the size of the contact area .
We generalized these findings in our previous work on the generalized perceived input point model .
To illustrate the error offset problem faced by devices based on the contact area model we reprint an extract of the data from this paper .
All 12 participants  repeatedly acquired a target on a touchpad under varying finger roll and pitch angles.
A wide range of touch technologies determine the input coordinates based on contact area .
Most optical technologies have adopted the same approach, such as frustrated total internal reflection .
Wang and Ren examined participants' input precision on such an optical system .
While ova als were small, they were off ffset with respe ect to o each other, which implied the need fo or the aforeme enti ioned corrective offsets.
On nly for Partici ipant #3  ovals align, a suggesti ing that this was w the only pe ers son the targetin ng behavior of f whom was appropriately a ded s scribed by the contact c area mo odel.
T The purpose of this study was w to learn mo ore about user rs' m mental models by means of an interview.
While users are a k known to have limited abil lity of rationa alizing low-lev vel a activities, our goal g was to cr reate a selectio on of potential lly r relevant models and elements that could be e used to form ma li ist of candidat te models.
We e did not worry y about incorre ect m models at this stage, as we would w eliminate e these in subs seq quent steps of our o process.
When asked to verbalize their "tar rgeting proced dure", most particip pants hesitated d. 4 participant ts insisted that they could not exp plain their behavior and "just t touched the ta arget intuitively w without giving g it too much th hought".
6 parti icipants stated right away th hat their exper rience with mobile e touch-screen devices had s shaped their in nput behavior.
W While two of th hem understoo od how such d devices determine e input coordi inates, they all l stated to aim m based on experie ence with the device.
They all said that the device had "ta aught" them ho ow to touch sm mall buttons ove er time.
Contac ct Area: 26 p participants sai id that they considered contact t area to be re elevant to their r targeting strat tegy.
24 of them s stated that the ey imagined th he contact are ea between their fi inger and the c crosshairs and centered it on n the target during the trials.
I In order to help p participants become aware e of their ment tal m models of touc ch input, participants started by repeated dly a acquiring a tar rget.
As show wn in Figure 4, , the target was w m marked by crosshairs drawn on a sheet of f paper and each p participant acqu uired it 50 time es.
Participants s were instructed to o place their finger f such tha at it would "acquire a tiny bu utto on located at the center of th he crosshairs if f the paper was sa to ouch screen".
I In order to hel lp participants s investigate th heir own ment tal m models in more e detail, partici ipants acquired d the target usin ng th he five finger postures show wn in Figure 5, 5 i.e., combin nati ions of finger pitch p and roll.
All participant ts completed th his p part of the study in 10 minute es or less.
A After they had completed the e trials, we inte erviewed partic cip pants about the e strategies they y had used to acquire a the targ get a and based on what criteria they had deci ided when the eir f fingers were "o on target".
We e were careful l not to use an ny terms that coul ld bias their an nswer, such as s "contact area a",
Particip pants' drawing gs of contact areas in the fo our figures suppor rted our assum mption that they y cannot fully rationalize their b behavior.
Most t drawings larg gely clashed w with reality; for a finger at a flat angle  the contact area while f extend ds fairly far t towards the u user's palm, p participants always s drew it too small.
Simila arly, for a rol lled finger , p participants dr rew the contact t area too large e and mostly cent tered inside th he finger, whe ereas in fact it t is mostly offset h horizontally an nd rather short.
Three participants m mentioned a sp pecial version of contact hey claimed to o touch the ta arget with the part of the area; th finger that "comes d down first".
Fi ive other partic cipants explained d to place thei ir finger such that it applied d the maximum a amount of pressure to the targ get.
Visual Feedback: 13 3 participants reported that they posiusing visual c control.
They stated that tioned their finger u mentally conne ected the cross shairs under t their finger they m and tri ied to move th heir finger suc ch that the targ get was always lo ocated under th he same positio on inside their finger.
Nine participants explained that they positioned the finger, such that the target was located at a certain distance from the edge of their fingernail.
Four other participants said they imagined a virtual 3D point inside their finger, which they repeatedly sought to position directly above the target.
Two other participants said that they "projected" a feature in their finger down to the table and then aligned it with the target.
This is an interesting observation, because such a projection is a comparably complex 3D operation that requires users to take head parallax into account.
Two participants described their targeting strategy as "cheating".
Both had a visible spot on their fingernail that they vertically aligned with the target whenever finger roll was 0.
For roll different from 0 they still aligned the spot with the horizontal line of the crosshairs.
Figure 7 shows a series of features that we found to be visible from above.
We classified them as horizontal features if they might help determine the finger's horizontal position and vertical features if they might help determine the finger's vertical position; some features, such as the corner of the fingernail are both .
Note the three-dimensional nature of the finger, which causes features, such as outline center to refer to the outline of the skin for some levels of finger roll and to the outline of the nail for other levels of finger roll.
While the study allows proposing a wide range of possible models that explain how participants targeted, such as models based on a camera that tracks with the user's head, we decided to make an educated guess and limit our search for candidate models to those based on features that users can perceive visually and from directly above.
This seemed plausible given that thirteen participants mentioned visual features and six of them mentioned some sort of vertical projection.
As discussed earlier when stating our 3-step approach, whether or not our intuition was right would have to be determined in the following pointing studies.
If the model should perform poorly, our guess would turn out to be wrong and we would have to come back and restart the process with another model .
In theory, users' mental models might combine any number of features in arbitrarily complex ways.
We felt, however, that the effortlessness of touch pointing suggests that only simple models are truly plausible.
We therefore only included models that use a single feature  and models that refer to the center point between two features, such as "sl|sr" for the mental model of users who aim relative to the center point of the finger's outline, i.e., between "skin left" and "skin right".
We will refer to terms such as "nr" or "sl|sr" as half models, because it takes two of them to describe the mental model of a user--one for x and one for y.
To avoid the overhead of evaluating the cross product of horizontal and vertical features, however, we keep these two classes of features and models separate throughout most of this paper and will not combine them until the final study.
Figure 8 lists the horizontal and vertical half models that we created from the respective features shown in Figure 7.
We constructed the following two  candidate models  contact area, which had produced a good fit for one user in our previous study , shown as Participant #3 in Figure 3 and  models based on features of human fingers that are visible from above.
We implemented this by tracking users' fingers using a camera placed directly above the crosshairs on the touchpad.
Distrac cters have a m major effect o on adaptive i input techniques , but not on un nmodified touch h. urpose of usin ng crosshairs w was to reduce n noise, thus The pu helping g us observe the underlyin ng mental mo odels more clearly y.
While the u use of visible c crosshairs may y in theory impact t participants' targeting beha avior, we did n not observe any suc ur studies.
N Next we elimin nated those  models tha at did not match th he mental mod dels of any use ers.
In order to o do so, we co ond ducted a pointi ing study.
Using a camera above a the targe et, w we recorded pa articipants as they t repeatedly y acquired a ta arg get on a capac citive touch pa ad.
We then tr ried to "explain n" th he observed da ata using each h of our half models m and elim min nated all half models m that did not fit any par rticipants.
T To keep the ov verall number of repetitions manageable, we w b broke this study y down into tw wo individual studies.
As sho own in Figure 10, we used th he same comb binations of finger pitch and finge er roll as we d did in previous work .
P Participants rep peatedly acqui ired a crossha air target located o on a touchpad d .
During D each tr rial, participan nts f first touched a 1"1" "start" " button locate ed 2" left of th he ta arget.
Particip pants then assu umed the finger angle for th he c current conditio on with their right r index fing ger and acquired th he target.
Part ticipants comm mitted the touc ch interaction by b p pressing a foo otswitch.
This recorded the e touch locatio on r reported by the touchpad, tr riggered the ca amera to take a p picture, played d a confirmation sound, and d completed th he tr rial.
Participan nts did not rec ceive any feed dback about th he lo ocation registe ered by the touc chpad.
Overal ll, participants performed a sequence of 12 angles  2 repetiti ions totaling 2 24 trials.
The o order of pitch-r roll combinations s was counte erbalanced ac cross participa ants.
Then particip pants filled ou ut a post-study questionnaire.
All participants completed the study in 15 mi inutes or less.
The stu udy apparatus recorded cont tact area using g a capacitive to ouch pad and c captured a pic cture of the pa articipant's finger using an overh head camera.
T The capacitive pad was a 6.5"  4.9" FingerWo Works iGesture; the camera wa as a Canon EOS 45 50D, capturing g participants' fingers at 140d dpi.
Participants committed tria als using a Bos ss FS-5U foots switch.
All onents were co onnected to an n Intel Core 2 Duo macompo chine r running Windo ows XP.
W We took the fo ollowing four measures to minimize m the im mp pact of other potential p factor rs.
First, participants kept the eir h head in a fixed d position abo ove the touchpad, as shown in F Figure 9.
This controlled for r parallax.
Sec cond, the cros ssh hairs marking the target extended beyond participant ts' f fingers, allowin ng participants s to maintain a certain amou unt o of visual cont trol during targeting.
Third d, the use of a f footswitch to commit c input allowed us to o avoid artifac cts c common with other commit methods, such h as inadverte ent m motion during take-off.
During g a pilot study y, we attached markers to pa articipants' fingers s in order to al llow for autom mated tracking.
However, particip pants mentione ed that the mar rkers distracted d them and some p participants ha ad started to i include them a as features into th heir targeting m model.
We ther refore dropped d the markd instead annot tated visual fea atures in the ph hotographs ers and by han nd.
Figure 11a shows which vertical half models produced the best fit  for how many participants.
We consider a half model to produce the best fit if the systematic offsets produced by this half model for each condition have the smallest distance from the center of mass of all error offsets produced by that model, across all half models.
No single model offers the best fit for all users, suggesting that different users may have different mental models.
The half model t|b, i.e., the vertical center of the fingernail performs best here--it offered the best fit for 9 participants.
It is followed by ng|b a slightly different version of the vertical center of the fingernail, with another 6 participants.
As expected based on  , the contact area model offers the best fit for a very small number of participants, here only 1 out of 30.
Figure 11b shows how well different subsets of vertical half models combined fit the data.
Bars represent the average vertical error offset if participants' data is processed using only the respective half models.
The red bar on the left represents the error offsets produced by the capacitive baseline condition contactarea.
Figure 12a shows the corresponding data for the horizontal half models.
The half model oc  produced the lowest error for over a third of the participants .
The contactarea model offered the best fit for 5 of the 30 participants.
The benefit of using per-participant models is only a factor of 1.4 and, thus, by far not as large as in the vertical case .
This is a result that we expected based on our previous results , because of the smaller horizontal extent of clusters in Figure 3.
Horizontal error has always been smaller, thus there is less potential for improvement.
Figure 11:  Number of participants for which each vertical half model produced the lowest error.
Switching from the model contactarea to t|b reduces error offsets to 44%; using all models listed in  reduces the error to 37% compared to the contactarea model.
The green bar on the right in Figure 11b represents the error offsets produced if every participant's input were processed using their personal best-fit model from Figure 11a; the switch to the best fit model reduces the error offsets by about 63%.
We will refer to this best-fit case as "perparticipant models" in the remainder of this paper.
Some of the half models listed as best fit model are similar.
As a result it may not be necessary to maintain all of them.
The gray bars in the middle of Figure 11b show how error rate increases if we drop some of the half models.
We see that dropping all but three models  incurs a penalty of only 5% compared to using all vertical half models.
Dropping all models but t|b incurs a penalty of 18.5% over the best-fit case.
The contactarea model alone, however, leads to large error offsets .
Overall, each participant completed a sequence of 2 pitch angles   2 roll angles   4 head positions   2 repetitions = 32 trials, in four blocks, one for each head position.
Finger angles as well as head positions were counterbalanced across participants.
Participants filled out a post-study questionnaire.
All participants completed the study in about 20 minutes.
Figure 15:  Number of times each of the horizontal models produced the lowest-error offsets per participant.
The three horizontal half models oc, sl|sr, and t|b alone account for this improvement.
As in the previous study, the half models describing the vertical center of the fingernail together  produced the best fit for half of all participants .
The contact area model, in contrast, never produced the lowest-error offsets for any participant in this study.
Again, we can reduce the number of half models without sacrificing too much precision; keeping only the vertical model t|b incurs a penalty of 6.5% over using all vertical half models.
It still reduces the error of the contact area model by a factor of 2.5.
5 mm As shown in Figure 14b, the use of per-participant best-fit half models reduced the error offsets 4 mm to 1.8mm, from 5mm of the contact area model to 40% of 3 mm that value.
Figure 16 lists the remaining candidate half models.
We obtained this list by eliminating all models that did not produce at least one best fit in either one of the two studies.
In addition, we eliminated all models the addition of which would have decreases error only marginally--the benefits of including nr, ng|b, and nt|b in the last study, for example, were less than 1%.
However, we did maintain the two halves of the contact area model as well as the model t : both have been implemented in products and related work, so we wanted to see how they do in the final study.
If we take a closer look at the three remaining horizontal half models, we notice that all of them are versions of the center of the finger outline, only sampled at different locations, i.e., at the bottom of the nail , at the location of the nail grooves , and at the horizontal center of the contact area.
The three remaining vertical half models describe the target location either in relation to the fingernail  or as an offset for the top of the fingertip .
As in the previous study, the horizontal half model oc produced the best fit for the largest number of participants .
Compared to the previous study, the capacitive half model produced the best fit for a similar fraction of all participants .
As in the previous study, the use of per-participant half models produced only a moderate reduction of error offsets over the contactarea model .
The purpose of this final study was to evaluate the remaining half models.
We could not re-use the data from the previous studies, because we had already used this data for learning and eliminating the very same half models.
More importantly, though, participants had performed only few trials per condition; thus the data did not allow us to distinguish error offsets from random noise .
In this final study, we addressed this by increasing the number of repetitions to 4 trials per condition and two blocks.
Aggregating these eight trials substantially reduced fat-finger noise and thus revealed the systematic error offsets we were looking for more clearly.
Figure 20 shows error offsets for the eight full models from Figure 19.
A one-way ANOVA with participant as a random variable found a significant main effect of model on error offsets .
Post-hoc t-tests using Bonferroni correction found that all six other models and the per-participant best-fit aggregate produced significantly lower error offsets than contactarea .
Figure 18:  Number of times each of the horizontal models produced the lowest error.
The best individual model was oc&t|b.
It says that participants target by placing the horizontal center of their finger outline and the vertical center of fingernail over the target.
In the introduction to this paper, we already referred to this model using the name projected center model and the images shown in Figure 1 are best explained using this model.
In summary, the projected center model performed best out of all the models tested.
Under the projected center model, the large systematic offsets of 4mm observed by the contact area model shrink down to 1.6mm, an improvement by a factor of 2.5.
At the same time, the remaining offsets are close enough to zero to suggest that this model approximates participants' mental model indeed well.
This is the main finding of this paper.
The final study did not produce anything unexpected as the performance of the participating half models was similar to the previous two studies.
As shown in Figure 18a, both oc and sl|sr produced the best fit for 5 of the 12 participants; t and t|b produced the best fit for 5 participants each.
While the use of all three horizontal half models yields only 15%
Switching to an engineering perspective for a moment, we might be interested in how devices built on these different models will perform, as this might inform which models to base future devices on.
So far, we have discussed models based on systematic offsets, as that is a good metric for testing the quality of mental models.
To answer questions about device performance, we add the other error variable, i.e., spread, back in.
The resulting minimum button sizes for 95% reliable touch input are shown in Figure 21.
These values specify how accurately a device based on the respective model can be expected to perform.
The chart shows that devices based on the projected center model allow users to acquire targets of 4.9mm with 95% accuracy, compared to 7.9mm target size for the corresponding contact area model .
In terms of target surface this difference amounts to a factor of 2.6.
This means that a device implementing the projected center model could pack 2.6 times more targets into the same screen space or, alternatively, that a device could be reduced to less than half its size and still allow users to operate it reliably.
In this paper, we conducted an exploration of users' mental models of touch.
Our primary contribution is scientific.
The fact that under the proposed projected center model the error offsets found by our previous work essentially disappear suggests that this model is likely to closely match how users proceed while acquiring a target on a touch device.
On the other hand, our findings suggest that systems that track fingers using cameras from above have the potential for substantially better pointing accuracy than capacitive sensing as currently implemented, even simpler devices that track fingers based on finger outline alone.
For reference, in Figure 21 we also included the 4.3mm minimum target size that we previously achieved by attaching retro-reflective markers to the users' finger and tracking using an optical tracking system .
Based on 600 repetitions of training data, it removes all known offsets, so that this model can be considered a current lower bound for touch accuracy.
In comparison, the 4.9mm minimum button size of the calibration-free projected center model gets surprisingly close.
In order to implement the projected center model a device needs to be able to reliably locate a user's fingernail, which is technically challenging.
Figure 21 points out an alternative.
At 5.35mm minimum button size, the oc&t model does not quite reach the 4.9mm of the projected center model.
However, it is comparably easy to manufacture, as this approach only requires locating finger outlines in a camera positioned above the target, namely the outlines of the sides and the top of the finger.
This approach has already been explored in a number of research prototypes, such as CSlate  and LucidTouch .
