HCI research has for long been dedicated to better and more naturally facilitating information transfer between humans and machines.
Unfortunately, humans' most natural form of communication, speech, is also one of the most difficult modalities to be understood by machines - despite, and perhaps, because it is the highest-bandwidth communication channel we possess.
While significant research efforts, from engineering, to linguistic, and to cognitive sciences, have been spent on improving machines' ability to understand speech, the CHI community  has been relatively timid in embracing this modality as a central focus of research.
This can be attributed in part to the relatively discouraging levels of accuracy in understanding speech, in contrast with often-unfounded claims of success from industry, but also to the intrinsic difficulty of designing and especially evaluating speech and natural language interfaces.
As such, the development of interactive speech-based systems is mostly driven by engineering efforts to improve such systems with respect to largely arbitrary performance metrics.
Such developments have often been void of any user-centered design principles or consideration for usability or usefulness.
Copyrights for third-party components of this work must be honored.
For all other uses, contact the Owner/Author.
Copyright is held by the owner/author.
Through this, we hope that HCI researchers and practitioners will learn how to combine recent advances in speech processing with user-centred principles in designing more usable and useful speechbased interactive systems.
Cosmin's multidisciplinary interests include speech and natural language interaction for mobile devices, mixed reality systems, learning technologies for marginalized users, assistive technologies for older adults, and ethics in human-computer interaction research.
Gerald Penn Department of Computer Science, University of Toronto http://www.cs.toronto.edu/~gpenn/ Gerald Penn is a Professor of Computer Science at the University of Toronto.
His area of expertise is in the study of human languages, both from a mathematical and computational perspective.
Gerald is one of the leading scholars in Computational Linguistics, with significant contributions to the formal study of natural languages.
His publications cover many areas, from Theoretical Linguistics, to Mathematics, and to Automatic Speech Recognition, as well as HumanComputer Interaction.
Cosmin Munteanu Institute for Communication, Culture, Information, and Technology, University of Toronto Mississauga, and Technologies for Ageing Gracefully Lab , University of Toronto http://cosmin.taglab.ca Cosmin Munteanu is an Assistant Professor at the Institute for Communication, Culture, Information, and Technology , and Associate Director of the Technologies for Ageing Gracefully lab.
Until 2014 he was a Research Officer with the National Research Council of Canada, where he designed mobile and immersive natural user interfaces for a wide range of applications.
His area of expertise is at the intersection of Human-Computer Interaction, Automatic Speech Recognition, Natural Language Processing, Mobile Computing, and Assistive Technologies.
He has extensively studied the human factors of using imperfect speech recognition systems,
The most recently-presented tutorial slides are available as a sample at: http://www.cs.toronto.edu/~mcosmin/speech_tutorial/ chi2015_speech-interaction_course.pdf The proposed CHI presentation is continuously updated to include more examples and analysis of recent commercial adoption of speech recognition, notably developments on mobile platforms .
Similar to previous courses, and based on the feedback received from participants, the proposed CHI course material is currently being updated with new interactive examples and short group exercises.
A new sub-topic that was developed for the presentation at CHI 2015 is interactive speech-based applications centred around language translation, language learning support, and interacting across multiple languages.
This was well-received by our CHI 2015 audience and will be updated and expanded for the proposed CHI 2016 tutorial.
The aim of the presentation is two-fold: present new concepts to the audience, and foster discussions and exchange of ideas.
Slides will be used to introduce the main points, while videos and audio clips will be played to illustrate various examples.
After  each of the main concepts of the tutorial outline is presented, time will be allocated for interaction between presenters and audience.
Cosmin Munteanu and Gerald Penn: "Hands-free Interfaces: The Myths, Challenges, and Opportunities of Speech-based Interaction", tutorial presented at the MobileHCI Conference, 2010, 2011, 2012, 2013, and 2014.
In-class activities and examples will fit this theme, through the use of case studies from Prof. Munteanu's extensive research in these areas.
The course also includes two interactive, hands-on activities.
For the second activity, participants will conduct an evaluation of the quality of the synthetic speech output typically employed in mobile-based speech interfaces, and propose alternate evaluation methods that better reflect the mobile user experience.
The course will be beneficial to all HCI researchers or practitioners without a strong expertise in ASR or TTS, who still believe in fulfilling HCI's goal of developing methods and systems that allow humans to naturally interact with the ever increasingly ubiquitous mobile technology, but are disappointed with the lack of success in using speech and natural language to achieve this goal.
Ideal number of participants: the course interactive activities are based on forming groups of 4-6 participants.
As such, there is no minimum or maximum recommended number of participants.
In the past, this course has been typically attended by 20 to 50 participants.
No prior technical experience is required for the participants.
The classroom activities will be conducted using the participants' smartphones  - no software download will be required .
Participants will work in small groups, ensuring that even participants without smartphone are able to fully contribute.
