We describe the critiquing approach to building knowledge-based interactive systems.
Critiquing supports computer users in their problem solving and learning activities.
The challenges for the next generation of knowledge-based systems provide a context for the development of this paradigm.
We discuss critics from the perspective of overcoming the problems of high-functionality computer systems, of providing a new class of systems to support learning, of extending applicationsoriented construction kits to design environments, and of providing an alternative to traditional autonomous expert systems.
One of the critiquing systems we have built - JANUS, a critic for architectural design - is used as an example of the key aspects of the critiquing process.
We also survey additional critiquing systems developed in our and other research groups.
We describe the critiquing approach to building knowledge-based interactive systems.
Critiquing supports computer users in their problem solving and learning activities.
The challenges for the next generation of knowledge-based systems provide a context for the development of this paradigm.
We discuss critics from the perspective of overcoming the problems of highfunctionality computer systems, of providing a new class of systems to support learning, of extending applicationsoriented construction kits to design environments, and of providing an alternative to traditional autonomous expert systems.
One of the critiquing systems we have built JANUS, a critic for architectural design - is used as an example of the key aspects of the critiquing process.
We also survey additional critiquing systems developed in our and other research groups.
This paper combines our experience with the research efforts of others to articulate foundations and characteristics for the critiquing paradigm.
We describe the rationale for critiquing and illustrate the approach using one of our systems  as an example.
A general characterization of the critiquing process is abstracted.
Other systems are surveyed in terms of this critiquing framework.
The next generation of knowledge-based systems will face the following challenges: * They will be high-functionality systems, and their complete mastery will exceed most individual's cognitive capabilities.
We will discuss how critics can meet each of these challenges in turn.
The critiquing approach is an effective way to make use of computer knowledge bases to aid users in their work and to support learning.
Our experience with this approach includes several years of innovative system building efforts, the integration of cognitive and design theories, empirical observations and the evaluation of prototypes.
Technical complexity and the associated human cognitive costs to master these systems have both grown dramatically and limit the ability of users to take full advantage of them.
One illustration of this situation is the Symbolics LISP machine; it contains over 30,000 functions and 3300 flavors  accompanied by 12 books with 4400 pages of written documentation.
Systems that offer a rich functionality are a mixed blessing.
In a very large knowledge space, something related to what we need is likely to exist, but may be difficult to fmd.
It is impossible and infeasible for anyone individual to know such systems completely.
Empirical studies  have shown that even very experienced users know only a subset of a large system.
They encounter the following problems: they often do not know about the existence of building blocks and tools; they do not know how to access tools.
Our goal is to increase the usability of high functionality computer systems.
Critics contribute to these goals by bringing knowledge to bear when it is needed.
Systems to SUpport learning The computational power of high functionality computer systems can provide qualitatively new learning environments.
Learning technologies of the future should be multi-faceted, supporting a spectrum extending from openended, user-centered environments such as LoGo  to guided, teacher-centered tutoring environments .
Design Environments To accomplish most things in this world, selective search, means-ends analysis, and other weak methods are not sufficient ; one needs to employ strong problem solving techniques with knowledge about the task domain.
But domain specialists are not interested in learning the "languages of the computer;" they simply want to use the computer to solve their problems and accomplish required tasks.
To shape the computer into a truly usable as well as useful medium, we have to make low-level primitives invisible.
We must "teach" the computer the languages of experts by endowing it with the abstmctions of application domains.
This reduces the transformation distance between the domain expert's description of the task and its representation as a computer program.
Human problem-domain communication is our term for this idea .
Design environments  are tools that foster human problem-domain communication by providing a set of building blocks that model a problem domain.
Design environments also incorporate knowledge about which components fit together and how.
These systems contain critics that recognize suboptimal design choices and inefficient or useless structures ...
Cooperative Problem Solving Systems The goal of developing joint human-computer cognitive systems in which the computer is considered a cognitive amplifier has challenged the more widely understood goal of Artificial Intelligence: the understanding and building of autonomous, intelligent, thinking machines.
A more important goal is to understand and build intemctive knowledge media  or cooperative problem solving systems .
The major difference between classical expert systems, such as MyCIN and R1, and cooperative problem solving systems is in the respective roles of human and computer.
Tmditional expert systems ask the user for input, make all decisions, and then return an answer.
Tutoring is one way to first learn a new system.
One can pre-design a sequence of microworlds and lead a user through them .
However, tutoring is of little help in supporting learning on demand when users are involved in their "own doing."
Tutoring is not task-driven, because the total set of tasks cannot be anticipated.
To support user-centered learning activities.
Giving users control over their learning and working requires that they become the initiators of actions and set their own goals.
They do not support situations where users get stuck during a problem solving activity or settle at a suboptimal plateau of problem solving behavior.
To successfully cope with new problems, users can benefit from a critic that points out shortcomings in their solutions and suggests ways to improve them.
In contrast to passive help systems, critics do not require users to formulate a question.
Critics allow users to retain control; they interrupt only when users' products or actions could be improved.
By integrating wooong and learning.
A strength of critiquing is that learning occurs as a natural byproduct of the problem solving process.
In a cooperative problem solving system, the user is an active agent and participates together with the system in the problem solving and decision making process.
The precise roles played by the two parties depend on their different strengths with respect to knowledge of the goals and task domain.
Critics are an important component of cooperative problem solving systems, especially when they are embedded in integrated design environments.
These critics detect inferior designs, provide explanations and argumentation for their "opinion" and suggest alternative solutions.
Tmditional expert systems are inadequate in situations where it is difficult to capture all necessary domain knowledge.
A critiquing system has two agents, a computer and a user, working in cooperation.
Both agents contribute what they know about the domain to solving some problem.
The human's primary role is to generate and modify solutions, while the computer's role is to analyze those solutions producing a critique for the human to apply in the next iteration of this process.
Some domains, such as user interface design.
Other domains are so vast that tremendous effort is required to acquire all relevant knowledge.
Critics are well suited to these situations because they need not be complete domain experts.
The traditional expert system approach is also inappropriate when the problem is ill-defined, that is, the problem cannot be precisely specified before a solution is attempted.
In contrast, critics are able to function with only a partial task understanding.
Critics do not necessarily solve problems for users.
The core task of critics is the recognition of deficiencies in a product and communication of those observations to users.
Critics point out errors and suboptimal conditions that might otherwise remain undetected.
Most critics make suggestions on how to improve the product.
With this information users can fix the problems, seek additional advice or explanations.
Advisors  perform a function similar to critics except that they are the primary source for the solution.
Users describe a problem, and they obtain a proposed solution from the advisor.
In contrast to critics, advisors do not require users to present a partial or proposed solution to the problem.
The system enriches traditional design practice by augmenting the designer's creative and analytical skills.
JANUS was developed as an integrated design environment to address some of the challenges of human problem-<lomain communication as previously discussed.
Building blocks  are selected from the Palette and moved to desired locations inside the Work Area Designers can also reuse and redesign complete floor plans from the Catalog.
The Messages pane displays critic messages automatically after each design change that triggers a critic.
Clicking with the mouse on a message activates JANUS-VIEWPOINTS and displays the argumentation related to that message.
JANUS-VIEWPoINTS is an issue-based hypertext system containing general principles of design to support argumentation about design.
Integration of JANUs-CRACK and JANUS-VIEWPoINTS allows argumentation to resolve the problems that designers encounter during construction.
JANUS is both a learning environment for design students and a tool for skilled designers.
Critics in JANUS-CRACK apply their design knowledge to critique the designer's partial solutions.
They are implemented as condition-action rules, which are tested whenever the design is changed.
The critics display messages, such as: "sink not infront of a window" in a critic window .
The system knows how to combine building blocks into functional kitchens.
Its knowledge includes three types of design principles : building codes, such as "the window area shall be at least 10% of the floor area.
Examples in the catalog facilitate the redesign approach and can also be used to support learning.
The user can copy both good and bad examples into the work area.
One learning example is shown in Figure 3.
The system can critique such designs to show how they can be improved, thus allowing users to learn from negative examples.
To learn about good features of prestored designs, designers can run the Praise All command, thus getting positive feedback as well.
Users can add their own designs to the catalog for future reuse or as additional learning examples.
In addition to allowing changes to the design within the design environment, JANUS supports end user modification of the design environment itself .
Figw-e 4 illustrates the subprocesses of critiquing: goal acquisition, product analysis, applying a critiquing strategy, explanation and advice giving.
Not all of these processes are present in every critiquing system.
This section describes these subprocesses and illustrates them with examples.
JANUS does not illustrate all of the issues; therefore, we will refer occasionally to systems that are described in the Section DESCRIPTIONS OF CR.TI1CS.
Critiquing a product requires at least a limited understanding of the intended purpose of the product That is problem knowledge which can further be separated into domain knowledge and goal knowledge.
Just having domain knowledge without any understanding of the particular goals of the user, a critic can reason only about characteristics that pertain to all products in the domain.
For example, domain knowledge allows JANUS to point out that stoves should not be placed in front of a window, because this arrangement constitutes a fIre hazard For a more extensive evaluation of a product, some understanding of the user's specifIc goals and situation is required.
A critic can acquire an understanding of the user's goals in several ways.
Using an implicit goal acquisition approach, a general goal is built into the system.
For example, JANUS is built for the problem domain of residential kitchen design, and the user's goal is assumed to be to design a "good" residential kitchen.
Another approach is for the system to recognize goals by observing the evolving product constructed by users; this is goal recognition.
A kitchen with a table and chairs located in the center of the kitchen suggests that the user intends to eat meals in the kitchen.
Goal recognition presupposes solutions that approximate a solution to the user's problem.
There are two general approaches to critiquing: dijferemiai and analytical critiquing.
In the former approach, the system generates its own solution and compares it with the user's solution pointing out the differences.
An advantage of differential critiquing is that all differences can be found.
Some domains allow radically different, but equally valid solutions.
This is a potential problem if the system generates its solution without regard to the user's solution approach.
If user and system solutions differ fundamentally, the critic can only say that the system solution achieves good results but cannot explain why the user's solution is less than optimal.
Different solution attempts fulfIll the goals to different degrees or are associated with different undesirable effects.
In such situations, metrics are needed to measure the quality of alternative solutions .
Based on the controversial nature of design problems, alternative.
An analytical critic checks products with respect to predefIned features and effects.
Analytical critics identify suboptimal features using pattern matching , and expectation-based parsers .
In analytical approaches, critics do not need a complete understanding of the product JANUS is an analytical critic that uses a set of rules to identify undesirable spatial relationships between kitchen design units.
JANUS does not identify all possible problems within a kitchen design.
Its rule base allows it to critique kitchens without knowing exact requirements and preferences of the kitchen user.
Users initiate the critiquing process by presenting a product to the critic.
In order to evaluate the product, the critic needs to obtain the user's goals either by recognizing them or from explicit user input.
The product analyzer evaluates the product against the goal specification.
Some critics do this by generating their own solution and comparing it to the user's.
A presentation component uses the product analysis to formulate a critique, to give advice on how to make improvements, and to provide explanations.
Critiquing strategies and a user model control the kind of critique, its form and timing.
Based on the critique, the user generates a new version of the product, and the cycle repeats,integrating the new insight.
Critiquing Strategies Critiquing strategies and a user model control the presentation component of a critic.
The critiquing strategies determine what aspects to critique and when and how to intervene in the working process of the user.
Critiquing strategies differ depending on the predominant use of the system, either to help users solve their problems or as a learning environment.
Critiquing strategies should consider intrusiveness and the emotional impact on the user.
Intrusiveness is the users' perception of how much the critiquing process is interfering with their work.
Critics can either interfere too much or fail to provide sufficient help, depending on the frequency of feedback, the complexity of the tasks, and the sophistication of the user.
Emotional impact relates to how users feel about having a computer as an intelligent assistant.
Critiquing from a computer might be more tolerable than critiquing from humans if it is handled as a private matter between the human and the computer.
Educational critics, whose prime objective is to support learning, and performance critics, whose prime objective is to help produce better products, have different requirements for their critiquing strategies.
A perfonnance critic should help users create high-quality products in the least amount of time using as few resources as possible.
Learning is not the primary concern of performance systems but can occur as a byproduct of the interaction between user and critic.
Educational critics should maximize the information users retain to improve their future performance.
They evaluate the product as a whole to achieve the highest possible quality.
Some critics critique selectively based on a policy specified by the user.
LISP-CRmc , for example, operates differently depending on whether readability or machine efficiency is specified as the primary concern for writing LISP programs.
Delayed critic messages may appear out of context and hence come too late to prevent the user from heading towards an undesirable state.
Critics can use any of various intervention modes that differ in the degree to which users' attention is attracted.
A critic can force users to attend to the critique by not allowing them to continue with their work.
A less intrusive mode is the display of messages in a separate critic window on the screen.
This gives users a choice whether to read and process the message immediately or first complete an action in progress.
The messages should be displayed in such a way that they do not go unnoticed.
Educational critics  usually employ a more complex intervention strategy that is designed to maximize information retention and motivation by users.
For example, an educational critic may forego an opportunity to critique when it occurs directly after a previous critiqUing episode.
Most existing critics operate in the negative mode by pointing out suboptimal aspects of the user's product or solution.
A positive critic recognizes the good parts of a solution and informs users about them.
For performance critics, a positive critic helps users retain the good aspects of a product in further revisions, for educational critics, it reinforces the desired behavior and aids learning.
To avoid repetitive messages and to accommodate different user preferences and users with different skills, a critiquing system needs an adaptation capability.
A critic that persistently critiques the user on a position with which the user disagrees is ooacceptable, especially if the critique is intrusive.
A critic that constantly repeats an explanation that the user already knows is also unacceptable.
Critics can be adaptable or adaptive.
Systems are called adaptable if the user can change the behavior of the system.
An adaptive system is one that automatically changes its behavior based on information observed or inferred.
An adaptation capability can be implemented by simply disabling or enabling the firing of particular critic rules, by allowing the user to modify or add rules, and by making the critiquing strategy dependent on an explicit, dynamically maintained user model.
User models in critics  share ideas and goals with student modeling in intelligent tutoring systems  and with similar efforts in advice giving natural language dialogue systems .
Computer critics require dynamic, persistent user models that can change over time but are accessible to the human user for inspection and modification.
How to acquire and represent individual user models is a topic of ongoing research .
Intervention strategies determine when a critic should interrupt and how.
Active critics exercise control over the intervention strategy by critiquing a product or action at an appropriate time.
They function like active agents by continuously monitoring users, responding to individual user actions.
Passive critics are explicitly invoked by users when they desire an evaluation.
Passive critics usually evaluate the  product of a design process, not the individual user actions that resulted in the product For active critics the intervention strategy must specify when to send messages to the user.
Intervening immediately after a suboptimal or unsatisfactory action has occurred  has the advantage that the problem context is still active in the users' mind, and they should remember how they arrived at the solution.
The problem can be corrected immediately.
A disadvantage of active critics is that they may disrupt cognitive processing and cause short term memory loss.
Critics have to be able to explain the reasons for their interventions.
This provides users with an opportunity to assess the critique and then to decide whether to accept it.
Knowing why a product was critiqued helps users to learn the Wlderlying principles and avoid similar problems in the future.
In a critiquing system, explanations can be focused on the specific differences between the system's and the user's solutions, or on violations of general guidelines.
All critics detect suboptimal aspects of the user's product .
Some critics require the user to determine how to improve the product by making changes to address the problems pointed out by the critic.
Other critics, however, are capable of suggesting alternatives to the user's solution.
We call these solution-generating critics.
In the JANUS system, a simple problem detecting critic points out that there is a stove in front of a window.
A solution-generating critic would, in addition, suggest a better location.
The purpose of this section is to provide an overview of critiquing systems that have influenced the development of the paradigm or that illustrate an interesting aspect of it.
We first describe two critic systems developed in our laboratory .
After that, we survey systems developed by others.
The critics are active, and the system displays the messages relevant to the currently selected checklist item in the window entitled Things to take care of .
Each message is accompanied by up to three buttons: Explain, Reject, and Execute.
The Bltplain button displays an explanation of the reasons why the designer should consider this critic suggestion; it also descn"bes ways to achieve the desired effect Optional suggestions have a Reject or Unreject button depending on the state of the suggestion.
The Zzecute button accesses the advisory capability of FRAMER, which is available for issues that have a reasonable default solution.
A previous version of FRAMER employed a passive critiquing strategy.
Experimental evidence  showed that users often invoked the critic too late when a major incorrect decision had already been made.
The active strategy with continoous display of messages used in the newest version of FRAMER solved this problem.
FRAMER prevents its users from permanently ignoring the critics by using the checklist Checklist items cannot be checked off until all suggestions are either resolved or rejected.
Short Descriptions of Critics What makes the critiquing approach attractive is that it has generality across a wide range of domains.
Most critics have been developed as research vehicles, but a few are successful commercial applications.
Critic or critic-like systems have been developed for the following application domains.
It helps its users to both improve the program they are creating and to acquire programming know ledge on demand.
Programmers ask USP-CRITIc for suggestions on how to improve their code.
The system then suggests transformations that make the code more cognitively effIcient  or more machine effIcient .
When USP-CRITIc finds pieces of code that could be improved, it shows the user its recommendation.
Users can accept the critic's suggestion, reject it, or ask for an explanation to aid in making that decision.
For example, LISP-CRmc suggests that the user replace a single conditional cond function with an if function.
The user can request an explanation of why if is preferable to cond The system develops an appropriate explanation, consulting a user model, and displaying the explanation in hypertext form.
The user can use the explanation to access more detailed information available about USP in an on-line documentation system .
To adequately support a wide range of user expertise, the system incorporates a user modeling component .
LISP-CRITIc uses that model to customize explanations so that they cover only what the user needs to know.
The purpose of the FRAMER design environment is to enable designers to make use of a high-level abstraction program frameworks - with little prior training.
The WEST system, an early effort to build a computer coach' , pioneered fundamental ideas that the critiquing paradigm incorporates.
WEST builds a bridge between open learning environments and tutoring.
Explicit intervention and teaching strategies are represented in the system and operate using information contained in a model of the user.
WEST provided an early demonstration of how to construct an intelligent learning environment Another system, that pioneered many current ideas in simulation-based learning environments, STEAMER, was later augmented with a critic.
STEAMER/Feedback Mini-Lab  is an environment in which simulated devices, such as steam plant controllers, can be assembled and tested.
After students have constructed a device, they may request a critique from the system.
Researchers in the domain of medicine developed several of the early crit1quing systems.
These systems were developed to aid the physician in diagnosis and planning of plUient treatment.
Miller and colleagues at Yale Medical School have done the majority of the work in this area .
A version of ONCOCIN, an expert system for cancer therapy , also uses the critiquing approach.
The ROUNDSMAN system  is a critic in the domain of breast cancer treatment.
It bases its critique on studies in the medical literature.
This figure shows a screen image of a session with FRAMER.
The system has the following components.
The checklist describes the elements of the task of designing a program framework.
The What you can do window shows the detailed options pertaining to a checklist item.
The window entitled Things to take care of displays the critic messages.
The work area is the place were frameworks are assembled in a direct manipulation interaction style.
A palette contains title panes, display panes, and other primitive parts for constructing program frameworks.
FRAMER also offers a catalog  for design by modification.
The Design Advisor TM , is a successful commercial system developed at NCR that provides advice on application-specific, integrated circuit designs.
It is designed to build scientiftc inquiry skills.
WANDAH  uses critiquing to assist authoring authors in all phases of writing; it is now commercially available for personal computers as "HBJ Writer.
One knowledge-based system provides assistance to teachers doing curriculum development ,
PROLOG Explaining  critiques a user's explanation of PROLOO code to guide the user toward a better understanding of the PROLOG language.
The GRACE Project at the NYNEX Artificial Intelligence Laboratory  is developing a multi-faceted integrated learning environment for COBOL programming.
It consists of a critic, a tutor, and a hypertext system.
KATE  critiques software specifications for automated library systems.
CONCLUSION Critiquing is an emerging approach to building knowledgebased systems.
Critics are a major component of cooperative problem solving systems, which can serve both as performance systems that help users solve real-world problems and as learning environments that support incremental learning.
A strength of critics is that they draw on the potential of hwnan problem solvers where appropriate.
Critics can operate with various degrees of domain knowledge.
However, critiquing is not without its limitations.
Supporting users in their own doing means that details of user goals are often not available to the system, limiting the speciftcity of the critique the system can provide.
Overall, the critiquing paradigm is an effective approach for applying knowledge-based system technology to empower users of computer-based systems in a broad range of domains.
Many J>eOP1e have contributed over the last decade to the development of our notion of the critiquing paradigm.
The authors would like to thank especially: the members of the Janus Design Project , the members of the USP-CRmc projeCt , all the people who have participated in discussions about the general f'nimework for critiq~~ , and the HCC research group as a whole.
This research was partially suJ>POrted by grant No.
MDA903-86-C0143 from the Army Research Institute, and grants from the Intelligent Interfaces Group at NYNEX and from Software Research Associates , Tokyo.
Providing Help and Advice in Task Oriented Systems.
Proceedings of the Eighth International Joint Conference on Artiftcial Intelligence, 1983, pp.
Proceedings of the 10th International Joint Conference on Artiflcial Intelligence , Los Altos, CA, August, 1987, pp.
End-User Modiftability in Design Environments.
Human Factors in Computing Systems, CHI'90 Conference Proceedings , ACM, New York, April, 1990.
Human Factors in Computing Systems, CHI'85 Conference Proceedings , ACM, New York, April, 1985, pp.
Developing an ITS in a Corporate Setting.
Proceedingsof the Human Factors Society 33rd Annual Meeting, Volume 2, Human Factors Society, 1989, pp.
The Nature of Expertise in UNIX.
Proceedings of INTERACf'84, IFIP Conference on Human-Computer Interaction, Amsterdam, September, 1984, pp.
Kitchen Planning Principles - Equipment - Appliances.
Small Homes Council - Building Research Council, University of Illinois, UrbanaChampaign, IL.
The CRITIER System: Automated Critiquing of Digital Circuit Designs.
Proceedings of the 21st Design Automation Conference, 1985, pp.
User Models in Dialog Systems.
Th., Department of Computer Science, University of Colorado, Boulder, CO, July 1989.
User Modelling in Computer-Based Critics.
Proceedings of the 23rd Hawaii International Conference on the System Sciences, IEEE Computer Society, 1990. to be published.
A Framework for a Decision Critic and Advisor.
Proceedings of the 21st Hawaii International Conference on System Sciences, Vol Ill, Kailu-Kona, Hawaii, January 5-8,1988, Jan, 1988, pp.
Expert Critiquing Systems: Practice-Based Medical Consultation by Computer.
Mindstorms: Children, Computers and Powerful Ideas.
Lecture Notes in Medical Informatics.
Volume 32: A computational model of reasoning from the clinical literature.
Decisionlab: A System Designed for User Coaching in Managerial Decision Support.
PrOCeedings of the International Conference on Intelligent Tutoring Systems , June, 1988, pp.
Cell-Based VLSI Design Advice Using Default Reasoning.
Proceedings of 3rd Annual Rocky Mountain Conference on AI, Rocky Mountain Society for Artificial Intelligence, Denver, CO, 1988, pp.
Artificial Intelligence and Tutoring Systems.
Morgan Kaufmann Publishers, Los Altos, CA, 1987.
Curriculum and Knowledge Representation in a Knowledge-Based System for Curriculum Development Proceedings of the International Conference on Intelligent Tutoring Systems , June, 1988.pp.97-102.
