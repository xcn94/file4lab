ABSTRACT We investigated subjects' responses to a synthesized talking face displayed on a computer screen in the context of a questionnaire study.
Compared to subjects who answered questions presented via text display on a screen, subjects who answered the same questions spoken by a talking face spent more time, made fewer mistakes, and wrote more comments.
When we compared responses to two different talking faces, subjects who answered questions spoken by a stern face, compared to subjects who answered questions spoken by a neutral face, spent more time, made fewer mistakes, and wrote more comments.
They also liked the experience and the face less.
We interpret this study in the light of desires to anthropomorphize computer interfaces and suggest that incautiously adding human characteristics, like face, voice, and facial expressions, could make the experience for users worse rather than better.
KEYWORDS User interface design, multimodal interfaces, anthropomorphism, facial expression, facial animation, personable computers INTRODUCTION Humanizing computer interfaces has long been a major goal of both computer users and HCI practice.
Humanizing has at least two aspects, that of making interfaces easier and more comfortable to use  and of making interfaces more human-like.
Previous research indicates that simply adding human qualities to an interface is not in itself guaranteed to produce a better human-computer interaction experience.
In a study in which subjects were tutored and evaluated by computer program, a voice interface produced more negative criticisms than a text interface .
In a historical hypertext database using icons of historical characters as guides, users over generalized from the character icons, expecting them to show personality, motivation, and emotion .
The most human-like interface of all of course would embody human characteristics in an agent with human form, of which the human face is one of the most compelling components.
Infants are born with information about the structure of faces; at birth infants exhibit preference for face-like patterns over others .
By the age of two months infants begin to differentiate specific visual features of the face  and process facial expressions .
Faces can induce appropriate behavior in social situation covering faces with masks can produce inappropriate behavior .
Faces, particularly attractive ones, even sell soap; physically attractive models are found to be effective in improving peoples' responses to advertisements .
Perhaps the most famous example of an embodied agent is "Phil," the computer-based agent played by a human actor, which appeared in the Knowledge Navigator envisionment videotapes from Apple Computer .
Exploration of human-like interfaces has been limited to date by technology but this situation is changing rapidly.
The base technology needed to implement a variety of personable interfaces is at, or close to, commercial availability.
With a combination of speech synthesis technology  and facial animation , it is possible to display a synthetic talking face on a workstation screen .
The face can speak arbitrary text and could participate more or less fully in an interaction with a user .
At one extreme, the face could simply provide a stylized greeting and introduce the user to a more conventional interface.
Moving toward the other extreme, the face could represent the computer side of an entire interaction, speaking all words that would otherwise be displayed on the screen as text and responding to the user orally instead of via text.
Talking faces may be particularly problematic in interfaces precisely because the human face is such a powerful stimulus, A talking face could focus people's attention on the face itself rather than on the task they are trying to perform, thereby leading to lower performance.
Alternatively, it might cue reminders of social evaluation, thereby leading to higher performance.
A talking face could also engender strong expectations for social intelligence from the interface, thereby leading to confusion or frustration if those expectations are not met.
This paper reports the results of an initial investigation of reactions to a talking face.
For exploring the first two issues, we compared text delivery of survey items to having them spoken by the synthetic face.
To look specifically for social response effects and to control for simple differences due to the method of delivery, we compared two versions of the speaking face that differed in expression.
METHODS The experimental context was a computer-based survey in which subjects received questions in either text or spoken form and typed in their answers.
We used a betweensubjects design with subjects assigned randomly to one of the three presentation conditions: questions spoken by a face with a neutral expression, spoken by a face with a stem expression, or text only.
Subjects The subject population was the staff of a computer research laboratory in a large industrial corporation.
This included full-time research, support, and administrative staff, parttime research staff, external consultants, and some off-site people associated with the laboratory on a permanent basis .
People who worked in the computer support organization or who were involved in conducting the study were excluded.
The population thus defined consisted of 49 people, who were assigned randomly to the three conditions.
We checked to be sure that part-time staff were not overrepresented in any one condition.
Tack All subjects answered questions designed to measure user satisfaction with the computer support services in the laboratory.
The survey had been commissioned by the computer support organization.
Thus the content of the questionnaire was both realistic and salient to the respondents.
Subjects were informed of the purpose of the study and were assured that their identities would be concealed in the final report.
Questionnaire The questionnaire contained 79 items: four background questions, 59 questions about computing attitudes and behaviors, and 16 questions about the experience of participating in the study.
The computing attitudes questions were a mix of open-ended questions 
The fist question is, simply, are people willing to interact with a talking face?
It is possible that people would find the prospect so bizarre that they would refuse to participate in a computer interaction in which the computer side of the interaction was represented by a talking face.
The second question is, even if they are willing to participate, will they be so distracted that their performance is seriously degraded?
Finally, the most important question is how people experience the interaction with the face.
How human does it seem?
Does it evoke a social response from the user?
We investigated these questions in an exploratory study using the social context of the interview survey.
People are quite familiar with the general social structure and form of interview surveys.
One person asks questions, usually through an agent such as a questionnaire or interviewe~ and another person answers them.
People are accustomed to answering questions asked by such agents and there is an extensive literature on how the nature of the agent affects peoples' responses.
See, for example, Bailey, Moore, and Bailar  for the effects of interviewer demeanor on the obtained data, Schuman and Presser  for the effects of question wording and order on the obtained data.
Generally, surveys delivered by human agents  are more socially involving than those delivered by paper and pencil.
Thus response rates are higher and missing data rates are lower.
Apparatus The workstation in the office was a Digital Equipment Corporation DECstation 5000/200, equipped with a 21-inch color monitor, a DECaudio board, amplifier, and speakers.
Images were shown in grey scale, not in color.
All materials were pre-computed to achieve acceptable performance and stored on a local disk to prevent variability in display speed due to network traffic.
The experimental sessions were managed using the Lisp facilities of Gnu Emacs.
The face was produced by texture-mapping an image onto a geometric wire-frame model .
On the screen, the face occupied 512 x 320 pixels, which is about half life size.
This was the maximum size provided by the technology.
The mouth was animated by computing the current mouth posture  corresponding to the current linguistic unit  and applying cosine-based interpolation between the images .
The voice was produced by a software implementation of the KLSYN88 revisions of the DECtalk text-to-speech algorithm .
The DECtalk parameters used were the "B" voice, a fairly neutral voice in the female pitch range, at 160 words a minute.
DECtalk speech is acceptably comprehensible at this rate .
The synchronized face and voice were presented using the Software Motion Pictures component of DECmedia .
Procedure Each subject completed the study individually in one of the offices in the laboratory, equipped with a computer workstation.
The subjects used workstations regularly as part of their jobs and the system used in the study presented an environment familiar to most of them.
The experimenter introduced the survey and explained how the questions would be displayed.
Each subject had the opportunity to answer three practice questions to make sure they understood how to control the interface before the experimenter left the room.
The survey was self-paced; subjects were free to work on it as long as they wished.
Subjects in the text condition first read an introduction to and explanation of the computer support survey in a text window.
They then saw the questions displayed, one at a time, in that window, They typed their answer after each question.
Subjects in the face conditions heard rather than saw the same introduction and questions, and typed in their responses in the same way as did subjects in the text condition.
The face remained on the screen between questions.
At any point, subjects could scroll backward to see any prior question or edit any answer.
The stern expression  was synthesized from the neutral expression by contracting the corrugator muscles in the underlying physical model for the animation, thus pulling the inner portion of the eyebrows in and down.
The expression produced by contracting these muscles is recognized as conveying negative emotion such as anger and threat .
The mouth itself was not involved in forming the expression; subjects in both face conditions saw exactly the same lip animation and heard the same voice.
The face we called "stem" was rated consistently more negatively by these subjects, thereby validating our label for the face.
Text  Attitudes to answering questions Were questions clear?
Involvement Time spent  Requests to repeat  Missing answers  Invalid answers  Unsolicited comments a Open-ended questions b Final comments 
Attitude measures toward computing resources and staff were defined as the sum of the responses to the ten 10-point scale items on these topics.
Overall measures of response extremity were defined as the frequency of using the extremes on the 10-point scales in the body of the Responses to the open-ended questionnaire .
Responses were first divided into remarks and then coded for comments about the face, voice, text editor, and question wording.
Comments were also coded for general positive or negative affect and for the presence of first person pronouns .
The system logged how long each session lasted and how many words subjects typed .
Missing and invalid data rates were derived from each subject's responses.
There were several main effects of presentation condition.
Subjects in the neutral face and text conditions typed the same number of words in answer to open-ended questions but people in the stem face condition typed almost twice as many words.
They were quite explicit about their dislike of the face, with many suggestions for how to "improve" it.
Probably as a result of hearing questions repeated and typing lengthy comments, they also spent significantly longer taking the survey than subjects in the other groups.
Subjects differed markedly in their assessments of the interviewer .
Since text condition subjects had not seen any question asker, their responses tended towards the "don't know" range of the 10-point scale.
Subjects in the face conditions expressed markedly more negative attitudes.
Eight out of the eleven comparisons were ordered with the text condition most positive, the stern face condition most negative, and the neutral face condition in the middle.
42 out of 49 people completed the survey for a response rate of 8670.
7170 of the respondents were male.
Twothirds of the respondents had been employed at the lab for three years or less.
D.; 81% were working in a research-related position.
The remaining 1970 worked in administrative support.
Respondents reported a mean level of general computing expertise of 8.0 .
Respondent characteristics were acceptably balanced across conditions.
We did, however, see some suggestion of an interaction between gender and education level in subjects' reaction to the experience, with high education females providing the most negative ratings on 11 out of 15 scales.
Although it was not significant, subjects in the face conditions were less willing to "continue a conversation" than were the subjects in the text condition.
There were no statistically significant differences in the rate of missing or invalid data, although the trend was towards greater accuracy in the face conditions.
We demonstrated the feasibility of having people interact with a talking face for purposes of asking and answering questions.
Given the untried nature of the talking face technology, it is encouraging that people performed similarly across face and text conditions in terms of substantive response to the actual topic of the questionnaire.
Furthermore, faces did not lead to poorer performance through distracting people.
On the contrary the performance of people in the face conditions was better than in the text condition as measured by  number of invalid responses.
Faces were more engaging than text as measured by how long people spent answering questions and in how much they wrote in response to open-ended questions.
Further, the face with "more" expression  led to greater engagement than did the face with "less" expression .
Note that engagement does not mean liking.
Respondents assessed the stem face less positively than the neutral face and assessed both faces less positively than the text condition.
Why would people spend more time, respond more, and respond more carefully to a face that they did not like?
Social psychologists have found that the presence of another person usually serves to increase arousal and motivation on the part of someone asked to perform a task .
This can lead to improved performance if the task is not very complex or to degraded performance if the task is complex.
The presence of another person apparently produces evaluation reminders and therefore leads people to try harder.
We posit that the more expressive face  in this study may have actually produced the most evaluation reminders of the thrm conditions.
If so, these evaluation reminders would cause people to pay closer attention to their task than did the other two conditions.
Synthetic talking face technology will continue to improve.
We will be able to manipulate expression more extensively and to expand the range of facial movements possible.
We will be able to incorporate more natural eye movements and more expressive speech.
The major question from an interface designer's point of view is how to use these capabilities.
This study raises many fundamental questions about the future nature of the human-computer relationship.
If a computer is a social actor, what is its role 
We further explored some of the main effects by direct comparison of the two face conditions.
Subjects who saw the stem face found the questions less clear and asked to have more of them repeated.
People in the stem face condition spent longer answering the survey than did people in the neutral face condition .
They wrote more in response to openended questions about their computing environment , They also wrote more  about the experience of answering questions .
There were no statistically significant differences in error rates or substantive answers and no difference in response to questions measuring question clarity, desire to continue answering questions this way, or subject comfort.
There were no significant differences in assessment of the auestion asker.
Emotion in the human face.
Cambridge: Cambridge University Press, 1982.
Does Image Size Affect Judgments of the Face?
Journal of Nonverbal Behavior, 1979.
Gaver, W.W, Auditory Icons: Using Sound in Computer Interfaces.
Multichannel Communication of Emotion: Synthetic Signal Production.
In Facets of emotion: Recent research, K.R.
Continuous Speech Recognition by Context-dependent Phonetic HMM and an Efficient Algorithm for Finding N-best Sentence Hypotheses.
Analysis, Synthesis, and Perception of Voice Quality Variations Among Female and Male Talkers.
The Journal of the Acoustical Society of America, 1990.
Laurel, B. Interface Agents: Metaphors with Character.
In The art of human-computer inte~ace design, B. Laurel, .
CONSPEC and CONLERN: A Two-process Theory of Infant Face Recognition.
Voices, Boxes, and Sources of Messages: Computers and Social Actors.
Human Communication Research, in press.
User-centered Hillsdale, N. J.: Lawrence Erlbaum system design.
The Influence of Self-esteem on Cognitive Responses to Machine-like versus Human-like Computer Feedback, The Journal of Social Psychology, 1985.
Rich, C. Evaluating the Contribution of Discourse Theory to an Interactive System.
In Proceedings of AAAl Fall Symposium on Human-Computer Collaboration.
Questions and answers in attitude surveys: Experiments in question form, wording, and context.
Should human facial realism be a goal?
If so, whose face should appear?
Based on this preliminary work, we anticipate differences in the appropriateness of face-based interfaces depending on the social interaction demands of the situation, on the expression and gender of the faces used, and on individual temperament characteristics of the users.
The goal of HCI work with synthetic faces should not necessarily be to give a computer a human face but rather to determine when a face-like interface is appropriate.
It is particularly important to follow up on the possibility of gender effects, particularly in light of HCI'S commitment to interfaces that are equally accessible and acceptable to all intended users.
Our results indicate that significant further research is necessary to identify the components of a satisfactory experience with a human-like computer interface.
ACKNOWLEDGMENTS Thanks to Keith Waters, Tom Levergood, Wecker for invaluable technical collaboration.
Which are the Stimuli in Facial Displays of Anger and Happiness?
Configurational Bases of Emotion Recognition.
An Interviewer Variance Study for the Eight Impact Cities of the National Crime Survey.
The Impact of Physically Attractive Models on Advertising Evaluations.
Journal of Marketing Research, 1977.
Case Histories and Shorter Communications.
Perceptions of Form by the Human Infant.
In Handbook of survey research, P.H.
Carey, S. Becoming a face expert.
In Processing the Facial Image, V. Bruce, et al., .
Eff~ts of Deindividuating Variables on Stealing by Halloween Trick-or-treaters.
Designing the user interface: Strategies for effective human-computer interaction.
Sidner, C. Using Discourse to Negotiate in An Artificial ILanguage.
1992, Collaborative Activity: Workshop on Cooperation Among Heterogeneous Agents: NCAI Conference.
Cooperative Work Environment Using Virtual Workspace.
In Proceedings of Computer Supported Cooperative Work.
Communicative Facial Displays as a New Conversational Modality.
Dialog Control in Social Interface Agents.
Waters, K. A Muscle Model for Animating Threedimensional Facial Expressions.
DECface: An Automatic Lip-synchronization Algorithm for Synthetic Faces.
Cambridge Research Laboratory, Digital Equipment Corporation Technical Report CRL 93/4, 1993.
Communication and Control Processes in the Delivery of Service Quality.
Delivering quality service: balancing cuslomer perceptions and expectations.
