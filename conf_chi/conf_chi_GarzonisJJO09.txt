With an ever increasing number of mobile services, meaningful audio notifications could effectively inform users of the incoming services while minimising undesired and intrusive interruptions.
Therefore, careful design of mobile service notification is needed.
In this paper we evaluate two types of audio  as mobile service notifications, by comparing them on 4 measures: intuitiveness, learnability, memorability and user preference.
A 4-stage longitudinal evaluation involving two lab experiments, a field study and a web-based experiment indicated that auditory icons performed significantly better in all measures.
Implications for mobile audio notification design are presented.
However, audio notifications that appear too frequently can cause undesired interruptions, annoyance and ultimately their deactivation by the user .
An approach to address the trade-off between an unwelcome interruption and missing a potentially useful service is to improve the meaning of the audio notifications.
Therefore, if we wish to design meaningful notifications, we need to investigate their innate meaning  and/or their ease of explicit learning and remembering.
Furthermore, since interaction with mobile devices constitutes an everyday activity for most people and often takes place in social contexts, user preference in the audio types utilised is also an important factor to be considered in the notifications' design.
Within the realm of auditory display research, sounds have been classified in several types and their characteristics thoroughly described.
Two common types are earcons and auditory icons.
To decide which type of sound is more appropriate for supporting service awareness, we designed and carried out a 4-stage evaluation process, comparing certain cognitive attributes of the two types of sound.
In particular, we investigated the immediacy of recognition of the notifications and their relation to the services , the ease with which they can be learned to represent these services  and the ease with which these associations can be retained .
Finally, user preferences were recorded throughout the evaluation and compared with the findings on the cognitive attributes of the sounds.
As mobile network providers are taking advantage of the available bandwidth and providing more data services, users are often left unaware of what services exist and when or where they are actually available.
One obvious way to improve service awareness is notifying users of the availability of services relevant to their current situation or needs.
For example, many users today have subscribed to receive alerts relating to sports results, weather forecasts, business news etc.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
In the remainder of this paper we present the evaluation process and discuss the findings.
The next section presents relevant research on the types of sounds utilised and is followed by the presentation of the research that led to the mobile service categorisation used here.
The following sections describe the design of the evaluation: a lab experiment for measuring intuitiveness and setting a baseline for measuring learnability; a field study for initiating and monitoring the learning process for the sound-service associations in a natural context; a second lab experiment for measuring learnability in the field  and learnability in the lab ; and a web-based experiment for measuring memorability of the associations after 1 and 4 weeks.
Results, discussion and conclusions are presented towards the end of the paper.
Unlike earcons, auditory icons utilise metaphors to relate them to their virtual referents, so that "if a good mapping between a source of sound and a source of data can be found, the meaning of an auditory icon should be easily learned and remembered" .
For example, the sound of shattering dishes can represent the drop of a virtual object into the  recycle bin , a door slamming indicates a remote user logging off the network , and tyre-skidding is used in vehicle collision warnings .
However, auditory icons lack flexibility, as metaphoric mappings are not always easy to find.
A further disadvantage is that they can be confused with actual environmental sounds .
Both earcons and auditory icons can vary on the level of directness of the semantic relationship between the sounds and their referents.
Nevertheless, it has been noted that users will construct their own meaning and stories to explain and memorise relationships between earcons  or auditory icons  and their referents.
Several types of sounds have been used in auditory interfaces.
These may vary greatly in their semantic relationship with the events or situations they represent.
In this paper, we present an investigation into non-speech notifications for mobile devices, comparing the suitability of two widely acknowledged sound types in the literature: auditory icons and earcons.
Auditory notifications are usually researched in the context of safety-critical and/or cognitively demanding systems.
Auditory icon notifications are generally found to be easier to learn and retain  and produce quicker reactions than earcon notifications .
This superiority of auditory icons seems to be rooted in the directness of the association with their referents  and there is evidence suggesting that memory performance varies more on a sound-by-sound basis rather than a sound type-by-sound type basis .
Also, the type of training method has been found to affect learning and remembering audio notifications, regardless of the type of sound used .
Finally, both earcons  and auditory icons  have been reported as annoying, but there are not many studies that measure and present comparative user preference findings.
Two exceptions can be found in  where musical sounds were found more pleasant and appropriate than real world sounds, and  where findings regarding user preferences were inconclusive.
It would appear that the context of use, the specific sound instances and individual aesthetic preferences outweigh any preference between the two sound types.
We are not aware of previous longitudinal studies comparing user preference in the real context of use.
Earcons are therefore flexible and can be designed to aurally extend any object, operation or interaction.
For example, Leplatre and Brewster  represented with earcons the hierarchical menu of a mobile phone, improving the performance of navigational tasks within the menu.
On the flip side of flexibility, the major disadvantage of earcons is the lack of meaningful relationship with their referent.
Since the number of individual mobile services can be very large, it would be impossible to create meaningful and distinguishable non-speech audio notifications for each one of them.
Therefore, in order to assess the suitability of the different audio types as mobile service notifications, a comprehensive categorisation of the services is needed.
This way, each category can be assigned a unique notification, informing the user of the generic nature of the service rather than the specific instance of the category.
A previous attempt at mobile service categorisation was presented in  and was based on the concept of the services' origins.
Three super-categories were devised, depending on whether the service was offered to the user from the `world', from other users or from the user herself.
Each category was further broken down into three subcategories and these nine categories were assigned individual audio notifications.
This categorisation has now been empirically validated and improved based on two card-sorting studies.
The first study presented 10 groups of 3 or 4 participants with 52 services , and participants were asked to group them so that each category would share the same notification.
The clusters were slightly amended so that the hierarchy more accurately represented the origin-of-service rationale, and was then tested in a subsequent closed card-sorting study.
This time the category titles and descriptions were provided to 12 participants, who were individually asked to assign each service to one of the categories.
The categorisation was validated with participants reaching 83% agreement on average in assigning the services to the intended categories.
Based on the qualitative results from the closed card-sorting study, some of the names and descriptions of the categories were amended, resulting in the hierarchy presented in Table 1.
A repeated measures experimental design was followed.
The independent variables were time and training, and the dependent variables were response accuracy and response time.
In the first stage , the intuitiveness of the notifications was measured.
Intuition may be defined as "the act or faculty of knowing or sensing without the use of rational processes, or immediate cognition"1.
Therefore, the more immediately one recognises a sound and relates it to a concept or event, the more intuitive the sound's meaning.
Since audio notifications' intuitiveness varies according to the strength of the metaphor associating them to their referents, auditory icons should  be more intuitive than earcons.
In the second stage , participants started learning the sound-service associations  in the natural context of mobile phone usage, during a 1 week long field study.
They received the audio notifications on their phones and they had to guess the corresponding service.
They then received feedback messages indicating  the correct service.
In related literature this learning process usually takes the form of training sessions in the lab, where participants are presented with stimuli as many times as needed for them to learn their meaning.
In the third stage , and since participants had not reached 100% accuracy during the field study training, they repeated the Lab 1 process so that learnability during the field study could be measured.
Then, they underwent rigorous lab training and were again tested in how well they learned the associations.
This provided us with further learnability data.
Stage 4  tested memorability after 1 and 4 weeks with no further training or exposure to any of the sounds.
User preference data were collected throughout all 4 stages.
In a previous study  it has been observed that questions such as "would you like to have this feature on your phone" give inconclusive results when the only exposure to the feature is during a short lab study.
We suggest here that if users are exposed to the different sounds over a longer period, and in the natural context of everyday mobile device use, they will develop a clearer and more confident opinion of which sounds they would prefer to adopt, if any.
No extra incentive was offered apart from 3 Amazon vouchers  for the 3 most responsive participants during the field study.
They were all familiar with using a computer, had been using a mobile phone for at least 3 years and were familiar with their current phone for at least 1 year.
Since only auditory icons are designed to have strong semantic relationships with their signified entities, it was hypothesised that auditory icons will be significantly more intuitive notifications than earcons  as untrained listeners will have no basis on which to guess the association between earcons and services.
Furthermore, it has been found that users perform poorly in learning earcon associations in the field .
Therefore, we hypothesised that auditory icons will be significantly more learnable notifications during the field study than earcons .
Also, we predicted that auditory icons would be quicker and easier to learn during the subsequent lab training .
During the lab training, participants were given an explanation of how the earcons represented the structure of the service hierarchy .
The associations between the sounds and the services were presented, and participants were given time to learn them.
Finally, literature suggests that auditory icons are easier to retain than abstract sounds .
Therefore, in the web-based experiment, 1 and 4 weeks after the lab training, we predicted that auditory icons' forgetting rate will be slower than earcons' .
The lab studies were designed and run using the MediaLab software, on IBM desktop PCs with a standard 15" display.
Logitech headphones were attached to each computer and user input was recorded by MediaLab through the use of the keyboard and the mouse of each PC.
For the field study, a Java application was installed on participants' Nokia N95 phones, which communicated with a server initiating the notifications and recording the responses.
For the last stage, a web-based questionnaire was developed in HTML and PHP, which was accessed via participants' home or work computers.
Ten auditory icons and 10 earcons were used throughout the 4 stages of the evaluation process, each corresponding to one of the mobile services presented in the categorisation in Table 1.
Next, we present the research carried out in order to generate and assign each set of stimuli to the services.
For auditory icons, everyday sound-producing events were initially assigned to the services as a result of a brainstorming session with four HCI researchers.
All ideas of events that would effectively represent each of the services were aggregated and sound instances were collected from royalty free websites or recorded by the authors.
The identifiability of these sounds was tested through an online survey and convenience sampling of respondents, with on average 81.5 responses for each sound.
This led to the elimination of the sounds that were least identifiable.
Only the 3 most identifiable sounds were retained for each service.
Next, a second online survey was carried out in order to assign to each service the most representative sound.
The three most identified sounds were presented for each service and 112 participants were asked to indicate the one they found most representative.
This ensured that the metaphors used to link the sounds with the services were empirically validated.
Earcons were initially designed to represent the hierarchy and be distinguishable, following guidelines from the literature .
Each one of the 4 super-categories  was represented with a different instrument/timbre, which is reported as "the most efficient parameter that can be used to distinguish sounds" .
Within each category a variety in rhythm complexity  was utilised to make the earcons as distinct as possible.
They were "Incoming MMS message" in the second super-category, and "Generic Alarm" in the third super-category.
This was done to disrupt the one-to-one relationship between sounds and services, and hence hinder users from deducing associations based on a process of elimination.
Participants repeated the same procedure for earcons and for auditory icons with a short break in between.
In each procedure, all 10 sounds were played in a random order twice, with all 10 sounds played once before the second round started.
All 12 services  in their 4 super-categories were continuously presented on screen throughout the process, with a function key represented next to each one.
Each time a sound was heard, participants were required to indicate  which service they thought it corresponded to by pressing a function key from F1 to F12.
Response time and correct/incorrect responses were recorded.
Each sound was repeated up to 3 times at 1.5 second intervals or until a selection was made.
Each trial was followed by a short questionnaire capturing user preferences with regard to each individual sound.
Finally, they were asked to answer a few comparative questions between the two sound types.
All questions were presented on screen and responses were captured using MediaLab.
Stage 2: Field Study - Learnability The field study commenced on the morning after the first lab study was completed.
The application on the participant's mobile phone played the experimental sounds at random times from 10am to 9pm every day for 1 week.
In order to draw participant's attention to the task, an SMStype notification was played, immediately followed by an option screen allowing him either to begin the task and hear the sounds, or dismiss the task until the next random time interval had elapsed.
Their task was to guess the correct correlation between a sound and a service .
The numbered list of 12 services was displayed on the phone's screen and they were required to type the corresponding number in a text box.
An on-screen button provided the option to replay the sound.
They were given feedback on their selection, informing them whether it was incorrect or correct, and the correct service for the sound was indicated .
They were found to be significantly better in their ability to represent the structure of the classification of the services, and more distinguishable than the control tones.
However, the 5 services of the first super-category  were found to be difficult to distinguish and remember.
Therefore, they were improved by a professional musician in order to be more pleasant and more distinguishable.
For example, the monophonic/ polyphonic dimension was manipulated to make sub-categories more distinct .
Twelve new participants tested the new earcons in a second experiment but no significant difference in learnability was found compared to the old earcons.
Examples of earcons are presented in Table 4.
Table 3 shows the 10 service categories along with descriptions of the auditory icons and earcons.
All sounds were sampled at 44.1 KHz at 128kbps bit rate and were normalised at -90 dB.
However, during the field study their quality had to be reduced to just 8 KHz sampling due to the memory limitations of the mobile phones.
Stage 1: Lab 1 - Intuitiveness Up to 8 participants at a time performed the experiment at adjacent computers in a quiet lab and wearing headphones.
Participants were presented with a list of the 10 services on their screens  and the 4 super-categories rationale was explained .
Note that 2 extra `dummy' ser-
A 4-step training process then took place for each of the sound types .
In the first step, each sound was presented along with its corresponding service, and their association was explained.
For the auditory icons, the events that produced the sounds and the metaphors associating them to the services were described.
For the earcons, the instrument and some properties of the musical pieces were described, along with any metaphorical associations .
In the second step of training, participants were given 4 minutes to memorise the associations.
The sound descriptions were displayed next to the services, and the sounds were played every time the participant clicked on the corresponding service buttons.
The third step of the training consisted of an absolute identification paradigm with trial-by-trial feedback.
The 10 sounds were played in a random order and participants had to choose the correct service.
They were prompted to retry if they made the wrong choice.
Sounds were repeated up to 3 times or until the correct choice was made.
The final step of the training was a similar test but feedback was given only at the end of the trial of 10 sounds.
Feedback consisted of a percentage score for their correct responses and a breakdown of which services they had guessed correctly.
Training stopped when the participant scored 100% or had been through 6 repetitions of the whole process, whichever came first.
The number of tests needed for each sound type was recorded to indicate ease of learnability for each sound type.
The same training procedure was repeated for the second type of sound after a 5 minute break.
A comparative questionnaire completed the experimental procedure.
At the end of the experiment a short debriefing focus group took place, where participants were encouraged to describe their experiences during the lab and field sessions.
Stage 4: Web-based Experiments - Memorability One and 4 weeks after the Lab 2 experiment, participants completed a web-based questionnaire.
The procedure for the questionnaire was very similar to the fourth step of training in Lab 2.
Participants listened to the 10 sounds of each type in a random order and indicated for each one the service they thought it represented.
They had the chance to replay the sound and they were asked to indicate whether they "would like to receive this notification in the presence of others".
At the end of each sound type they were provided with a percentage score for their correct responses, but no detailed breakdown.
Finally, participants were asked to rate how much they would like to have that particular notification on their mobile phone for that service.
The sounds were presented in pseudo-random order in pairs: one earcon and one auditory icon  at a time.
This was done for two reasons.
First, it ensured that participants were responding to both types of sounds in the same context each time.
As the participants' activities, level of concentration, distractions etc were expected to be changing throughout the day, we wanted to make sure that neither sound type was favoured by being responded to in more `comfortable' situations.
Secondly, the perceived annoyance or preference for the different sound types could also be affected by the context  within which the sounds were received.
The presentation order of earcon and auditory icon within each pair was swapped each time.
Sounds that were responded to were not repeated in the same day.
If they failed to respond to some of the sounds, the frequency of the notifications was increased to around every half hour in order to increase the chances of responding to all the sounds within the day.
The interaction process of the mobile application is graphically modelled in Figure 1 and screenshots of the application are shown in Figure 2.
Stage 3: Lab 2 - Learnability The Lab 2 experiment took place 1 week after Lab 1 .
The first part of the Lab 2 experiment was identical to the evaluation process of the Lab 1 experiment.
This again indicates that it was easier for participants to learn associations between auditory icons and services than between earcons and services.
This section describes the analysis of participants' ability to correctly identify the meaning of notifications in the first lab session, plus the degree to which identification improved in the second lab session.
A 2x2 ANOVA was conducted, with two repeated measures variables, notification-type  and session .
This indicates that auditory icons were more easily associated with the correct service than were earcons regardless of training.
A paired-samples t-test shows a significant difference between scores for the two notification types in the first session =11.007, p<0.001.
Thus the argument from definition that auditory icons are more intuitive than earcons is supported by the empirical evidence.
This indicates that participants were more successful in correctly identifying services associated with both notification types in the Lab 2 session, after the field study training, than they were in Lab 1.
There was a significant interaction between notification-type and session, F=9.7, p=0.008.
This indicates that auditory icon associations were more easily learned during the week between lab sessions than were earcon associations.
This is illustrated in Figure 3.
Reaction times showed similar characteristics to the number of correct identifications.
Reaction times were lower for the identification of auditory icons, in both lab sessions, than for the identification of earcons, F=42.01, p<0.001.
Reaction times were also lower in the second lab session than the first, for both types of notification, F=49.05, p<0.001.
Performance was analysed 1 and 4 weeks after the second lab session in order to determine whether one or other set of notifications was more quickly forgotten.
A 3x2 ANOVA was conducted, with two repeated measures independent variables; notification-type  and session .
This indicates that associations between sound and meaning were forgotten over time, for both earcons and auditory icons, as would be expected.
This indicates that auditory icon associations were remembered better than were earcon associations at each of the 3 stages .
This shows that earcon associations were forgotten more quickly than were auditory icons.
Figure 4 illustrates the overall change in performance of participants for each of the sessions described .
Sessions have been labelled according to the measurement they relate to .
Correlational analyses were used to compare average preference scores  with performance in matching notifications with services in both the first and second lab sessions.
There was a strong, positive correlation between preference and successful identification of notifications in both the first  and second lab sessions .
This indicates that the most intuitive notifications were preferred more, and later on more successfully learned.
In all 4 stages of the study presented in this paper, several interesting results with regard to earcons' and auditory icons' suitability as mobile service notifications emerged.
All of our hypotheses were supported with auditory icons performing significantly better in terms of intuitiveness , learnability  and memorability ; and lab training significantly improved performance of both sound types  but more for auditory icons .
Furthermore, auditory icons were consistently preferred over earcons as mobile audio notifications across all stages of the study.
This unfamiliarity is further underlined by the fact that participants in the Lab 1 experiment indicated at a rate of 56% that this sound actually represented an incoming SMS .
The next 2 auditory icons to underperform were the `truck reversing'  and the `wind chimes' , scoring in Lab 1 at 21% each.
Their performance increased to 100% right after the metaphors were explained during Lab 2 training.
Therefore, we conclude that this poor performance was a result of poor choice of metaphors for these particular auditory icons.
Indeed, in the identification survey the service 8 auditory icon achieved the lowest score of the accepted sounds, at only 64%.
The next lowest identification score was for auditory icon 2 at 77%, which scored 97% in intuitiveness.
This finding suggests that soundsource identification rates have to be higher than 70%  for successful mobile audio notification design.
Auditory icons performed significantly better than earcons in terms of intuitiveness, confirming the assumption from their respective definitions , and validating our choice of metaphors for the auditory icons.
However, the auditory icon for self-reminders  performed the worst in its group , almost at chance rate.
An interesting result in terms of learnability is that earcons required only some basic training  in order to reach scores similar  to the more intuitive auditory icons before training.
Many participants reported with relief that earcons made much more sense after they were explained and the rationale for memorising them was presented.
For participants to develop their own semantics or follow different strategies for memorising associations is not uncommon .
However, the rate of improvement in their Lab 2 attempts to reach 100% accuracy was significantly slower than with auditory icons.
Therefore, basic training with earcons seems enough to achieve scores of about 70% but even after substantial training, they fail to reach auditory icons' performance.
It has been found that if more time is given for familiarisation earcon learnability improves , but for everyday technologies like the mobile phone, lengthy learning procedures are not ideal.
Because of these comments, we rephrased the preference question from "would you like to have this notification on your mobile phone" in the first 3 stages to "would you like to receive this notification in the presence of others" in the web-based experiments.
However, the responses still favoured the auditory icons.
Finally, we have previously found  that preference questions with regard to potential real usage of audio types were inconclusive and unreliable when asked during a lab experiment.
However, in the current study we found that participants were consistent in their preferences throughout the lab and field studies.
We therefore may be able to put more trust in users' initial preference reactions to audio notifications.
Similar to the learnability results, earcons seem to be a less appropriate choice for mobile notifications, since their meaning is easier and quicker to forget.
In a real world scenario the number of services could be more than just the 10 that were used here, but even more importantly, some of them could occur infrequently.
Even if users undertook extensive learning to memorise the associations, if an earcon notification occurred once a week, the likelihood is that its meaning would have been forgotten.
Least frequent notifications have the greatest need to be based on meaningful metaphors.
Apart from earcons scoring lower in subjective preference, they also seemed to cause strong negative feelings and frustration to some participants.
This was apparent from involuntary comments during the training, explicit responses in the questionnaires and comments during the debriefing focus group after the Lab 2 experiment.
For example, earcons were characterised by some as "horribly discordant", "ugly" or "miserable" and one even stated "I loathe this sound" .
However, a possible explanation for this negative attitude towards earcons is the inefficiency of the learning process during the field study.
As one participant put it "Came to hate them all because I got them wrong so they just irritated me, which was a kind of vicious circle!"
This is further supported by the strong correlation found between preference and intuitiveness.
Therefore, earcon design for mobile notifications needs not only to meet literature-based requirements in terms of structure and distinguishability, but also involve users in order to produce aesthetically pleasant sounds.
It is interesting to note that the same earcons received very positive feedback in the experiments establishing their validity .
However, if one looks carefully at the preferences for individual sounds, there are earcons that scored relatively high.
In particular, earcons 8 and 9  seem to score consistently higher than all other earcons in terms of preference throughout all stages of this study.
This could possibly be due to the familiarity of the timbre, which sounded more similar to how mobile phones currently sound .
In the field study data, we observed a sudden drop in the performance of both types around day 4, and a slight drop on day 7 .
This can be explained by a technical problem that significantly reduced the number of notifications delivered on day 4 and slightly reduced the responses on day 7.
With fewer questions asked each answer had more effect on the average.
As incorrect answers were more likely at that stage, the effect was to depress the averages.
However, reduced responsiveness on Sunday also appeared for participants who did not face the technical problem, and similar but smaller unresponsiveness is also observed on Saturday and on a public holiday.
Perhaps participants felt less willing to participate during their leisure time.
Furthermore, one of the limitations of the field application was that the sound quality had to be significantly reduced in order to run on the phones.
It was observed  that the acoustically more complex auditory icons were affected more than the earcons.
Many participants reported that the low quality of the auditory icons made them annoying, in contrast to the high quality sounds during the lab sessions.
Despite this quality bias in favour of earcons, participants still preferred the auditory icons during the field study.
In this paper we have presented an evaluation study comparing the appropriateness of auditory icons and earcons as mobile service notifications.
Auditory icons performed significantly better in terms of intuitiveness, learnability, memorability and user preference.
Drawing from these findings, we have discussed design implications for mobile audio notifications.
In particular, we suggest that commonly identified sounds should be used, or those that can be learned with quick and basic training.
