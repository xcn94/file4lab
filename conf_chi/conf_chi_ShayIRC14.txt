Ultimately, he was able to restore access to his accounts and much of the data that had been lost, though at considerable cost, time, and effort on his part .
When one of the attackers contacted him, Honan was able to ask why the attacker had done this damage - it was to access Honan's coveted 3-letter Twitter handle, "mat"; the data destruction was just "collateral damage."
Honan's article is gripping not only as a story about his experiences, but also as a cautionary tale.
With so much of our lives now digital, online, and not entirely under our control, we can easily imagine losing access to our communications, reputation, and data, with little recourse.
Recent years have brought a rash of other stories of highprofile account hijackings.
For example, U.S. Vice Presidential candidate Sarah Palin's email account was compromised in 2008 , the personal email account of a Twitter executive's wife was compromised in 2009 , the group Anonymous broke into accounts of executives at a security firm in 2011 , and attackers broke into the Twitter accounts of numerous media outlets, including the Associated Press , the Financial Times , the Guardian , and the Onion  in 2013.
Account hijacking is hardly limited to high-profile accounts; anecdotal evidence suggests that it is widespread and can be devastating.
In response, service providers continue to improve authentication, compromise detection, and account recovery mechanisms.
However, the design space for these systems is vast, and they often require user participation, which is notoriously hard to get for securityrelated tasks .
A better understanding of the hijacking problem - and how to motivate users to take action against it - should help improve the design of such systems.
To gain a better understanding of the hijacking problem from the user's perspective, we surveyed 294 people about their experiences with and attitudes toward email and social network account hijacking.
We confirm that the problem is, in fact, widespread; 30% of our 294 participants reported that at least one of their email or social networking accounts had been accessed by an unauthorized party.
We also highlight five themes that emerged from our results:
With so much of our lives digital, online, and not entirely under our control, we risk losing access to our communications, reputation, and data.
Recent years have brought a rash of high-profile account compromises, but account hijacking is not limited to high-profile accounts.
In this paper, we report results of a survey about people's experiences with and attitudes toward account hijacking.
The problem is widespread; 30% of our 294 participants had an email or social networking account accessed by an unauthorized party.
Five themes emerged from our results:  compromised accounts are often valuable to victims,  attackers are mostly unknown, but sometimes known, to victims,  users acknowledge some responsibility for keeping their accounts secure,  users' understanding of important security measures is incomplete, and  harm from account hijacking is concrete and emotional.
We discuss implications for designing security mechanisms to improve chances for user adoption.
Copyrights for thirdparty components of this work must be honored.
For all other uses, contact the Owner/Author.
Copyright is held by the owner/author.
However, they emphasize password management measures for preventing account compromise and seem less aware of anti-phishing and anti-malware measures.
Even when it is minimal, users experience strong feelings of anger, fear, and embarrassment about the compromise.
We discuss implications for designing security mechanisms into large, modern Web services in ways that improve chances for users to adopt those mechanisms.
The researchers found that interviewees often applied their own understandings of real-world physical security when making access-control decisions.
Another line of research has explored how people react to security incidents or changes in security policies.
For example, in a survey of 301 undergraduate students, Rader, Wash, and Brooks investigated how stories that people tell about security incidents that they or others have experienced resonate with people and, in turn, are translated into security-related beliefs .
The researchers found that respondents encapsulated and transmitted security lessons in the form of stories and that these stories can affect behavior and understanding.
In another example, Shay et al.
The researchers found that while respondents tended to be annoyed, they also felt more secure and were neutral about reverting to the previous policy.
And finally, Harbach et al.
This related work suggests that by identifying shortcomings in users' understanding, designers might be able to correct misunderstandings and encourage users to practice better security-related behaviors.
The work presented in this paper fits into this space by helping to describe how users experience and perceive account hijacking so that we and others can figure out how to encourage users to make decisions and practice behaviors that help prevent their accounts from being compromised.
To the best of our knowledge, this is the first such study on this topic.
Our work fits into the space of research about people's experiences with and attitudes toward online security.
In this section, we highlight key related work in that space.
One area of research has focused on models of how people think about security.
For example, Camp proposed five mental models that were derived from a review of the literature .
Her models - physical security, medical, criminal, warfare, and market - represent a broad view of how people think about privacy and security and how they frame security decisions.
Camp points out that people's understandings tend to rely too strongly on their own past experiences.
For example, if a person has previously engaged in a risky computer activity without negative consequences, then that person may underestimate the risk of that activity and continue to engage in it.
Wash provides another view of how people think about computer security based on interviews with 33 people .
He identified several "folk models" that describe how people think about malware and attackers .
Similar to Camp, Wash points out how shortcomings in these models can lead people to misidentify threats.
For example, those who think attackers would not bother going after them personally might not be aware of the threat posed by botnets.
Other researchers have explored how people make specific security-related decisions.
For example, Mazurek et al.
In July 2013, we conducted an online survey of people in the U.S. who use a personal email or social networking account at least once per month.
In this section, we describe the survey - including supplemental data that we collected from an additional microsurvey, the participants' demographics, and how we analyzed the qualitative data.
The online survey had two main branches: one branch was administered to people who had experienced the compromise of a personal email or social networking account  and the other was administered to people who had not .
We recruited participants from the Amazon Mechanical Turk crowdsourcing service .
When we recruited, we did not mention that our survey was about account hijacking; rather, our posting proposed, "Answer a survey about your email or social networking account."
Participants were assigned to one of the branches based on their response to the question: "As far as you know, has anyone ever broken into any of your personal email or online social networking accounts?"
Both branches included open- and close-ended questions.
We collected data over three hours on the evening of Friday, July 26, 2013.
Each participant could only take the survey once and received $1 as compensation.
Participants who had experienced the compromise of an email or social networking account were asked about their experience .
If participants indicated having experienced more than one such compromise, they were instructed to answer the questions about "the most upsetting" episode.
We asked about their account, how the compromise happened, who they thought did it, its consequences, and whose responsibility it was to prevent their accounts from being compromised.
They found Turkers to be more female than male, and average 36 years with more education than the general U.S. populace.
They also found evidence of MTurk resulting in data comparable in quality to surveying on a university campus.
Participants who had not experienced the compromise of an email or social networking account were instructed to think about either their primary personal email  or social networking  account throughout the survey.
Those having only one or the other were asked about that one; otherwise we asked about one at random.
We asked about whom participants were concerned about breaking into their accounts, how they thought accounts were compromised, what they thought an attacker would do if he or she broke into the participants' accounts, and whose responsibility it was to prevent their accounts from being compromised.
To develop the survey, we conducted five semi-structured interviews with a convenience sample of friends and family of our extended research team who had experienced an account compromise.
Results from the interviews provided us with insight for creating the survey.
After drafting the survey, it was reviewed by experts from our institution, revised, and then piloted with a convenience sample of six people from our institution who were not from our research team.
After subsequent improvements, we launched a pilot on MTurk with 20 people.
After we made minor adjustments from that pilot, we launched the final survey.
We do not report data collected from these pilot studies.
We received 300 completed surveys and discarded six that were duplicates or did not meet our criteria for participation, such as if a participant did not have a personal email or social networking account that was checked at least once per month.
Although MTurk has been shown to be a trustworthy platform for past user studies, it is possible to get lowquality responses.
As with any online survey, participants on MTurk can cheat to receive incentives by answering all required questions as quickly as possible and providing junk data in the process.
We took three measures to guard against such junk data in our results.
First, we required that the Turkers who responded to our survey have a task approval rate of 95% or better, and have completed at least 100 tasks, so we expected to have a relatively high-quality pool of participants.
Second, one member of the research team reviewed all responses to the open-ended questions to ensure that responses were on topic and determined that they all were.
Finally, we had three trap responses to our multiple-choice questions - responses that were obviously wrong, and we expected no participant who was paying attention would choose.
We found that six participants did choose trap responses.
However, no participant chose more than one, and those participants did provide valid responses to open-ended questions.
Thus, we assume the few trap responses we received were errors due to misreading or misclicking rather than cheating, and we include these participants' data in our analysis.
MTurk, which has been used in prior usable security research , allowed us to collect data from a large number of diverse participants.
MTurk has also been used by Kittur, Chi, and Suh to investigate how well "Turkers"  assessed the quality of Wikipedia articles .
The researchers were impressed with how well the Turkers'
We ran a separate one-question survey  with a different survey service  , and thus a different population, to confirm our finding about the rate of account compromises.
Web users respond to microsurveys from GCS in order to access premium Web content .
We used GCS's "multiple choice, single answer" microsurvey format to ask, "As far as you know, has anyone ever broken into any of your personal email or online social networking accounts?"
We set the "audience sample" feature to target the general population in the U.S., and we collected data from 1,501 participants from Tuesday, July 30 through Thursday, August 1, 2013.
As to their highest level of education, just over a third had Bachelor's degrees and another third had some college.
The remaining third was spread over a broad range of from some high school  to having a Master's or doctorate .
19.7% were students, some of whom were also employed, and 16.3% were unemployed or looking for work.
Participants represented a broad range of occupations, including customer service representative, sign fabricator, human resources assistant, retired teacher, piano mover, biologist, lawyer, day trader, youth development professional, video editor, filmmaker, administrative assistant, web developer, construction worker, homemaker, writer, and lead programmer.
While we cannot account precisely for the difference in MTurk and GCS responses, we note that the motivations for completing surveys may be different; Turkers set out to complete a survey, while GCS participants are trying to get to premium Web content.
Differences in the responses may be due to this motivational difference or to other demographic differences, but we note that account compromises are reported at high levels and seem to be a common experience.
Our findings are consistent with a 2013 study from the Pew Research Center, which found that 21% of Internet users have had an email or social networking account compromised .
To mitigate priming and learn from participants in their own words, we asked open-ended questions.
Participants who had experienced the compromise of an email or social networking account were asked five open-ended questions, and the other participants were asked one.
For each question, we created a codebook to interpret responses.
Coding categories were developed from our review of the responses and related work.
Two coders independently categorized each response using the codebooks.
We validated the codebooks through preand post-discussion coding, measuring agreement with Cohen's Kappa .
After discussion, the coders were in "Almost Perfect" agreement on responses from every question  .
Of the 89 participants who reported experiencing an account compromise, 73  used their accounts at least once a week, and 53  used their accounts daily.
When we asked participants for the main reasons they used their accounts, 69  indicated "Personal communication," which we take to be an important use, compared with options such as "Receiving deals or coupons" or "Receiving updates or newsletters."
We asked the 89 participants who had experienced a compromise, "Who do you think was behind the break-in?"
In this section, we review details of the compromises that participants experienced as well as who participants think is responsible for keeping their accounts safe and the role they think passwords have in account protection and recovery.
We refer to participants who experienced an account hijacking as H1, ... , H89 and participants who did not as NH1, ... , NH205.
At the beginning of the survey, all participants were asked, "As far as you know, has anyone ever broken into any of your personal email or online social networking accounts?"
Of our 294 participants, 89  answered that one or more such accounts had been compromised.
In our supplemental GCS microsurvey , 15.6% of participants indicated that they had experienced one or more account compromises.
Though less than our MTurk sample, it still represents a meaningful portion of the Web population experiencing account compromises.
We followed that by asking for participants' confidence level about who broke in.
Just over half  indicated they were "Not at all" confident about who broke in, but of the 35 who were at least moderately confident, 30  indicated it was someone they did not know.
Of the remainder who expressed at least moderate confidence, three were extremely confident it was someone they knew but did not live with, and two indicated it was someone they lived with.
Of those who expressed they were "Slightly" or "Not at all" confident, 51  indicated it was someone they did not know, and only two  indicated it was someone they knew but did not live with.
The next dominant emotion was annoyance.
Furthermore, some participants felt "violated," "frustrated," or "vulnerable."
For some, the emotional damage persisted because they could not fully gauge the consequences.
H5 explained, "The harm was mental because I was afraid that the email hacking may have also allowed a computer bug to infiltrate  system."
H72 continues to worry about potential future fraud: "So far I have  noticed any thing  like credit fraud yet, but I'm still nervous."
Participants didn't just feel annoyed or afraid; a few were also "embarrassed."
H19 reported, "A lot of my friends and colleagues had received spam emails from  and it made a bad impression of me to them."
Overall, six participants indicated that the compromise caused bad feelings for their contacts, making their contacts "annoyed" with the spam or "a little upset."
H48 expressed the harm in terms of damage to his reputation: "Rumors were spread, and people might look at me differently because of it."
The embarrassment sometimes was caused by the inappropriate content of the spam messages.
For example, H52 explained, "My religious aunt asked why I was trying to sell her viagra ."
However, the social implications were not all negative.
When asked what good came of the compromise, H62 stated, "I knew my friends cared!
They warned me and asked if I was alright."
Sixteen participants  reported experiencing a negative feeling, such as "It was frustrating, but not harmful" .
However, for some, the harm was more substantial.
Five participants reported being locked out of their accounts, two of whom never regained access.
We note that in a later multiple-choice question, 25  of the 89 participants reported that they were locked out of their accounts at least temporarily; however, only five mentioned it as a harm in the earlier open-ended question.
Four participants reported having other accounts hijacked as a result of the compromise, one of which was financially related: "my amazon account  hacked and purchases were made" .
Four reported that data in their account was altered or deleted  and "hundreds of my emails had been deleted" .
See Figure 1 for a breakdown of the open-ended responses.
To understand what the 205 participants who had not experienced an account compromise believed might happen in a compromise, we asked, "If someone you don't know broke into your account, how likely is he or she to do the following?"
Response options, which participants ranked from "Not at all likely" to "Extremely likely," were: * * * * * * * * * Break into your other accounts, Send spam to your contacts, Find things to blackmail you with, Find things to blackmail your contacts with, Try to trick your contacts into sending him or her money, Lock you out of your account, Delete your account, Delete stuff in your account, and Impersonate you .
Although most participants reported no substantial harm, when asked how they felt when they learned their account had been compromised, all but seven expressed strong negative feelings, such as "I was mad," "violated," or "angry."
For example, though H50 reported, "No harm came from it.
It was just a nuisance," he nevertheless reported feeling "angry" and "upset."
The most prominent feelings, each reported by over a quarter of participants, were anger  and fear .
When asked who is responsible for preventing account compromises, 173 , said the service provider is at least partially responsible.
Of these 173, 26  indicated that the service provider was responsible for general security.
For example, H73 said, "It is the provider's responsibility to make sure the system is as hackproof as possible."
Furthermore, 22  mentioned that providers need to keep their systems secure.
For example, NH185 wrote, "The provider needs to maintain a secure website and keep up to date on security threats," whereas NH6 mentioned that providers are responsible for "keeping password databases secure."
Most participants indicated that they alone were responsible for preventing break-ins , or that they share responsibility with the service provider.
Table 1 summarizes the results.
Only 11  mentioned an entity other than the user or service provider, of which five  indicated the attacker.
We found no significant difference in responses between participants who had or had not experienced a compromise.
Some participants  indicated that the responsibility depends on the type of compromise.
As NH116 explained: "It depends, if someone breaks into Facebook and steals my password from them it's their fault.
Furthermore, several participants stated clear responsibilities for users and service providers, such as users being responsible for following good password practices and service providers being responsible for providing a secure website or system.
A few participants stated that the service provider has a duty to prevent the attacker from breaking in, detect suspicious activity, inform the user of the compromise, and help the user get back into the account.
NH121 explained, "They should be able to tell if an account has been hacked, and have a way to contact me."
H31 reported how being notified about the compromise by the service provider increased her trust in them, "I trusted gmail  because they notified me immediately" .
In a check-all-that-apply question, we asked the 89 participants who had experienced an account compromise, "How did you discover that your account was broken into?"
Participants chose from: * * * * * I got locked out because my password didn't work, Someone told me about something suspicious from my account , I was notified by the service provider , I noticed things happening in my account that I didn't do, and Other .
Seventy-six participants  indicated specific responsibilities for users, of which 61  mentioned something about password management.
Responses varied, with most mentioning the need for strong passwords .
For example, NH107 said, "I need to have a strong password that isn't easy to crack."
Twenty-six  were informed by their account's service provider.
However, the most common response was that someone told them about something suspicious from their account .
Twenty-seven  noticed things happening in their account that they didn't do, and fifteen  couldn't log in to their account.
We asked all 294 participants the check-all-that-apply question, "Which of the following would help prevent your account from being broken into?"
Participants chose from: * * * * * * * * * * * * * * Changing passwords often, Changing your computer wallpaper, Upgrading your web browser, Using two-factor authentication , Deleting your web browser cookies, Using a strong password, Installing photo editing software, Avoiding logging in on public computers , Avoiding using the same password on different accounts, Locking your computer or device screen, Signing out when you're done checking your account, Using your username as your password, None of these, and Other .
We asked the 89 participants who had experienced a breakin, "What good, if any, came as a result of the break-in?"
More than two thirds reported something positive from the experience, most often a heightened awareness or improved security-related behavior.
For example, H74 said that the compromise "gave me a wake up call about my password security."
The most popular response  was changing the account password or improving password management.
For example, H60 said, "It made me realize that I need a more secure password and now I have the hardest password in the world."
H72 also "started using more secure passwords."
Overall, 23 participants  reported changing the password for their account, with nearly half expressing that they had created a stronger password than before.
Ten  mentioned better password behavior not only for the account that was broken into, but also for other accounts.
In contrast, having to change their account's password was mentioned as a harmful outcome by 12 participants , as H79 explained, "I had to change my password that I've used for a long time."
Furthermore, 13 participants  provided a general statement about being more mindful or better about online security.
H86 explained, "I developed smarter habits.
I change my passwords often.
I also am careful about clicking on things I'm not sure about."
Other participants reported a change in their account-related behavior.
Five  mentioned switching to another email provider as a positive, and three  listed deleting or abandoning the account as a positive outcome.
We asked the 89 participants who had experienced a compromise the open-ended question, "How do you think your account was broken into?"
H67 explained, "I used the same username and password for everything," whereas H37 did not know how her password was stolen, "Someone, somehow, found out my password.
Maybe they used a `password cracking' machine."
Besides compromised passwords, there was no other popular explanation for how participants thought the compromise occurred.
Thirty participants  indicated not knowing or being unsure about how their accounts were compromised; nine  attributed it to phishing or a malicious link; seven  blamed it on viruses or other malware; and five  thought the compromise was a result of the service provider being hacked.
We asked the 205 participants who had not experienced a compromise the check-all-that-apply question, "Which of the following do you think are the most common ways that someone might try to break into your account?"
The most popular option  was "Installing a virus or other program on your computer."
Modern Web services that host millions of accounts can take a wide variety of measures to prevent account compromises.
For system designers who are responsible for the security of these services, the set of design possibilities and tradeoffs is vast and often difficult to navigate.
For example, password-based authentication can potentially be made more secure in a variety of ways: perhaps with a policy that prohibits easily guessed passwords; by serving content securely over HTTPS rather than over HTTP; or by using two-factor authentication .
Each candidate solution has costs and risks.
Costs may include a learning curve for users and implementation and operational costs for the service provider.
Potential risks include increased user lockout,
A system designer might ask which solutions are worth pursuing.
Even after a service implements a solution, the designer is faced with choices about how to educate users about the new solution and how to motivate adoption.
Our results bring some data to bear on the difficult design tradeoffs that designers face.
We discuss our results with an eye toward their implications for the secure design of large, modern Web services.
With this perspective, we see five important themes emerging from our results:      Compromised accounts are often valuable to victims; Attackers are unknown and known to victims; Users acknowledge some responsibility; Understanding of security measures is incomplete; Harm from hijacking is concrete and emotional.
Users place different values on their various digital accounts .
Some may be unimportant, such as accounts users set up merely to try out a new service that they soon abandon; others may be very important, such as a daily-use email or social-networking account.
Our results suggest that most of our participants' compromised accounts were frequently used, and a primary use of those accounts was personal communication.
Designers should acknowledge that many of today's vulnerable accounts are important, and that users might be willing to invest more effort into protecting them if users better understood the risks and outcomes of having their accounts compromised.
Given the literature indicating limited patience and cooperation of users for security measures , we were surprised that a large majority of participants indicated that they alone were responsible for keeping their accounts safe, or that they shared that responsibility with the service provider - 82% and 89% of compromised and noncompromised participants, respectively.
These high rates at which participants acknowledged some responsibility suggest - though they do not guarantee - that users may be open to additional security features, such as two-factor authentication or social-based account recovery, that provide greater security at the cost of somewhat increased friction.
Certainly, there are numerous barriers to adoption for such features , but our data suggest that at least one barrier - user attitudes - may be overcome.
When asked about the common ways accounts are compromised, participants selected malware , phishing , and third-party password database breaches  as the top ways.
This indicated a surprising  awareness of the most common ways accounts are compromised.1 Nevertheless, when asked what they did or would do if their account were compromised, more participants mentioned password-related measures, such as using stronger passwords or unique passwords for each service, than antimalware or anti-phishing measures.
In particular, 90.5% of our participants selected "Using a strong password" as a way to prevent their account from being broken into, and in open-ended responses, participants emphasized the importance of "secure" and "strong" passwords.
We note that "secure" or "strong" passwords are commonly interpreted to mean passwords with a variety of characters or with random-looking patterns.
However, such passwords only mitigate some instances of one class of attack - password cracking.
Even "Avoiding using the same password on different accounts," a response selected by 81.3% of our participants, only mitigates against third-party breaches and other reuse attacks, but not against phishing and malware.
Guarding against phishing and malware attacks requires users to put other preventive measures in place.
Different security mechanisms have strengths and weaknesses in protecting against different kinds of attacks, so it is valuable for system designers to understand the common forms of attack.
Over 90% of the 89 participants who experienced a compromise believed their attackers to be unknown to them.
Still, attacks by people close to the account holder occur and should not be ignored.
If designers must make resource tradeoffs, our results suggest focusing on unknown attackers, but that known attackers should also be considered.
These results can help inform the cost-benefit tradeoff of using authentication systems like social authentication , which may provide some security against people unknown to the account holder, but may leave them vulnerable to people known to the account holder.
These results also suggest that two simple password memorability techniques that can help users use unique passwords for their different accounts -  writing passwords down at home; and  using a password manager on a home computer - are likely to be secure against the most common attackers.
Password managers on a home computer also have the added benefit of being secure against phishing, since they provide passwords only to the correct domains.
Users may emphasize password management measures because they are a commonly communicated message in many account set-up processes, security training, and in the press; or because users may view password management as a relatively easy, actionable step they can take.
Either way, it seems security mechanisms that focus on easily messaged and easily actionable steps are likely to have a chance at user acceptance.
In fact, there are simple steps users can take against malware and phishing, such as updating their browser to the latest version, ensuring that automatic updates are enabled, and using a password manager.
Simple steps like these could be more widely and clearly communicated through advice and training.
In this paper, we presented results of a survey about people's experiences with and attitudes toward the compromise of a personal email or social networking account.
We confirm that the problem is widespread; 30% of our 294 participants reported that at least one of their email or social networking accounts had been compromised.
We highlighted five themes that emerged from our results:  compromised accounts are often valuable to victims,  attackers are unknown and known to their victims,  users acknowledge some responsibility for keeping their accounts safe,  users' understanding of security measures is incomplete, and  harm from account hijacking is concrete and emotional.
We discussed implications for designing security mechanisms into large, modern Web services in ways that we hope will improve chances for user adoption.
Our results suggest that the concrete harm that users experience from an account compromise is often minimal, though it can sometimes be severe.
But even when concrete harm is minimal, users experience strong negative feelings such as anger, fear, and embarrassment.
Designers who are trying to motivate users to adopt enhanced security mechanisms might try emotional appeals about the harms of compromised accounts to gain users' attention and interest.
As one idea on this theme, designers might try using stories about the potential effects of account compromise.
In fact, Rader, Wash, and Brooks found that stories are a prevalent and effective way for users to learn about security .
Our sincere thanks go out to Adrienne Porter Felt, Allison Woodruff, Anna Avrekh, Antonio Fuentes, Borbala Benko, Cindy Yepez, Diana Smetters, Ed Chi, Eddie Chung, Elie Bersztein, Jay Nancarrow, Kathy Baxter, Martin Ortlieb, Mayank Upadhay, Nadja Blagojevic, Noam Bernstein, Roberto Ortiz, Steve Gribble, Susan Gentile, Tadek Pietraszek, and the many other family, friends, colleagues, participants, and reviewers who have contributed to this work.
This exploratory study has limitations with the population that we surveyed as well as with the methodology that we employed.
We used MTurk as our recruiting platform and limited our population to Turkers in the U.S. who were over 18 years of age.
As described above, MTurk has known biases, but allowed us to conduct this research quickly and in a reasonably cost-effective manner; we discussed several quality control mechanisms that we used to mitigate the biases.
We used the GCS platform to compare our MTurk population to a more broad Web population, but the GCS platform comes with its own limitations.
As to our method, we relied on self-report data collected online.
Such data is unconfirmed, and can be impacted by biases such as recall, social desirability, and lack of understanding.
For example, participants may have been more likely to recall or even notice the compromise of an important account; therefore, such accounts may be disproportionately reported as compromised.
Further, our survey of participants who had not experienced an account compromise often asked them to speculate.
Future work should validate and expand on our results, for example, by considering the experiences of and attitudes toward account hijacking in other countries, for other types of accounts, with different age groups, and by using other methods to investigate these issues.
