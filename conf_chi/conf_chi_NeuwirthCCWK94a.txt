ABSTRACT Previous research indicates that voice annotation helps reviewers to express the more complex and social aspects of a collaborative writing task.
Little direct evidence exists, however, about the effect of voice annotations on the writers who must use such annotations.
To test the effect, we designed an interface intended to alleviate some of the problems associated with the voice modality and undertook a study with two goals: to compare the nature and quantity of voice and written comments, and to evaluate how writers responded to comments produced in each mode.
Writers were paired with reviewers who made either written or spoken annotations from which the writers revised.
The study provides direct evidence that the greater expressivity of the voice modality, which previous research suggested benefits reviewers, produces annotations that writers also find usable.
Interactions of modality with the type of annotation suggest specific advantages of each mode for enhancing the processes of review and revision.
To explore ways to balance the relative costs and benefits of spoken comments, we built an interface to provide some structure for the voice annotations and to allow recipients of annotations some degree of control over this very high bandwidth information, without sacrificing ease of use for the annotator.
In addition, we undertook a study with two goals: to compare the nature and quantity of comments produced in voice and in writing, and to evaluate how writers responded to comments produced in each mode.
To examine these issues, we conducted an experiment in which writers were paired with annotators who commented on their texts.
The annotators made either written or spoken annotations and the authors revised on that basis.
THE INTERFACE DESIGN In the present study, participants used a voice interface in a prototype collaborative writing environment, called the PREP Editor.
The PREP Editor provides a document with multiple columns .
Unlike columns for printing, these columns are like margins--they provide a space for communicating about a document.
To produce comments in the PREP Editor, the user creates an annotation column and specifies a default mode of annotation from among three available modes: text, drawing, and voice.
Then to create annotations, the user simply clicks in the annotation column near the relevant document content, an operation that resembles putting pen to paper in the margin of a hard copy document.
For reception of voice annotations, we worked on ameliorating problems in  accessing voice annotations,  listening to them, and  revising in response to them.
In a study of tape recorder users, Degan et al.
We hypothesized that allowing reviewers to associate individual comments with particular parts of a document, as described above, would alleviate this somewhat.
INTRODUCTION A recent study of speech versus text as media for reviewing documents found benefits for producing voice annotations for reviewing documents : whereas subjects using speech were more likely to comment more on higher-level concerns than those using text, subjects using text were more likely to comment more on lower-level concerns than those using speech.
When subjects using text did comment on higher-level concerns, their comments were judged to be less useful.
The study did not, however, examine the effects of the spoken annotations on the recipient.
Recipients of voice annotations may be at a disadvantage when compared to recipients of written annotations.
For example, recipients of a voice message are more limited in their ability to review, skim and otherwise abstract the content.
While speech is faster than writing for the producer, it can be slow and tedious for the receiver to process .
In sum, the design of the interface was intended to preserve the ease with which reviewers are able to produce voice annotations while ameliorating problems authors might experience in using such annotations.
The experimental study assessed how well the interface achieved its goals and explored the relative effectiveness of the two modes for authors and reviewers.
The participants in the study consisted of twenty authors paired with twenty reviewers.
The authors were members of the School of Computer Science, recruited from a pool of people who by self-report had manuscripts that were close to being ready for review.
They participated by submitting an on-line version of their manuscripts, by suggesting appropriate reviewers, and by revising the manuscripts based on a reviewer's comments.
The reviewers participated by annotating a manuscript.
The authors and reviewers were not compensated in any way.
Authors' manuscripts included grant proposals, conference papers, book chapters, technical reports, and journal articles.
All participants used the PREP Editor.
The study employed a 2x2 mixed factorial design.
The first factor, production mode, was varied between subjects: half the reviewers produced annotations in voice mode and half in written mode.
The second factor, reception mode, was varied within subjects.
As discussed below, annotations were manipulated so that each writer received half the comments in voice and half in text.
This design allowed us to see, for example, whether comments produced in voice but received in writing might be superior to those received in voice.
Each pair of participants took part in three sessions.
During the annotation session, the reviewer commented on the draft.
In the revision session, the writer read and listened to the reviewer's comments and revised.
In the evaluation session, the reviewer evaluated the responsiveness of the writer's revised draft to the comments he or she had made.
Prior to the annotation session, reviewers were asked to read a hard-copy of the manuscript  within twenty-four hours of their session.
During that session, reviewers had one hour to annotate the manuscript.
They were asked to follow their usual manner of reviewing, except that they were asked to use the PREP Editor.
Additionally, their mode of commenting was restricted to either voice or text.
Reviewers were randomly assigned to either voice or written production mode.
Following these sessions, every other annotation was converted to the alternative mode.
In the voice condition, half of the comments were transcribed into written text and substituted for the original comments In the text condition, reviewers made only written annotations during their initial session and were then asked to record half of their annotations.
Figure 1: Annotation column  next to a content column in the PREP Editor.
Users play voice annotations by clicking on the iconic representation.
This method was hypothesized to be most useful for authors who want to work with comments while revising a text.
The second access method is via a "down to next" command that jumps to the next comment, where, if it is a voice comment, it automatically plays.
This method was hypothesized to be most useful for obtaining a quick overview of all the comments.
To alleviate some of the problems in listening to comments, we designed a direct manipulation "sound palette" interface, depicted in Figure 2.
The buttons across the top of the sound palette correspond to buttons on a standard tape player : record, stop, play, rewind, pause, and fast forward.
An important feature of the rewind button is that the sound resumes playing automatically after the user lets up on the button.
This feature is common in transcription machine interfaces and allows users to relisten to the last bit of sound easily.
Across the bottom of the sound palette, a progress bar shows how much of the sound has played.
When a user clicks on a location in the progress bar, the sound begins playing from that point in the recording.
Thus the progress bar can fast forward, rewind, or loop the sound by direct manipulation.
While the mouse button is down in the progress bar, a short sample  of the sound continuously cycles.
By moving the mouse the user can "skim" through the sound.
All these features are designed to help users replay sounds rapidly.
When working with a written comment, an author can read part of the comment, revise the text, read the next part of the comment, revise, and so on.
To facilitate this process for voice comments, the interface pauses the playback whenever a user takes certain actions such as selecting, revising, or creating text.
This allows authors to respond to voice comments and then resume the playback easily.
Prior to the revision sessions, the documents were prepared so that the writer's manuscript would appear in one column and the annotations  would appear in a second column.
During the session, writers had one hour in which to listen to or read their reviewer's After annotations and to revise their manuscripts.
First, writers reported their impressions of both the reviewer and the review in terms of competence, personal integrity and likability.
In the second survey, writers rated their preferred mode for receiving comments on audience, purpose, substance, organization, style, and grammar.
During the evaluation session, reviewers listened to or read the comments they had made and rated the revised draft on its responsiveness to each comment.
All participants were asked to "think-aloud" throughout their sessions; all sessions were audio- and videotaped.
ANALYSIS In both modes of production, reviewers sometimes recorded more than one problem within a single chunk of the manuscript.
Independent raters parsed the reviewers' chunks into units containing a single annotation.
The inter-rater reliability of the two coders as indicated by signal detection analysis was .83.
On average, 28% of the chunks were identified as containing more than one annotation.
Agreement concerning these classifications between two trained raters on 15% of the data was .88 by Cohen's Kappa.
Extraneous and irrelevant remarks were excluded from further anal ysis.
RESULTS AND DISCUSSION We looked first at the effects of production modality on the cognitive and social aspects of reviewers' annotations.
Then we examined the effects on writers' perceptions of reviewers as well as on writers' performance.
Finally, we looked at writers' preferences for mode of annotation.
Cognitive Aspects of the Annotations While it seems unlikely that the mode of producing annotations would affect reviewers' abilities to identify and judge the problems in a text, it might affect their ability to communicate those problems.
We examined three factors that might be affected: the number of problems communicated, the type of problems communicated, and the characterization of the problems communicated.
Producing Number of problems communicated.
Given constraints of time or motivation, reviewers making voice comments may make more comments than they would if they were writing.
On the other hand, previous research by Kiesler et al.
The present study supports the latter position, as indicated by comparing the number of annotations produced to the relative number of words per comment.
The mode of producing annotations might also affect reviewers' choices of the type of problem to communicate.
Research on cognitive processes in revision indicates that representing a text problem is a demanding process .
Part of the difficulty lies in the nature of the problems themselves, which can range from well-defined, relatively easy-to-communicate problems  to more difficult to define, difficult-to-communicate problems .
The more difficult problems are those which are harder to designate with a specific term, those whose effect is more diffuse, and those for which there are fewer readily specifiable solutions.
Table 1 shows the distribution of annotations by problem category and mode of production.
We analyzed the data with a 2x6 repeated measures ANOVA, with production mode as the first factor and problem category as the second factor.
Writing, even for mature writers, remains a complex activity and people often complain they cannot put ideas to paper fast enough to keep up with their thoughts.
Thus, the mode of production may influence the way reviewers characterize problems, with reviewers using voice communicating more elaborated representations and those using keyboards producing sparer representations.
To examine this possibility, annotations from five subjects in each condition were randomly selected and coded as to whether or not they contained reasons for a recommended change.
Inter-rater reliability of two coders on a subset of the data was .71 by Cohen's Kappa.
While reviewers using voice did not produce a greater absolute number of annotations with reasons than reviewers using keyboards , annotations with reasons represented a greater proportion of the total annotations made in voice  than of the total annotations made with keyboards  .
Taken with the results reported above, this finding supports the hypothesis that the effort required to produce a comment influences its length and its content.
Later, we consider whether these differences in the comments also influence their reception by writers.
Reviewers identified about the same total number of problems in both production modes , but mode of production did influence the type of comments produced, as indicated by a significant interaction : In most categories, reviewers in voice mode produced more comments than reviewers working in text mode.
This pattern is reversed, however, for substance comments--to a great enough degree that the total number of comments in the two modes balances out.
These results seem in marked contrast to a previous study of voice vs. written annotations .
Although the coding categories are not directly comparable, in that study, across modalities, copy-editing annotations  were by far the most frequent.
Moreover, reviewers working in the written modality were more likely to make more low-level annotations than reviewers in voice modality while reviewers in voice modality were more likely to make more global annotations than reviewers in written modality.
The reviewers in the study reported here, however, included faculty as well as graduate students, whereas the reviewers in the previous study were all MBA students.
Research in writing processes indicates that less experienced writers tend to focus on low-level errors when revising the texts of others .
Also, reviewers in the previous study handwrote rather than typed their written comments, possibly resulting in an even greater degree of production difficulty in the written mode .
There is some evidence that, at least for very young writers, focus on low-level aspects in the composition of original texts can be shifted to higher-level concerns when they are freed from the mechanical production difficulties of written language by being allowed to dictate rather than write .
Further research is required to detemine whether greater expertise or technological differences influenced the reviewers in the current study to produce more comments on substance in the written mode.
The mode of production might also affect how reviewers characterize the problems that they communicate.
Social Nature of the Annotations Reviewers often use various language mechanisms to maintain social ties .
In this section, we review results reflecting the social quality of the annotations.
The production mode of annotations might affect how politely reviewers communicated problems to the writers.
Politeness mechanisms such as equivocation and mitigation generally take more words to express than their unequivocal or unmitigated counterparts.
Therefore the slowness of typing compared to speech might result in reviewers in the written production mode expressing themselves in more succinct and unmitigated ways, with the result that their comments might be seen as less polite.
Inter-rater reliability of two coders on a subset of the data was .88 by Cohen's Table 2 shows the distribution of comments in Kappa.
We analyzed the data with a 2x4 repeated measures ANOVA, with factors production mode and politeness category.
Overall, subjects produced many more mitigated and unmitigated problem identifications than rude remarks or compliments.
The mode of production did have the expected effect on politeness, as indicated by a significant interaction .
As illustrated in Table 2, subjects who produced annotations by voice were more likely to use mitigated language in identifying problems ; subjects who keyboarded were more likely to use unmitigated language .
With less mitigating language in their feedback, reviewers working in text mode might be evaluated less favorably by writers than reviewers working in voice mode.
We examined writers' subjective assessments vis-a-vis their reviewers along three dimensions: perceived competence , personal integrity , and likability .
We focused on these dimensions because previous research suggested that these perspectives on the source of an annotation can influence how persuasive the writer finds the annotation .
The mode of production could plausibly affect each of these factors.
Research on the human speech production system indicates that it is frequently overtaxed, with the result that speech is filled with errors and unplanned pauses.
And research in persuasion indicates that dysfluencies in delivery  may result in lower judgments of the speaker's competence, with judgments of personal integrity and likability unaffected .
While no significant effect was found for production mode on writers' assessment of reviewer competency, writers' assessment of reviewers' personal integrity was more likely to be lower when reviewers produced their comments by writing rather than speaking  .
Producing comments in writing also marginally  lowered assessments of reviewers' likability.
In all, these findings support the hypothesis that writers' evaluations of reviewers will be less positive when reviewers produce written annotations than when they produce spoken comments.
The fact that we found this effect even when writers selected their own reviewers is striking.
The next question we explored is how writers responded to comments in each mode.
Because the reviewers themselves were the most competent judges of how well their comments were addressed, we asked them to rate the revision for degree of responsiveness to their comments.
Recall that regardless of how the annotations were produced, writers received half of them as voice annotations and half as written annotations.
We therefore analyzed reviewers' assessments both by production mode and by reception mode, but neither factor influenced the responsiveness of the revisions.
In all cases, the ratings averaged about 4.6 on a 7-point scale, indicating a reasonable degree of responsiveness across the board.
We take this result as indicating that voice annotations--at least given the technology employed here--are no harder to This respond to effectively than written comments.
We used 7-point scales to assess writer preferences for modality for receiving various types of annotations: Mechanics, Style, Organization, Substance, and Purpose/Audience.
The ratings for each type are displayed in Table 4 as a function of mode of production .
We analyzed the data with a 2x5 repeated measures ANOVA, with the first factor, mode of production and the second, type.
As illustrated, ratings for the two modes of production were the same overall--and were fairly neutral.
However writers did significantly prefer to receive certain types of comments in particular modes .
The analysis also indicated that the mode of production and preference for reception interacted .
Authors were more likely to prefer receiving comments on Organization in voice if they had been produced in voice and had been produced in writing.
On the other hand, a small number of authors read through all annotations before making a single revision.
This latter group, however, did make evaluations of the annotation during the first pass .
Thus, both groups would probably benefit from having a way to mark annotations to which they want to return.
Remembering the content of annotations.
While authors can rapidly skim written comments to remind themselves of the contents, authors had to replay voice comments to do so.
One solution to this difficulty might be to provide authors with a convenient way of jotting a few notes while listening to a voice comment.
We have implemented keyboard commands so that an author can access and control the voice annotations without having to move from the keyboard to the mouse to control the sound palette.
These commands may make it easier for authors to make quick notes for themselves about the annotations as they listen.
CONCLUSIONS This study complicates the previous picture of the utility of the voice modality for supporting collaborative writing activities.
The results can be summarized as follows: 1.
The mode of production affected the type of problem that reviewers communicated: While all the reviewers in the study produced more comments on problems of substance than any other type of problem, reviewers in voice mode were likely to produce more comments about purpose and audience than reviewers in keyboard mode, while reviewers in keyboard mode were likely to produce more comments about substance.
It may be that the written text, which more readily permits review of what has been written, reflection upon it, and revision, may facilitate comments that involve complex substantive issues.
If production modality does influence the types of problems communicated, then writing tools offering both modes may need to provide guidelines for choosing the most appropriate mode to work in for encouraging evaluation at the appropriate level.
Interestingly, the type of comments produced by subjects in this study seems to differ markedly from those produced in a previous study .
It is reasonable to hypothesize that some of the contrasts between the two studies stem from differences in subject sample, written mode , and task motivation.
The mode of production affected how reviewers characterized problems.
While reviewers in both modalities produced about the same number of annotations overall, the number of words per annotation was far greater in speech.
This difference can be accounted for, in part, by the greater frequency of reasons and by the greater number of words used to produce mitigated statements.
A higher proportion of the annotations produced in voice contained reasons why the reviewers thought something was a problem and polite language that mitigated the problem.
Reviewers were required to produce all their comments in one modality, so we did not assess their modality preferences.
A previous study found that reviewers preferred voice for producing high-level comments and writing for producing low-level comments .
Of course, preferences can be conditioned by circumstances and these results may not generalize to other situations such as different acoustic environments, social situations, or user activities.
For example, in the present study, voice comments were received in a private office.
Writers might view voice annotations far less favorably if they had to listen to them in less private places in which it would be inappropriate or awkward to speak aloud or to hear someone's criticisms broadcast .
It is interesting that we found no systematic preference for having either the same production and reception modality or disjunct modalities.
This result suggests that our methodology for transcribing comments did not produce noticeably artificial comments.
Implications For Interface Design Prior to the study, each aspect of the interface underwent many changes through an iterative design process.
The study itself also resulted in numerous qualitative observations about ways in which the interface design worked well or could be improved.
At the time of the study, the grainsize for the unit of text which could be annotated was the paragraph .
Both reviewers and writers found this grain-size to be too large.
In response, we have implemented a smaller-grain size: annotations can be attached to any region of text.
Authors used the "rewind" feature so they could relisten to parts of the comments they didn't catch or understand.
It is questionable whether authors' favorable attitude toward Yoice annotations would transfer to interfaces lacking this feature.
Since this capability seems crucial, it seems worthwhile to enhance this function.
For example, our informal observations indicate that users may find a graphical representation of sound waves even more useful than a uniform progress bar, so that they can use speech pauses to detect points of interest.
The mode of production affected how writers perceived their reviewers.
Writers' evaluations of their reviewers were likely to be less positive when reviewers produced written annotations than when they produced spoken.
The study failed to find an overall difference in reviewers' assessments of how responsive writers were to annotations produced or received in the two modalities.
Future analyses are planned to examine whether the nature of the annotations and writers' perceptions of reviewers interacted with responsiveness.
Despite the previous research findings that spoken annotations would likely be tedious to listen to and more difficult to process , writers using the PREP Editor interface for voice annotations were generally favorably disposed or neutral to voice annotations for most types of comments, except low-level mechanical ones, In this study, authors chose their reviewers and reviewers were constrained to produce comments in only one modality.
More research is needed that varies both conditions of producing annotations and the social relations between the writer and reviewer and looks at annotation interfaces for other sorts of documents .
The results presented here suggest that it will be useful to explore the effects of tools offering both voice and text modalities further, especially tools incorporating the ability to switch between modes easily when producing annotations.
There are outstanding technological challenges associated with providing users the same functionality with voice annotations as they have with text annotations.
In the PREP Editor, for example, it is possible for authors to make annotations on their reviewers' written annotations, This feature is used frequently by distributed collaborative writing groups to discuss particular annotations.
Providing a similar functionality for voice annotations requires addressing issues of how an author selects a region of a voice comment on which to comment and how a voice annotation that itself has a voice annotation should be played.
This study gives some foundation for future interface design and uses of voice in collaborative systems.
ACKNOWLEDGMENTS This work was supported by a grant from the Information Networking Institute, sponsored by Bellcore.
Development of the PREP Editor is supported by a grant from the National Science Foundation  and by a grant from Apple Computer, Inc. Other members of the PREP Editor project group  contributed user interface ideas.
We thank the anonymous CHI reviewers, Jorg Haake, Jorg Geisler, and Jolene Galegher for insightful comments on an earlier draft.
The PREP Editor prototype is available via anonymous ftp,
Degan, L., Mander, R., & Salomon, G. , Working with audio: Integrating personal tape recorders and desktop computers.
An experimental study of writing, dictating, and speaking.
Hillsdale, NJ: Lawrence Erlbaum Associates.
Why computer-supported cooperative work applications fail: Problems in the design and evaluation of organizational interfaces.
Cambridge, England: Cambridge University Press.
Affect in computer-mediated communication: An experiment in synchronous terminal-to-terminal discussion.
Task requirements and media choice in collaborative writing.
