Learning an environment can be challenging for people with visual impairments.
Braille maps allow their users to understand the spatial relationship between a set of places.
However, physical Braille maps are often costly, may not always cover an area of interest with sufficient detail, and might not present up-to-date information.
We built a handheld system for representing geographical information called SpaceSense, which includes custom spatial tactile feedback hardware--multiple vibration motors attached to different locations on a mobile touch-screen device.
It offers high-level information about the distance and direction towards a destination and bookmarked places through vibrotactile feedback to help the user maintain the spatial relationships between these points.
SpaceSense also adapts a summarization technique for online user reviews of public and commercial venues.
Our user study shows that participants could build and maintain the spatial relationships between places on a map more accurately with SpaceSense compared to a system without spatial tactile feedback.
They pointed specifically to having spatial tactile feedback as the contributing factor in successfully building and maintaining their mental map.
Although such activities can help visually impaired people increase their independence and confidence in their navigation, burdens associated with these activities often discourage them to explore and learn an environment .
Prior work has shown that Braille maps can help visually impaired people prepare for their future trips to an area .
But, they use physical materials that are often costly to produce, may not always cover an area of interest with sufficient detail, and might not present updated information .
We explore a way of representing geographical information to visually impaired users on a handheld device.
We chose this form factor because mobile devices have been interwoven into their daily life  .
Thus, a map application on mobile devices can provide users with easy access to geographical information and encourage their spatial learning about the area of interest.
Our investigation includes the use of two feedback channels--auditory  feedback and tactile feedback--to present places of interest, provide detailed information about those locations, and present routes to those points.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
The main contribution of this work is the design and evaluation of a system that helps people learn directions to a location and its spatial relationships with other locations on a map through use of spatial tactile feedback to represent geographical information.
Our map system, SpaceSense, is a mobile application for touch-screen devices enhanced with custom spatial tactile feedback hardware.
This hardware embeds nine vibration motors aligned in a 3 x 3 grid , and can be used to generate vibrotactile feedback in different positions of the user's palm and fingers holding the device.
Through this spatial tactile feedback, SpaceSense offers high-level information about the direction towards the destination when the user browses route information .
Furthermore, SpaceSense provides directional information towards other locations that the user may know or like through vibrotactile feedback.
In this manner, SpaceSpace can help visually impaired users maintain high-level spatial relationships between multiple locations.
SpaceSense also adapts the Review Spotlight system  for summarizing online user reviews about nearby locations.
It reads out the most frequently-used adjective-noun word pairs extracted from online reviews to offer an overview of what people often mention about a specific place.
Thus, the user can obtain information about a location before deciding whether she wants to further learn routes to it and its spatial relationships to other locations.
Through a user study with twelve visually impaired users, we learned that participants were able to build and maintain the spatial relationship between four places more accurately with SpaceSense than a system without spatial tactile feedback.
Participants also explicitly mentioned benefits with having spatial tactile feedback in building and maintaining their mental map.
Additionally, the Review Spotlight presentation through the auditory channel was received positively by the participants because of its succinct presentation about a location.
For example, the NOMAD system  uses a touchpad placed under a paper Braille map to detect which part of the map the user is contacting.
When the user touches an area on the map that contains information, the system generates speech feedback to describe the user's contact point.
Jacobson  developed a similar system which replaces the use of static Braille maps with dynamically generated maps.
It provides auditory feedback  to describe what the user is touching and its surrounding content.
Jacobson validated that visually impaired users could reconstruct map information after they used such a system.
Parente and Bishop  showed that vibrotactile feedback when combined with speech and non-speech audio feedback helps visually impaired users discover the boundaries of mapped elements .
Lahav and Mioduser  showed that a virtual environment system, which combines speech audio and force feedback through a joystick, enabled visually impaired users to build a cognitive map of an indoor location, and successfully navigate the corresponding physical space based on this cognitive map.
Some map systems describe path information .
Google's Intersection Explorer is a hand-held application which allows the user to drag her finger on the screen to explore walkable paths that a person can take from any intersection .
With non-speech sound cues, Timbremap  helps users trace routes on a mobile device and learn geometrical patterns of walkable path segments.
Its evaluation showed that visually impaired users could learn non-trivial geometries using only touch and simple audio cues.
Similarly, Crossan and Brewster demonstrated that the combination of force feedback and sound feedback can also facilitate the learning of trajectories .
The main focus of SpaceSense is to provide visually impaired users with a high-level understanding of the spatial relationships between multiple locations instead of the exact shape of a street or a building.
Thus, our system can complement these existing systems by facilitating the acquisition of route information and high-level spatial information for multiple locations.
Their techniques can be used for learning spatial relationships between multiple locations, but may not be appropriate for devices with a small form factor.
Our exploration also examines the effect of vibrotactile feedback in learning spatial relationships.
Braille maps have been recognized as an effective means of learning spatial relationships between multiple objects for people with visual impairments .
However, these maps are physical, and their production cost is often considerable.
These maps may sometimes not have sufficient detail or updated information of the space.
Digital maps can address these issues; in this section, we review computer systems to support learning spatial relationships between multiple objects for visually impaired people.
Past research also has explored ways to provide visually impaired users with trajectory information for wayfinding.
Tactile feedback has also been used to aid visually impaired people in wayfinding.
Ross and Blasch  compared speech audio, non-speech audio, and tapping haptic feedback to indicate the direction in which a user should walk.
They found that visually impaired users overall performed navigation tasks fastest and with fewest errors using the haptic interface, with non-speech audio coming in close second.
Amemiya and Sugiyama  developed a mobile device using force feedback to provide the user with a sensation of being pulled towards the destination by the device, allowing her to navigate at her normal walking speed.
These projects aim to help visually impaired users learn their environment in situ and reinforce their cognitive map of the geographic area.
SpaceSense attempts to provide an additional means which helps the user prepare for future trips  by supporting the learning of map information and spatial relationships of objects using tactile feedback which differentiates it from prior work.
Any two of the motors are separated with a gap of at least 2 cm, and each motor vibrates at 200 Hz when activated.
The placement of the motors is partly based on psychological understanding that it is difficult to distinguish two vibration sources located closer than 1 cm , but is adopted primarily so that the system can have greater spatial granularity than the SemFeel prototype .
SpaceSense uses all the vibration motors except the one located in the center.
For audio feedback, SpaceSense uses the FliteTTS1 package to read out information through a synthesized voice.
We use this package instead of the VoiceOver functionality already built in some of the iPhone devices because we wanted the ability to precisely tune the timing of the speech feedback.
SpaceSense allows the user to select places of interest from a pre-defined list of categories .
The system retrieves up to 20 locations  sorted by distance within a 2 km radius centered on the user's current simulated location.
After the user selects a category, SpaceSense begins to present information about each location, starting with the closest.
SpaceSense offers spatial information in an exo-centric manner similar to when a person views at a map.
It reads the name and street address of each place, and uses spatial tactile feedback to indicate the place's distance and cardinal direction.
For instance, if the place is to the west of a referenced location , the left side of the device vibrates .
We designed the current prototype to provide vibration at four different strength levels  to represent the distance .
The user can perform an upward or downward flick gesture to navigate the category list and subsequent location list.
The user can also repeat the current item by double-tapping the screen.
We use a double tap gesture because the user is less likely to perform a double tap accidentally than a single tap.
The user can select a category by rightward flick gestures.
These gestures are also used for navigation and selection consistently throughout the system.
SpaceSense is a map application that runs on a handheld touch-screen device  enhanced by our custom spatial tactile feedback system.
Our motivation for choosing a mobile touch-screen device is that it allows for taps and flick gestures--interactions that are easy for visually impaired users to perform .
In the remainder of this section, we describe our hardware for producing spatial tactile feedback, and the interactions supported by SpaceSense: identifying locations, learning place details, and learning directions.
SpaceSense also offers an overview of what people mention about a specific public or commercial location on online review Websites .
It uses the adjectivenoun word pairs extracted from the original review text that Review Spotlight  normally presents in a visual interface.
Instead of visually displaying, SpaceSense reads out the ten most frequently mentioned adjective-noun word pairs through the speech feedback instead of the original review text .
The user can add the location to their bookmark list by using a two-finger rightward flick gesture on the touch screen.
This bookmark functionality allows the user to save and quickly access places that she likes.
The system conveys the distance and direction to the destination through spatial tactile feedback.
For example, if the destination is located to the north-east from the current intersection, the top-right side of the device will vibrate .
Spatial tactile feedback is provided every time the system presents an intersection.
In this manner, SpaceSense shows the user how the relationships of the destination and other locations change through the simulated movements of the referenced location similar to when reading a map.
The interactions in this mode are consistent to other modes in SpaceSense.
The user can perform upward or downward flick gestures to navigate the route instructions .
The user can also doubletap on the screen to repeat the current instruction.
SpaceSense also provides spatial tactile feedback about nearby bookmarked locations.
It will vibrate in the direction of a bookmarked location near the simulated route while the speech feedback indicates the location's name.
For example, in Figure 2D, the system will vibrate on the left side of the device to indicate the bookmarked location.
We designed this feature to help the user build and maintain spatial relationships between multiple places of interest.
Finally, SpaceSense gives the user directions to a location.
The user can perform a rightward flick gesture to select a location while she is browsing the details of that location .
The system then begins to provide step-by-step walking instructions  obtained through the Google Directions API3.
The system presents each step of the instructions in the cardinal directions along with its walking distance  one at a time .
SpaceSense also offers audio descriptions about the intersection at which a simulated performance of the previous step would put the user .
The target usage scenario of SpaceSense is when the user searches for locations that support a particular activity before she travels outside.
Thus, a laboratory study reflects this scenario better than a study in which participants are walking on the street.
All conversations between the investigator and participants were audiotaped and transcribed for the analysis.
Before the experiment, we asked them to describe familiar areas in the city, and none of them expressed a significant familiarity of the areas used in this experiment.
Additionally, we asked participants about their familiarity with the locations used in the second part of the study; none was familiar with either location as well.
The entire study took on average 80 minutes in total for participants to complete.
Participants were compensated with $50 for their participation after the study.
We demonstrated the full system to participants and allowed them to interact with the system.
We then interviewed participants to examine SpaceSense from a usability perspective.
We encourage them to provide feedback on any aspect of the system by asking them to comment on the design of the gestures, the different features of the system, and potential use scenarios.
We also examined whether an audio adaptation of Review Spotlight  could be useful in providing visually impaired users with descriptive information about a public or commercial place.
We prepared two places  for this task.
For each location, we prepared two presentations for reviews: ReviewSpotlight  and ReviewHighlights .
Participants were asked to express their opinions about both presentations.
This setup allowed us to examine how well our system design could help participants learn spatial relationship between multiple locations.
We selected two neighborhoods in a North American city with an area of approximately 4 km2.
For each neighborhood, we set the starting point near the center, and selected four locations which were on average 770 m from the starting point, and required three turns to reach.
We labeled these locations as the stores of four hypothetical persons .
Participants were allowed to navigate the route instructions freely by using flick gestures or double-taps  until they felt comfortable with the route.
The experimenter helped the participants when the system did not register gestures or taps accurately, but did not provide any information about the route information.
The participants held the mobile device with their non-dominant hand, and used the dominant hand to interact with the device.
After the participants went through the directions to one location, they were asked to reproduce the route with acrylic pieces and indicate the locations of the destination and the bookmarked place .
This route reconstruction is a common task used to probe the visually impaired user's understanding of spatial knowledge , and was used to evaluate the effects of the two feedback types on the participant's understanding of the route information.
We prepared thin rectangular pieces with four different lengths for streets , L-shape pieces for corners, and circles for the destination and the bookmarked place.
The participants were allowed to use any piece to compose a route.
To examine whether spatial tactile feedback can help visually impaired people learn routes and develop a highlevel understanding of the spatial relationships between multiple locations, we asked participants to learn the directions to four locations from the same neighborhood, one at a time .
For each destination, another location from the same neighborhood was set in the bookmark list beforehand; thus, each instruction provided to participants would always include directional information towards the destination and one other place as explained in the Learning Directions section.
The experimenter did not correct the participant's route composition at any point.
After participants were exposed to the directions to all the locations and composed routes, the experimenter asked them to draw locations of all the placesindicating their perception of the positions of the four locationson a blank sheet of paper with a blue marker .
This drawing was used to examine the effects of the two feedback types on learning the spatial relationships between the four locations.
The experimenter made annotations for later analysis, but did not make any correction even if the spatial relationships among the four locations indicated by participants were incorrect.
We simplified the drawing requirements; thus, it is unlikely that individual drawing skills affected the results.
For this part of the experiment, we set up two conditions to compare: Tactile  and Audio .
In the Audio condition, the system read out the direction and distance towards the destination and bookmarked location .
We tuned the speed of the speech feedback at a slower rate than the iPhone VoiceOver so that participants could follow the information provided by the system more easily.
The presentation order of the two interface conditions and the maps were counter-balanced across the participants.
We fixed the combinations of destinations and bookmarked locations , but we randomized their presentation order for each participant.
At the beginning of the task, we provided all participants with training and practice using each interface until they were comfortable with the procedure.
I don't really go outside by myself, but I think  could give a little bit more independence.
You can ask people when you are on the street, but it would be neat to do it by yourself .
I don't walk very far at this point, but it would give me more confidence.
They liked its succinct presentation.
They also liked that the ReviewSpotlight presentation summarized all reviews instead of presenting one particular review.
Some explicitly commented that the ReviewSpotlight presentation was easier to follow than ReviewHighlights.
The first one  is obviously a better one, much much better.
It's clear in a sense, because of its form.
The other one  is more jumpy...
Your brain has to sort out...
It stops randomly too much, and is missing data.
It  would be something you have to replay.
All participants could navigate the route instructions and understand the information presented through the spatial tactile feedback hardware after receiving the explanation from the investigator.
None of them experienced difficulty performing the flick or double-tap gesture.
Participants commented that they would use SpaceSense before they need to visit an unfamiliar area.
Participants used the system on average for 201 seconds to learn the route instructions  and 95 seconds to reproduce a route with acrylic pieces .
Table 3 shows InstructionTime and CompositionTime across the conditions and neighborhoods.
Participants were exposed to both conditions but with different neighborhoods.
Thus, we ran a two-way mixed ANOVA on both time measures for the conditions and neighborhoods.
Two of the researchers independently estimated the values for these three metrics for each route composition.
We then used the average value for the analysis.
Table 4 illustrates the error metrics for the route composition.
Because each participant was exposed to a different map for each condition, we used unpaired Welch's t-tests for our statistical analysis.
Our analysis did not show any significant difference between the Tactile and Audio conditions at the 95% confidence level.
Route instructions were given through the speech feedback in both conditions.
Therefore, it is sensible that we did not observe large differences in the accuracy of the route compositions.
A difference between the two conditions could appear in their understanding of spatial relationships between the four places in a map.
We, thus, analyzed the drawings of the four places provided by the participants.
Figure 6 shows examples of the routes created by participants.
We adapted an evaluation approach used by Passini et al.
We used the following metrics:  NumberElementsError: The number of unnecessary acrylic pieces that participants used to recreate a route.
The correct number of pieces was always seven because there were four different streets and three corners/turns in each route.
FormElementsError: The Levenshtein distance  between the participant's route composition and the correct route composition.
PositionError: The number of incorrect orientations of the L-shape pieces.
PlacementError: The number of street blocks used with the incorrect length.
We added three metrics to measure the accuracy of the positions of the destination and bookmarked place:  DestinationDistanceError: The absolute difference of the straight line distance between the starting point and destination from the one in the correct route composition.
BookmarkDistanceError: The absolute difference of the straight line distance between the starting point and bookmarked place from the one in the correct route composition.
For the place drawings , we used different neighborhoods for the two feedback conditions.
Therefore, comparing and determining the accuracy of the two drawings by each participant was not straightforward.
We decided to use subjective ratings to evaluate the spatial relationship between any two of the places from the starting point with three levels of correctness ratings: 2: Very close to the correct placement of the two places, 1: Neither completely correct nor incorrect, and 0: Not correct.
For the example shown in Figure 5, the rating between S and T  was 2.
The rating between A and S  was 1 because the orientation between the two places is not correct but their relative positions from the starting point are close to the correct answer.
With several randomly chosen drawings, we confirmed that this rating scheme could represent the accuracy of the drawings.
Two of the researchers then independently rated all the drawings.
They only knew which neighborhood each drawing was for.
And instead of having to take out a piece of paper with streets and stuff labeled and then have to look and see "ok this is south-west," for example, the vibration gave me that visual sense.
Particularly, they liked having directional information provided through the tactile channel.
It gave me information about the direction more quickly.
Because it takes more time to say "north-east" or "southwest."
But feeling the vibration in your hand gets the information to my brain more quickly.
The tactile feedback provided in each step of the directions helped to confirm their mental map.
I could anticipate the next direction based on the vibration of the locations.
It took longer  with audio...
I sort of knew which direction was next because the vibration was pointing me to a particular direction.
So I could anticipate the audio instruction.
I could anticipate that because of the vibration.
I had to abstractly think where we are going, and put the information provided by the system together.
It is a little easier to put together in the map with the tactile stimulation with the combination of the sound as supposed to .
In this calculation, the disagreements of the ratings were weighted according to their squared distance from perfect agreement.
The average rating was used to determine the accuracy of each drawing.
Table 5 shows the ratings for the correctness of the spatial relationship of all possible pairs of places in each map across the two conditions.
A Mann-Whitney test found a significant difference in the correctness ratings between the Tactile and Audio conditions .
The drawings created by participants after they used SpaceSense were more accurate than those which provided map information using the speech feedback solely.
The main difference was in what direction participants perceived the locations to be from one location to another.
Results also indicate that Neighborhood B was seemingly harder than Neighborhood A for participants to learn.
But regardless of the neighborhoods, participants understood the spatial relationships between locations better with the SpaceSense system than the Audio condition.
Overall, as one participant mentioned, the system provided information in a way that was very similar to what she experienced when orientation and mobility specialists taught her routes.
I like that the coordinate is actually on my hand...
When I first started to learn how to do routes, my instructor would draw maps on my hand and use the exact same points as coordinates like the vibration system uses .
We found that the place drawings by the participants were more accurate in the Tactile than the Audio condition.
The major reason participants found benefits with having a separate feedback channel for directional information was that spatial tactile feedback enhanced their memory of the spatial relationships between locations.
They explicitly mentioned that the information was overwhelming in the Audio condition.
P4 pointed out that it was difficult for her to maintain all the information in her mind.
And I had to keep track of Mary's store, Bob's store, the two names of the people.
And then I had to keep track of the directions to get there.
P4 explained this as follows.
With the tactile stimuli, you get the directions in your hand.
So you don't have to worry  because you can feel it.
So you take it away from your memory.
And now you just focus on how to get there.
Thus, we conclude that spatial tactile feedback can help participants understand spatial relationships between multiple locations.
The accuracy of the route and spatial relationships between places was not high.
One reason might be that participants still often had to process information provided through the speech feedback even while the spatial tactile feedback provided the directional information.
Further research is necessary to understand what an effective presentation of geographical information would be to support visually impaired people to gain accurate route information and cognitive map of multiple locations.
The current SpaceSense system only provides high-level spatial relationships between locations and covers straight streets.
When visually impaired users actually navigate space later, they may also need other information, such as the shape of a street or intersection.
We believe that integration with a system like Timbremap  would enable users to gain such information.
Future work includes extending SpaceSense to support the user's acquisition of both high-level and low-level geographical information.
There are several aspects of the system which were not covered in this paper.
For example, due to the large difference in the number of congenitally and after-birth blind participants, we did not examine the effect of this difference in learning spatial relationships.
Our current implementation of SpaceSense uses the exo-centric presentation of directions.
But the ego-centric presentation can benefit users better in some cases .
Our study shows that participants were able to learn routes and the spatial relationship between places through an exo-centric presentation of the map information similar to when a person reads a map before visiting a location; further research is necessary to investigate how to best present the spatial relationship of locations through a system like SpaceSense while the user is navigating in situ.
We developed SpaceSense, a handheld system using spatial tactile feedback to help visually impaired people acquire details about places, learn the directions to a place, and understand high-level spatial relationships between multiple locations.
Our user study showed that participants could maintain spatial relationships between four places on a map more accurately when directional information was also presented using spatial tactile feedback than only speech feedback.
We also found that the Review Spotlight presentation through the auditory channel was received positively by the participants.
The audio adaptation of Review Spotlight was received positively by the participants mainly because of its succinct presentation of reviews.
This is in line with the findings reported in , but our study confirms that the Review Spotlight presentation can benefit visually impaired users as well.
However, as participants indicated, they may want to access to portions of the original review text to gain more detailed information.
This was discussed in the original Review Spotlight work, which incorporates a hyperlink on the adjective-noun word pair to the sentences from which the clicked word pair was extracted .
A faithful adaptation of the Review Spotlight system is out of the scope of this work; however, future work should investigate how an audio-based system can effectively support both a quick overview and exploration of details in online user reviews through the speech feedback.
There are several limitations to mention in this study.
Our user study included only four places in one neighborhood.
During the presentation of route instructions, only two places were presented through the spatial tactile feedback .
Future work needs to investigate how the number of places in the space and the number of places presented in the route instructions can affect people's learning of spatial relationships.
