In particular, we notice that many implementations of virtual environments only give the user one point of view  and a single scale  at which to operate.
A single point of view prohibits the user from gaining a larger context of the environment, and the 1:1 scale in which the user operates puts most of the world out of the user's immediate reach.
This paper explores a user interface technique which augments an immersive head tracked display with a hand-held miniature copy of the virtual environment.
We call this interface technique the Worlds in Miniature  metaphor.
By establishing a direct relationship between life-size objects in the virtual world and miniature objects in the WIM, we can use the WIM as a tool for manipulating objects in the virtual environment.
In addition to describing object manipulation, this paper explores ways in which Worlds in Miniature can act as a single unifying metaphor for such application independent interaction techniques as object selection, navigation, path planning, and visualization.
The WIM metaphor naturally offers multiple points of view and multiple scales at which the user can operate, all without requiring explicit modes or commands.
Informal user observation indicates that users adapt to the Worlds in Miniature metaphor quickly and that physical props are helpful in manipulating the WIM and other objects in the environment.
Many benefits have been claimed formally and informally for using immersive three dimensional displays.
While virtual reality technology has the potential to give the user a better understanding of the space he or she inhabits, and can improve performance in some tasks , it can easily present a virtual world to the user that is just as confusing, limiting and ambiguous as the real world.
We have grown accustomed to these real world constraints: things we cannot reach, things hidden from view, things beyond our sight and behind us, and things which appear close to each other because they line up along our current line of sight.
Figure 1: The World In Miniature  viewed against the background of a life-size virtual environment.
To address these two concerns, we propose allowing a virtual reality user to hold in his or her hands a three-dimensional interactive model - a miniature copy of the life-size virtual world .
The objects in the model each correspond to a life-size object; the positions and orientations of these objects in the real world "shadow" those of their proxies in the miniature.
Moving an object on the model moves an object in the real world and vice versa.
This World In Miniature  gives the user another point of view from which to observe the scene, and the ability to change that point of view under direct manipulation as rapidly as the user can turn the model in his or her hands.
As an adjunct to the WIM, we have explored the advantages and disadvantages of grounding the user's perception of the model with a physical prop; in this case, a clipboard.
The rest of this paper discusses previous work in the realm of miniature worlds used for three dimensional interfaces, a description of our WIM implementation, the basic interaction techniques we have used to demonstrate the effectiveness of the WIM concept, and the importance of asymmetric two-handed interaction.
We conclude with results from informal user observation of the WIM interface and a discussion of future work.
Butterworth states that users sometimes found the scaling disorienting.
Schmandt's  early explorations of Augmented Reality  used a half-silvered mirror over a stationary drafting tablet in order to specify both a base plane and a slicing plane in computer generated VLSI models.
He found this surface invaluable in constraining the user's input to a plane.
The scene was not immersive and the system only displayed one scale view at a time.
Many researchers have dealt with the open questions of three dimensional object manipulation and navigation in virtual environments.
The World in Miniature metaphor draws on these previous experiences, and attempts to synthesize an intuitive, coherent model to help address these questions.
Most previous work falls into two categories:  object manipulation and  navigation in virtual environments.
We use the term "navigation" to mean allowing the user to move in his or her virtual environment and helping the user maintain orientation while there.
Darken's  discussion of navigating virtual environments enumerates many important techniques and compares their relative strengths and weaknesses.
Several of the navigation techniques presented were WIM-like maps, but were primarily two-dimensional in nature.
Through the WIM interface, some of these techniques have been extended into the third dimension.
Ware  explored the possibilities of holding the threedimensional scene in hand for the purpose of quickly navigating the space.
He found this scene in hand metaphor particularly good for quickly viewing the bounding-cube edges of a scene.
The scene in hand task was a unimanual operation which employed ratcheting to perform large rotations.
The work most closely resembling the WIM interface was Fisher's map cube in virtual reality .
The NASA VIEW system used a three dimensional miniature map of the immersive world to help navigate.
In addition, it used multiple two dimensional viewports to jump from one place in the virtual environment to another.
A user's manipulation of the "map cube" was unimanual.
A similar map-cube concept was referred to as the God's-eye-view in the super cockpit project .
Ware's Bat  interface demonstrates the use of a 6 degree-of-freedom  input device  to grab and place objects in a virtual environment.
In this work, Ware used the bat to pick up and manipulate the virtual objects themselves, not miniature, proxy objects.
Ware found that users easily understood the 1:1 mapping between translations and rotations on the input device and the object being manipulated.
This study was a unimanual task and did not place the user's hands in the same physical space as the graphics.
In Sachs's 3-Draw , we see two hands used asymmetrically in a three-dimensional drawing and designing task.
In addition to this, Sachs used props for each of the user's hands and found that relative motion between hands was better than a fixed single object and one free mover.
3-Draw was not implemented in an immersive, head-tracked environment and the system did not provide multiple, simultaneous views.
The input props controlled the point of view by rotating the object's base plane.
Hinkley's  work with props exploited the asymmetric use of hands, which follows from work by Guiard .
This work showed how a prop in the non-dominant hand can be used to specify a coordinate system with gross orientation, while the user's preferred hand can be used for fine grain positioning relative to that coordinate system.
This work is also three dimensional but non-immersive and directly manipulates an object at 1:1 scale in a "fishtank" paradigm.
Many researchers have explored methods for selecting objects in a virtual world.
Both of these techniques suffer from object occlusion and therefore need to be tied closely with some mechanism that can quickly establish different points of view.
Put-That-There  used selection via a combination of pointing and naming .
Pointing in this two dimensional application is analogous to raycasting in virtual environments.
To explore the benefits and limitations of the WIM metaphor, we built a simple three dimensional modeling package that could be used as a design tool for a traditional architecture design project called a Kit of Parts.
We outfitted the user's non-dominant hand with a clipboard attached to a Polhemus position sensor.
This buttonball was used as the selection and manipulation tool for all of our user observation and WIM development.
The first button on the buttonball was used for selection of objects, and the second was left open for application-specified actions.
Thus equipped, the user's view from inside the HMD is exactly like that in any other immersive virtual environment, except that the user can raise the clipboard to view a miniature copy of the world in which he or she is standing and can lower the WIM graphics out of sight to remove them from his or her field of view .
Being able to see objects from many different angles allows us to quickly remove or reduce occlusion and improves the sense of the three-dimensional space it occupies .
Because the WIM is a hand-held model, the user can quickly establish different points of view by rotating the WIM in both hands.
Note that this form of "WIM fly-by" can often give the user all the information that he or she needs without destroying the point of view established in the larger, immersive point of view.
We believe that this interaction technique can establish a new viewpoint more quickly and with less cognitive burden than a technique that requires an explicit "flight" command and management of the flight path.
Figure 2: A user manipulates the WIM using the physical clipboard and buttonball props.
The WIM graphics attached to the clipboard are nothing more than a miniature copy of all the surrounding graphics in the immersive environment.
Each of the objects in the WIM copy are tied to their counterparts in the immersive environment through pointers and vice versa at the point of WIM creation.
In this way, when an object responds to a method call, the object has enough information to ensure that the same method gets called on its "shadow" object.
Thus the user can manipulate the objects in the WIM and the objects in the world will follow .
The environment itself  becomes its own widget for manipulating objects in the environment .
If the virtual, immersive environment is very large, there will be objects that are out of physical arm's reach.
If the user must touch an object to select it, the user would have to employ a separate flying mechanism, which means moving the camera; a sometimes disorienting or otherwise inappropriate approach.
Armed with a World In Miniature, the user now has the choice of selecting objects either by pointing to the object itself  or by pointing to its proxy on the WIM.
By turning the model in his or her hands, the user can even view and pick objects that are obscured by his or her current line of sight from the immersive camera viewpoint.
The WIM provides a second  point of view from which to examine the scene.
Once objects are selected, the WIM allows us to manipulate those objects at either the scale offered by the WIM or the one-to-one scale offered by the immersive environment.
If the scale of the WIM is smaller than that of the immersive world, manipulating objects on the WIM necessarily gives the user far-reaching coarse-grained control of objects.
The WIM can also display objects at a greater than one-toone scale, implementing a three dimensional magnifying glass of sorts.
This gives the user very fine grain control of objects through the WIM at the expense of range.
Though we have not implemented zooming in our current system, we clearly see the need for allowing the user to get more detail on the WIM or to zoom out to view more context.
We are currently pursuing this avenue of research.
We speculate that because the WIM is clearly a model attached to the user's hand, it is seen as something separate from the rest of the immersive environment.
The WIM therefore naturally offers two different scales to the user without requiring explicit modes or commands.
The Kit of Parts modeler was implemented using the Alice Rapid Prototyping System  running the simulation on a Sun Microsystems Sparc 10TM and rendering on a Silicon Graphics Onyx Reality Engine 2TM.
Typical rendering rates were about 25 frames per second , while simulation rates were typically 6 FPS.
A Virtual Research Flight HelmetTM was used for the display and was tracked with a Polhemus Isotrak magnetic tracker.
The buttonball and clipboard each carried a Polhemus tracker sensor for position and orientation information.
With a WIM, a single user can stand at a comfortable distance to view the picture in context, while at the same time reaching into the WIM to manipulate it.
Of course, the user could choose to use the WIM the other way around: fly close to the wall to stand next to the picture, then use the WIM to view the entire room in miniature to determine if the picture is straight.
Examining relative strengths and weaknesses of each of these approaches is an area of further study.
A good special case of post-mortem update is the case of moving the user's viewpoint.
We find that immediate update of the camera while the user is manipulating the camera proxy is highly disorienting, so instead we wait until the user has stopped moving the camera, and then use a smooth slow in / slow out animation  to move the camera to its new position.
This animated movement helps maintain visual continuity .
Another useful form of update delay is batch update.
This is useful for two reasons.
First, before the user commits his or her changes, the user has two independent views of the environment .
Secondly, it might be the case that moving one object at a time might leave the simulation in an inconsistent state, and so "batching" the changes like this gives the user a transaction-like commit operation on the changes to objects in the scene .
Viewing, selection, and manipulation are independent operations.
Because the WIM gives the user another scale at which to operate, the user can choose the most appropriate scale for any given subtask, and even switch scales in the middle to suit the requirements of the task.
For example: the user can reach into the WIM to select a distant object , and then reach out to the immersive world to move the WIM-selected object at a distance in 1:1: scale   all the while viewing the scene in the WIM.
Our current implementation allows users to rotate objects, through ratcheting   and is therefore more awkward than a rotation done with just the fingers .
Interestingly, some users found it just as effective to grab the object and to counterrotate the entire WIM.
In our current implementation, rotation is gridded to 30 degree increments, primarily to assist in aligning rectilinear objects .
We found that if the rotation grid is too course , some people assume that they cannot rotate at all and if set to 15 degrees or less, users report that rotation behaves as if it had no gridded increments at all.
The Worlds in Miniature metaphor supports several kinds of displays and interaction techniques that fall loosely under the heading of visualization.
These techniques exploit the WIM's ability to provide a different view of the immersive data with improved context.
It would seem that the WIM is good for visualization for all the same reasons that a map is good for visualization: Spatially locating and orienting the user: the WIM can provide an indicator showing where the user is and which way he or she is facing relative to the rest of the environment.
Path planning: with a WIM we can easily plan a future camera path in three dimensions to prepare for an object fly-by.
The user can even preview the camera motion before committing him or herself to the change in the larger, immersive viewpoint.
History: if the user leaves a trail behind as he or she travels from place to place, the WIM can be used like a regular 2D map to see the trail in its entirety.
Dropping a trail of crumbs is not as useful if you cannot see the trail in context.
Measuring distances: the WIM can be configured to display distances between distant  points that are difficult to reach at the immersive one-to-one scale.
The WIM also provides a convenient tool for measuring areas and volumes.
To make the view travel through the immersive environment, the most common user interface technique in virtual environments is probably "flying."
If the WIM includes some representation of the user as an object in the scene, the user can simply reach into the WIM and "pick himself up" to change his location in the environment.
This raises the question of when to update the immersive world as objects in the WIM are manipulated.
When changes are made on the WIM, we usually move the real object and the proxy object simultaneously, something we refer to as immediate update.
Under some conditions, immediate update is either not desirable  or impossible .
Here, the WIM acts more like a three dimensional version of Beir's "magic lenses"  or one of Fitzmaurice's "active maps" .
Three Dimensional Design: the WIM, being a small three dimensional model, serves the same functions that architectural models have traditionally served.
Until now, we have considered only a single instantiation of a WIM in a virtual environment, but clearly there might be a reason to have more than one such miniature active at a time.
Multiple WIMs could be used to display: * * * * widely separated regions of the same environment several completely different environments worlds at different scales the same world displayed at different points in time Figure 3: The clipboard and buttonball props.
This last option allows the user to do a side by side comparison of several design ideas .
A logical extension of this notion is that these snapshots can act as jump points to different spaces or times, much the same way hypertext systems sometimes have thumbnail pictures of previously visited documents .
Selecting a WIM would cause the immersive environment to change to that particular world .
Multiple WIM s enable users to multiplex their attention much the same way Window Managers allow this in 2D.
These multiple views into the virtual world, allow the user to visually compare different scales and/or different locations .
This prop allows the user to rotate the WIM using a twohanded technique that passes the clipboard quickly from one hand to the other and back when the rotation of the WIM is greater than can be done comfortably with one hand.
Interestingly, some users hold the clipboard from underneath, rotating the clipboard deftly with one hand.
Both of these techniques are hard to imagine doing in the absence of haptic feedback provided by a physical prop.
Before we settled on the buttonball as our primary pointing device, we experimented with a pen interface to the WIM.
This technique is most appropriate for manipulation of objects when they are constrained to a plane  .
When manipulation of objects in three dimensions is called for, a pen on the surface of the clipboard does not appear to be expressive enough to capture object rotation well.
One of our early implementations of the WIM work did not use physical props; the user grasped at the WIM graphics as he or she would any other graphical object in the scene.
As long the user continued the grasping gesture, the WIM followed the position and orientation of the user's hand and when released, it would remain hovering in space wherever it was dropped.
While this was sufficient for many tasks, we found that rotating the WIM without the benefit of haptic feedback was extremely difficult.
Invariably, users would contort themselves into uncomfortable positions rather than let go of the WIM to grab it again by another, more comfortable corner.
After Sachs , we decided to use physical props to assist the user's manipulation of the WIM itself.
Our implementation of the WIM metaphor takes advantage of several previously published results in the field of motor behavior that have not been fully exploited in a head tracked virtual environment.
The most important of these results state that a human's dominant  hand makes its motions relative to the coordinate system specified by the non-dominant hand, and the preferred hand's motion is generally at a finer grain .
In our case, the non-dominant hand establishes a coordinate system with the clipboard and the dominant hand performs fine grained picking and manipulation operations.
While the dominant hand may be occupied with a pointing device of some kind, it is still sufficiently free to help the other hand spin the WIM quickly when necessary.
Like all real world artifacts, the shape of the props and the users' experience suggest things about the usage of the props .
For example, the shape of the clipboard says something to users about its preferred orientation.
The cursor's physical prop is spherical, indicating that it has no preferred orientation, and in fact it does not matter how the cursor is wielded since rotation is relative to the plane specified with the non-dominant hand, which holds the clipboard.
The clipboard also provides a surface that the user can bear down on when necessary.
This is similar to the way an artist might rest his or her hand on a paint palette or a guitarist might rest a finger on the guitar body.
Holding a physical clipboard, even a relatively light one, can cause users to fatigue rather quickly.
To overcome this problem, we created a simple clutching mechanism that allows the user to alternately attach and detach the WIM from the physical prop with the press of a button.
When detached, the WIM "floats" in the air, permitting the user to set the prop down .
This clutching mechanism extended well to multiple WIM s: when the user toggles the clutch, the closest WIM snaps to the user's clipboard.
Toggling the clutch again disengages the current WIM and allows the user to pick up another WIM.
Another technique for relieving arm stress is to have the user sit at a physical table on which the clipboard could be set.
Users can also rest their arms on the table while manipulating the model.
The presence of the table clearly presents a mobility problem for the user because it prevents the user from moving or walking in the virtual environment, and so may not be ideal for all applications.
Figure 4: The starting configuration of the Kit of Parts WIM.
The parts themselves are at the bottom, outside the regular working area.
In many ways, this design task replicates the traditional architectural design project known as a Kit of Parts.
The furniture pieces  represent the kit of manipulable objects.
Moving the traditional kit of parts project into virtual reality was particularly appealing for several reasons: * It constrains the space in which the user can work.
The WIM that we used was a 1/4" scale version of the immersive world, with a snap spacing of 1/8" .
In addition to the translation snap, rotation was constrained to be about the Z axis in increments of 30 degrees.
In our experience, one of the first things a user of the WIM is likely to try is to hold the WIM close to his or her face in order to get a closer, more dynamic look at the world.
Users quickly discover that this is an easy, efficient way to establish many different points of view from inside the miniature.
Unfortunately, many times the physical prop itself gets in the way, preventing the user from putting the tracker in the appropriate position to get a useful viewpoint.
Fortunately, the ability to disengage the WIM, leaving it in space without the clipboard helps alleviate this problem.
We observed users in order to see how viable a solution the WIM interface was to several types of tasks.
While it was not our intention for the study to produce concrete numbers, we were after what Brooks refers to as interesting "Observations" .
Do they take to it easily?
None of the users expressed problems establishing the map-
We observed ten people using the WIM.
Users were given a simple architectural modeler and asked to design an office space.
We proceeded with a rapid "observe, evaluate, revise" methodology to learn about the Worlds in Miniature interface.
Several users were even able to grab and manipulate objects on the WIM without explicitly looking at the WIM itself.
This was the strongest evidence that people had developed an internal model of the three dimensional space in their hands.
Arm fatigue was not a major problem.
Subjects developed a pattern of raising the WIM, making the manipulations and then lowering the WIM out of view to look at the life-size world.
Also, subjects were sitting, which allowed them to rest their arms on their legs and adjust their gaze to look down at the WIM.
The weight of the head-mount was the only fatigue complaint we received, although most users were not immersed for more than fifteen minutes.
The participants generally understood and liked the clutching mechanism and found that the second button on the buttonball was an easy to understand interface.
Users found that rotating the camera with immediate update was very disorienting.
Not surprisingly, we found that the animation from the starting point to the ending point needed to be as smooth as possible; whether through slow frame rates or jumping great distances to meet an animation deadline, discontinuities of the camera motion are to be avoided at all costs.
Interestingly, none of our users in our informal studies noticed this effect until it was pointed out to them.
Another issue related to our software implementation was that the lighting effects on the model do not represent the lighting effects seen on corresponding objects in the virtual world.
This may not be a problem for many applications, but will probably be an issue for classically trained architects who traditionally use models to test lighting.
Because of the encouraging experience we have had with the current WIM implementation, we intend to continue exploring some of the issues behind WIM-based interaction.
Value of the Prop: While anecdotal evidence suggests that the WIM interface with the clipboard prop is faster than manipulating the WIM with a virtual hand, an informal study is planned to determine to what extent the presence of the prop enhances the WIM interface.
Scrolling: At some point, scaling issues cause a straightforward WIM interface to break down.
For example: if the WIM 's scale is very small, selection and manipulation become to difficult.
One solution is to maintain a reasonable scale, and allow the user to scroll the world into the working volume of the WIM.
Clipping: Clipping a large WIM in X and Y seems intuitive,  but the clipping in Z remains an issue yet to be explored.
Zooming: When the immersive world is large, we need to adjusting the scale of the WIM to keep the working volume within the user's physical reach.
We intend to explore the best ways of extending this functionality to the WIM.
Three Dimensional Design: We would like to give the WIM to more architecture students to determine whether it is a more effective design medium for some tasks than traditional pencil, paper and foam core modeling board.
We have speculated that the clipboard, and possibly a table would be viable surfaces on which to project standard 2D GUI widgets, whenever those controls would make sense.
We see this as an interesting opportunity to explore ways of "recovering" decades of 2D GUI results in the relatively new arena of virtual environment interfaces and head tracked displays.
Intentional misregistration of the WIM and clipboard.
Interestingly, none of our users noticed that the position of the WIM is about a decimeter above the physical location of the clipboard.
When asked whether the miniature world rested on the clipboard, all the users said yes, even though they often moved the cursor through the base plane of the virtual model during object placement.
This of course should be impossible because the clipboard would prevent the physical cursor from penetrating its plane.
This is a good example of the perceptual phenomena known as "visual capture",  .
Selection by trolling: Pressing the buttonball's selection button and trolling through objects in order to select them seemed a much more effective selection technique than the traditional "position-then-select" technique.
Because the world was sparsely populated with objects, users had few problems accidentally passing through  the wrong object.
Few users discovered the trolling technique on their own.
One noteworthy implementation decision was to configure the SGI hardware to only draw the front faces of polygons.
A side-effect of this was that the viewer could look into the WIM from any angle without the exterior walls occluding the interior, but the walls on the opposite side of the WIM from the user would still be visible .
The WIM interface gives the user of an immersive three dimensional environment a chance to operate at several different scales through several different views at once without engaging explicit modes.
The most encouraging result from our informal observations was that users fluidly used multiple capabilities of the WIM.
For example, users often manipulated objects in the World In Miniature while simultaneously changing their point of view.
This level of integration implied to us that users were able to focus on the task without being distracted by the interface technology.
We would like to thank Rich Gossweiler, Ken Hinkley, Tommy Burnette, Jim Durbin, Ari Rapkin, and Shuichi Koga for their help in the construction of the WIM interface, for the creation of the supporting video tape, and for their many invaluable ideas and for pointers to previous work done in this area.
Eric A. Bier, Maureen C. Stone, Ken Pier, William Buxton, Tony D. DeRose.
Toolglass and Magic Lenses: The See-Through Interface.
Jeff Butterworth, Andrew Davidson, Stephen Hench, Marc Olano.
3DM: A Three Dimensional Modeler Using a Head-Mounted Display.
Grasping Reality Through Illusion: Interactive Graphics Serving Science.
In Proceedings of the 1988 ACM SIGCHI Human Factors in Computer Systems Conference.
Robert C. Zeleznik, Kenneth P. Herndon, Daniel C. Robbins, Nate Huang, Tom Meyer, Noah Parker, John F. Hughes.
A Toolset for Navigation in Virtual Environments.
Visualizing nDimensional Virtual Worlds with n-vision.
The AMES Virtual Environment Workstation .
Situated Information Spaces and Spatially Aware.
Dr. Thomas A. Furness, III.
The Super Cockpit and Human Factors Challenges.
Human Interface Technology  Laboratory of the Washington Technology Center, September 1986 Yves Guiard.
Asymmetric Division of Labor in Human Skilled Bimanual Action: The Kinematic Chain as a Model.
Ken Hinckley, Randy Pausch, John C. Goble, Neal F. Kassell.
Passive Real-World Interface Props for Neurosurgical Visualization.
In Proceedings of SIGCHI, pages , October 1993.
Apple Computer, Inc.. Hyperscript Language Guide: The Hypertalk Language.
JDCAD: A Highly Interactive 3D Modeling System.
Principles of Traditional Animation Applied to 3D Computer Animation.
Randy Pausch, M. Anne Shackelford, Dennis Proffitt.
A User Study Comparing Head-Mounted and Stationary Displays.
In Proceedings of the IEEE Symposium on Research Frontiers in Virtual Reality, pages 41-45, October 1993.
Emanuel Sachs, Andrew Robert, David Stoops.
3 Draw: A Tool for Designing 3D Shapes.
IEEE Computer Graphics and Applications, pages 18-25, November 1991.
Spatial Input/Display Correspondence in a Stereoscopic Computer Graphic Work Station.
A Head-Mounted Three Dimensional Display.
Colin Ware, Danny R. Jessome.
Using the Bat: A SixDimensional Mouse for Object Placement.
IEEE Computer Graphics and Applications, pages 65-70, November 1988.
Exploration and Virtual Camera Control in Virtual Three Dimensional Environments.
Using Hand Position for Virtual Object Placement.
