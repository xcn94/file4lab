Music is a multi-dimensional experience informed by much more than hearing alone, and is thus accessible to people of all hearing abilities.
In this paper we describe a prototype system designed to enrich the experience of music for the deaf by enhancing sensory input of information via channels other than in-air audio reception by the ear.
The system has two main components--a vibrating `Haptic Chair' and a computer display of informative visual effects that correspond to features of the music.
The Haptic Chair provides sensory input of vibrations via touch.
This system was developed based on an initial concept guided by information obtained from a background survey conducted with deaf people from multi-ethnic backgrounds and feedback received from two profoundly deaf musicians.
A formal user study with 43 deaf participants suggested that the prototype system enhances the musical experience of a deaf person.
All of the users preferred either the Haptic Chair alone  or the Haptic Chair with the visual display .
The prototype system, especially the Haptic Chair was so enthusiastically received by our subjects that it is possible this system might significantly change the way the deaf community experiences music.
Such listeners can tap their foot or otherwise move rhythmically in response to a musical stimulus.
They can quickly articulate whether the piece of music is in a familiar style, and whether it is a style they like.
If they are familiar with the music, they might be able to identify the composer and/or performers.
The listeners can list instruments they hear playing.
They can immediately assess stylistic and emotional aspects of the music, including whether or not it is loud, complicated, sad, fast, soothing, or generates a feeling of anxiety.
They can also make complicated socio-cultural judgments, such as suggesting a friend who would like the music, or a social occasion for which it is appropriate.
Now, if the listeners are hearing-impaired, what would their musical behaviour be?
Partial or profound lack of hearing makes the other ways humans use to sense sound in the environment much more important for the deaf than for people with normal hearing.
Sound transmitted through the air and through other physical media such as floors, walls, chairs and machines act on the entire human body, not just the ears, and play an important role in the perception of music and environmental events for all people, but in particular for the deaf.
In fact, it has been found that some deaf people process vibrations sensed via touch in the part of the brain used by other people for hearing .
This provides one possible explanation for how deaf musicians can sense music, and how deaf people can enjoy concerts and other musical events.
These findings suggest that a mechanism to physically 'feel' music might provide an experience to a hearing impaired person that is qualitatively similar to the experience a normal hearing person has while listening to music.
However, little research has specifically addressed the question of how to optimise a musical experience for a deaf person.
This paper describes the design and evaluation of a system we have developed to enhance the musical experience for the deaf.
Some previous work has been done on providing awareness of environmental sounds to deaf people .
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
In order to keep our focus on the musical experience for the deaf and minimise potential bias from assumptions about musical experiences of hearing people, it was imperative to involve hearing impaired people in the design loop from the beginning.
To what extent do deaf people engage in musical activities?
What type of music do they listen to?
What are the strategies used to listen to music?
Are they upset by not being able to enjoy music as much as they would like?
What type of assistive devices would enhance their musical experience?
We also include some of the comments received and a discussion of the qualitative experience reported by some of the deaf participants.
Limitations of the current study follow, and the last section gives the conclusion and an outline of our plans for future work.
Based on the results of this survey, we implemented a prototype system which has two components: a `Haptic Chair' that vibrates with the music; and a computer display that generates different visual effects based on musical features such as note onsets, pitch, amplitude, timbre and key changes.
We conducted informal interviews with hearing impaired musicians, and applied their feedback to improve the initial design.
Since their comments were very positive, relatively minor adjustments were needed at this stage.
We then conducted a formal user study with 43 participants with hearing impairments to find the answers to the following questions.
Does the visual display enhance their experience?
Does the Haptic Chair enhance their experience?
Does a combined output  enhance their experience?
What is the optimal configuration?--visual display alone, the Haptic Chair alone, or a combination of visual display and Haptic Chair.
Profoundly deaf musicians and those with less pronounced hearing problems have clearly demonstrated that deafness is not a barrier to musical participation and creativity.
Dame Evelyn Glennie is a world renowned percussionist who has been profoundly deaf since the age of 12 years but `feels' the pitch of her concert drums and xylophone, and the flow of a piece of music through different parts of her body--from fingertips to feet .
Other examples include profoundly deaf musicians such as Shawn Dale--the first and only person born completely deaf who achieved a top ten hit on Music Television  in 1987; and Beethoven, the German composer who gradually lost his hearing in mid-life but who continued to compose music by increasingly concentrating on feeling vibrations from his piano forte.
The results of the user study suggest that the Haptic Chair has a significant effect in enhancing the musical experience of a deaf person.
In fact, we received a number of comments from the subjects, many of whom said listening to music while sitting on the Haptic Chair was an "amazing experience unlike anything they had experienced before".
We hope this work might ultimately change and improve the way the hearing impaired community experiences music, and can also see applications for people with normal hearing.
We begin with a discussion of related work and then present the results of the background survey.
This is followed by a brief description of the prototype system.
The visual representation of music has a long and colourful history.
In the early 20th century Oskar Fischinger, an animator, created exquisite `visual music' using geometric patterns and shapes choreographed tightly to classical music and jazz .
Walt Disney, in 1940, released a movie called `Fantasia' where animation without any dialogue was used to visualise classical music.
Another example is Norman McLaren, a Canadian animator and film director who created 'animated sound', by hand-drawn interpretations of music for film .
Among the earliest researchers to use a computer based approach was Mitroo  who in 1979 input musical attributes such as pitch, notes, chords, velocity, loudness, etc., to create colour compositions and moving objects.
Since then, music visualisation schemes have proliferated to include commercial products like WinAmp and iTunes, as well as visualisations to help train singers.
It is not the purpose of this work to discuss a full history here.
Evans  gives an excellent review of visual music.
However, the effect of these different music visualisations on the hearing impaired has not been scientifically investigated and no prior specific application for this purpose is known to the authors.
As mentioned in the introduction, feeling sound vibrations through different parts of the body plays an important role in perceiving music, particularly for the deaf.
Based on this concept, Palmer, in 1994, developed a portable music floor which he called Tac-Tile Sounds System  .
However, we have not been able to find a report of any formal objective evaluation of the TTSS.
Recently, Kerwin developed a touch pad that enables deaf people to feel music through vibrations sensed by the fingertips .
As in the previously cited case , not many technical or user test details about this device are available.
The closest commercially available comparisons to the proposed Haptic Chair include the `Vibrating Bodily Sensation Device' from Kunyoong IBC Co, the `X-chair' by Ogawa World Berhad, the `Multisensory Sound Lab'  from Oval Window Audio, and Snoezelen vibromusic products from FlagHouse, Inc.
These devices are designed to process sound, including music inputs according to pre-defined transformations before producing haptic output.
Our current system is different from most of the above because we do not electronically pre-process the natural vibrations produced by music.
Because people sense musically derived vibrations throughout the body when experiencing music, any additional or deliberately altered `information' delivered through this channel might disrupt the musical experience, and this confounding effect is potentially more significant for the deaf.
Since we know that the human central nervous system  is particularly plastic in its intake of various sensory inputs and production of often different sensory output, it is important to support this ability to create new sensory experiences for people with specific sensory impairments.
The human CNS is still largely a `black box' in data processing terms and it would be unforgivable to assume we can create a computerised system to replace its many and various abilities.
Therefore, we decided not to alter the natural vibrations caused by musical sounds, but to design our prototype Haptic Chair to simply amplify the natural vibrations produced by music and give the user of the system the freedom to acquire the input they found most beneficial.
Preliminary testing suggested that the Haptic Chair was capable of providing, not only haptic sensory input  but also bone conduction of sound via ear or directly to the CNS.
The latter observation on the contribution of bone conduction of sound requires more formal study.
We asked the respondents whether they took part in musical activities: whether they attend concerts or listen to music at home.
Seventy seven percent of subjects with partial hearing reported taking part in musical activities, whereas only 32% of the profoundly deaf subjects reported being involved in musical activities .
This observation supports the hypothesis that the partially deaf are more likely to have taken part in musical activities than the profoundly deaf.
The results are shown in Table 1.
In other words, the data suggests that partially deaf subjects are more involved in musical activities than the profoundly deaf.
This might seem obvious but needed to be formally tested.
We investigated the music genres enjoyed by the hearing impaired.
In order to help us decide what music we should work with in our study, we asked the subjects who participated in the background study to tell us the types of music or songs they listen to.
Figure 1 summarises their responses and suggests that most hearing impaired people listen to music with a strong beat.
We studied 41 people  with various degrees of hearing impairment by asking them to complete a standardised survey form.
There were 22 partially deaf and 19 profoundly deaf participants who all had normal eyesight.
We asked the respondents to identify the dominant factor that enables them to enjoy a musical activity and used this to inform our decisions about the type of assistive system we should develop.
From the responses shown in Figure 2, it is clear that most deaf people rely either on feeling vibrations or watching visual displays.
We asked the e subjects who o have attende ed musical act tivities whether they regret the fac ct that they we ere not able to o enjoy the music as much m as they would like.
Sixty S five perc cent of the partially deaf d and 67% % of the profo oundly deaf su ubjects reported that they feel `ups set' about not being able to o enjoy music to their r potential abi ility.
These observations o support the hypothesi is that, regard dless of their hearing h ability y, deaf people are lik kely to expres ss some degre ee of dissatisf faction over any obst tacle to full en njoyment of music.
Since e some cells of the contingency c t table  2 have value es less than 5, Yate's s correction was w applied.
The value of chi-squa are, $  # 0.27, p % 0.05 supports the null n hypothes sis of no association betwe een the two variables s--`level of d deafness' and d `regretting lack of musical acces ssibility'.
Figures 3 an nd 4 illustrate e the types of o assistive devices d hearing impa aired people have used while w engaging g in a musical activi ity and wheth her they were deemed d usefu ul.
Sign language and sub-title displays are the most m commonl ly used ing a musica al activity.
One O reason fo or this methods duri could be the fact that the ese are the most m easily available cant observati ions for the pu urpose options.
We asked the participants W p in n the study whether w they would w be e willing to use a visual dis splay that refl lects basic mu usical fe eatures such as note ons sets, pitch, loudness, l typ pe of in nstrument and d changes in the overall pitch p context.
We fo ound that mos st partially de eaf and profou undly deaf pe eople ar re willing to use u such a de evice .
5 The chi-sq quare va alue, $ 2  # 0.95, p % 0.05 , ind dicates that the ere is no o association n between th he level of deafness d  and the willingness to o use a visual display y.
When asked whether subj jects would be b willing to use a brates to reflec ct the musical l sound signal l, most chair that vib partially deaf f and profoun ndly deaf peop ple said they would use it .
As in th he previous case, c the chi-square 7, p % 0.05 , re value, $ 2  # 1.37 evealed that th here is no associatio on between the level of f deafness an nd the willingness to o utilise haptic c input.
Another fundam A mental display y decision con ncerns the win ndow of f time to be visualised.
The `p piano roll' pre esentation refe ers to a displa ay that scrolls from le eft to right in which events s correspondin ng to a given time w window are displayed in a single column n, and past ev vents an nd future eve ents are displa ayed on the left l side and right si ide of the cu urrent time r respectively.
In contrast, in a `m movie roll'-ty ype presentatio on, the entire display is used to sh how instantan neous events w which also allo ows more free edom of f expression.
The visual effect for a particular audio a fe eature is visib ble on screen f for as long as that audio fe eature is s audible, and d fades away y into the scr reen as the audio a fe eature fades away.
When n listening, people p only hear in nstantaneous events: e future events are no ot known ; and past eve ents are not heard h .
Thus, a `m movie ro oll'-type visua al presentation n more accura ately represent ts the m musical listeni ing process th han the `pian no roll' depic ction.
O pilot stud Our dy with deaf musicians co onfirmed the more na atural feel of the t `movie rol ll'-type presen ntation.
Previous to this t study, we w had develo oped a system m that codes sequences of inform mation about a piece of mus sic into ence that wou uld be both mu usically inform mative a visual seque and aesthetica ally pleasing .
We mapped high notes to o small shape es and low no otes to large shapes, a mapping th hat is more `natural' and in ntuitive than the rever rse because it is consistent with our expe erience of the physic cal world .
Similarly, there is a ra ational basis for amp plitude being m mapped to vis sual brightness s. This seems to be related to th he fact that both b amplitud de and brightness are e measures of f intensity in the t audio and visual domains res spectively, a concept which has been experimentall ly explored .
Our informal interview ws with deaf musicia ans suggeste ed that they y would lik ke to differentiate between b the various v instrum ments that are e being played.
We therefore used colou ur informatio on to b instru uments such that t each instr rument differentiate between being played at a given tim me is mapped to a unique colour.
Extracting not E te and instrum ment informa ation from a live au udio stream is s an extremel ly difficult pr roblem  and a is no ot the main objective of this study.
Hence, H in the first ph hase of the work w we decided to use Musical M Instru ument D Digital Interfac ce  da ata, a commu unications pro otocol re epresenting musical m inform mation similar r to that conta ained in n a musical score, as the e main sourc ce of inform mation in nstead of a live audio stream.
Usi ing MIDI makes m de etermining note n onsets, p pitch, duratio on, loudness and in nstrument iden ntification str raightforward.
However, ju ust as w musical sc with cores, key cha anges are not explicit e or triv vially ex xtractable from m the MIDI n note stream and, a to accom mplish th his task we us sed a method d developed by Chew  based b on n a mathema atical model for tonality called the `S Spiral A Array Model'.
The processing layer takes in a MIDI data stream and extracts note onset, pitch, loudness, instrument and key changes.
This processing layer is implemented using the Max/MSPTM musical signal and event processing and programming environment.
The extracted musical information is passed to a Flash CS3 program written using Action Script 3.0 via a Max flashserver external  object.
The basic functionality of the flashserver is to establish a connection between Flash CS3 and Max/MSP.
The TCP/IP socket connection that is created enables exchange of data between both programs in either direction thereby enabling two-way Max-controlled animations in Flash CS3.
A textured cotton cushion with a thin foam filling was designed to fit the frame of the chair to increase physical comfort but not significantly interfere with haptic perception of the music.
This might have reduced bone conduction of sound but since this was not the specific focus of the present study, the cushion was used because it increased the overall comfort of the user.
A literature review, our background survey results and informal interviews with deaf musicians suggested that if vibrations caused by sound could be amplified and sensed through the body as they are in natural environmental conditions, this might increase the enjoyment of music over a mute visual presentation or simply increasing the volume of sound.
Thus we developed a device designed to achieve this which we have called the `Haptic Chair'.
Initial tests suggest that the prototype enables the listener to be comfortably seated while being enveloped in an enriched sensation created by the received sound.
The current concept underlying the Haptic Chair is to amplify vibrations produced by musical sounds without adding any additional artificial effects into this communications channel, although such an approach might be used in future if it produces better results.
We used contact speakers  designed to make most surfaces they are attached to vibrate and produce sound.
The quality and frequency response of the sound they produce is similar to that of conventional diaphragm speakers.
This is important since many partially deaf people can hear some sounds via in-air conduction through the `conventional' hearing route: an airfilled external ear canal.
After exploring many different materials and configurations for the chair frame and contact speakers, we decided on a densely laminated wooden chair that was widely available at relatively low cost .
The frame comprised of layer-glued, bent beech wood which provided flexibility and solid beech cross-struts that provided rigidity was able to vibrate relatively freely and could also be rocked by the subjects .
Two contact speakers were mounted under the arm-rests, one under a similar rigid, laminated wood foot-rest , and one on the back-rest at the level of the lumbar spine.
A thin but rigid plastic dome was mounted over each hand-rest and helped to amplify vibrations produced by high frequency sounds sensed by hands and fingers.
The domes also provided an ergonomic hand rest that brought fingertips, hand bones and wrist bones in contact with the vibrating structures in the main body of the chair.
Vibrations were measured in different parts of the chair in response to different input frequencies using an accelerometer , a data acquisition module  and a laptop running LabVIEWTM 8.2.
The system response was tested in the range of 50-5000Hz, where the lower frequency was limited by the response of the contact speakers and upper limit was chosen such that it effectively covers the range of most musical instruments .
The response measured from the foot rest and the back rest of the chair was fairly flat  while the response measured from the arm rest showed more fluctuations  with lower amplitude.
A user evaluation study was carried out to examine the effectiveness of the proposed system.
Participants were asked to follow the music while sitting in the Haptic Chair and watching the visual display.
They were also invited to make themselves comfortable in the chair "as if they were relaxing at home".
The studies were conducted in accordance with the ethical research guidelines provided by the Internal Review Board  of the National University of Singapore and with IRB approval.
The study was carried out in a quiet room resembling a home environment.
A notebook computer with a 17-inch LCD display was used to present the visual effects.
We did not include the size of the LCD display as a variable in this study, and chose the commonly available 17 inch monitor that was both easily portable and widely available in homes and workplaces.
During the various study blocks, subjects were asked to sit on the Haptic Chair , and/or to watch the visual effects while listing to the music, or simply listen to the music.
The visual display was placed at a constant horizontal distance  and constant elevation  from the floor.
Participants switched off their hearing aids during the study.
Before starting the blocks, each participant was told that the purpose of the experiment was to study the effect of the Haptic Chair and the visual display.
In addition, they were given the chance to become comfortable with the Haptic Chair and the display.
Also, the sound levels of the speakers were calibrated to the participant's comfortable level.
Once the participant was ready, trials were presented in random order.
After each block, the subjects were asked to rate their experience by answering a questionnaire.
The questions were designed based on the Flow State Scale  .
Each question was rated on a 5-point scale, ranging from 1  to 5 .
Upon completion of the four trials for a given piece of music, the participants were asked to rank these four configurations  according to their preference.
This procedure was repeated for the 3 different musical pieces.
Each subject took approximately 45 minutes to complete the experiment.
It took 8 days to collect responses from 43 participants.
The experiment was a within-subject 4 x 3 factorial design.
The two independent variables were: musical composition  and prototype configuration .
The musical test samples were based on the background survey results.
MIDI renditions of Mozart's Symphony No.
41, `It's my life' , and a hip-hop beat pattern were used as classical, rock, and beat only examples, respectively.
Samples of these tracks are available online .
The duration of each of the three musical test pieces was approximately one minute.
We analysed the collected responses to find the answers to the questions we presented at the beginning of this paper.
The overall FSS score was used as a measure of the optimal experience.
The FSS score was calculated as a weighted average of the ratings given for the questions, and ranged from 0 to 1 where a FSS score of 1 corresponded to an optimal experience.
Preliminary investigations were carried out to examine the effect of the proposed system.
For this purpose, we graphed the mean FSS score across all experimental conditions.
From the results shown in Figure 9, it is clear that the Haptic Chair had a dominant effect on the FSS score.
Also, as we expected, the FSS score was minimal for the control situation in which both the visual display and Haptic Chair were turned off.
A 2-way repeated measures ANOVA  suggested that the order of blocks  did not significantly affect the FSS score.
A one way repeated measures ANOVA reveals a significant difference between the different combinations .
We used Tukey's honestly significant difference  test to compare the means.
Mean FSS score of music with visuals  was significantly higher  than music alone .
Mean FSS score of music with Haptic Chair  was significantly higher  than music alone .
Mean FSS score of music, visuals and Haptic Chair together  was significantly higher  than music alone .
Mean FSS scores of music, visuals and Haptic Chair together  and music with Haptic Chair  were significantly higher  than music and visuals .
The difference between the mean FSS score of music with Haptic Chair  and music, visuals and Haptic Chair  was not significant .
The statistical analysis given in the previous section shows that the Haptic Chair has the potential to significantly enhance the musical experience of a hearing impaired person.
However, this does not adequately reflect the enthusiasm we received from the deaf community.
After the formal study was completed, we had the opportunity to interact with our deaf participants in a more informal way that provided insight into how our system worked in a more natural environment.
We selected a sub-group of 11 particularly enthusiastic subjects and allowed them to listen to songs of their choice.
They were asked to imagine the Haptic Chair was their own and use it in whatever way they wanted.
They were also given a demonstration of how to connect an audio device  to the Haptic Chair, and they were free to choose whether or not to use their hearing aids.
We observed their behaviour and, after the session, we asked them for their reactions to the experience.
One very excited participant told us that it was an amazing experience unlike anything she had experienced before.
She said now she feels like there is no difference between herself and a person with normal hearing.
She preferred the combination of the Haptic Chair and visual display the most.
She said, if she could see the lyrics  and if she had the opportunity to change the properties of the visual display 
Many of the participants told us that they could clearly identify the rhythm of the song and could hear the song much better compared to when using standard hearing aids.
Another mentioned that he wanted to use headphones together with the chair and display so that he could detect the sound through the headphones as well.
A few participants who were born with profound deafness said that this was the first time they actually `heard' a song and they were extremely happy about it.
They expressed a wish to buy a similar Haptic Chair and connect it to the radio and television at home.
We observed that many profoundly deaf participants were actually `hearing' something when they were sitting on the chair.
The following comments were encouraging: "Yes, I can hear from my legs!"
We consulted deaf musicians to get their feedback on future developments for the system.
One of them  said that she enjoyed the experience provided by the Haptic Chair and suggested that we should provide an additional pair of conventional headphones together with the Haptic Chair to assist partially deaf people who can detect certain sounds via air conduction through their ears.
As seen from Figure 10, the Haptic Chair had a substantial effect on the FSS score.
When the participants were asked to rank the most preferred configuration, 54% chose music together with the Haptic Chair.
46% ranked music and visuals together with the Haptic Chair as their first choice.
None of the participants preferred the other possible options .
A profoundly deaf concert pianist told us that he could detect almost all important musical features via the Haptic Chair but wanted to feel musical pitch more precisely.
When we explained the options and the need for familiarisation with the system for such a high level input of information, he said he learned continuously throughout his initial test of the system and would continue to participate in refining the concept.
The current study is our first design to understand whether and how a combination of tactile and visual information might be used to enhance musical experience for the hearing impaired.
The questions we address here are important but necessarily quite general, and the implementation leaves much room for refinement and improvement.
The current system, for example, makes no attempt to electronically process the music in any way, but instead deliver the same entire audio stream to each of the separate vibration systems targeting the feet, back, arms and hands.
This is not necessarily the optimal strategy for vibrotactile presentation.
Work by Karam et al.
One explanation for the improved enjoyment is that there may be masking of some portion of the audio signal that is eliminated by the spatial separation of musical or frequency components.
Another potential explanation is that in natural environments, vibrotactile stimulation from multiple signals is typically already spatially segregated.
The current study delivered the entire frequency range of the music as potential tactile stimulation, even though most studies report that the tactile system is only responsive up to approximately 1000 Hz.
In addition to our strategic motivation not to manipulate the signal naturally available for tactile music perception, we believe that the role played by higher frequencies in tactile perception is still an open question as the frequency response curves reported in the literature have only been measured with sine tones .
It is possible, however, that the role of higher frequencies in more realistic audio signals, for instance, in creating sharp transients, could still be important.
In one sense a limitation of the study but in another an exciting possibility is that in addition to tactile sensory input, bone conduction might be providing an additional route for enhanced sensory input.
Bone conduction of sound is likely to be very significant for people with certain hearing impairments and a far greater range of frequencies is transmitted via bone conduction of sound compared with purely tactile stimulation .
Measuring the quality of a musical experience is also challenging.
We use the notion of `musical experience' often in everyday life.
However, to our knowledge, no one has come up with a widely accepted definition to quantify musical experience.
In this study, we use the FSS instrument to measure the musical experience.
Csikszentmihalyi describes flow as a state in which people are so involved in an activity that nothing else matters: the experience itself is so enjoyable that people will do it even at a high cost, for the sheer joy of doing it.
Although `flow theory' has been widely used in interactive experiences such as plays, sports or gaming, among the passive activities that can result in flow is relaxing while listing to music .
This explains the link between enjoying a musical performance and optimal experience--when someone is really enjoying a musical performance, he or she is said to be in flow state.
However, some of the nine dimensions of flow described by Csikszentmihalyi do not apply for a passive activity such as listening to music.
For example, when listening to music, there is no immediate feedback confirming that everything is proceeding according to the plan.
Therefore, we modified the original FSS instrument in such a way that only the questions applicable to a scenario of listening to music were used.
Nevertheless, the fact remains that a musical experience is much more than the measures of enjoyment and complete characterisation of musical experience is still an open question.
It is obvious from our casual observations that our subjects were in fact having a musical experience when they tapped or otherwise moved to the music and sang the songs when karaoke videos were played.
Our studies may have been confounded by a host of cultural differences between the Sri Lankan population we studied and others, or between different age groups.
Our current study makes no attempt to address these issues.
Feedback received from our two deaf musicians was very valuable.
Both typically perform for hearing audiences and thus might not have any special insight into deaf audiences with limited or no musical training; however, one also teaches deaf children and therefore offered a more balanced opinion.
In fact, musical backgrounds and tastes differ as widely for the deaf as for the hearing.
In this study we do not differentiate between different skill levels or musical tastes.
Based on the results of the background survey and the informal interviews with hearing impaired people, we developed a prototype system designed to enhance the musical experience of the deaf.
The prototype system has two main components--an informative visual display and a Haptic Chair.
We conducted a formal user study with 43 deaf participants to evaluate the system and found that the Haptic Chair is capable of substantially enhancing the musical experience of deaf people, both children and adults.
Many participants reported that the display alone was not very effective, but when presented together with the Haptic Chair the visual effects conveyed additional musical meaning.
From the comments received, it seems that adding karaoke-style lyrics to the visual display  and providing a set of headphones would make the system even more effective.
Furthermore, during the formal user study, one of the sign language interpreters  wanted to try using the Haptic Chair when training deaf people to speak.
Upon conducting her speech therapy program with and without the Haptic Chair, she expressed confidence that the Haptic Chair would be a valuable aid in this kind of learning.
We will explore this more systematically, and in December 2008 developed and installed a system in a school for the deaf based on the Haptic Chair concept but aimed to support group activities including speech therapy and dance.
Finally, we also believe this technology might enhance the enjoyment of music for people with normal hearing and those with narrow sound frequency band drop-outs.
The latter is a relatively common form of hearing loss that is often not severe enough to classify the person as deaf but might cause annoying interruptions in their enjoyment of music or conversation.
The Haptic Chair has the potential to bridge these gaps to support musical enjoyment for this community, as well.
The authors gratefully acknowledge the support of Dr. Reijntjes School for the Deaf, Sri Lanka; National Council for the Deaf, Sri Lanka; Singapore Association for the Deaf, Singapore; and the National Centre on Deafness, California State University, USA.
We would like to thank Associate Professor Elaine Chew, University of Southern California, for her technical contributions.
The authors thank Dr. Deborah Fels for pointing out some of the limitations of the current study and for valuable suggestions for improvements to the paper and future research directions.
Finally, we are grateful for help provided by our colleagues at various stages of this complex project.
Speaker allows deaf musicians to feel music, Brunel University press release.
Chew E. Modelling tonality: Applications to music cognition.
Csikszentmihalyi, M. Beyond boredom and anxiety, Jossey-bass Press, San Francisco, CA, USA, 1975.
Foundations of a visual music.
Ten films, Los Angeles, Center for Visual Music CVM .
Glennie, D. E. Hearing essay.
Gunther, E., Davenport, G., and O'Modhrain, S. Cutaneous grooves: Composing for the sense of touch.
Haptic chair with visual input: Music excerpts used in the experiment.
