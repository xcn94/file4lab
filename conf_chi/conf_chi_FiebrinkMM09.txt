Multi-touch interactions are a promising means of control for interactive tabletops.
However, a lack of precision and tactile feedback makes multi-touch controls a poor fit for tasks where precision and feedback are crucial.
We present an approach that offers precise control and tactile feedback for tabletop systems through the integration of dynamically re-mappable physical controllers with the multi-touch environment, and we demonstrate this approach in our collaborative tabletop audio editing environment.
An observational user study demonstrates that our approach can provide needed precision and feedback, while preserving the collaborative benefits of a shared directmanipulation surface.
Our observations also suggest that direct touch and physical controllers can offer complementary benefits, and that providing both allows users to adjust their control strategy based on considerations including precision, convenience, visibility, and user role.
The precision of touchbased systems is further limited by a lack of feedback: a touch-sensitive surface provides very limited haptic feedback, and visual feedback may be impaired by the finger occluding the object under manipulation .
Furthermore, the visibility of gesture--a core benefit of multi-touch control in a collaborative setting--may be diminished when the physical manipulations are small in magnitude.
For these reasons, multi-touch interactions may be a poor choice when fine-grained control is necessary.
Motivated by the challenge of allowing greater precision while also supporting collaboration, we propose an approach to integrating dynamically mapped physical controllers with a shared multi-touch tabletop.
Specifically, we allow users to dynamically bind application parameters to both virtual controls  and physical controls  that offer precision and feedback for fine-grained manipulations.
Physical controls are deployed in the form of several small, repositionable boxes that can be distributed among users, providing individuals with their own replications of a subset of the available virtual controls .
We provide users with mechanisms to dynamically map these physical controls to the available parameters, allowing a flexible tailoring of the mapping state to the group interaction style and task requirements.
This approach is applicable to an array of tasks requiring fine-grained control over many parameters and requiring the collaboration of multiple users, such as media editing, gaming, graphic design and layout, and data visualization.
Single display groupware  systems  allow multiple co-located users to collaborate by sharing control over a single display.
Tabletop systems controlled by multitouch gestures represent an exciting step toward wide availability of SDG, and such systems are now being commercially manufactured .
Multi-touch control allows simultaneous direct manipulation by multiple users, and the rich expressiveness of multi-touch gestures allows for natural and intuitive interactions .
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
The contributions of this work include techniques for integrating high-precision physical controllers into a collaborative tabletop environment, an observational user study demonstrating the effectiveness of these techniques and exploring the factors influencing users' preferenc es for physical or direct-touch controls and for local or central controls, and a discussion of our findings and their implications for direct-touch tabletop systems supporting precision-sensitive collaborative tasks.
Many strategies for increasing the precision of touchcontrolled user interfaces have been proposed, including insitu zooming , the exploitation of additional fingers , and the appearance of non-occluded callouts for small targets .
Such work has not explicitly considered the implications for co-located, collaborating users.
On the other hand, there exists a growing body of work around interface design for co-located tabletop groupware, addressing fundamental questions regarding how input modality and interface layout can affect efficiency and the collaborative experience.
For example, direct input allows for control gestures that are noticeable and understandable to users, but can also induce fear of physical collision or crossing into another user's territory, and present difficulty in reaching far-away items.
Interface layout merits particular consideration in the design of tabletop groupware.
The DiamondSpin toolkit , for example, accommodates a single shared interface, multiple replicated interfaces, or both.
This preference for replicated controls may be influenced by users' tendency to treat the portion of the table nearest them as their own territory .
However, simply replicating controls presents a challenge when the number of replicated controls is large, and can lead to controls becoming smaller  in order to fit on the table.
Physical artifacts have been integrated into tabletop and other computing environments with a variety of goals.
Physical artifacts may be employed as tangible props, in an effort to endow computer interfaces with the rich interactions afforded by physical objects .
For example, the Metadesk  uses physical representations of buildings to display, scale, and rotate a map, and the Actuated Workbench  allows a tabletop to provide physical outputs by automatically moving electromagnets on its surface.
Other work has integrated computational devices into tabletop environments.
Rekimoto and Saitoh  augmented physical objects placed on a table with virtual auras.
In contrast, we explore the use of generic, re-mappable physical controllers that work in concert with direct-touch controls to support co-located collaborative work.
We share some motivations with other work incorporating generic physical input devices into PC environments.
In particular, Hartmann et al.
However, neither work deals with collaboration or touch interfaces.
Finally, also of relevance is work by Forlines et al.
While we do not use a mouse, we do propose that there are benefits to complementing multi-touch interaction with other input methods.
Based on this existing work, we outline key elements of our design approach for effectively supporting both precise control and collaborative interaction in a tabletop environment for high-precision tasks such as media editing.
Allow users to choose between direct touch  and indirect control .
Based on the tradeoffs of direct and indirect control outlined in , neither modality may be clearly optimal for a particular task.
All editing and system display parameters in our system can be controlled using either modality.
Provide a single, shared multi-touch display area.
This shared area contains a visual representation of the editing artifact.
This central area also contains multi-touch widgets that identify all available editing parameters, visually indicate the current values of these parameters, and expose control over the parameters via touch manipulation.
Thus all users have a common display for planning and observing the editing process, and touch gestures executed on this space are apparent to the group.
Provide several small, moveable physical controllers for users to exercise indirect, precise control with tactile feedback.
Physical controllers in our system can be distributed to individual users, acting as personal control spaces that supplement the shared group display and control space.
This approach supports replication and accommodates territoriality while allowing users freedom over their own positioning around the table.
Provide a means for users to map and re-map controllers to editing parameters, via direct touch, and convey the current mapping states visually.
Space dictates that individual controllers may not have enough buttons, knobs, or sliders to accommodate all system parameters.
Instead, users explicitly decide how to map the continuous and discrete physical controls to a subset of continuous and discrete parameters.
The mapping process is executed using direct touch on the shared control space to promote awareness of mapping state across users.
Users can re-map controllers at any time.
Visual cues indicate mapping state so the user does not have to memorize the mapping state as it changes.
Support saving, reloading, and sharing of controller mappings.
This may reduce overhead if there is a tendency to reuse mappings over time, and it facilitates collaborative behaviors that are challenging without system support, such as role switching and offline review of group dynamics.
Respondents to our survey described many ways that collaboration on audio editing tasks is beneficial, mentioning the creative synergy, the combination of ideas and talents, and general shared bliss when we both click on an idea.
However, 43 of the 51 respondents  worked alone more often than not, and indicated that this reluctance to collaborate was in part due to the software editing environments: it's crowded, there is only one mouse and keyboard, each person must have their own computer to be effective.
73% of respondents agreed that they would be interested in tools that made co-located collaboration on audio editing easier.
When asked about potential technological enhancements to make collaboration more satisfying and enjoyable, 94% of respondents agreed that a big display would be beneficial, and 76% agreed there was benefit in modifying the interface to allow several users to simultaneously control editing parameters.
These properties match well with the affordances of tabletop systems.
In fact, several tabletoplike systems have been created for music performance and audio synthesis , including Audiopad  and Reactable , both of which employ tangible tags as input devices, and a multi-touch system by Davidson and Han  that does not integrate physical artifacts.
While Ensemble seeks to promote musical collaboration in a similar spirit to these systems, the task domain is quite different , and our use of physical artifacts serves to complement multi-touch interactions by providing needed feedback and precision.
In this, our work also relates to a larger context of research regarding the design of appropriate physical and virtual interfaces for musical performance and audio control .
In addition to the design goals outlined in the previous section, Ensemble was designed around a goal of being usable by people with no previous audio editing experience, so we exposed fewer and simpler control parameters than might appear in a commercial editing package.
Audio editing is one of several domains requiring precise control over a large number of parameters, and where support for collaborative editing is desirable but poorly supported by existing software.
Even audio editing software for novices, such as GarageBand , exposes hundreds of continuous editing parameters, including volume level and pan , and parameters for each of many audio effects such as chorus, distortion, and reverberation.
Furthermore, such software typically employs a track editing paradigm, where each recorded instrument or audio source may comprise its own unit or track.
Though tracks are played simultaneously, each track's parameters can be manipulated independently, multiplying the effective number of control parameters in the system.
Amateur audio editing seems like a naturally collaborative task; for example, all members of a band are stakeholders in the editing process required to turn the raw output of a recording session into an album.
In order to assess the suitability of audio editing as an application domain in which to implement our approach, we conducted a survey of 51 Microsoft employees who were amateur users of audio editing and mixing software.
Survey questions focused on status quo software support for collaboration.
The Ensemble system was built on a prototype interactive tabletop  that employs an under-table infrared vision system to track fingers and objects on the table's surface.
Two adjacent overhead projectors provide the display, yielding an overall display resolution of 1024x1536.
The tabletop itself measures approximately 120cm wide by 180cm long, and stands 90cm high.
The software was written in C# and WPF and uses a version of Microsoft's Surface SDK that was modified for this table's vision system.
The two discrete, on-or-off parameters are mute  and solo .
The five continuous parameters are volume, pan, offset , level of chorus effect, and level of distortion effect1.
The two discrete parameters are controlled using touch buttons, and the five continuous parameters are controlled using horizontal touch sliders.
These touch widgets are sized to be approximately fingersized by default to facilitate easy manipulation, though users are able to resize the editor to make the display and widgets larger or smaller.
The central editor also contains buttons to play, pause, and stop the audio, as well as slider controls for vertically scrolling to select the tracks currently displayed, zooming in and out on the track waveforms, horizontally scrolling the waveforms, and changing the playback position .
Users can control the zoom and horizontal viewing position using direct-touch manipulations on the track waveforms, and they can control the size, position, and orientation of the editor itself using multi-touch gestures on the editor border.
Figure 2: Physical controller with virtual, multi-touch aura.
The aura contains eight "slots."
The four slots below the box contain virtual buttons, which are mapped to the same discrete editing parameters as the four physical buttons on the box.
The four slots on the sides of the box contain virtual sliders, which are mapped to the same continuous editing parameters as the four physical knobs on the box.
This particular controller was chosen for its size , programmability, low cost, and accommodation of both continuous and discrete controls.
On the bottom of each box is a tag that uniquely identifies the box to the table's vision system, allowing a visible aura to track the box as it moves around the table.
Inside this aura are several touch-sensitive buttons used to manage the control mapping state, as well as eight slots, each of which corresponds to one knob or button, the identity of which is determined by a simple color-coding scheme .
When a knob or button is mapped to a parameter, the corresponding slot will be filled with a graphical representation of that parameter and a uniquely identifying label .
Whenever an editing parameter's value changes, regardless of how the change was initiated, all graphical representations of that control will change in synchrony.
For example, if a user manipulates the Flute Chorus control on the central editor, the slider in Figure 3 will simultaneously update to reflect the change.
Or, if a user manipulates the Flute Volume using the knob on the controller in Figure 3, the adjacent widget and the Flute Volume slider control on the central editor will similarly change.
Virtual widgets displayed in a physical controller's aura can be controlled by direct touch.
Both virtual controls and physical knobs are mapped linearly to the editing parameters, which were bounded by parameter-specific ranges .
A 360degree turn of a knob corresponded to approximately the entire range of a parameter .
Chorus and distortion are common effects used in music production.
Increasing the level of chorus applied to an audio track gives the impression that the track is being played by an increasing number of sound sources.
Increasing the level of distortion applied to an audio track makes the track sound rougher and fuzzier.
These effects were selected because they are both common in audio processing and easily perceived by novices.
Assigning parameters to a physical controller box.
Touching any of the highlight ed parameters will place that parameter in the user's clipboard.
Touching a continuous control in the clipboard above the box has activated the virtual "slots"  corresponding to the box's four physical knobs.
When any of these slots is touched, the selected control will be mappe d to the corresponding knob.
When Ensemble initializes, none of the knobs and buttons are mapped to control parameters, and their corresponding aura slots are blank.
Users can construct a mapping from knobs and buttons to parameters using the following process, which is summarized in Figure 4.
First, pressing a controller's touch-sensitive Copy toggle button, located on the right side of the aura for each box, initiates the process of mapping  editing parameters to that controller.
This causes a clipboard space to appear above the controller aura, and a yellow highlight to appear around the aura's border.
This also causes the central editor to display bright yellow virtual touch buttons around all of the available controls, including track controls, playback controls, and editor controls such as zoom .
Second, touching any of these yellow buttons causes a copy of the corresponding control widget  to appear in the controller's clipboard .
Third, touching a control in the clipboard selects it, causing green highlights to appear over the aura slots corresponding either to knobs  or to buttons .
Finally, touching one of these green highlights will cause the control to leave the clipboard, map the associated knob or button to control the parameter, and populate the slot with the corresponding  widget.
The user can touch the Copy button once more to end the mapping process for that controller and return the central editor to its normal state.
At any time, only one controller can control the mapping process, as indicated by possession of the yellow aura highlight.
Ensemble does not prohibit multiple users from copying the same parameters to their controllers, nor impose any assumptions regarding which parameters should be mapped to which controllers.
Users can modify the mapping of a controller box at any time.
Touch buttons on the aura allow the user to delete any mapping and undo any mapping deletion or creation.
Additionally, users may press Copy again at any time to reopen the clipboard and initiate another mapping session to that controller.
Ensemble supports saving the mapping state of any controller box--that is, which knobs and buttons are mapped to which editor parameters.
When a user presses the Save button in a controller box's aura, the current state is saved and appended to a local, touch-scrollable history list, from which the user may reload any saved mapping state to the box.
Saved states may also be loaded into another control box by dragging and docking the history list to the chosen box.
Our approach raises several questions regarding its impact on the collaborative user experience.
For example, do users actually employ the physical controllers to achieve precise control and create an individual, local control space?
Given that users have several options for exercising control , are any of these options clearly preferred?
Are the collaborative benefits of shared multi-touch tabletops maintained despite some interactions being performed using indirect control?
Is the mapping process useful, and what implications does it have for the collaborative experience?
Of the 34 participants, 97% agreed that they understood how to use the system .
Unlike a typical matching task study, we were not interested in correlating the degree of success with aspects of the task or user behaviors.
In fact, this degree is hard to measure objectively, since simple metrics such as Euclidean distance in parameter space do not correlate well to perceptual similarity for these parameters.
Rather, we were concerned that the task focused the participants on a common, reasonable goal, so that we could explore participants' use of the integrated physical controllers.
82% of participants either somewhat agreed or strongly agreed that they were able to successfully perform the matching tasks .
Given a rough objective success criterion of the percentage of parameters that were edited to within 20% of the prompt value, groups succeeded for a median of 75% of the available parameters on each prompt .
We recruited 40 Microsoft employees to form 10 groups of 4 participants each.
Due to cancellations, the 10 groups varied in size: 6 groups had 4 members, 2 groups had 3 members, and 2 groups had 2 members, for a total of 34 participants .
Participants' ages ranged from 20 to over 55.
29 subjects had used multi-touch technology once or twice, 5 had never used multi -touch technology, and none had used multi-touch on a regular basis.
24 participants self-identified as musicians, and 29 reported having used audio editing software previously.
User groups consisted of people who were not necessarily musicians, who did not necessarily have significant audio editing experience, and who did not know each other or necessarily share subjective opinions about audio content.
Therefore, the group editing task was selected to be both objective and accessible to novices.
Specifically, each group was asked to perform three matching tasks.
In each task, the group was presented with a set of four or five unedited audio tracks along with an audio prompt lasting between 15 seconds and 1 minute.
In a real-world audio editing scenario, participants would work together to edit the raw tracks to meet a shared set of subjective, aesthetic criteria; here, participants were asked to work as a group to edit the raw tracks to sound like the prompt.
The prompts were created by one experimenter prior to the experiment using Ensemble's physical and virtual controls, starting from the same audio tracks provided to the group.
Prompts were designed so that each task could be completed in around 10 minutes .
The three prompts used in our experiment are available at http://research.microsoft.com/~dan/ensemble.
Each task required the editing of a somewhat different set of audio parameters.
Participants used the Ensemble system as described earlier, but augmented with a timer showing the time remaining in the task, and virtual buttons for playing, pausing, and stopping the prompt.
Each group was given a 5-minute hands-on tutorial on multi-touch tabletop manipulations, followed by a 15minute tutorial on the functionality of Ensemble and the matching tasks.
Groups were given 10 minutes to match each of the 3 prompts, for 30 minutes of total task time.
The order of the prompts was varied among groups as a Latin square with an incomplete repetition.
At the conclusion of the study, individual participants completed questionnaires.
The physical controllers were perceived to be helpful in supporting precision manipulations, and the controllers were perceived to provide a greater accuracy advantage for continuous parameters than discrete parameters.
A Friedman test comparing participants' 5-point Likert scale ratings of perceived accuracy for discrete and continuous parameters using either physical or touch controls found significant differences  = 49.77, p < .001 .
Follow-up pairwise Wilcoxon tests found that all pairwise differences were also significant.
These tests showed that participants felt that the physical controls were significantly more accurate than the touch controls, for both continuous parameters  and discrete parameters .
Tests also showed that participants felt that the physical controls provided a significantly greater accuracy boost for the continuous parameters than the discrete ones , whereas they felt that the touch controls were more accurate when dealing with discrete, rather than continuous, parameters .
Our observations suggest that our system is effective at supporting equitable participation and individuals' awareness of the group's activities.
85% of participants strongly or somewhat agreed that everyone in their group participated equally.
Our system was designed to support cooperative work by providing awareness of group members' actions, despite the introduction of individual Control Type physical, continuous touch, continuous physical, discrete touch, discrete Median 5 2 5 3 Mean 4.79 2.15 4.50 3.15 Std.
This awareness support succeeded: 85% of participants strongly or somewhat agreed that they were aware of others' editing actions, and 94% strongly or somewhat agreed that their level of awareness of others' actions was adequate.
Results show that participants used the controller boxes to establish personal control spaces.
During the introductory tutorial, groups were instructed that the controller boxes could be used as they wished, to be distributed to individuals, used collectively by the group, or not used at all.
One group chose not to use controller boxes at all for their second prompt.
Otherwise, members of four-person groups each used one box per person exclusively throughout the task .
Members of both two-person groups and one three-person group either used one box exclusively throughout the task, or used one box until they ran out of empty slots, then switched to an extra  box.
In the other three-person group, one very dominant person controlled the conversation and executed the majority of the edits; after the first prompt, the other two users gave up and did not create any mappings for their boxes.
Even in this case, however, they stood behind the box they had used for the first prompt.
The boxes were never used collectively or shared among users.
23 participants  strongly agreed and 8  somewhat agreed that they treated one controller box as their own.
In short, the controller boxes were consistently used as individual control spaces, and any extra boxes either sat unused or were eventually assigned to individuals who ran out of room for new controls.
The tracking mechanism of the table allowed users, in principle, to bring their control space  with them when they changed position to better see or reach the central editor, or communicate with another user.
We did not observe this behavior, however.
The maximum distance a controller box ever traveled from its starting position over any 10-minute task was about 75cm, and the vast majority moved less than 30cm; considering the 2.2square-meter size of the table, these movements are quite small.
Two users, from different groups, often walked up and down the table in order to touch or gesture at the central editor, but most users stayed in place, directly behind their controllers, and resorted to reaching  or asking others nearer the central editor to execute a touch manipulation on their behalf.
It is unclear whether this is because the users felt territorial claims to particular parts of the table as suggested by Scott et al.
In any case, our observations do not support the conclusion that the mobility of personal control spaces effectively addresses reach or orientation issues.
25 participants  said they preferred physical control overall.
Of these, 16 mentioned accuracy or responsiveness and 6 mentioned feedback when answering a free-response question asking them to explain their preference.
Only six participants  strictly preferred touch controls, citing reasons such as intuitiveness, the presence of visual feedback and an identifying context in the exact same location as the gesture, and ease-of-access .
Despite preferring physical controls overall, participants made extensive use of touch controls.
Figure 5 shows the total number of edits made using each type of control, for discrete and continuous parameters.
For all tasks, the number of touch edits was high: 78 per prompt on average, as compared to 30 edits using the physical controllers.
The difference in behavior between continuous and discrete parameters was quite pronounced, with 39% of all continuous parameter edits executed via the physical knobs, and just 4% of all discrete parameter edits executed via the physical buttons.
Considering only the track parameters, which were more frequently mapped to the control boxes, users employed the physical controls roughly as often as touch controls  for continuous parameters, and used touch controls more often than physical controls for discrete parameters.
Users were less likely to map discrete parameters than continuous controls to physical controllers .
When discrete parameters were mapped, users employed the touch controls on the local aura more often than the buttons on the controller itself .
When asked for reasons why they employed local touch buttons instead of physical buttons, despite participants' perception that physical buttons were more accurate, common explanations were the increased visibility and ease of use of the local touch buttons.
68% of participants stated a preference for using local controls , and 32% preferred using the central controls.
Reach was cited as a reason for preferring both locations: local controls were easier to reach for most people, but people positioned near the editor could reach a greater number of controls easily.
People who liked central controls mentioned their greater visibility to the group and the fact that the controls were surrounded by more contextual information.
Often, users employed the central editor even when they realized they might be sacrificing precision or had to stretch a great distance to reach it, citing that it was easy to use for rough or one-time edits, without incurring the overhead of mapping.
The central editor also served an important purpose beyond offering touch control; as a shared, visible space, it was often the object of pointing gestures, and employed to focus group conversation and attention.
This process may be one reason there was such high awareness of other users' mappings and actions, though it may involve a greater degree of explicit planning than some users prefer.
The abilities to save, reload, and share mappings were not exercised by users in these tasks, and participants neither agreed nor disagreed that they were useful in this context .
Four participants annotated their Likert ratings, unprompted, to add that such functionality would be appreciated in longer or more complex tasks.
Given the tight relationship between user role and controller mapping, it seems reasonable that these functions and others like them could contribute to promoting rich and dynamic user roles.
With the majority of users expressing ownership over one box, the process of mapping the controllers to parameters can be considered in terms of mapping the users to parameters.
This notion was reflected in that users referred to the mapping as a process of establishing ownership, such as, Why don't you take the volume?
The mapping process was used as a tool for users to delegate or assert responsibility in the group.
For some groups and tasks, users verbally agreed on a strategy for delegating parameters before anyone began to copy parameters.
Other times, one assertive user would assign roles to the others  without consensus.
Group work often iterated between a planning phase, in which participants delegated responsibility for and set up mappings to a group of parameters they anticipated editing soon, and actually performing edits.
One -off edits that were not planned in advance were more often made using the central editor; such edits took place outside the role structure established by the planning phase.
We did not observe participants intentionally assigning the same parameters to multiple people; of the 496 instances in which parameters were mapped to controllers, only 24 of these duplicated parameters that were already mapped elsewhere.
Throughout each task, participants also tended to verbally establish that no other group member possessed a parameter before mapping it to their own controller.
Users sometimes subverted the cooperative process by hitting Copy and selecting parameters to add to their clipboard, without announcing this to the group.
When more than one user acted independently in this way, without others being aware of their actions, this resulted in confusion, as users ended up stealing the copy privilege from each other.
Five participants noted that the tight cooperation that was necessary to establish mappings and/or user roles was the most challenging aspect of collaboration with the system.
We observed users employing the mapping to change categories of user responsibilities according not only to the group style  but also to the perceived task requirements.
For example, for Prompt B and Prompt C, 8 and 9 groups, respectively, assigned individuals control over the parameters of a particular track.
For Prompt A, on the other hand, the first thing most groups noticed when listening to the prompt was that the sound events proceeded in a strict timing sequence, and 3 groups responded by initially assigning all offset controls to a single user, who could then recreate the timing sequence.
For this prompt, only 4 groups employed the strategy of dividing the work by tracks, and the 2 other groups that used the controllers at all employed different strategies.
In most tasks, at least one person modified his or her mapping from its initial state in a way that was not necessarily consistent with the original strategy .
The variation of mapping among groups, users, and tasks underscores the need to support flexible and changeable mappings.
By observing 10 groups use our dynamically re-mappable controllers in the context of the Ensemble audio editing system, we observed several consistent themes in users' interaction with and perception of the system.
Physical sliders were perceived to be more accurate than virtual sliders, and physical buttons were perceived to be more accurate than virtual buttons, but the difference in perceived accuracy was less pronounced for buttons.
Most users stated they preferred physical manipulations to touch manipulations, citing reasons including precision and feedback.
However, some users preferred touch manipulations, for reasons such as the increased visual context.
Our approach's mixture of touch and physical control options for each parameter accommodated these varied preferences.
Most users stated they preferred local controls to central controls.
However, the central, shared control space remained a focal point of interaction for all groups.
Users often gestured or pointed at the central editor when discussing the task.
Many touch manipulations were performed on the central editor even in groups that heavily utilized the physical controllers, due to increased contextual information, visibility, and immediacy; the central editor was especially used to make quick and rough edits.
Users had a strong tendency to claim ownership over one controller and over the parameters to which it was mapped.
The controllers became individual control spaces that reflected the roles of the users.
Users exhibited different strategies for mapping the controllers, and strategies varied across both task and group, suggesting that a static controller mapping would be inadequate.
Furthermore, the mapping strategy was directly related to the roles of users in the group, and was used to delegate or assert ownership over particular controls.
Multiple users trying to control the mapping process at the same time, without communicating their intentions to each other, occasionally created confusion.
Controllers with built-in reprogrammable LCD indicators, or a top-projection system projecting onto controllers with fixed positions off of the table might offer such feedback.
On the other hand, the occlusion presented by small, relatively stationary controllers may be of less consequence than that of many arms and hands when only touch is used in a smaller collaborative tabletop environment.
We expect the nature of the interaction with any system to depart from our observations for tasks involving very few parameters .
In this case, there may be less incentive for users to divide responsibility amongst themselves, and other infrastructure may be more appropriate to support broad participation.
On the other hand, we anticipate that our approach will scale well to tasks where there are many more parameters.
Reflecting on our experiences observing groups using Ensemble, we highlight several phenomena that informed our own evaluation of the system and suggest how such an approach might be most useful in future applications:  Ensemble's physical controllers became de facto personal control spaces.
Therefore, we propose that providing one controller per user is a reasonable configuration for collaborative systems of this nature.
Pilot subjects expected the local aura to be controllable by touch, and study participants often used touch control on the aura, especially for discrete parameters.
Therefore, we propose that local virtual representations of discrete controls be touch controllable if possible.
Participants used physical controllers for parameters that needed to be manipulated very precisely, parameters that they expected to need more than occasionally, and logical groups of parameters that they could assign to an individual participant .
While participants exercised the ability to map both continuous and discrete parameters into a local control area, they found the physical controller less essential for discrete parameters, and often opted for local virtual buttons.
We therefore understand the usefulness of remappable physical controllers to be highly dependent on the types of parameters present.
We observed that the shared multi-touch control area still offered practical benefits  and collaborative benefits , even when precision of some touch manipulations was inadequate.
This suggests that touch interaction and physical controllers play complementary roles.
Based on our experiences, the choice of mapping creation paradigm may support certain group collaboration styles and discourage others.
Our approach of integrating dynamically re-mappable controllers into tabletop group editing system can be applied in a variety of collaborative, precision-sensitive editing tasks, such as graphic design, print or Web layout, scientific visualization, or video editing.
It is sensible that controller hardware and mapping strategies might vary for other domains, as our use of knobs mapped to onedimensional parameters was motivated by existing audio hardware interfaces.
The knobs might be replaced by other controls that are appropriate for a different task and/or already familiar to domain experts.
For example, a joystick may be appropriate for 2D positioning tasks.
The granularity of the mapping from hardware to parameters will also be application-  dependent, according to the necessary precision and range.
The integration of a different controller would require specifying the number and type  of the new inputs, the relation mapping each new input to application parameters, and the visual appearance of the controller's aura.
Infrastructure similar to the Input Configurator toolkit  could facilitate the dynamic specification of more complex mappings by the users, when hard-coded mappings are insufficient.
The appropriateness and appearance of our local aura visualization method also depends on the choice of controller, the size and type tabletop, and the nature of the application GUI.
Alternatively, greater efficiency may be achieved by allowing users to create mappings in parallel, which would be feasible if our approach is combined with an identity-differentiating tabletop technology such as DiamondTouch .
Given the observed relationships between user roles and controller mappings, the set of allowable mappings may strongly influence the types of user roles that are allowable.
Designers might restrict the mappings to try to enforce more equitable participation , turn taking , or other work styles.
We hypothesize that supplying users with shortcuts to mapping presets might also bias the delegation of responsibilities along lines suggested by the presets.
Without restrictions, users can employ a variety of mapping strategies based on their own criteria.
In designing a collaborative system integrating physical controls with a multi-touch tabletop, we hoped to support both collaboration and precision.
Our observational study of Ensemble, our prototype collaborative audio-editing system, suggests that physical controllers can complement touch-based interactions and support a productive collaborative experience in a domain not typically served by co-located collaborative software.
