We propose using discovery-based learning games to teach people how to use complex software.
Specifically, we developed Jigsaw, a learning game that asks players to solve virtual jigsaw puzzles using tools in Adobe Photoshop.
We conducted an eleven-person lab study of the prototype, and found the game to be an effective learning medium that can complement demonstration-based tutorials.
Not only did the participants learn about new tools and techniques while actively solving the puzzles in Jigsaw, but they also recalled techniques that they had learned previously but had forgotten.
The work described in this paper demonstrates that games designed for guided discovery learning can supplement tutorials as an effective learning aid for software applications.
We study this approach in the context of a complex photo editing application, Adobe Photoshop.
The photo-editing domain is a particularly interesting one, as non-experts are often interested in using professional quality software.
To study how games can encourage discovery-based learning of software applications, we built Jigsaw, a virtual jigsaw puzzle game, and embedded it inside of Adobe Photoshop.
Each puzzle in Jigsaw focuses on a specific set of Photoshop tools.
Some puzzles are exact virtual analogs of physical jigsaw puzzles, and the user is expected to restore a picture that has been broken into multiple pieces using selection and transformation tools .
Other puzzles ask the user to adjust some puzzle pieces to match the rest of the image .
Although each puzzle offers hints on tools that might be appropriate, the user is free to solve the puzzle using any technique.
We observed 11 participants as they played Jigsaw and found that not only did the participants learn about new tools and techniques while tinkering with the puzzles, but they also recalled techniques that they had forgotten.
In the following sections, we describe the related research, the design of Jigsaw, and our preliminary evaluation.
When learning how to use software applications users often switch back and forth between two strategies: trial-anderror and searching for help .
Tutorials are a popular form of help content, as they offer step-by-step instructions for how to accomplish a task.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
The software learnability community has taken this approach to develop a number of training tools such as Guided Exploration cards, the Minimal Manual, and Training Wheels, which were empirically found to be more effective than learning from software manuals .
Although there are many games that embrace discovery learning , there are few examples emphasizing learning of software applications.
The two games that stand out are Microsoft Ribbon Hero and The Monkey Wrench Conspiracy, which provide a narrative story that leads users through small tasks to help them accomplish a broader goal.
While there is some exploration in these games, users are encouraged to solve tasks using a specific strategy or technique.
In Jigsaw, we allow users to solve each puzzle with any strategy.
In a related but sufficiently different domain, RoboCode  encourages users to learn how to program by asking them to program the behavior of battle tanks.
Though its success was an inspiration to us, RoboCode was designed for a very technical and highly motivated community.
We focus on software environments that are used by people with varied levels of expertise.
Moreover, Jigsaw provides customized hints for each puzzle.
There are three different types of hints, and they serve different purposes.
First, the brief instructions printed directly on the puzzle canvas explain the goal of the puzzle and suggest the tools that the player should use.
Second, the player can click on Hints  to find links to external tutorials describing the tools suggested by the puzzle.
Finally, complete beginners can open a step-by-step video that demonstrates how to solve one piece of the puzzle.
The benefit of building on top of an existing game is that anyone who is familiar with jigsaw puzzles will immediately understand the goal of playing Jigsaw: to match the target image.
Jigsaw does not prescribe how players should solve each puzzle.
An advanced user might experiment freely to find the most efficient way of solving a puzzle, while a beginner can follow the hints and tutorials to pursue a safer path.
For those who want a challenge, Jigsaw offers the Speedrun mode, which requires that a puzzle be solved in under a few minutes, and the Blacklist mode, which requires that the puzzle be solved without certain tools.
The Blacklist mode encourages users to find alternative techniques for tasks that they already know how to do.
Providing feedback is regarded as one of the most important features in both play and learning .
To this end, Jigsaw analyzes the player's puzzle and reports on the number of correct and incorrect puzzle pieces .
Each correct puzzle piece results in skill points for the player.
To analyze the player's puzzle and find correct pieces, Jigsaw compares the user's puzzle to a solution file and computes the mean squared error  of the RGB pixel values for each piece.
If the error is below a threshold, the puzzle piece is considered correct.
Although this technique is simple, it works reasonably well for many images.
Jigsaw is implemented as an Adobe Photoshop extension using the Adobe Creative Suite SDK.
The game user interface is a Photoshop panel that allows users to browse and open available puzzles, get feedback and hints, and track their points.
Based on Kirkpatrick's four levels for evaluating training , we conducted an eleven-person within-subjects lab study to examine: * * * Reaction: how do users react to Jigsaw?
Learning: what do users learn, and how do they learn by playing Jigsaw?
Behavior: can users transfer what they learn to realistic tasks?
All participants had at least some prior exposure to Photoshop but were not experts.
Each study session consisted of five components and lasted for one hour.
We asked each participant to describe a strategy for turning each before image into the corresponding after image.
Each of the 9 image sets required manipulations with tools that corresponded to a puzzle in Jigsaw.
This initial assessment allowed us to establish a baseline for tracking participants' development of Photoshop skills throughout the session.
All participants started with the puzzle about layers, one of the most fundamental features in Photoshop, and then played more puzzles of their choice.
We asked participants to think aloud as they were solving the puzzles.
The session ended with a discussion about learning outcomes, engagement with Jigsaw, and user interface improvements.
It's more interesting and challenging ."
For example, P8 did not follow the puzzle progression and jumped to the advanced selection puzzle before completing some of the easier puzzles.
Also, he chose to play in the Speedrun game mode.
However, he did not know how to complete the puzzle and looked for help in a text tutorial.
It would not have been possible for any participant to read all of the text and complete the puzzle in the fast-paced Speedrun mode.
P8 was not successful in completing the advanced selection puzzle and had to go back to more basic puzzles.
In contrast, participants who followed the systematically designed sequence of puzzles and viewed the step-by-step demonstration videos appeared to have a more satisfactory experience.
All participants reported that playing Jigsaw was an effective and fun learning exercise, and most of them recognized the unique value of the discovery learning experience Jigsaw provided.
For example: "I would recommend it to other active learners like me.
It definitely helped me learn something that I probably would have missed."
First of all, the metaphor of jigsaw puzzles was attractive to participants who like leisure games.
P4, a self-identified Sudoku fan, made the following comment while she was rotating and scaling puzzle pieces: "This is one of those things where I could get very obsessive about getting it exactly right.
Third, novel setup of puzzles could serve as the catalyst of engagement.
For example P5 liked a puzzle that revealed the right pieces only when the layer order was right:
Those improvements were achieved by three main mechanisms of learning facilitated by Jigsaw: discovering by exploration, actively following demonstrations, and refreshing skills.
From our observations, both successful attempts and mistakes led to discovery of new facts and techniques.
For example, when P6 was using the Magnetic Lasso tool for the first time, he made a lucky guess that led to successful completion of the puzzle: "Now I'm kind of confused.
There is a cursor here, but also a line there.
I don't know which one is the starting point.
Is the upper-left corner or the bottom-left corner?
I think it looks like the bottom-left corner, so...  Yes, I was right!"
We found that the participants' general knowledge about how complex applications work could make their explorations more fruitful and efficient:
Because in Windows or Mac, when you want to select more than one thing, you press Shift."
Then I could figure out the details."
Moreover, we found that Jigsaw's progressive challenge levels and the embedded hints are both important and helpful in creating a supportive environment for users to engage in discovery-based learning.
Nonetheless, our observations also suggest that we need to improve the timeliness of hinting, the granularity of feedback, and the level of engagement to make Jigsaw more effective and fun.
We plan to explore just-in-time hinting to encourage more exploration and prevent frustration.
Also, we hope to offer feedback on the process in addition to the results, as the less-experienced participants requested more granular feedback for new tools.
Last, we want to support collaborative play, which will allow players to learn new editing techniques from one another.
Eight participants viewed the tutorials embedded in the game panel.
While some participants considered tutorials as their last resort and avoided them until they were really stuck, others viewed tutorials before attempting to solve the puzzle.
The different preferences in consulting tutorials were consistent with the participants' general learning styles as stated in the background interviews.
The tutorials and puzzles supplemented each other effectively.
Jigsaw motivated participants to apply the content of tutorials immediately after viewing.
This facilitated the transformation of the operations they knew to techniques they could employ.
In addition to the discovery of new facts and techniques about Photoshop, playing Jigsaw also helped participants recall operations they had forgotten.
Interestingly, participants often did not realize that they knew an operation until they performed it.
For instance, one of the puzzles asked participants to reorder layers to make all black and white pieces visible.
P5 was staring at the Layers panel, and said, "Actually I don't know how to reorder the layers."
But immediately after he said that, he dragged a layer and moved it above.
He seemed to be pleased by the fact that dragging worked.
Later when he was asked whether he previously knew that he could drag layers, he said, "I think I did.
In Kirkpatrick's training evaluation model, the Behavior level is concerned with the ability to apply acquired knowledge and skills to new contexts.
To assess knowledge transfer we asked participants to complete one or more of the before-after tasks they did not know how to do at the start of the study.
Using the skills they developed playing Jigsaw, all of the participants were able to complete tasks they did not know how to do at the start of the study.
