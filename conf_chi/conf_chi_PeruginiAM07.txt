We present the first user study of out-of-turn interaction in menu-based, interactive voice-response systems.
Out-ofturn interaction is a technique which empowers the user  to take the conversational initiative by supplying information that is currently unsolicited, but expected later in the dialog.
The technique permits the user to circumvent any flows of navigation hardwired into the design and navigate the menus in a manner which reflects their model of the task.
We conducted a laboratory experiment to measure the effect of the use of outof-turn interaction on user performance and preference in a menu-based, voice interface to voicemail.
Specifically, we compared two interfaces with the exact same hierarchical menu design: one with the capability of accepting out-ofturn utterances and one without this feature.
The results indicate that out-of-turn interaction significantly reduces task completion time, improves usability, and is preferred to the baseline.
This research studies an unexplored dimension of the design space for automated telephone services, namely the nature of user-addressable input  supplied , in contrast to more traditional dimensions such as input modality  and style of interaction .
While a menu design provides a familiar motif for users, it can also be a source of frustration when the structure of the menus does not match the user's model of the task.
Specifically, users are faced with selecting a menu item at each level which best fits the task.
This can often lead to dead-ends and back-tracking .
For instance, consider dialog 1  between a user and a voicemail IVRs.
Dialog 1: directed Welcome to voicemail.
Please say one of the following: `listen,' `send,' `system settings,' or `answering options.'
I just want to set my password.
Not sure which to select.
You have no new messages.
Please say one of the following: `listen,' `send,' `system settings,' or `answering options.'
7 System: Okay answering options.
Please say one of the following: `personal greetings,' `notification options,' or `answer mode.'
8 User  Password is personal, but it's not a greeting.
Let me back out and try system settings.
10 System: Okay main menu.
Please say one of the following: `listen,' `send,' `system settings,' or `answering options.'
12 System: Okay system settings.
Please say one of the following: `groups,' `password,' or `additional settings.'
The user's second choice -- `answering options'  -- leads to options 1 System:
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Thus, the user backs out of this path by saying `main menu'  and selects the `system settings' item  which ultimately leads to successful completion of the task.
Notice that in this dialog the user must directly respond to the system prompts in the order in which they are played, and the system, on the other hand, is unable to deviate from its predefined script.
Such a dialog is said to be a directed dialog and we say the user is making in-turn  responses at each step.
Due to the hardwired nature of the menu design, setting the password involves trail and error and potentially a taxing series of drill-downs and roll-ups to traverse the path through the menus leading to task completion.
This problem is endemic to all menu-based systems.
There can be several interpretations of out-of-turn interaction, but only one should be used in an implementation for purposes of consistency .
Here, we assume that an outof-turn utterance indicates that the user desires to experience a sequence of progressive steps through the menus where a subset of the terms in the utterance are involved in the menu choices within that sequence.
We use the decision tree for Siemens  PhoneMail voicemail system shown in Fig.
1, which is used in several organizations, as a running example to illustrate this operational interpretation.
Consider processing the out-of-turn utterance `greeting' spoken from the home state of Fig.
Using the interpretation given above, we first retain each sequence through the menus which involve the term in the utterance as a menu item and prune out all others .
While there are 40 sequences in total from the home state of PhoneMail to each terminal item , only the following five contain a menu item named `greeting' and, therefore, would remain following the utterance `greeting' spoken from the home state of PhoneMail:
An approach to this problem is a technique we call out-ofturn interaction.
The idea is to permit the user to make unsolicited utterances when unsure how best to respond to the current prompt.
This technique is illustrated in dialog 2 .
Dialog 2: mixed-initiative Welcome to voicemail.
Please say one of the following: `listen,' `send,' `system settings,' or `answering options.'
Please say one of the following: `set' or `remove.'
This causes the dialog to immediately focus on the password submenu .
At this point, the user decides to respond directly to the prompt and say `set' .
Progressive utterances are interpreted as a conjunction.
The implicit assumption is that the out-of-turn utterance is not only relevant to the task at hand, but also a valid response to a forthcoming prompt.
Interleaving out-of-turn utterances  with inturn responses  has been recognized as a simple form of mixed-initiative interaction .
Therefore, dialog 2 is said to be a mixed-initiative dialog.
In this paper, we present a user study to evaluate the effectiveness and usability of out-of-turn interaction  in a menu-based, IVRs to voicemail.
Our results indicate that out-of-turn interaction reduces task completion time and is preferred.
In exploring the nature of the user-addressable input  supplied , our study is fundamentally distinct from other research which has focused on more traditional design dimensions such as input modality  or interaction style  .
We first discuss the details of out-of-turn interaction including interpretations for it and survey related research wrt these design dimensions, and then discuss our comparative user study, its results, and contributions.
2  illustrates the pruned menu structure, which contains only the sequences above, resulting from speaking `greeting' out-of-turn.
It is important to note that the dialog structure is not flattened as a result of interacting out-of-turn, but rather preserved.
Note also that while many menu items are removed from the entire menu structure, only those removed from the home state are salient to the user .
There are a few practical, post-processing optimizations which we can conduct.
Consider that, while dependent on the structure of the menus at the time that the out-ofturn utterance is spoken, an out-of-turn interaction often results in some menus with only one option.
2 , `personal greetings' is the only menu item under the `answering options' menu which, similarly, is the only menu item from the home state.
A menu containing only one item implies that the item is no longer an option.
In these cases, we follow classic menu-design research which indicates that the no menu should contain less than two items.
Single-item menus should be consolidated with the previous menu  or the menu to which it leads.
2  shows the final menu structure resulting from saying `greeting' out-of-turn from the home state of PhoneMail and illustrates that the `answering options' and `personal greetings' items from Fig.
Sometimes an out-of-turn interaction results in a single sequence.
For example, saying `password' from the home state of PhoneMail results only in the sequence: mailbox options, password.
In this case, the consolidation of single-
However, it is important to note that the main menu is not always among the single-item menus.
For instance, consider saying `change' from the home state in Fig.
1 which results in the menu structure shown in Fig.
Now two choices remain from the home state because sub-menus containing items labeled with the term `change' are nested under both the `answering options' and `mailbox options' menus.
Notice further that in this example one menu choice in Fig.
3  is labeled exactly with what was spoken out-of-turn .
In such cases, since the user has effectively selected such items through the utterance , we can remove any menu item  which exactly matches the outof-turn utterance.
However, we do not remove the facility accessed through it.
Rather it is now accessed through the menu item predecessor of the removed item.
Notice that while the organization of the menus resulting from an out-of-turn utterance is different in each example above, the interpretation of  it, on the other hand, is fixed.
Note also that the presentation of the menu prompts is never re-ordered.
Prompts are are only pruned as a result of interacting out-of-turn.
The original order of the remaining menu prompts is sustained.
More importantly, the dynamic reduction of the tree, and thus the vocabulary, actually improves speech recognition accuracy, in contrast to de facto degradation of recognition accuracy common to most systems with support for mixed-initiative interaction.
In summary, out-of-turn interaction is optional and can be invoked  by the user at multiple points in a dialog at the user's discretion.
Moreover, future  utterances are cast within the context of past utterances.
When the user speaks out-of-turn, we 1. retain each sequence through the menus which involves a subset of the term in the utterance as a menu item and prune out all others, 2. remove the menu item addressed by the utterance from each remaining sequence,
3. collapse any series of menus from the remaining organization, where each contains only one item, and 4. re-play the  prompts from the main menu.
In some cases, steps 2 and 3 may not remove any further choices from the menus remaining after step 1.
There can be several variations of this basic technique with minor differences in the interpretation and implementation details.
However, the main idea is the same: permit the user to respond to a prompt nested deeper in the dialog structure before it is played, reducing the dialog appropriately.
It is a hybrid between menu-based and natural language solutions.
It is more flexible than fixed, hierarchical menus, but less open-ended than solutions involving natural language.
Outof-turn interaction is also not simply a search of the terminal objects  themselves .
We shall have more to say about where our research is situated within the conceptual design space for automated telephone services  in our survey of related research below.
Out-of-turn interaction is not barge-in .
Barge-in permits the user to respond to the current prompt for input before it is played.
Out-of-turn interaction, on the other hand, empowers the user to respond to any prompt nested deeper in the menu organization before it is played.
Out-of-turn interaction and barge-in are orthogonal techniques and can be used in concert if desired, and are in our study.
Lastly, while an out-of-turn interaction can result in a shortcut, , it is not simply a shortcut to a menu nested deeper in the dialog.
The shortcuts approach involves anticipating all points in the dialog where the user might desire to skip the current prompt and including mechanisms  to transfer control to an alternate menu.
On the other hand, outof-turn interaction never augments the original menu structure.
Depending on the application domain, there can be several reasons for interacting out-of-turn.
In the voicemail examples given here, out-of-turn interaction helps isolate the menu choice relevant to the user's task by pruning out irrelevant options.
The user is provided with auditory feedback when the new set of menu choices are played.
We use the word `isolate' rather than `determine'  since the user may still need to predict which menu item will lead to task completion when out-of-turn interaction leaves the main menu with more than one choice.
However, at this point, the user has the option of interacting out-of-turn again to hone in on the appropriate choice.
An out-of-turn utterance does not involve natural language.
By natural language we mean an IVRs which employs an open-ended prompt such as `How may I help you?'
Recall that the out-of-turn utterance is limited to a valid response to a prompt nested deeper in the menu organization; no other form of speech dialog is involved.
Yin and Zhai  describe FonePal, a system which permits the user to search the decision tree of an IVRs like they would a hierarchical website.
While the spirit of the search strings involved are out-of-turn , users enter the search strings using a textual modality which, unlike out-of-turn interaction, involves a context switch.
Results indicate that users were faster on average at searching than browsing.
Resnick and Virzi  offer the Skip and Scan approach to designing and interacting with an ATS.
Skip and Scan involves fragmenting each menu in an existing ATS decision tree into a series of several menus by enumerating purely navigational links between each to skip forward and back.
The user then, when interacting with a system augmented with these links, can easily navigate back and forth through menus without first having to listen to all of the prompts for a particular menu.
Notice that while Skip and Scan tackles within-menu navigation, we are studying between-menu navigation.
Moreover, since the users are prompted to follow each of these purely navigation links, this approach also involves in-turn responses.
While hardwiring additional navigation paths is one approach to increasing the scope of addressable information, support for out-of-turn interaction does not require augmenting the structure of the decision tree.
Rather it requires transforming it  during the processing of an out-of-turn input.
Results indicate that users were faster with a Skip and Scan interface and preferred it to standard menus.
To the best of our knowledge, no study has explored the area between the  and  points and, therefore, we contribute a study which does.
While most appropriate for casting our work, these three dimensions are not the only by which to design and study ATS .
Examining the intrinsic nature of system-manipulated information reveals a dimension with a content- vs. structurebased dichotomy.
Therefore, a different, but related, problem which has received attention is that of browsing and searching or managing/prioritizing the  voicemail messages themselves  as opposed to the access of them described here.
For example, FonePal , out-of-turn interaction, and Skip and Scan  focus on customizing access  to terminal objects, while Jotmail , ScanMail , and TalkBack  focus on searching/manipulating the terminal objects .
Specifically, here we focus on non-serial interaction with a menu  rather than non-serial interaction with a terminal object itself.
This requirement may be optimistic, especially in esoteric or emerging domains where no standard nomenclature has been established.
However, since a byproduct of the reduced menu is an improvement in speech recognition accuracy, expanding our lexicon with synonyms for menu items  is within the scope of viable approaches to this problem.
There are several ways to study automated telephone services.
The design dimensions which are most relevant to our research are the nature of the user-addressable1 input , input modality , and interaction style .
4 illustrates the conceptual design space described by these dimensions and situates related work within the space.
Note that three corners -- , , and  -- of the cube are undefined.
You cannot communicate out-of-turn information using a touch-tone modality.
Similarly, you cannot use natural language through a touch-tone modality.
While the majority of deployed systems in industry lie at the origin, over the past few years they have been shifting down the modality axis toward the voice-response end , e.g., Siemens PhoneMail is now available in both touch-tone and voice versions.
Research has tended to focus on areas away from the origin.
Out-of-turn interaction is not mutually-exclusive with any of these approaches.
Rather, it affords different, but complementary, interaction to enumerative , visual , multimodal , or content-based  approaches.
Out-of-turn interaction is a simple, optional, uni-device, uni-modality, transformation-based approach which does not involve any augmentation of the original phone tree, subsumes traditional interaction, and is applicable from day-one.
The goal of our research was to evaluate the effect of interacting out-of-turn with a menu-based, IVRs on task completion time, usability, and preference.
Since out-of-turn interaction automatically removes options from the menus which are not related to the utterance spoken -- thus preventing the user from exploring irrelevant paths -- we expected that it would increase the task success rate and reduce task completion time.
We also expected that faster completion times would lead users to prefer interacting out-of-turn.
Therefore, we conducting a comparative study in which participants performed two different sets of similar tasks in a voicemail, menu-based IVRs: one with the ability to interact out-ofturn and one without .
We evaluated differences in the above factors using common protocols and instruments from HCI such as questionnaires and the SUS  .
We administered a questionnaire to 151 undergraduate students which revealed that respondents were extremely familiar with and frequently use ATS, including voicemail.
Therefore, for purposes of familiarity, we decided to conduct our study within the domain of voicemail.
Furthermore, in order to insulate our study against the nuances of a particular commercial voicemail system as well as make our results more generalizable, rather than employing a commercial system, we designed a menu-based, voicemail IVRs  specifically for use in our study.
While there are several commercial voicemail systems available, each with minor variations, idiosyncrasies, and facilities , they all have a common set of core functions .
In order to include in our system a representative cross-section of the landscape of the features and functions available in voicemail systems, we based our system on a survey we conducted of approximately 10 commercial voicemail systems, including Siemens PhoneMail, Nortel Networks MerdianMail, and Verizon VoiceMail.
We implemented the voicemail system using VoiceXML and hosted two instances of it -- out-ofturn and baseline -- in the BeVocal Caf e, a free web-based service which hosts VoiceXML applications on the Internet, interprets them using Nuance automated speech recognition  technology, and provides toll-free access to them.
Our study employed a mixed-factorial design with order counter-balanced.
We only analyzed data from participants who had never interacted with systems similar to those using out-of-turn interaction , determined through an exit questionnaire.
While 46 undergraduate students  participated in the experiment, we disqualified six : five for this reason and another for not completing questionnaires according to the instructions.
Due to the Nuance ASR engine used in BeVocal, which requires no training, only naive speakers of English, 18 years of age or older, were permitted to participate.
Each participant was paid $10 and each session took approximately one hour.
The mean participant age was 20.6 and 77.5% of participants were psychology majors.
Half  of the 40 participants were exposed to the baseline interface first followed by the out-ofturn interface, and vice versa for the other half.
Participants were assigned to an order of interfaces based on the order in which each signed-up to participate.
Moreover, it did not preclude us from evaluating performance on the first and second interface used across all subjects should we not observe any learning from the first to second interface condition, therefore increasing the power of the statistical tests involved.
Since interacting out-of-turn is optional in an interface, the out-of-turn interface subsumes the baseline.
Therefore to foster an effective comparison, we instructed participants to interact out-of-turn from the main menu only when performing the tasks within the out-of-turn interface condition.
Recall that our goal was to measure the effect of out-of-turn interaction and not to evaluate whether or not participants employed it when presented with a task which might benefit from its use.
At the beginning of each interface condition, we gave participants instructions on how to interact.
Before using the out-of-turn interface, participants were instructed that they could ignore the current prompt and say up to three words in a single out-of-turn utterance rather than responding directly to a prompt.
Participants were also told that they could say `main menu' at any point in the interaction using either interface to return to the home state.
For instance, the first practice task requires 2-steps: one from the home state to the `system settings' menu and one from there to the password facility.
The second practice task requires at least 4 steps to complete: from the main menu to `system system settings' to `groups' to `edit members' and finally to the `add members' menu.
We annotate each task below with its value for this metric, which provides a measure of complexity.
These practice tasks were presented to each participant in both interfaces conditions in the order shown above.
The experimental tasks used in our study were: *  Recently you have been receiving messages from unknown people and you need to prevent your mailbox from accepting messages.
Turn your answer mode to off.
Since you want to be notified, turn the notification on.
Change your busy greeting to: `Please call back later.'
Add a group named `Group 2.'
Change the prompt speed to rapid.
The road noise is substantial so you must change the volume of your messaging system to high.
You would like to change the system language to Spanish.
You find this feature annoying and want to turn it off.
Turn the deletion notification off.
In order to eliminate task-based learning, each participant performed the four experimental tasks in each condition in a random order.
Specifically, one 2-step task was selected randomly from the set of two 2-step tasks, and three 3-step tasks were randomly selected from the set of six 3-step tasks.
Therefore, the number of 2-step and 3-step tasks was balanced in each condition.
However, all 2-step tasks preceded all 3step tasks.
We feel that this matches the pattern of a novice user learning a system: they typically start with simple tasks and gradually move up to more difficult tasks.
During the experiment as well as in all documents, the two interface conditions were referred to as red and blue, not baseline  and out-of-turn.
Participants were instructed that they had 5-minutes to complete each task.
Immediately before performing any tasks with a particular interface, each participant listened to an approximately halfminute recording of a sample dialog between a user and a menu-based, IVRs demonstrating how a user could find the weather conditions in Boston.
We used two instances of this dialog: the one to which the participants listened prior to using the baseline interface involved only solicited responses, while that to which they listened prior to using the outof-turn interface involved out-of-turn utterances.
The prerecorded dialogs were not created from the system used in this study; they were only intended to illustrate the interaction technique, and not to help the user learn the structure of the menus they would navigate to perform the actual tasks.
Each participant performed 12 tasks in total during the session.
While they performed 6 in each interface condition, the first two tasks attempted in each were practice and common across each condition.
Therefore, our study involved 10 distinct tasks, of which 8 were experimental.
Participants performed the following two tasks for practice.
You need to change your password to make sure no one has access to your protected phone information.
The phone-calling group allows you to leave voicemail messages simultaneously in the mailboxes of those on your calling list.
We categorized tasks based on the optimal number of steps necessary to successfully complete each using the baseline interface.
We define a step as a transition from one menu to a sub-menu.
Participants used a standard cordless telephone to access the system.
We recorded the audio from each participant session using a digital voice recorder and used a stopwatch to measure task completion time from recorded audio files.
We started timing the task at the start of the menu main prompt.
We stopped timing each task either when the participant arrived at the menu relevant to the task at hand or hung up the phone.
After completing each experimental task, each participant rated the interface for that task on four factors  using 6-point  semantic differential scales.
Immediately after performing the final task with each interface, participants completed an interface questionnaire followed by the SUS.
At the end of the experiment participants completed an interface comparison questionnaire followed by an exit questionnaire.
Our experimental design involved 320  experimental tasks attempted.
Of the 15 remaining trials, eight were not completed within the five-minute time limit.
On the other seven trials, participants hung up the phone before completing the task .
Of the 15 unsuccessful trials, 11 involved the `notification on' task, 2 involved the `deletion notification' task, and one each came from the `change busy greeting' and `change answer mode off' tasks.
Both unsuccessful attempts at the `deletion notification' task involved prematurely hanging up within the baseline interface condition.
Each unsuccessful attempt at the `change busy greeting' and `change answer mode off' involved an early hangup, using the baseline interface for the former and the out-of-turn interface for the latter.
Overall, four of our eight experimental tasks were completed successfully by all participants.
Ten participants did not complete one task, one participant did not complete two, and only one did not complete three.
A deeper analysis of the 15 unsuccessful trials indicates that participants were not likely to complete tasks more often in one interface than another.
We shall have more to say below about the `notification on' task - that which had the lowest task success rate.
The task with the longest successful mean task completion time  took 78s.
Those participants who exceeded the 240s limit may not have fully understood the capabilities of the system or were confused by the menus.
Those participants who hung up before completing the task may not have read the task carefully enough or may have confused one task for another.
These unsuccessful trials are not related to a specific interface as seven were not completed with the baseline interface and the remaining eight trials not completed with the out-of-turn interface.
We only analyzed time and semantic differential data from participants who completed the specified task successfully.
To determine whether the order in which our experiment exposed participants to the two interfaces had an effect on successful task completion time, we conducted a 2x2  ANOVA on mean task completion times for each of the eight experimental tasks.
We found no significant interaction effect  between conditions on task completion time on any task.
This is important because it meant that we could analyze completion times without regard to the order in which participants used the interfaces, thus, substantially increasing the power of the statistical tests.
Therefore, we performed a 2x2 ANOVA3 on mean successful task completion times.
We found a significant  main effect of interface type for seven of the eight tasks .
This is noteworthy because it means that all tasks, except for the `notification on' task, were completed significantly faster, on average, while using the out-of-turn interface than the baseline interface.
While participants completed the `notification on' task faster on average using the out-of-turn interface, we may have observed an insignificant difference in mean times because only 29 participants successfully completed the task, thus reducing statistical power.
We shall have more to say about this task below.
Moreo3 Since the distribution of task completion times was significantly different from a normal distribution, we also used the MannWhitney U test for non-parametric statistical significance.
However, since the patterns of significant differences  of the eight tasks were the same for the ANOVA and the Mann-Whitney U , we present the results of the ANOVA.
The differences in the percentages could be attributed to the idea that an initial exposure to a quicker interface makes the slower interface seem much slower, than if users begin with the slower interface first.
When the baseline interface was used first, the mean SUS score for it and out-of-turn interface was 65.38 and 85.38, respectively.
When the out-of-turn interface was used first, the mean SUS score for it and the baseline interface was 72.13 and 66.75, respectively.
We conducted a 2x2  ANOVA on mean SUS scores and found no significant interaction effect of the order of interface presentation =2.955, p=0.090.
Therefore, we examined all SUS scores without consideration of the order in which our experiment exposed participants to each interface and found no significant main effect of order on SUS scores =2.638, p=0.108.
However, we did find a significant main effect of interface type on SUS scores =9.456, p=0.003 indicating that participants found the out-of-turn interface significantly more usable than the baseline .
In the baseline interface, those who navigated to the deletion notification setting first may have assumed that this option was the same as the notification option.
However, saying `notification' out-of-turn would only eliminate two options from the main menu , and participants would therefore still have to make a selection between the two remaining main menu choices: `system settings' and `answering options.'
This decision is also present in the baseline interface, which may explain why the mean completion times in the out-of-turn interface  and baseline  are relatively similar.
In the other seven tasks, the initial out-of-turn utterance from each participant resulted in a shortcut to task completion.
For instance, during the `change language' task, participants most often said either `change language' or `language' - either utterance brings users directly to the language setting facility, obviating the need to make a subsequent choice at the main menu.
Another possible reason for difficulty might be that the task scenario itself may have been unclear or participants may have misread the scenario, again confusing it with the `deletion notification' task.
In summary, the experimental results indicate that * participants completed 7  of the 8 tasks significantly faster using the out-of-turn interface than the baseline, * the order of interface exposure did not significantly affect mean task completion time, * overall preference  significantly favored the out-of-turn interface and significantly more participants preferred it for each individual task, * based on SUS data, participants found the out-of-turn interface significantly more usable than the baseline, and * participants had difficulty successfully completing tasks when their initial out-of-turn utterance did not result in a shortcut.
Also, note that we do not report any speech recognition errors because they were too low  to be meaningful.
Using the Mann-Whitney U test for non-parametric statistical significance, participants rated the `answer mode off' task significantly simpler  and significantly more usable  with the out-ofturn interface than the baseline.
Similarly, participants rated the `deletion notification' task significantly more usable  with the out-of-turn interface.
Overall, participants rated the out-of-turn interface easier, simpler, more usable, and less frustrating than the baseline on 7 of the 8 tasks, with the exception of the `notification on' task - the only task for which participants rated the baseline interface  simpler.
The results obtained from the `notification on' task  did not follow the result pattern from other tasks.
Since 11 of the 15 unsuccessful trials involved this task, it was problematic to 11 of the 40 participants.
While mean task completion times showed that participants successfully completed this task faster using the out-of-turn interface, the difference was not significant as in all the other tasks, and this task also had the highest mean task completion time .
Similarly, participants significantly preferred to use the out-of-turn interface over the baseline on this task, but the preference percentage  was the lowest percentage of all the tasks.
Lastly, on each of the four semantic differential rating scales, mean ratings showed that participants found the baseline interface easier, simpler, more usable, and less frustrating for this task; the opposite was found on all of the other  tasks.
There are several possible explanations for this result.
The unfamiliar nature of the `notification on' task may have confused some participants.
Only two participants in the entire sample had ever changed the message notification setting in their own voicemail account.
To the best of our knowledge, we contribute the first formal, scientific user study establishing an upper bound on the impact of out-of-turn interaction on task efficiency in menubased, IVRs.
Out-of-turn interaction is a technique which provides the user with the option to make utterances which are unsolicited from the current menu, but constrained by the choices available in subsequent sub-menus.
While a hybrid of restricted and natural language, the utterances made using this technique are always out-of-turn .
Such tasks will require further study.
Moreover, to be effective, out-of-turn interaction requires users to have a basic understanding of the general nomenclature of the underlying domain  .
However, the results of our study have provided substantial evidence that out-of-turn interaction significantly reduces task completion time, improves usability, and is preferred over fixed menus, thus confirming our original expectations.
These results can be used to make an informed decision on whether or not to support out-of-turn interaction within an existing IVRs tree.
Moreover, armed with the current results, we can study the effect of relaxed assumptions and constraints in future studies.
The ubiquity of IVRs in a variety of service-oriented domains  provide fertile ground for the application of out-of-turn interaction and our results, especially to reduce agent costs in call routing.
For these reasons we feel that our study is worthwhile and particularly timely.
P. Resnick and R. A. Virzi.
Skip and Scan: Cleaning Up Telephone Interface.
In Proceedings of the ACM Conference on Human Factors in Computing Systems , pp.
P. Resnick and R. A. Virzi.
Relief from the Audio Interface Blues: Expanding the Spectrum of Menu, List, and Form Styles.
ACM Transactions on Computer-Human Interaction, Vol.
M. Ringel and J. Hirschberg.
Automated Message Prioritization: Making Voicemail Retrieval More Efficient.
In Proceedings of the ACM Conference on Human Factors in Computing Systems , pp.
Designing the User Interface: Strategies for Effective Human-Computer Interaction.
S. Srinivasan and E. Brown.
Is Speech Recognition Becoming Mainstream?
A Comparative Study of Speech in the Call Center: Natural Language Call Routing vs. Touch-tone Menus.
In Proceedings of the ACM Conference on Human Factors in Computing Systems , pp.
Harris, A. Toth, J. Sanders, A. Rudnicky, and R. Rosenfeld.
Towards Efficient Human Machine Speech Communication: The Speech Graffiti Project.
ACM Transactions on Speech and Language Processing, Vol.
S. Whittaker, R. Davis, J. Hirschberg, and U. Muller.
Jotmail: a voicemail interface that enables you to see what was said.
In Proceedings of the ACM Conference on Human Factors in Computing Systems , pp.
S. Whittaker, J. Hirschberg, B. Amento, L. Stark, M. Bacchiani, P. Isenhour, L. Stead, G. Zamchick, and A. Rosenberg.
SCANMail: A Voicemail Interface that Makes Speech Browsable, Readable and Searchable.
In Proceedings of the ACM Conference on Human Factors in Computing Systems , pp.
How Do Users Know What To Say?
M. Yin and S. Zhai.
The Benefits of Augmenting Telephone Voice Menu Navigation with Visual Browsing and Search.
In Proceedings of the ACM Conference on Human Factors in Computing Systems , pp.
W. Zadrozny, M. Budzikowski, J. Chai, N. Kambhatla, S. Levesque, and N. Nicolov.
Natural Language Dialogue for Personalized Interaction.
Communications of the ACM, Vol.
