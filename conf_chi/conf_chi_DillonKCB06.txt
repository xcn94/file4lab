Two experiments comparing user performance on ClearType and Regular displays are reported.
In the first, 26 participants scanned a series of spreadsheets for target information.
Speed of performance was significantly faster with ClearType.
In the second experiment, 25 users read two articles for meaning.
Reading speed was significantly faster for ClearType.
In both experiments no differences in accuracy of performance or visual fatigue scores were observed.
The data also reveal substantial individual differences in performance suggesting ClearType may not be universally beneficial to information workers.
Improvements in image quality for display technologies are assumed to offer meaningful benefits to users performing a variety of office tasks .
Nielsen argues that small improvements in reading speed could save companies up to $2000 per worker who spends about 20% of their time reading emails, web pages etc.
Since most information tasks involve a mix of direct reading, searching, scanning, and manipulation of documents, it can prove difficult to tease out exactly where, and to what extent image quality will have the greatest effect, but tasks involving significant serial reading where the eye makes continuous and extended contact with text are the most likely to benefit .
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
The history of research on the benefits of image quality has been dominated by reading tasks requiring users to proof or read serial text .
While initial research on this theme pursued a single variable explanation, it has become clear to researchers over the last decade that multiple factors affect the user response to electronic text.
Certainly among the key variables affecting human processing of electronic text is image quality.
Reading proceeds with the visual processing of textual representations, and while the human perceptual system is capable of extracting meaning from even partial images, there can be a temporal cost associated with reduced image quality.
Subsequent studies have shown that, for highly controlled short text reading, reading speed differences between the media could be reduced with the use of high resolution screens employing black, anti-aliased text on a white background with a screen-optimized font.
However in contemporary work environments users often shift between information activities and are likely to perform a range of tasks with displays that vary considerably from the extended reading scenario of traditional experimental trials.
Task variability may therefore play a significant role in determining the benefits of any image quality improvements.
O'Hara and Sellen  for example noted that ease of manipulation was a more significant factor than image quality in determining performance and satisfaction in a note taking and summarization task.
Their data come from a limited set of interviews and selfreports, not from direct observation of users so must be considered exploratory, but these findings may place some constraints on the impact of image quality.
Nevertheless, even Adler et al.
Given the known parameters of human perceptual and cognitive processing of text, image quality will at least affect the speed with which users can process a text and therefore directly influence rate of comprehension .
Microsoft's ClearType technology promises significant improvement in the visual quality of text presentation on screen.
ClearType is a setting that is manipulated through the Windows operating system of devices using Liquid Crystal Displays  and works by altering the vertical color stripe within a pixel allowing for changes in how the text looks at fractional levels.
These changes aim to enhance the resolution of the screen text and thus improve readability.
While font design has continued to be studied as a factor in electronic document presentation , ClearType can work across multiple fonts and may have more applicability in a world where many users like to choose their own font displays.
Experimental findings to date on this display technology are limited but early indications are that users respond favorably under some circumstances though the performance benefits are not obvious.
In a study of editing, scanning and reading tasks, each involving progressively greater amounts of direct eye-on-text contact, Dillon et al.
A detailed examination of user performance in that scanning study suggested a possible confound since the calculation of task speed measured both visual scanning and the physical activities of typing the task answer.
As the physical components of the total reading activity are unaffected by image quality, the resulting task time was not an accurate index of scanning performance.
Indeed not only was typing adding to the estimate of speed, but the requirement to specify the cell's text often necessitated several back and forth glances between target and keyboard.
Similarly, for the editing task, much of the users' time was spent moving between screen and paper, and typing.
In both these tasks, the impact of image quality was likely to be lessened, and its effects swamped by other factors.
The present experiments are intended to explore this issue further, particularly as it pertains to scanning, a typical information worker activity that is highly visual.
Specifically, we sought to control the user's interaction with the document so that only the visual act of interaction, rather than any physical document manipulation or typing, was involved.
Unlike serial reading of text, scanning does not require users to follow a defined visual path, and the goal of target location involves different cognitive processes than text comprehension .
We designed two separate experiments.
In the first, users scanned a set of spreadsheets for target information.
The task was designed to require rapid scanning and time spent reading the task and answering did not contribute to the speed score, this overcoming one of the potential sources of confound observed in the Dillon et al.
In the second experiment, users read a 2000 word article and answered a set of comprehension questions.
This task required extended eye-on-display reading.
Distinct user populations were employed for each experiment to control for any task or fatigue effects which may have impacted the earlier results.
In the second experiment, the 2000 word document was presented in blocks of 400 words.
By most measures, this is not a very lengthy text and no participants complained about the length or reported that the task was unusual for them.
We selected this text length for reading in order to reflect typical article lengths found in popular web sites, and to overcome some of the published criticisms of Gould et al.
The two experiments should be seen as part of one study, the aim of which is to engage users in different but common information tasks that vary in the amount of time their eyes spend directly on the screen.
We believe this to be the first time such a manipulation has been formally conducted despite increasing evidence from years of readability and document use studies that this factor underlies much of the reported variability in performance .
Participants were recruited through posted advertisements at a large research university in the southwestern USA and online job web sites in the same region.
The study employed a within-subjects  design with each participant completing ten unique scanning tasks in each of two conditions: ClearType and Regular text displays.
After completing each set of tasks, the participant answered a visual fatigue questionnaire.
Each scanning task was presented using test software, controlled by the participant, which automatically captured time data and user responses.
Accuracy data was based on the number of correct answers the participant provided; the total possible score was 20 points .
The visual fatigue scores were based on Tyrrell's six scales of mental and physical fatigue with answers ranging on a seven point scale of strongly disagree to strongly agree .
Participants all used the same Dell Latitude C840 laptop, with the choice of using a mouse attached peripherally or the mouse-equivalents on the laptop keyboard.
The screen size of the laptop was 15 inches, with a display setting of 1600x1200 pixels.
ClearType was gamma tuned for the laptop to optimize its setting for this specific laptop.
Gamma tuning adjusts brightness levels so that colors are correctly displayed.
Internet Explorer 6.0 was used as the browser environment to present the test software and task.
For each task the subject was asked to determine the frequency of occurrence of target items in a spreadsheet display, see example in Figure 1 .
All the text content in the scanning tasks came from actual web sites with 12 pt fonts.
Of the 20 test pages, 12 used Verdana, four were Courier, and four were Arial.
Since all fonts were deemed representative by the experimental team no formal balancing of this variable occurred but tasks were matched for each condition so that the participant always completed a similar scan  in both conditions.
Order was counterbalanced for ClearType and Regular, as was the content within these conditions.
Each participant was seated in a closed room environment facing the laptop.
The moderator explained the multi-part procedure for the session and then gave the participant practice scanning tasks.
After completing two practice scans, participants proceeded through the first block of ten scans at their own pace.
As instructed, the participant again clicked "enter" when they had determined the answer, thus stopping the timer, at which point the test software then prompted the user to type their answer.
After submitting the typed answer, the next task was presented on screen and the participant proceeded as before, until the first block of ten scans was complete.
In this way, the timer only recorded the duration of the task for which the participant was scanning the spreadsheet.
At the end of this block, the stimuli and the moderator prompted the participants to answer the visual fatigue questionnaire .
The display condition was switched automatically by the test software while the participant filled in the fatigue scales and the second block of ten scans commenced as before.
Once more, at the end of this second block, the participant again completed the visual fatigue scales, after which the experiment ended.
Time, accuracy and visual fatigue scores were calculated for each participant and the summary data is presented in Table 1.
Participants performed scans more quickly when ClearType was present, and there was noticeably greater variation in performance observed in the Regular condition.
On average, participants were 24 seconds faster completing the scans with ClearType, a significant improvement of , see Table 2.
There were no significant differences in accuracy or visual fatigue.
My back and/or neck hurts from sitting in this position while answering the questions.
Answering these questions on a computer gives me a headache.
After answering these questions, my vision seems blurry when I look at distant objects.
I feel mentally fatigued right now.
My eyes feel strained right now.
Overall, answering these questions has made me feel fatigued.
While the significant effect for display points to a robust benefit for ClearType on this type of visual scanning, the individual participant scores indicate that only 16 of the 26 participants performed better in the ClearType condition.
However, for these people, the advantage of ClearType was pronounced, as shown in Table 4.
These results support the hypothesis that ClearType can improve performance in visually intensive scanning tasks.
On average, where the eye-on-screen component of the task dominates, people performed 7.2% faster with ClearType than with Regular displays, with equivalent levels of accuracy and fatigue.
Of the 16 who performed better with ClearType, four performed over 100 seconds faster, on a set of tasks that on average took around 300 seconds to perform.
No equivalently large differences were observed for participants who were faster with Regular text.
We can examine the full distribution of these individual differences graphically in Figure 2.
As this shows, once you remove those who demonstrated less than a 10% difference between conditions in either direction  then there are only 5 participants who were much better with Regular text but 11 who performed much better with ClearType.
In fact, the mean performance benefit between displays was 53.5 seconds for the "ClearType-advantaged" users compared to a 26.2 seconds benefit for the "Regular-advantaged"  users.
These data seem to suggest that while ClearType can yield a general improvement in reading speed for many people, its benefits are not universal.
Once more, test software was developed to enable automatic capture of time data for each task.
To give us better insight into the reading process we divided the text into five screens of text, each approximately 400 words in length.
To remove scrolling from the task, each screen was presented as a whole, and the participant pressed the space bar to move forward.
The timer started running at the moment the participant displayed the first screen and also captured each screen's reading duration.
Accuracy data was based on the number of correct responses to questions on the material; the total possible score was 6 points.
Five multiple-choice questions prompted for factual information from the article ; one point was given for each correct answer.
Another additional point was calculated for a semi-structured question which asked the participant to list five themes or ideas that the article conveyed--1/5 of a point was given for each correct theme.
The participant also responded to an open-ended question to summarize the article in three to four sentences, this was not calculated in the accuracy score but served as a check that the participant had actually read the text for comprehension.
Again, the visual fatigue scores were based on Tyrrell's six scales , modified as in the scanning task to suit this context.
For this task we also added a preference score, calculated by presenting the participant with ClearType and Regular text side-by-side .
As before, participants were recruited through posted advertisements at a large research university in the southwestern USA and online job web sites in this same region.
Each participant read two articles of general interest: one about the history of newspapers, and the other about the etiquette of tipping.
These texts were selected for equivalent interest and reading levels, as judged by the experimental team.
Each article was approximately 2000 words long, and was divided over five screens and presented in Arial 12 pt font.
Text and display orders were counterbalanced across participants.
See Figure 3 for an example screen.
After reading five screens  the timing stopped and the participant answered the multiple and short-answer questions presented by the test software.
After answering these questions, the moderator prompted the participant to answer the visual fatigue questionnaire by hand on paper while the display condition was switched.
The participant then proceeded with the second reading article and questions, and answered the visual fatigue questionnaire a second time.
The moderator finished the test session by showing a comparison of the ClearType and Regular texts on one screen, asking the participant to rate preference and perceived blurriness for each.
On completion of these scales the experiment ended.
Participants all used the same Dell Latitude C840 laptop, with the choice of using a mouse attached peripherally or the mouse-equivalents on the laptop keyboard.
The screen size of the laptop was 15 inches, with a display setting of 1600x1200 pixels.
ClearType was gamma tuned for the laptop to optimize its setting for this specific laptop.
Gamma tuning adjusts brightness levels so that colors are correctly displayed.
Internet Explorer 6.0 was used as the browser environment to present the test software and task.
The summary data from all participants is shown in Table 5.
On average, participants read 31 seconds  faster with ClearType.
There were no significant effects for accuracy or visual fatigue.
Each participant was seated in a closed room environment facing the laptop.
The moderator explained the multi-part procedure for the session and demonstrated an example reading task to the participant who was allowed to ask questions and become comfortable with the procedure.
Participants were asked to begin the first reading block by pressing the space bar and proceeding through the reading at their own pace.
Overall, more participants strongly preferred ClearType and rated it less blurry when comparing it to Regular text.
Tables 8 and 9 show the number of participants for each of the scales grouped into categories of preference and blurriness.
Please note that three questionnaires were discarded from the 25 participants as unusable.
There is a significant negative correlation between preference and blurriness scores , as expected.
Figure 4 shows the comparison of task completion time between ClearType and Regular text across each of the five screens  of text.
Participants consistently performed faster with ClearType across all five screens, indicating a steady performance benefit for most users.
The results of mental effort and visual fatigue score are summarized in Table 7.
For all scores, a higher score represents greater perceived and physical demand or effort.
Once again, no significant differences were observed between display conditions.
My back and/or neck hurts from sitting in this position while answering the questions.
Answering these questions on a computer gives me a headache.
After answering these questions, my vision seems blurry when I look at distant objects.
I feel mentally fatigued right now.
My eyes feel strained right now.
Overall, answering these questions has made me feel fatigued.
Again, viewing these graphically  we can see that the differences are more pronounced in one direction.
Mean improvement scores for the "ClearType-advantaged" users were 85.75 seconds compared to a 65.77 seconds decrement for the "ClearType-disadvantaged" users.
These data again suggest that where ClearType helps, it does so in a more pronounced fashion than it hinders.
However, once gain, the benefits are not universal.
For most users ClearType-enhanced text produces a significant improvement in performance times on tasks involving extended eye-on-text interactions.
For both reading and visual scanning tasks of the type employed here, which were designed to simulate routine office tasks for information workers, the recommendation to use ClearType is supported.
Across 51 users in this study, 32 witnessed improvements in their speed compared to the Regular text display.
Furthermore, the size of this performance improvement seen by these users was more pronounced than the decrement witnessed by the 19 users who were faster on Regular displays.
The data from the reading task alone confirm the earlier finding from Dillon et al., which showed a 5.1% speed advantage to ClearType over Regular displays .
The present study examined reading alone, not as a part of a combined task block, and it showed a 5.65% advantage to ClearType.
This suggests a relatively consistent effect on reading speed for ClearType.
The performance on the visual scanning task was also improved by use of ClearType.
The isolation of the visual scanning activity in the present study enabled us to gain an isolated measure of visual scanning without other task components intruding, and here we see speed was improved an average of 7.2% by ClearType.
Both these tests support the argument that image quality improvements have maximum benefit for tasks where the user is spending large proportions of the tasks with their eyes on the text.
Since information work consists of many interrelated physical, perceptual and cognitive activities, the impact of image quality improvements will not always be pronounced.
The issue of individual differences remains a source of interest.
With 19 out of 51 users experiencing some disadvantage in a ClearType condition one cannot uniformly endorse ClearType and there is a need to determine what factors may be at work here.
Since we have no demographic or perceptual processing data here by which to compare participants we can only speculate on potential acuity or related visual processing factors that may be at work.
However, to check for the possibility of an unusual order effect, we conducted a post-hoc analysis with display order as a variable.
Interestingly, even though order was fully counter-balanced in this experimental design, there was an interaction effect for display condition with order for the scanning task  = 10.95, p < .01 and a three-way interaction effect between order, display and content for the reading task  = 9.20, p < .01.
In both tasks, there is no evidence of a practice effect  but all four of the participants who were more than 100 seconds faster with ClearType in the scanning task happened to be exposed to ClearType before the Regular display.
In other words, it is possible that ClearType produces different effects in users when it is turned off, and they are required to read Regular text than when it is turned on after they have spent time reading Regular text.
This is an issue for further study.
For now the recommendation is to employ ClearType for most contexts of use but to allow users to disable it if they find it produces effects other than improved performance.
Image quality still matters but its effects are subtle and highly dependent on the information task structure.
To this we would add that individual differences in response to certain image enhancements are large and warrant further investigation.
To develop more accurate assessments of the dollar value of image quality improvements in display technologies, it would be useful to extend Adler et al's.
