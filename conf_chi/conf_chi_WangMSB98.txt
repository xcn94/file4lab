ABSTRACT An experiment was conducted to investigate the relationship between object transportation and object orientation by the human hand in the context of humancomputer interaction .
This work merges two streams of research: the structure of interactive manipulation in HCI and the natural hand prehension in human motor control.
It was found that object transportation and object orientation have a parallel, interdependent structure which is generally persistent over different visual feedback conditions.
The notion of concurrency and interdependence of multidimensional visuomotor control structure can provide a new framework for human-computer interface evaluation and design.
Keywords Direct manipulation, input device, multi-dimensional control, visuomotor control, visual conditions, information processing, interface design, virtual reality.
INTRODUCTION Object manipulation is a basic operation in humancomputer interaction .
Modern computer technology advances towards affording multi-dimensional object manipulation.
A virtual environment can typically provide at least six degrees of freedom of control for a graphic display with a controller.
The spatial state of a rigid object in a multi-dimensional space can be completely described by its location and orientation.
By definition, the spatial state of an object's location is independent from that of its orientation at the descriptive level.
Accordingly, the spatial state of an object can be changed with object translation and object rotation processes in a parallel or serial pattern.
If, however, a human hand is the manipulator, as is the case of direct manipulation with a pointing device, the relationship between object transportation and object orientation is no longer so simple .
Two streams of research are related to the relationship between object transportation and object orientation.
One is on the structure of interactive graphic manipulation in HCI derived from the perceptual structure of visual information, and the other is research on the hand prehension in human motor control.
One important question is, what is the natural structure of control for object translation and rotation.
There is not a ready answer to this question from previous research.
This study address this question by exploring the structure of object transportation and object orientation by the human hand in the context of human-computer interaction, and therefore provides implications for human-computer interface design.
Perceptual structure of visual information and the control structure of input devices According to the theory of perceptual structure of visual information by Garner, a multi-dimensional object can be characterized by its attributes into two categories: integral structure and separable structure .
Visual information has an integral structure if its attributes can be perceptually combined to form a unitary whole, e.g., lightness and saturation of a color.
If visual object attributes demonstrate perceptually distinct and identifiable dimensions, they are separable.
For example, the lightness and size of an object have a separable structure.
The type of the perceptual structure of an object can be determined by direct similarity scaling methods.
An integral structure shows Euclidean distance, while a separable structure demonstrates city-block distance in the perceptual attribute space.
Jacob and his colleagues extended Garner's notion of integral and separable structure to interactive tasks by observing that manipulating a graphic object is simply the changing of values of its attributes .
They predicted that the interaction movement in an integral space should be Euclidean, straight-line distance between two points, and movement in a separable space should be city-block and run parallel to the axes.
In turn, the pattern of Euclidean distance and the city-block distance indicates the type of the perceptual structure.
With an integral device, the movement is in Euclidean space and cuts across all the dimensions of control.
A separable device constrains movement along one dimension at a time, showing a cityblock pattern.
They hypothesized that human performance improves when the perceptual structure of the task matches the control structure of the device.
They conducted an experiment in which subjects performed two tasks that had different perceptual structures, using two input devices with correspondingly different control structures, an integral three-dimensional tracker and a separable mouse.
The integral task was the control for a graphic object's location and size, and the separable task was the control for object's location and brightness .
Their results converged to support their hypothesis.
They concluded that the interplay between task and device was more important in determining performance than either task or device alone.
The framework proposed by Jacob et al.
However, the notion of the integral and separable structure is not automatically applicable to multi-dimensional object manipulation including object transportation and orientation by the human hand.
The original notion of integral and separable structure by Garner only deals with intrinsic properties of a visual object, such as the size and color .
The location and orientation of an object are extrinsic properties.
Furthermore, recent research shows that humans may have two separate visual systems, one for perception, the other for action .
This evidence suggests that the perceptual structure of an object may not be the same structure of the interaction movement of an object.
It is arguable whether or not a structure in a perceptual space can be extended to an interactive space.
Ware found that subjects could easily achieve simultaneous object transportation and orientation using a 6DOF controller, but some other researchers reported that it was rather difficult for humans to transport and orient an object at the same time .
The relationship between object transportation and orientation remains an open question.
Jeannerod's "independent visuomotor channels" hypothesis states that there may be independent neural pathways controlling hand reaching and grasping separately .
Furthermore, the reaching component may be more related to the extrinsic properties  of a target object, while the grasping component may be more related to the intrinsic properties  .
The independent visuomotor channels hypothesis was developed originally for the phase of prehension before the hand makes contact with a target object .
A recent review by Paulignan and Jeannerod demonstrated neural, biophysical and behavior evidence supporting this hypothesis .
The empirical data showed that object location  affected the hand reaching component and object size  affected the grasping component separately.
However, since object transportation and object orientation are both extrinsic properties, it is inappropriate to draw conclusions on the relationship between object transportation and orientation based on visuomotor channels theory.
Further, human prehension with an object in hand such as operating a mouse in HCI, where tactile information is available, can be very different from grasping prior to contact with an object .
These considerations warrant further investigation into the relationship between object transportation and orientation by the human hand in HCI.
Research hypotheses We argue that an interface design should not only accommodate the perceptual structure of the task and control structure of the input device, but also the structure of motor control systems.
However, research in HCI generally does not address the motor control aspect of human-computer interaction per se.
At the same time, motor control researchers do not examine object transportation and orientation in the context of HCI.
The assumptions underlying the theoretical framework by Jacob et al.
Based on the notion of integral and separable perceptual structure, object transportation and orientation could be integrable because the spatial attributes are generally considered integral .
On the other hand, the hypothesis of independent visuomotor channels suggests that it is likely to make the control of object transportation and orientation separable .
Results regarding the relationship between object transportation and orientation are not conclusive from both streams of research.
Object transportation and orientation can be described as two processes in the tempo-spatial domain.
We propose a new framework to encompass both aspects of the relationship between object transportation and orientation processes.
We define a structure of object transportation and orientation in terms of concurrency and interdependence between two processes.
The concurrency indicates the relationship between the time courses of two processes, either in parallel or in serial.
The notion of parallel and serial is similar to that of integral and separable by Jacob et al., but in a multi-dimensional visual motor control space.
If two processes occur simultaneously, they are parallel.
As a special case of parallel, if one process contains the other one, the longer process dominates the shorter one.
Interdependence reflects the interaction between object transportation and orientation processes.
If the inputs of one processes affects the outputs of the other process, two processes are interdependent.
Our main research hypothesis is that object transportation and orientation have a parallel and interdependent structure.
We also expect that object transportation and orientation processes show different weights in object manipulation and one process may dominate the other.
We further hypothesize that, as visual feedback conditions change, the structure of object transportation and orientation may change.
An experiment was conducted to test above hypotheses.
METHOD Experimental setup A virtual environment  was set up for this experiment, as shown in Figure 1.
A stereoscopic, head-coupled graphical display was presented with a Silicon Graphics Indigo RGB monitor.
A half-silvered mirror was placed parallel to the computer screen and the table surface.
The image on the screen was reflected by the mirror, and then was perceived by the subject as if it was on the table surface.
There was a light under the mirror  to control the visual conditions.
When the light was on, the subject could see through the mirror, and thus the visual feedback of the hand and the wooden cube was present.
When the light was off, the subject could see neither his/her hand nor the wooden cube.
For both conditions, the graphic target was always visible, with a black background on the computer screen.
The subject was comfortably seated at a table, with the forearm at approximately the same height with the table surface.
The body was about 30 mm away from the front edge of the table.
The subject was wearing CrystalEYES Goggles to obtain a stereoscopic view of an image.
Three infrared markers  were fixed to the side frame of the goggles, and individual subject eye positions were calibrated relative to these markers.
The movements of the head were recorded with an OPTOTRAK motion analysis system , which measured the threedimensional position of the IREDs on the goggles.
The stereoscopic, head-coupled, graphic display was updated at 60 Hz with 1 frame lag of OPTOTRAK co-ordinates.
The target image was a graphic, wireframe cube projected on the table surface.
The 30 mm graphic cube was positioned at one of three locations and two orientations.
The object to be manipulated was a wooden cube with the size of 30 mm * 30 mm * 30 mm, the same as the target cube.
The wooden cube weighted 11 grams.
Two IREDs were placed on the top of the wooden cube, IRED 1 at the center and IRED 2 diagonally 15 mm away from IRED 1.
Data from the OPTOTRAK were sampled and recorded at 60 Hz by a Silicon Graphics Indigo Extreme computer workstation.
A thin physical L-frame  was used to locate the starting position of the wooden cube, at the beginning of each trial.
A mouse was operated with the subject's left hand to control the start and end of a trial.
Subjects Eight university student volunteers were paid $20 for participating in a two-hour experimental session.
All subjects were right-handed, and had normal or corrected-tonormal vision.
Subjects all had experience using a computer.
Procedure The task was to align or dock a small wooden cube with the graphic target cube.
Manipulation tasks were designed that required both object transportation and orientation, under different visual feedback conditions.
The subject held the wooden cube with the right hand, with the thumb and index finger in pad opposition on the center of opposing cube faces which were parallel to the frontal plane of the body.
To start a trial, the subject pressed the mouse left button, with the left hand; this generated the graphic target cube on the table top, 30 mm, 100 mm or 200 mm from the starting position, and rotated by 22.5 or 45 degrees from the frontal plane of the subject.
The subject was asked to match the wooden cube to the graphic target cube as fast and accurately as possible.
When the subject was satisfied with the match, he/she pressed the mouse middle button to end that trial.
Trials were blocked by two visual conditions: without visual feedback , or with visual feedback .
Four subjects started with the visual feedback condition, and the other four started with the no visual feedback condition.
Target location and orientation were randomized within a block.
For each experimental condition, 15 trials were collected.
Data analysis OPTOTRAK 3-D position data collected from two IREDs on the top of the wooden cube are analyzed here.
Data were filtered with a 7 Hz low-pass second-order bi-directional Butterworth digital filter to remove digital sampling artifacts, vibrations of the markers, and tremor from the hand movement.
Original IRED position data were interpolated and filtered only once, and then were used for the following data manipulation including angular data generation.
A computer program determining the start and end of a pointing movement was used for the transportation and orientation processes separately, based on criterion velocities .
The start and end of each process were then confirmed by visually inspecting a graph of the velocity profile.
A trial was rejected if the program failed to find a start and end or there was disagreement between experimenter's visual inspection and the computer's results.
This case usually occurred when subject made a false start.
Primary dependent measures of object manipulation were Movement time , transportation time , Orientation Time , and spatial errors of object translation and rotation to the target.
MT was defined as the task completion time, which should be equal to or greater than the longer one between the transportation and orientation processes.
TT was the transportation time determined with translation data from IRED 1 at the center of the cube top.
OT was determined with data calculated from the horizontal rotation of the cube around IRED 1.
Results of spatial errors were reported elsewhere by Wang et al.
ANOVA was performed on the balanced design of 2 visions  * 3 distances  * 2 angles  with repeated measures on all three factors.
We also examined the effects of target location and orientation under each vision condition.
Twoway ANOVAs were performed, separately, with full vision of the hand and the object and without the hand and the object in view.
In the vision condition, the experiment setup provided a realistic visual world and an unconstrained control for six degrees of freedom of object manipulation.
Therefore, the performance under the vision condition was considered to be "natural", while the no vision condition was considered to be visually "impoverished".
Separate data analyses for each visual condition as well as a comparison between two visual conditions were performed for this study.
RESULTS We examine the structure of object transportation and orientation in terms of concurrency and interdependence between two processes.
Within each, the natural performance, where visual feedback of action was available, is discussed first.
Then the results of the object manipulation are reported where visual feedback of the hand and the object was unavailable.
Finally, a comparison between two visual conditions will be made.
Concurrency Concurrency with vision of the hand and object Total movement time  in the vision condition had an average value of 776 ms.
The average transportation time  was 766 ms in the visual feedback condition, only 10 ms shorter than the total task completion time .
Apparently, the average MT was much less than the sum of average TT and OT.
Time courses of object transportation and orientation processes.
White areas indicate transportation only.
Dark areas are orientation overlapping transportation.
The concurrency of the time courses between two processes in the vision condition is shown in the top part of Figure 2.
Experimental results clearly demonstrated that object translation and object rotation were processed in parallel in the time domain.
In general, object manipulation first started with the object transportation process.
The simultaneous execution of two processes remained for an average period of 479 ms until the orientation process finished.
The transportation process continued another 257 ms on average and object manipulation ended.
Nevertheless, the total task completion time was mainly determined by object translation, that is, the transportation process was the critical path.
The parallel structure of natural object manipulation was stable over all experimental conditions.
However, a detailed analysis showed that the overlap portion of two processes changed with experimental conditions.
Subjects would start the orientation process earlier if they anticipated that the orientation process could be longer.
On the other hand, if the transportation process could be long enough to complete the orientation process within it, subjects would not mind starting the orientation process a little late.
The fact that the difference in the ends decreased with the target angle  = 37.85, p < .001 may be due to the longer time to orient the object of 45 degrees than 22.5 degrees.
Concurrency with no vision of the hand and object The structure of object manipulation under the "visuallyimpoverished" condition was similar to that under the "natural visual" condition in terms of the concurrency between two processes .
The transportation and orientation processes were executed in parallel.
The orientation process was contained within the transportation process, that is, the object translation started earlier and finished later than the object rotation.
The difference in the starts of two processes between TT and OT increased significantly with the target distance  = 16.01, p < .001.
The difference in the ends of two processes between TT and OT increased significantly with the target distance  = 10.17, p < .01.
Overall, there were no differences in MT between two visual feedback conditions.
Effects of visual feedback on concurrency Effects of visual feedback on object manipulation were examined with pooled data over two vision conditions.
ANOVA was performed with repeated measures on vision condition, target distances and target angles.
Deprivation of vision of the hand and the object significantly delayed the start of the orientation process relative to the start of the transportation process, F = 8.05, p < .05.
The average difference between the starts of two processes increased from 30 ms in the vision condition to 64 ms in the no vision condition.
Vision had no significant effects on the difference in the ends of two processes between TT and OT.
Interdependence Interdependence with vision of the hand and object During object manipulation, the target distance was assumed to be the input for the transportation process with the output of TT, while the target angle was the input for the orientation process with the output of OT.
However, it was found that the input for each process affected the output of the other process.
As a general trend, both TT and OT increased as the requirement of either object transportation distance or object orientation angle increased.
It seemed that the effects of the target distance were more pervasive on the OT than vice versa.
Object transportation and orientation processes were thus interdependent on each other.
Interdependence with no vision of the hand and object Similar effects were found in the "visually impoverished" condition.
Both processes contributed to the MT, but the transportation process was the critical path to determine the MT.
The object rotation affected the object translation, showing the interdependence of TT on the target angle.
OT as an output of the object rotation increased with the object translation.
The difference in OT between two target angles seemed to increase with the target distance.
Total movement time , transportation time  and orientation time  under various experimental conditions.
The interdependent structure of two processes was persistent over visual conditions.
Visual effects on interdependence As shown in Figure 3, TT and OT presented a similar pattern for vision conditions in relation to target location and orientation variables.
Visual conditions of the hand and object did not have main effects on both object transportation and orientation times.
However, Vision conditions showed interactions with the target distance and rotation angle of the target.
DISCUSSIONS AND CONCLUSIONS Parallel structure These results demonstrated a parallel structure of object transportation and orientation, supporting our research hypothesis.
The total object manipulation time was less than the sum of object translation time and rotation time.
There was a large portion of overlap between object transportation and orientation processes where object manipulation cut across the object translation dimension and rotation dimension simultaneously, showing a Euclidean distance in the space.
In this sense, object transportation and orientation seemed to have characteristics of a integral structure, according to the notion by Jacob et al.
However, our results also indicated that even though object transportation and orientation processes were in parallel, they were not completely overlapped from the beginning to the end.
Usually the object orientation started a little late and completed quite early compared with object transportation, and the final stage of movements reflected only object transportation portion.
On average, the time course of object transportation contained that of object orientation, that is, object transportation dominated object orientation.
This evidence made object transportation and orientation distinct and identifiable, and therefore suggested a separable structure based on the definition of a perceptual structure  .
Even though, as recognized by Jacob et al., "Integral and separable define two classes of perceptual structure that mark the endpoints of a continuum rather than forming a sharp dichotomy", a structure should not be described as both integral and separable.
The interpretation to the mechanism underlying the parallel structure of object transportation and orientation has to be extended beyond the notion of integral and separable.
We attribute our results to the structure of visuomotor control rather than only the perceptual structure of visual information.
Object manipulation is not involved with visual information alone, and therefore the structure of tasks cannot be dictated by only visual information.
Indeed, our results show that the vision condition of the hand and object interacts with the target attributes jointly to affect object manipulation performance, rather than acts alone.
Haptic and kinesthetic information have a strong role to play in object manipulation tasks as well.
Human separable visual systems for perception and action imply that a structure of an object in a perceptual space may not be the same one in an interactive space .
Object manipulation as a goal-directed movement should take into account the attributes of the target as well.
Actually, all information including visual display of the task environment and the manipulator may be relevant to determine the structure.
The notion of concurrency not only addresses whether or not object transportation and orientation occur simultaneously, but also identifies where and when each process starts and ends.
This allows us to explore subtle but important differences in the structure of object transportation and orientation.
Obviously, a parallel structure is more efficient than serial one in terms of the task completion time.
To achieve a parallel structure in object manipulation, subjects have to coordinate two processes in the temporal domain.
It was interesting to note that the difference between the starts of transportation and orientation was very short, 30 ms in the vision condition, but consistently increased with the target distance.
This observation was unlikely to be a result from the on-line adjustment after object manipulation started because the time was too short for a feedback adjustment.
A possible interpretation is that subjects formed a plan to start the orientation process earlier if the transportation process would be shorter so as to achieve an efficient parallel structure.
This interpretation is consistent with the fact that the orientation process started earlier when subjects anticipated a longer object rotation.
It seemed that there was a need to allocate enough time for on-line correction on object transportation in the last phase of the movement.
Evidence shows that the time course of one process of object manipulation has to be planned in coordination with that of the other process.
In conclusion, object manipulation is a unitary visuomotor output with a coordinated control for object translation and rotation.
Interdependent structure Evidence from this study does not support the extension of Jeannerod's "independent visuomotor channels" hypothesis to the structure of object transportation and orientation by human hand .
In contrast, our results showed a strong interdependence between object transportation and orientation processes.
The object translation time depended on not only the target distance, but also the target orientation angle, and vice versa.
This indicates that even though the spatial states of object translation and rotation can be described separately within a coordinate system, the two processes of object translation and rotation are executed interactively by humans.
Note that Jeannerod's empirical data for grasping was based on grasp aperture, not orientation of grasp.
Object size  affects grasp aperture but object orientation  affects both transportation and orientation of the hand.
This is an important distinction, both for motor control and HCI researchers.
It was evident that the increase in object translation requirements extended the object rotation time, while a larger object rotation resulted in a longer object translation.
However, the two processes did not affect each other evenly.
The transportation process appeared to have more significant effects on object manipulation than the orientation process.
Evidence showed that the transportation time course contained the orientation time course so that TT was determinant of MT.
Quite a long time was allocated for transportation only during the last phase of object manipulation.
TT was the critical path for object manipulation with two processes.
Effects of visual conditions In general, object manipulation structure was similar under two vision conditions in terms of the concurrency and interdependence between transportation and orientation processes.
When the visual feedback on the hand and the object was deprived, same as in the visual feedback condition, the transportation time course contained the orientation time course, and two processes were interdependent on each other.
This means that the visual feedback information of the manipulator and the object being manipulated is not important for forming the structure of object transportation and orientation.
In another word, the parallel and interdependent structure of object manipulation is persistent to changes in visual feedback conditions.
One possible explanation is that, given the target location and orientation, the structure is already programmed before the start of the movement.
Another explanation is that the structure is insensitive to the difference between proprioceptive feedback and visual feedback.
This topic deserves further investigation.
Deprivation of visual feedback of the object and the hand increased spatial errors of object translation and rotation, but the effects were more significant on the translation errors than the rotation errors see Wang et al  for detail.
Implications for HCI design Human-computer interfaces should be designed to accommodate the natural structure of object manipulation.
Constraints or interruption on the integration of object manipulation may result in a structural inefficiency.
At the same time, if the main goal of interface design is to achieve the "naturalness" or realism such as virtual reality, remaining the natural structure of human object manipulation will be particularly important.
A hand-centered approach can be beneficial for evaluating and designing input devices, especially multi-dimensional pointing devices.
This study shows that the orientation control can be totally integrated to the transportation control, and the transportation control is the critical path for task completion.
These features of hand prehension should be carefully considered for the input device design.
In a virtual environment design, the quality of visual presentation of a controller may not be as important as that of other graphic objects.
For example, if we want to design a 6DOF virtual hand, a stick-like hand may do the same job as a fully rendered hand with graphic skin, and be more cost effective.
Object transportation and orientation have a parallel, interdependent structure that can be fully understood only in the human visuomotor control system.
The structure of object transportation and orientation is generally independent of visual feedback conditions.
The object transportation process dominates the object orientation process.
The research on control structure for object manipulation provides an appropriate framework for HCI design.
Prehension movements - the visuomotor channels hypothesis revisited.
In Hand and Brain, ed.
Parallel, interdependent channels for location and orientation in sensorimotor transformations for reaching and grasping.
Frames of reference in sensorimotor integration - Position sense of the arm and hand, In Hand and Brain, ed.
Object manipulation in virtual environments: human bias, consistency and individual differences.
Extended In Abstracts of the Conference on Human Factors in Computing Systems CHI `97 /ACM, 349350.
Using hand position for virtual object placement.
Human performance evaluation of manipulation schemes in virtual environments.
The influence of muscle groups on performance of multiple degree-of-freedom input.
In Proceedings of the Conference on Human Factors in Computing Systems CHI `96 /ACM, 308-315.
