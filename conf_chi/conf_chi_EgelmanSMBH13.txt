Password meters tell users whether their passwords are "weak" or "strong."
We performed a laboratory experiment to examine whether these meters influenced users' password selections when they were forced to change their real passwords, and when they were not told that their passwords were the subject of a study.
We observed that the presence of meters yielded significantly stronger passwords.
We performed a followup field experiment to test a different scenario: creating a password for an unimportant account.
In this scenario, we found that the meters made no observable difference: participants simply reused weak passwords that they used to protect similar low-risk accounts.
We conclude that meters result in stronger passwords when users are forced to change existing passwords on "important" accounts and that individual meter design decisions likely have a marginal impact.
The implicit premise is that strong passwords are always desirable and that users who choose weak passwords do so because they are unaware that their passwords are weak; when made aware of weak passwords through a meter's feedback, there is an expectation that the user will choose a stronger password.
Despite their ubiquity, we are unaware of prior research examining the effectiveness of password meters in situ.
As we will show in this work, their results are not reliable predictors of meter effectiveness because they did not account for the varying contexts in which meters are shown .
In this paper we performed two experiments, one in the laboratory and one in the field.
We explored two different use cases: passwords used to protect sensitive accounts and passwords used to protect unimportant accounts.
Across both use cases, we tested two types of meters: the traditional "weak" versus "strong" meter, as well as a new type of password meter that we developed to show password strength relative to other users on the system.
Our contributions are as follows: * We measured the extent to which password strength meters influenced users' password choices when they used their real passwords and were not told that passwords were the subject of the study.
If we need that extra push over the cliff, you know what we do?...Eleven.
In fact, of Alexa's top 20 websites , fifteen  present users with meters during either password creation or changes.
To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
Despite attempts by many large sites to influence users with password strength meters, there has been very little study of them in the literature.
The extent to which they influence users' password selections is largely unknown.
We present an overview of prior research on password strength, password usability, and the use of soft paternalism to nudge users into making better decisions.
While flawed as a metric for absolute password strength, zero-order entropy is a reasonable metric for examining the effectiveness of password meters because it is the metric on which many meters currently base their feedback .
Thus, we study password meters as they currently are, rather than as one might want them to be.
That user-chosen passwords fall into predictable patterns has been well documented.
Morris and Thompson found that a large fraction of passwords on a Unix system were easily guessable .
Three decades later, Flor encio and Herley found that web users gravitate toward the weakest passwords allowed .
Several recent leaks of large password datasets have revealed that certain popular choices, such as "123456," are exceedingly common .
While much effort has been devoted to encouraging users to choose strong passwords, the concept of password strength remains surprisingly difficult to define.
The natural measures, such as Shannon entropy or guessing entropy require knowing the probability distribution of passwords.
Early efforts to quantify password strength resembled the measures of cryptographic strength: a password of length N , drawn from an alphabet of size C , would then have strength N log2 C bits.
NIST guidelines give a variation of this approach , where strength is a function only of length and character composition.
Passwordcracking tools, such as John The Ripper , make heavy use of word-lists and achieve success far in excess of what the NIST entropy predicts .
Some passwords that appear strong under the early entropy measures fall relatively quickly to cracking tools.
Probabilistic contextfree grammars are likely to surpass even the best wordlist based results .
While the concept of strength may be ill-defined, it appears clear that an ideal strength of a password would be an increasing function of the difficulty it presents to modern cracking tools.
Bonneau proposed a novel measure and showed that it is a good predictor of attacker success over a corpus of 70 million Yahoo!
Yet none of these metrics are well-suited to strength meters because they either cannot be computed in realtime or they require web browsers to download unfeasibly large tables of probabilities.
They used an N-gram Markov model to predict characters and built an adaptive strength-meter.
However, they did not validate their meter with real users, so the extent to which their new meter may influence user behavior is unknown.
Many sites try to prevent weak password choices by enforcing password composition policies, which can also make passwords harder to remember .
While the usability burden is high, numerous attempts to replace passwords have accomplished little.
In fact, Herley and van Oorschot argue that despite their shortcomings, passwords are unlikely to be supplanted soon .
The number of passwords that users must manage has increased, and thus usability has decreased.
Flor encio and Herley found that the average user has 25 passwordprotected accounts .
To cope with this burden, most users reuse passwords between accounts.
Surprisingly, there has been little systematic analysis of how strength can be achieved with minimal usability impact.
Their participants found the transition very annoying, but perceived that security had improved.
This correlates well with the anecdotal evidence that users find password composition policies particularly frustrating .
Thaler and Sunstein suggest that subtle encouragements, or nudges, can be effective at improving outcomes .
They posit that this is true for many economic and health problems, where mandates are difficult or undesirable, but poor user-choice can lead to bad effects.
Passwords certainly provide an example where broadcasting suggestions on choosing strong passwords has not been successful.
Indeed our work is in part inspired by the desire to determine whether a better usability-security tradeoff can be achieved by delivering a nudge in the form of password meter information about how a userchosen password compares to those of peers.
Some of these techniques have started to be applied to solving computer security problems.
For instance, Egelman et al.
They found that users' initial choices were often weak, but they accepted the modifications, which significantly improved the zero-order entropy.
Since the password is still derived from the original choice, they plausibly claim that the usability reduction is smaller than would be achieved by other approaches.
Most recently, Ur et al.
They examined 14 different meter designs and concluded that meters, regardless of specific design choices, resulted in significantly longer passwords over the control condition.
Because participants did not use their actual passwords and understood that passwords were the subject of the experiment, their results represent a theoretical upper bound; they studied meter efficacy, whereas we study meter effectiveness.
Thus, we are not aware that anyone has performed an ecologically valid study of password strength meters.
We performed a between-subjects laboratory experiment in the fall of 2011 to test the following hypotheses: H0 : Password are not stronger when meters are present.
H1 : Passwords are stronger when users see relative strength meters compared to no meters.
H2 : Passwords are stronger when users see relative strength meters compared to "traditional" meters.
Our experiment involved 47 participants who changed passwords protecting important accounts.
We examined how two different meters influenced password selection and memorability.
In this section we describe our methodology, present our results, and discuss some open questions that this experiment was unable to answer.
Our password meters used zero-order entropy as a metric for strength, calculated by the equation, N log2 C , where C is the character set size , and N is equal to the length of the password.
While this metric suffers from several limitations, the most serious of which is that character frequency is not considered, it is the metric upon which existing password strength meters are currently based .
Our interest was in examining whether users would choose longer passwords with more diverse character sets when presented with meters encouraging them to do so.
Therefore, zero-order entropy was entirely appropriate for quantifying relative differences between conditions.
We tested whether the meters yielded stronger passwords , not whether individual passwords were considered strong by themselves, which is why this metric fulfilled our needs.
Because we did not know the passwords of every user on the system we examined, we needed a way of calibrating the meters.
We used the RockYou dataset by removing all passwords that did not meet our system's enforced minimum requirements--eight characters including one letter and one digit--and then we examined the median zero-order entropy of the remaining passwords.
This median was then used to represent the "medium" level in the EM condition and the 50th percentile in the PPM condition.
In a pilot experiment  we observed that almost all participants' initial passwords were well above this median, which meant that they had no reason to change their passwords based on the meters' feedback .
Because of this, we artificially inflated our thresholds to yield the intervals shown in Table 1.
The goal of our first experiment was to evaluate two types of password strength meters .
One experimental condition featured a traditional meter that presented feedback in terms of whether the password was "weak," "medium," or "strong."
We called this the "existing motivator" condition .
Our second experimental condition framed the password in terms of social pressure by presenting strength relative to all of the other users on the system.
We called this the "peerpressure motivator" condition .
We randomly assigned participants to one of three between-subjects conditions: EM, PPM, or a control condition in which participants saw no password strength meter.
One concern when conducting security usability studies is that participants may not behave as they normally would if they are aware of the study's true purpose.
Specifically, security is a secondary task; most users do not sit down at the computer to "do security."
Thus, to maximize external validity, we ensured that partici-
We recruited 51 participants with flyers around campus, as well as messages to various departmental mailing lists.
Our only participation requirement was that participants had a university SSO account.
We compensated participants with $20 after completing the first session, and an additional $25 after completing the second session.
During the experiment, one participant did not feel comfortable changing his password on a shared computer, another could not remember his initial password, and two others' data was lost due to proxy server difficulties.
Thus, we were left with 47 participants in the initial session.
Participants' ages ranged from 18 to the 56 - 65 range, with a plurality of participants being in the 19 - 24 range.2 We observed no significant effects based on demographic factors and therefore do not discuss them further.
To satisfy these constraints, we limited participation to affiliates of the University of British Columbia, which maintains a single sign-on  system for use by students, faculty, and staff.
SSO accounts are used to perform tasks such as checking email, checking out books, viewing grades, and various other sensitive activities.
SSO accounts are also used to access a campus portal.
We told participants that we were studying the usability of this portal.
Participants logged in to the portal with their real passwords.
We routed traffic through a proxy server in order for us to collect data.
Upon successful login, the proxy server injected a dialog box informing them that a password expiration policy had taken effect and that they must change their passwords to proceed.
At this point, participants in the experimental conditions saw password meters.
Due to privacy concerns, we did not save participants' passwords, though we did save hashes of their original and changed passwords.
We also collected the Levenshtein edit distances between these two passwords, the zero-order entropies, lengths, and the number of symbols from each character class.
Participants actually changed their real passwords.
After changing their passwords, participants performed three subterfuge tasks that involved browsing the portal for information.
After each of these tasks, they answered questionnaires in order to further convince them that this was the true purpose of the study and that the password change was not a planned part of the experiment.
Upon completing all of the tasks, we compensated participants for their time.
We invited participants back to the laboratory two weeks later so that we could measure password memorability.
We informed participants that they would be completing a followup survey on the portal, which required that they login again.
We captured the same data with our proxy server as we did in the initial session.
In addition to observing whether they were able to login, we also observed whether or not they had changed their passwords during the interim.1 After this task, participants completed an exit survey that gathered qualitative data about their experiences.
Prior to changing their passwords, participants' password strength did not significantly differ between the conditions.
We performed Wilcoxon Signed Ranks tests to compare the bit strength of the previous and new passwords in each condition.
After changing their passwords, the bit strength of participants in the control condition did not change significantly; the new passwords were 49.3 bits strong .3 However, we did observe statistically significant differences in both the EM and PPM conditions.
Since this effect was not present among users in the control condition, it is clear that the meters were responsible for nudging users towards stronger passwords.
Figure 3 shows the feedback shown to participants in the experimental conditions.
We compared the changes in zero-order entropy between the three conditions using Mann-Whitney U tests.
We observed that when compared to the control condition, passwords created in both the EM condition  and the PPM condition  contained significantly more entropy.
However, there were no observable differences between our two experimental conditions .
Our results indicate that password meters--both traditional and those based on social pressure--can nudge users towards creating stronger passwords.
However, nudging users to create stronger passwords may have drawbacks if users cannot remember them or choose to revert to weaker passwords.
We measured whether our participants were still able to log in to their accounts two weeks after the experiment, as well as whether they had changed their passwords during the interim period.
Of our 47 participants, 40 re-authenticated and completed our exit survey.
Of these, 10  participants had since changed their passwords.4 A chi-square test indicated that participants who were exposed to meters were no more likely to change their passwords than those in the control condition.
Nine of the 10 participants who had subsequently changed their passwords reverted to their previous passwords.
Four of these participants indicated that they did not want to remember an additional password.
That is, their previous SSO password was used for other accounts, and as a result of our study, they needed to remember an additional password.
Another 4 participants indicated that they had forgotten their new password, whereas the ninth participant said he was uncomfortable changing his password on a shared computer and therefore reverted to his previous password.
Finally, the tenth participant who had changed his password indicated that he had done so because he had thought of an "even more secure" password.
The results of our exit survey indicate that while at least 19% of our participants reverted to their previous passwords, there is no evidence that this was because the meters nudged them into choosing overly burdensome passwords.
We did not examine the new passwords of participants in the control condition because their strength did not significantly change.
Likewise, the ways in which strength increased between the EM and PPM conditions did not observably differ.
Thus, we merged the two experimental conditions and performed a Wilcoxon Signed Ranks test to compare the characteristics listed in Table 2, between participants' previous and changed passwords.
We applied the Holm-Sidak correction and found that with meters, passwords changed in three statistically significant ways.
Thus, the meters motivated participants to create longer passwords through the inclusion of symbols and additional lowercase letters.
Participants in the control condition were just as likely to forget their new passwords or express frustration at the thought of having to remember yet another password.
We believe this finding is a greater indictment of the burden of password expiration policies than of meters.
Participants changed passwords for existing accounts.
It is unclear whether password meters have the same effect when users register new accounts.
Given the rates of password reuse that have been documented in the literature  and our exit survey , one might expect that many users will attempt to create an account with a reused password, rather than create a new password.
The extent to which meters may mitigate this behavior is unclear.
Participants in our experiment used their actual passwords.
As such, participants had clear incentives to choose very strong passwords--participants' original passwords were significantly stronger than the entropy of the bare minimum requirement, 43.6 bits .
It is unclear whether users would expend similar effort in creating passwords for accounts they consider less important.
We initially designed eight different experimental conditions to control for three different factors: meter orientation , meter meaning , and the choice between text and graphics to communicate that meaning.
Thus, our intended conditions were as follows: 1.
Control: No meter was displayed.
EM: A horizontal "weak" to "strong" meter, identical to the one in our laboratory experiment.
EM2: A vertical meter going from "weak" to "strong," but similar in area to the meter in the PPM condition.
PPM: A vertical meter depicting relative strength, identical to the one in our laboratory experiment.
EM2NoTxt: A vertical meter identical to the EM2 condition, but with all text removed .
EMNoBar: Words without graphics were displayed: "Your password is weak/medium/strong."
EMNoTxt: A horizontal meter identical to the EM condition, but with all text removed .
PPMNoBar: Words without graphics were displayed: "Your password is stronger than X% of other users."
We ran a pilot on 200 participants, randomly assigned to the eight conditions.
We observed no significant differences based on password entropy.
Upon performing a power analysis , we observed that we would need a sample size several orders of magnitude greater to yield significant differences between our latter four conditions.
Participants in the EM condition saw a horizontal meter that took up minimal space.
Participants in the PPM condition, however, saw a much larger vertical meter.
This meter may have been more prominent, increasing the likelihood that participants noticed it .
Thus, it is possible that the statistically insignificant difference between these two conditions was merely a lower bound, and that presenting a vertically oriented EM condition may produce a much larger effect size.
While the average entropy of passwords created under the PPM condition was greater than those created under the EM condition , this difference was not statistically significant.
It is possible that a much larger sample may have yielded statistically significant results.
Thus, we cannot say whether differences in effects may exist between these two meters.
Based on the open questions from our first experiment, we tested the following null hypotheses in the field: H0a : Passwords are not stronger when users see meters, when creating unimportant accounts.
H0b : Changes to the orientation and text of password meters will not result in different passwords.
The reason for this was that we wanted to observe the number of attempts participants would make when forced to recall their passwords.
Upon logging in, we informed them that they did not qualify for the beta test.
Finally, after a month had passed, we emailed participants to inform them that they had taken part in a study on passwords.5 We included a link to an exit survey and offered a $2 payment for successful completion.
We asked participants how they created the passwords used in this experiment, whether they used these passwords for other accounts, and how strong they believed these passwords were compared to their other passwords.
Thus, before accessing the survey, we asked them to login again to ensure that the password that was the subject of the survey was fresh in their minds.
Because the purpose of the login task was to prime participants, rather than re-examine password memorability, we allowed participants to receive forgotten passwords via email.
As a result, we removed the latter four conditions, and recruited participants for the first three experimental conditions  and the control condition.
Thus, we measured the effects of traditional password meters  and meters based on social navigation , while controlling for meter orientation .
We calibrated the meters with the entropy distribution found in the RockYou dataset .
We reasoned that the entropy distributions would be similar since they were collected without minimum requirements and neither account was likely considered "important."
As in our first experiment, we did not want participants to know we were studying passwords.
To accomplish this, we added an account creation page to a website being used for another, unrelated study.
In that study, participants visited the website of a fictitious startup that was beta testing an Android application in order to gather behavioral data on smartphone application pricing .
This website was privately registered and could not be linked with us or our institutions.
Participants in that other study had no reason to disbelieve our explanation.
For this study, we added a page to that website so participants could create accounts to register for a private beta.
This page featured password and password confirmation fields.
We did not list or enforce any minimum password requirements.
We randomly assigned participants to one of our four between-subjects conditions.
We collected usernames and passwords, as well as instrumented the page to record the amount of time it took each participant to type a password.
We intentionally did not tell participants when or if we would be contacting them again, because we did not want to bias them towards writing their passwords down or otherwise expending additional effort on remembering them; we wanted the registration and subsequent authentication tasks to be as realistic as possible in order to maximize ecological validity.
Two weeks after registering on our website, we sent each participant a message containing a link to a login page.
We explained that upon successfully logging in, they would receive a $0.50 bonus payment for their time, as well as see whether they qualified for the beta test.
We recruited participants using Amazon's Mechanical Turk.
Our only requirements were that participants be over 18 years of age and in the U.S. Because this experiment was run in conjunction with another experiment that was focused on Android users, all of our participants were also Android users.
A total of 541 participants created passwords in the first part of our experiment.
While we cannot identify the precise demographics of the subset of subjects who participated in this study, 61.3% of the 763 participants in the Android study were male, with an average age of 29  years .
When participants created passwords for unimportant accounts, we observed no effects that could be attributable to the presence of the meters.
This contrasted with our first experiment, in which participants who were shown meters chose significantly stronger passwords when changing the passwords for important accounts.
In this section, we present our results in terms of password strength, memorability, and our exit survey results.
Overall, participants' passwords had a median bit strength of 41.4 and were a median of 8 characters long.
We were concerned that data from participants who failed to subsequently login may skew our data, since we cannot know whether they forgot their passwords or did not take the task seriously.
For example, some participants may have entered gibberish if they never expected to login again.
We observed no significant differences with regard to the proportion of participants in each condition who either attempted or succeeded at logging in.
The 87 participants who gave up made a median of 3 attempts.
We observed no significant differences with regard to password strength between participants who were successful and those who were not; password strength was not correlated with memorability .
We were concerned that the use of browser-based password saving features may bias our results.
To check for this, we measured the amount of time participants spent typing their passwords.
We found evidence that only 3.2%  of participants used these features, and therefore they did not influence our results.
Thus, while the meters did not nudge participants into choosing significantly stronger passwords over those in the control condition, participants who viewed meters were no more likely to forget their passwords either.
Nonetheless, Table 4 depicts the median lengths, bit strengths, and sample sizes across the four conditions.
We observed no statistically significant differences with regard to strength metrics between the three experimental conditions and the control condition.
We hypothesize that this may be partially due to unexpectedly strong passwords across all of our conditions .
Two-thirds of our participants employed multiple character classes and relatively long lengths, despite the lack of minimum strength requirements.
In fact, only 33.3% of our 541 participants used a single character class  and only 24  participants created passwords that were shorter than six characters.
We performed Levene's Test for Equality of Variances to compare the entropy distributions between the control and the three experimental conditions.
Since the meters were updated in realtime as participants typed, we hypothesized that if the meters were noticed, participants may interrupt their typing, which could result in significantly longer password creation times.
Thus, our empirical data suggests that while participants noticed the meters, their resulting passwords were ultimately unaffected by them.
A primary goal in both of our experiments was to maximize ecological validity during the password creation and login phases by making these tasks required steps to complete larger subterfuge tasks.
Thus, up until this point, we did not reveal the true purpose of the experiment.
Based on the divergent results between our laboratory and field experiments, we ended the deception by inviting our field experiment participants to answer an exit survey regarding their password choices.
We ensured that participants knew the password about which we were asking by forcing them to login again, but allowed them to recover forgotten passwords by email.
Of our 331 participants who attempted to log in, 218 completed this survey.
Similar to our first experiment, we observed widespread password reuse among participants: 132  reported using their passwords elsewhere.6 Reuse rates did not significantly differ between the four conditions, indicating that the meters did not observably nudge participants towards creating new passwords.
We hypothesize that 63.8%  represents a lower bound, as some participants may not have admitted that they knowingly engaged in poor security practices.
Nonetheless, we observed several significant correlations that corroborate password reuse.
For instance, participants who reused passwords were likely to spend less time typing passwords during the first phase of this experiment .
Participants who claimed to reuse passwords were more likely to remember them during the second phase , and less likely to use the password recovery feature to access the exit survey .
Two weeks after participants created passwords, we asked them to return to our website.
This required logging in, though no password recovery or reset mechanism was available.
We examined whether any of the conditions significantly differed with regard to password memorability.
Table 4 depicts the number of participants who attempted to login, those successful, and the median number of attempts it took them.
Not only did participants reuse existing passwords, but they knowingly reused weak ones.
We asked participants to rate the strength of their password relative to their other passwords using a 5-point Likert scale .
Only 37 participants  responded that their study passwords were either "stronger" or "much stronger" than their other passwords.
Likewise, a Wilcoxon Signed Ranks test indicated that participants' observed experimental passwords were significantly shorter than their self-reported longest passwords .
However, we found that reused passwords were not observably weaker than the passwords of those who claimed not to have reused passwords.
Thus, the extent to which password reuse impacts strength remains unclear.
We believe that effects stemming from participants' perceptions about the unimportance of the website outweighed any effects relating to the meters or their choice to reuse existing passwords; when passwords were reused, weaker existing passwords were employed.
Others acknowledged that if meters were shown, they would have labeled their passwords as weak: * "I'm sure it would have said it was weak."
Thus, the results of our field experiment suggest that when password meters are shown when creating new accounts on websites that users consider unimportant, the meters are unlikely to influence password strength.
As with any study, ecological validity is hard to ensure.
While we made a concerted effort in both experiments to mask our primary interest in participants' passwords, we cannot be absolutely sure that no participants saw past the deception.
That said, we observed no evidence that our results were due to the Hawthorne effect; if subjects created stronger passwords solely because they believed that was what we wanted, we would not have observed significant differences between conditions in the laboratory .
In both experiments, majorities of participants reported reusing passwords: 55% in the laboratory and 63.8% in the field.
Only when laboratory participants were forced to change their passwords while viewing meters did they choose stronger passwords .
It is unclear whether the meters impacted password reuse behaviors.
For instance, it is possible that when creating a new password for a high-risk account, users may still reuse a password, but may be nudged into reusing one of their stronger existing passwords.
One interpretation of our results is that presenting a password meter at the time of registration is too late, because users already know which of their existing passwords they plan to reuse.
However, significant improvement is achieved when users are creating new passwords.
This suggests that password meters not associated with account registration pages  might have considerable influence.
The minority of users who seek out such feedback are probably far more amenable to influence than the average user .
Some motivation for password meters seems guided by the belief that users do not understand when their passwords are weak.
The results of our study draw this belief into question.
We found that, in many cases, participants knowingly chose weak passwords.
At least in the case of unimportant accounts, they demonstrated an understanding that the password they used was not merely being reused, but also weak.
Weakness was not a problem of which they were unaware, but one of which they were aware but insufficiently motivated to fix.
Our main contribution is in showing how password creation behaviors are heavily dependent on context.
Some may be quick to charge this as obvious; while our results may not be very counter-intuitive, we point out that they suggest that current practice at many major websites then defies the obvious.
For example, one of our findings is that password meters do not yield much improvement in helping users choose passwords for unimportant accounts, yet they are very commonly deployed in such contexts.
Equally, where meters make a difference-- password changes for important accounts--they are less often seen.
Thus, practice at real sites appears to be very far from what our results dictate.
This indicates a real opportunity for improvement.
We tested the impact of two variables on password meter effectiveness: creating a new account vs. changing the password on an existing account, and doing so on important vs. unimportant accounts.
Because we only performed two experiments, rather than the four needed to exhaust the space, we do not know the extent to which each variable independently influenced behavior.
Likewise, because each experiment was performed at differ-
J. Yan and A. Blackwell and R. Anderson and A.
Password Memorability and Security: Empirical Results.
Komanduri, S., Shay, R., Kelley, P. G., Mazurek, M. L., Bauer, L., Christin, N., Cranor, L. F., and Egelman, S. Of Passwords and People: Measuring the Effect of Password-Composition Policies.
In CHI '11: Proceeding of the 29th SIGCHI Conference on Human Factors in Computing Systems, ACM Press .
Kuo, C., Romanosky, S., and Cranor, L. Human selection of mnemonic phrase-based passwords.
In Proceedings of the second symposium on Usable privacy and security, ACM , 67-78.
R. Morris and K. Thompson.
Password Security: A Case History.
Schechter, S., Herley, C., and Mitzenmacher, M. Popularity is everything: A new approach to protecting passwords from statistical-guessing attacks.
Shay, R., Komanduri, S., Kelley, P. G., Leon, P. G., Mazurek, M. L., Bauer, L., Christin, N., and Cranor, L. F. Encountering stronger password requirements: user attitudes and behaviors.
Influencing users password choice through peer pressure.
Master's thesis, University of British Columbia, 2011.
Thaler, R., and Sunstein, C. Nudge: Improving decisions about health, wealth, and happiness.
Yale University Press, New Haven and London, 2008.
In Proceedings of the 21st USENIX Security Symposium .
Weir, M., Aggarwal, S., Collins, M., and Stern, H. Testing metrics for password creation policies by attacking large sets of revealed passwords.
Password cracking using probabilistic context-free grammars.
Users are not the enemy.
Alexa Internet, Inc. Alexa top 500 global sites.
Besmer, A., Watson, J., and Lipford, H. R. The impact of social navigation on privacy policy configuration.
In Proceedings of the Sixth Symposium on Usable Privacy and Security, ACM .
The science of guessing: analyzing an anonymized corpus of 70 million passwords.
Castelluccia, C., Duermuth, M., and Perito, D. Adaptive password-strength meters from markov models.
In Proceedings of the Network & Distributed System Security Symposium , San Diego, CA .
The Way I See It: When security gets in the way.
Password strength: An empirical analysis.
Egelman, S., Felt, A. P., and Wagner, D. Choice architecture and smartphone privacy: There's a price for that.
In The 2012 Workshop on the Economics of Information Security  .
Egelman, S., Molnar, D., Christin, N., Acquisti, A., Herley, C., and Krishnamurthi, S. Please continue to hold: An empirical study on user tolerance of security delays.
In Proceedings  of the 9th Workshop on Economics of Information Security .
Flor encio, D., and Herley, C. A large-scale study of web password habits.
Forget, A., Chiasson, S., Van Oorschot, P., and Biddle, R. Improving text passwords through persuasion.
In Proceedings of the 4th symposium on Usable privacy and security, ACM , 1-12.
Herley, C., and van Oorschot, P. C. A research agenda acknowledging the persistence of passwords.
